Introduction
Everyone by nature desires to know.
Aristotle, Metaphysics A1 980a21 (modernized)

1 Knowing and Acting
Knowledge and action are the central relations between mind and world. In action, world is adapted to mind. In knowledge, mind is adapted to world. When world is maladapted to mind, there is a residue of desire. When mind is maladapted to world, there is a residue of belief. Desire aspires to action; belief aspires to knowledge. The point of desire is action; the point of belief is knowledge.
Those slogans are not platitudes—unless platitudes can be generally contested. According to many philosophers, desire aspires only to satisfaction, and belief only to truth. Action is a systematic way to satisfied desire, and knowledge to true belief, but desires can also be satisfied and beliefs true by chance. There is satisfied desire without action and true belief without knowledge.
Why ask for more? Satisfaction and truth already constitute the required match between mind and world, with the appropriate directions of fit. Of course, we sometimes desire to act; those desires are satisfied only if there is action. We sometimes believe ourselves to know; those beliefs are true only if there is knowledge. But such cases are special; our desires and beliefs frequently concern states of the world of which actions and beliefs are not themselves constituents.
Although desires can be satisfied as well by chance as by action, that is no reason to marginalize the category of action in the understanding of mind. The place of desire in the economy of mental life depends on its potential connection with action. Similarly, although beliefs can be true as well by chance as by knowledge, that is no reason to marginalize the category of knowledge in the understanding of mind. This book develops a conception on which the place of belief in the economy of mental life depends on its potential connection with knowledge.
The foregoing vague phrases will later be partially replaced by something more precise. But that is not the purpose of this introduction, which is painted with a broad brush. Its aim is to give the reader a rough overall picture in which the layout of the main parts is visible. Subsequent chapters fill in details in the parts. Even they will amount to nothing like a proof that the picture is correct. Epistemological theories are not usually susceptible of proof. This book shows how to understand cognitive phenomena on the basis of some simple but generally overlooked ideas. The reader will judge those ideas by their fruit.
2 Unanalysable Knowledge
Contemporary accounts of mind tend to marginalize the category of knowledge, sometimes not mentioning it at all; they certainly make it less central than the category of action. As a reverse counterpart of the output from mind to world in action, they admit the input from world to mind in perception. The latter is a more restricted category than knowledge; it excludes the products of memory and conscious inference. Perception is the reverse counterpart of action if both are single episodes of causal interaction with the environment. But acting, in the sense of intentionally making something the case, includes far more complex and mediated adaptations of world to mind over extended periods. The reverse counterpart of action in that sense is knowledge. It includes far more complex and mediated adaptations of mind to world over extended periods than perception does.
On contemporary accounts of mind, the general category for states with the mind-to-world direction of fit is belief. The belief is true if it fits the world, false otherwise. Although true and false belief are the same mental state in different worlds, the place of belief in the economy of mental life depends on its potential connection with truth. Knowledge is merely a peculiar kind of true belief. Since Gettier showed that even justified true belief is insufficient for knowledge, epistemologists have expended vast efforts attempting to state exactly what kind of true belief knowledge is, but that programme is assigned no significance for the philosophy of mind. On such a view, knowledge is to be explained in terms of belief, and belief is what matters for the understanding of mind. The converse attempt to explain belief in terms of knowledge sounds eccentric and perverse. To summarize this orthodoxy: belief is conceptually prior to knowledge.
The orthodox claim is frequently taken for granted, rarely supported by argument. Why should we suppose that belief is conceptually prior to knowledge? One argument is that since knowledge entails belief but not vice versa, the entailment should be explained by the assumption that we conceptualize knowledge as the conjunction of belief with whatever must in fact be added to belief to yield knowledge—truth and other more elusive features. The conjuncts are conceptually prior to the conjunction. Given that knowledge entails belief, it is trivial that one knows p if and only if (1) one believes p; (2) p is true; and (3) if one believes p and p is true, then one knows p. But that equivalence is useless for establishing that belief is conceptually prior to knowledge, for it is circular: 'know' occurs in (3).
The received idea is that we can conceptualize the factors whose conjunction with belief is necessary and sufficient for knowledge independently of knowledge; we can think of the former without already thinking of the latter, even implicitly. But the argument does not show that such independent conceptualization is possible, for a necessary but insufficient condition need not be a conjunct of a non-circular necessary and sufficient condition. Although being coloured is a necessary but insufficient condition for being red, we cannot state a necessary and sufficient condition for being red by conjoining being coloured with other properties specified without reference to red. Neither the equation 'Red = coloured + X' nor the equation 'Knowledge = true belief + X' need have a non-circular solution.
Thus belief can be a necessary but insufficient condition of knowledge even if we do not implicitly conceptualize knowledge as the conjunction of belief with that which must be added to belief to yield knowledge. Perhaps the inference from knowledge to belief derives from a conceptualization of belief in terms of knowledge rather than from a conceptualization of knowledge in terms of belief. If believing p is conceptualized as being in a state sufficiently like knowing p 'from the inside' in the relevant respects, then belief is necessary for knowledge, since knowing p is sufficiently like itself in every respect, even though knowledge is conceptually prior to belief. Indeed, the inference from knowledge to belief does not even require knowledge and belief to be conceptually ordered. We might master 'know' and 'believe' independently, from examples, and then realize on that basis that believing is necessary but insufficient for knowing, just as we might master the terms 'red' and 'scarlet' independently, from examples, and then realize on that basis that being red is necessary but insufficient for being scarlet. That belief is necessary but insufficient for knowledge does not show that belief is conceptually prior to knowledge. The orthodox claim would require a deeper defence.
Some epistemologists defend the conceptual priority of belief over knowledge by citing their favoured analyses of knowledge in terms of belief. Just what kind of conceptual priority such an analysis might support would depend on its status: for instance, on whether it was analytic or knowable a priori in some sense. But those issues become notional when, as usually happens, a counterexample is found to show that the proposed condition is not even necessary and sufficient for knowledge. Other analyses are circular rather than false; if someone insists that knowledge is justified true belief on an understanding of
'justified' strong enough to exclude Gettier cases but weak enough to include everyday empirical knowledge, the problem is likely to be that no standard of justification is supplied independent of knowledge itself. This book makes no attempt to survey even the most salient analyses of knowledge proposed in recent decades and the counterexamples to which they succumb; many other authors have already done that adequately. It will be assumed, not quite uncontroversially, that the upshot of that debate is that no currently available analysis of knowledge in terms of belief is adequate (not all parts of the book depend on that assumption). Consequently, the supposed conceptual priority of knowledge over belief is not to be defended by appeal to a particular analysis of knowledge in terms of belief.
A more cautious argument for the conceptual priority of belief over knowledge is that, even if all currently available analyses of knowledge in terms of belief are circular or fall to counterexamples, some of them are sufficiently good approximations to indicate strongly that a further refinement on similar lines will eventually succeed. But the possibility of approximating one concept with others is not good evidence that the former can be analysed in terms of the latter. For instance, to a very good approximation, x is a parent of y if and only if x is an ancestor of y and x is not an ancestor of an ancestor of y. The only counterexamples are recherché cases of incest: if a father incestuously begets a son on his daughter, the father is an ancestor of an ancestor of his son.
But no more refined definition of parenthood in terms of ancestry alone avoids the problem. Since the father and the mother of his daughter are symmetrically related to the daughter and son in terms of ancestry but not in terms of parenthood, parenthood cannot be defined in terms of ancestry without extra conceptual resources. Moreover, the approximate definition of parenthood in terms of ancestry plays no significant role in our understanding of 'parent'. We can approximate a circle as closely as we like with sufficiently many sufficiently small triangles; it does not follow that we should think of the circle as made up out of triangles. The possibility of approximating knowledge in terms of belief and other concepts is not good evidence for the conceptual priority of belief over knowledge (section 1.3). Section 1.4 shows how one might characterize knowledge without reference to belief. Section 1.5 briefly discusses how one might characterize belief by reference to knowledge.
A chief aim of this book is to develop a rigorous way of doing epistemology in which knowledge is central, and not subordinate to belief. It enables us to abandon the attempt to state necessary and sufficient conditions for knowledge in terms of belief without abandoning epistemology itself. Indeed, by abandoning that fruitless search we can gain insight into epistemological problems, because we are freed to use the notion of knowledge as an instrument of understanding in ways that its subordination to belief would not permit (see, in particular, Chapter
9).
3 Factive Mental States
The idea that belief is conceptually prior to knowledge has another source: the internalist conception of mind, and world external to mind, as two independent variables. Belief is simply a function of the mind variable. Truth is simply a function of the external world variable, at least when the given proposition is about the external world. For the internalist, knowledge is a function of the two variables, not of either one alone; whether one knows that it is raining does not depend solely on one's mental state, a state which is the same for those who perceive the rain and those who hallucinate it, but it also does not depend solely on the state of the weather, a state which is the same for those who believe the appearances and those who doubt them. The internalist therefore conceives knowledge as a complex hybrid crying out for analysis into its internal and external components, of which belief and truth respectively are the most salient. The analysis is expected on general metaphysical grounds.
Recent developments in the philosophy of mind have called the metaphysics of internalism into question by indicating ways in which the content of a mental state can constitutively depend on the environment. I believe that tigers growl; an exact physical replica of me lacks that belief if his contact has been not with tigers but with schmigers, beasts of a similar appearance belonging to a different species; his belief is that schmigers growl. Some internalists conclude that not even belief as attributed in ordinary language is simply a function of mind, and try in theory to isolate a core of purely mental states. Such attempts have not succeeded. Rather, we may conceive mind and external world as dependent variables, and reject the metaphysics that led us to expect analysis into purely internal and purely external components. On this view, belief as attributed in ordinary language is a genuine mental state constitutively dependent on the external world.
If the content of a mental state can depend on the external world, so can the attitude to that content. Knowledge is one such attitude. One's knowledge that it is raining depends on the weather; it does not follow that knowing that it is raining is not a mental state. The natural assumption is that sentences of the form 'S knows p' attribute mental states just as sentences of the forms 'S believes p'
and 'S desires p' do. Chapters 1 and 2 defend such an externalist conception of knowing as a state of mind. In particular, section 2.3 refutes internalist attempts to isolate a non-factive state as the purely mental component of knowing.
What is at stake is much more than whether we apply the word 'mental' to knowing. If we could isolate a core of states which constituted 'pure mind' by being mental in some more thoroughgoing way than knowing is, then the term 'mental' might be extended to knowing as a mere courtesy title. On the conception defended here, there is no such core of mental states exclusive of knowing. If we want to illustrate the nature of mentality, knowing is as good an example as believing. The philosophy of mind cannot afford to neglect knowing, for that state is part of its core subject matter. For similar reasons, other truth-entailing attitudes such as perceiving and remembering that something is the case may also be classified as mental states. Knowing can be understood as the most general of such truth-entailing mental states (section 1.4).
Sceptics and their fellow-travellers characteristically suppose that the truth-values of one's beliefs can vary independently of those beliefs and of all one's other mental states: one's total mental state is exactly the same in a sufficiently radical sceptical scenario as it is in a commonsense scenario, yet most of one's beliefs about the external world are true in the common-sense scenario and false in the sceptical scenario. But if knowing is itself a mental state, that supposition is tantamount to the sceptical conclusion that in the common-sense scenario one's beliefs do not constitute knowledge, even though they are true. For, since false beliefs never constitute knowledge, one certainly does not know in the sceptical scenario; the supposition that one is in exactly the same mental state in the two scenarios therefore implies that one does not know in the common-sense scenario either, given that knowing makes a difference to one's total mental state
(section 1.2). The anti-sceptic should not accept the supposition. Any mental life in the sceptical scenario is of a radically impoverished kind. Of course it does not feel impoverished 'from the inside', but that failure of self-knowledge is part of the impoverishment.
If action is the reverse counterpart of knowledge, and knowing is a mental state, should we expect acting to be a mental state too? If so, we might compare the sceptic's denial that we know about the external world to the denial that we act on the external world (perhaps made by those who believe that free will is both an illusion and a precondition of genuine action). But the analogy between knowledge and action is not perfect. Acting is by definition no state of any kind; it is dynamic, not static. Moreover, while knowing that the door is shut may be a mental state, shutting the door is surely not a mental action. Only actions such as inferring are naturally classified as mental. Similar asymmetries arise if we pursue the more restricted analogy between action and perception, for instance, between breaking the window and seeing that the window is broken. One starts seeing that the window is broken after the light rays reach one's retina; we do not make the apparently symmetric claim that one finishes breaking the window before the stone leaves one's hand. Why do we conceptualize the input and output sides so differently? The answer may lie in our tendency to individuate by origins. Effects depend on their causes in a way in which causes do not depend on their effects. Thus early stages in the process leading from a cause in the environment to a perceptual experience typically do not depend on the perceiver's involvement, whereas even late stages in the process leading from an intention to an effect on the environment do depend on the agent's involvement. Thus we naturally group both early and late stages of the output process into something attributable to the agent, while grouping only late stages of the input process into something attributable to the perceiver (this notion of grouping is intended to be neutral between different theories of the ontology of action). We treat early stages of the input process merely as preconditions for what we attribute to the perceiver. We extend this scheme to cases of knowledge and action with a more complex causal structure. Since late stages of the output process which occur without need of continued mental involvement are grouped into the action, we are reluctant to conceive it as mental. By contrast, since early stages of the input process are not grouped into the perception or knowledge, there is no corresponding block to conceiving it as mental.
Knowledge and action are related in another way. We expect genuine mental states to occur significantly in causal explanations of action, for otherwise postulating them looks redundant. Thus if knowing is a genuine mental state, it should occur significantly in such explanations. But many philosophers assume that attributions of knowledge in causal explanations of action can be replaced without explanatory loss by the corresponding attributions of belief. Section 2.4 and, in more depth,
Chapter 3 undermine that assumption. Action typically involves complex interaction with the environment; one needs continual feedback to bring it to a successful conclusion. For example, writing a book involves reading during the process. Attributions of knowledge often explain the success of these interactions better than do the corresponding attributions of belief, even of true belief. One's belief in a proposition p is more robust to evidence if one knows p than if one merely believes p truly; one is less likely to lose belief in p in the course of interacting with the environment by discovering new evidence which lowers the probability of p.
Thus one is more likely to complete an extended action that depends on a continuing belief in p if at the start one knows p rather than merely believes p truly. One is better placed to write a mathematical paper if one knows the truth of Goldbach's Conjecture than if one merely believes the conjecture and it is true. The point is not answered by an analysis of actions into series of basic actions, for the causal explanations even of basic actions often cite mental states at a temporal distance. One deliberates, forms an intention and then executes it later or abandons it in the light of new developments. The gap between deliberating and completing the action allows differences between knowledge and mere true belief in the basis of the deliberation to manifest themselves in action. If the causal explanation of the action cited only mental states immediately preceding the action, it would omit those on which the deliberation was based, and thereby miss the rationality of the action. These considerations can be generalized from attributions of knowledge to attributions of mental content involving reference to the environment; they all play distinctive roles in the causal explanation of temporally distant actions. Chapter 3 uses such considerations to argue that an externalist mental state normally cannot be decomposed as the conjunction of purely internal and purely external components.
4 Knowledge as the Justification of Belief and Assertion
The idea that belief is conceptually prior to knowledge easily leads to the idea that evidence and justification are conceptually prior to knowledge too. Although that is most vivid in the traditional definition of knowledge as justified true belief, Gettier's counterexamples to that definition did not remove the idea that the concept of justification or evidence would occur with the concept of belief in a more complex analysis of the concept of knowledge. Consequently, the concept of knowledge was assumed to be unavailable for use in an elucidation of the concept of justification or evidence, on pain of circularity. Once we cease to assume that belief is conceptually prior to knowledge, we can experiment with using the concept of knowledge to elucidate the concepts of justification and evidence.
Chapter 9 makes the experiment. It argues that one's total evidence is simply one's total knowledge. Thus a hypothesis is inconsistent with the evidence if and only if it is inconsistent with known truths; it is a good explanation of the evidence if and only if it is a good explanation of known truths. One's evidence justifies belief in the hypothesis if and only if one's knowledge justifies that belief. Knowledge figures in the account primarily as what justifies, not as what gets justified. Knowledge can justify a belief which is not itself knowledge, for the justification relation is not deductive. For example, I may be justified in believing that someone is a murderer by knowing that he emerged stealthily with a bloody knife from the room in which the body was subsequently discovered, even if he is in fact innocent and I therefore do not know that he is a murderer.
The equation of one's evidence with one's knowledge does not imply any particular theory of how a given body of propositional evidence justifies a given belief. Rather, it connects absolute and relative justification. A belief is justified relative to some other beliefs from which it has been derived in some appropriate way (perhaps by deduction), but it is not justified absolutely unless those other beliefs are justified absolutely. Where does the regress end? On the assumption that it ends at evidence, the equation of evidence with knowledge implies that one's belief is justified absolutely if and only if it is justified relative to one's knowledge. The regress of justification ends at knowledge.
The account might be thought to make all knowledge self-justifying in an absurdly trivial way: one's knowledge is justified absolutely if and only if it is justified relative to itself. This objection would be fair if the point of justification were to serve at its best as a condition for knowledge. But on the present account that is not the point of justification. Rather, justification is primarily a status which knowledge can confer on beliefs that look good in its light without themselves amounting to knowledge. Knowledge itself enjoys the status of justification only as a limiting case, just as, trivially, every shade of green counts as similar to a shade of green.
The objector might still point out that non-trivial questions appear to arise about the justification and evidence for much of our knowledge, especially that which is mediated by theory.
We miss the specificity of these questions if we treat them merely as general questions about how we know. Nevertheless, they can be understood as non-trivial on the present approach. For even if one knows p, one can call that knowledge into question, provisionally treat p as though it did not belong to the body of one's knowledge, and then assess p relative to the rest of one's knowledge—one's independent evidence. Non-trivial issues of evidence and justification will then arise for p. This procedure is a good test of some kinds of supposed knowledge, especially those mediated by theory. In such cases, given the purported manner of knowing p, one knows p only if the rest of one's knowledge justifies p. But the test is not universal; it yields poor results if too much of one's knowledge is simultaneously called into question, for then one may easily have that knowledge even if removing it from the body of one's knowledge leaves too little to justify it. Some sceptics go wrong by applying the test in such cases.
The consideration of reduced bodies of evidence serves a different purpose. It enables us to isolate the contribution of specific pieces of evidence to the justification of specific hypotheses by comparing the status of those hypotheses relative to the total body of evidence with their status relative to the result of removing the piece of evidence in question from the total body of evidence
This point is related to a form of the so-called problem of old evidence.
Chapter 10 develops these ideas in a more technical direction, by combining them with a theory of evidential probability in a modified objective Bayesian framework (some readers may prefer to skip this chapter). The evidential probability of a hypothesis for one is its probability conditional on one's total evidence; given the equation of one's evidence with one's knowledge, that is its probability conditional on one's total knowledge. Thus knowledge automatically receives evidential probability 1. Even so, knowledge is not treated as indefeasible evidence, for one can lose as well as gain knowledge. Thus the future evidential probability for me of my present knowledge may be less than 1. Together, Chapters 9 and 10 illustrate a way of doing epistemology on which knowledge is taken as the starting point, the unexplained explainer, yet some degree of rigour is maintained.
Chapter 11 extends the approach to the philosophy of language, with an account of the speech act of assertion. In a natural way we can regard assertion as the verbal counterpart of judgement and judgement as the occurrent form of belief. If one assumes that belief is conceptually prior to knowledge, one will therefore expect an account of assertion not to use the concept of knowledge. It might instead use the concepts of truth and justified belief, perhaps independently of each other. But if belief is not conceptually prior to knowledge, and knowledge is what justifies belief, then knowledge should play a key role in an account of assertion. On the proposal made in Chapter 11, the fundamental rule of assertion is that one should assert p only if one knows p. Although that knowledge rule might appear to be derivable from the truth rule that one should assert p only if p is true, by the consideration that in asserting p one does not know that one is conforming to the truth rule unless one is in fact conforming to the knowledge rule, the attempted derivation fails because it predicts the wrong epistemology for some examples. Even more incorrect predictions issue from an account of assertion based on the justification rule that one should assert p only if one is justified in believing p. The concept of knowledge is needed to capture our practice of assertion.
Given the combined conclusions of Chapters 9 and 11, the propositions which one is permitted to assert outright are exactly those which constitute one's evidence. More speculatively, we may project the account of assertion back onto its mental counterpart, judgement (or belief). What results is the rule that one should judge (or believe p) only if one knows p. That would make some sense of the claim that belief aims at knowledge. It also harmonizes with the account of evidence: to believe p without knowing p is to exceed one's evidence. Although we may have qualms about applying the notion of a rule to mental acts in addition to speech acts, the idea that belief is governed by a norm of knowledge is at least as intelligible as the idea that it is governed by a norm of truth.
5 The Myth of Epistemic Transparency
An account has been sketched of knowledge as a mental state which constitutes the evidential standard for assertion and belief. The several components of the account face a common epistemological objection. It starts from the observation that one is not always in a position to know whether one knows something. If one knows p, it does not follow that one is in a position to know that one knows p (section 5.1); if one does not know p, it does not follow that one is in a position to know that one does not know p (section 8.2). In both cases, the conclusion fails to follow even if we add the extra premise that one is wondering whether one knows p; the problem is not confined to subjects who are unconscious, lack the concept of knowledge, or the like. In the simplest examples, one does not know and is not in a position to know that one does not know p. Sometimes p is false, so one does not know p, even though systematically misleading appearances place one in a state which feels just like knowing p 'from the inside', so one is not in a position to know that one does not know p.
One falsely but justifiably believes oneself to know p. Examples in which one knows without being in a position to know that one knows will be discussed later. Why are these limitations on one's ability to know whether one knows supposed to threaten the foregoing account of knowledge?
Consider first the thesis that knowing is a mental state. We are often said to have special access to our own mental states, so that we can know without observation what mental states we are in. If S is a mental state only if one is always in a position to know whether one is in S (at least when one is in a position to wonder whether one is in S), then knowing is not a mental state.
A similar objection applies to the equation of evidence with knowledge. Rationality requires one to conform one's beliefs to one's evidence. Rationality cannot require one to do the impossible.
But how can one conform one's beliefs to one's evidence unless one is in a position to know what it is? If one is always in a position to know what one's evidence is, then one's evidence is not one's knowledge.
Since one is not always in a position to know whether one knows p, one is not always in a position to know whether in asserting p one is complying with the rule 'Assert only what you know'.
In particular, one may fail to meet the knowledge condition even though it feels 'from the inside'
just as though one met the condition. A violation of the knowledge rule in such circumstances may look blameless. How can a speech act be governed by a rule that one can blamelessly violate? If one is always in a position to know whether one's assertions comply with the rule for assertion, then the rule is not 'Assert only what you know'.
If the first objection is sound, then every mental state has the property that one is in a position to know whether one is in it (the qualification 'whenever one is in a position to wonder whether one is in it' will henceforth often be left tacit). If the second and third objections are also sound, then mental states are qualified by their possession of that property to be both evidence and the standard for assertion, at least in respect of accessibility. Indeed, it is unclear how anything other than a mental state could be accessible in the required way (we may exclude trivial states which one is always or never in). For suppose that one is always in a position to know whether a condition C obtains. Consider an ordinary case α in which one might be and a sceptical counterpart
α* of α. In α*, one is not in α but appears to oneself to be in α and for all one knows one is in α. If C
obtains in α, then for all one knows in α* one is in a situation in which C obtains; thus if C does not obtain in α*, one is not in a position to know in α* whether C obtains, contrary to hypothesis; therefore C obtains in α*. By a parallel argument, if C does not obtain in α then
C does not obtain in α*. Thus C obtains in α if and only if C obtains in α*. C is insensitive to the difference between ordinary cases and their sceptical counterparts. Mental states are the only obvious candidates for exhibiting such insensitivity.
We have also uncovered another temptation to scepticism, for if we combine the argument of the previous paragraph with the principle that one is always in a position to know what one's evidence is, the upshot is that one has exactly the same evidence in an ordinary case and its sceptical counterpart. How, then, can one know which case one is in?
The three objections assume that some non-trivial states meet the accessibility requirement; one is always in a position to know whether one is in them. Chapter 4 challenges that assumption. It provides a general form of argument, applicable to almost any condition, to undermine the claim that one is always in a position to know whether it obtains. More specifically, with rather trivial exceptions it undermines the claim that the condition is luminous, in the sense that whenever it obtains (and one is in a position to wonder whether it does), one is in a position to know that it obtains. The main idea behind the argument against luminosity is that our powers of discrimination are limited. If we are in a case α, and a case α ′ is close enough to α, then for all we know we are in
α ′. Thus what we are in a position to know in α is still true in α ′. Consequently, a luminous condition obtains in α only if it also obtains in α ′, for it obtains in α only if we are in a position to know that it obtains in α. In other words, a luminous condition obtains in any case close enough to cases in which it obtains. What counts as close enough depends on our powers of discrimination.
Since they are finite, a luminous condition spreads uncontrollably through conceptual space, overflowing all boundaries. It obtains everywhere or nowhere, at least where we are in a position to wonder whether it obtains. For almost any condition of interest, the cases in which it obtains are linked by a series of imperceptible gradations to cases in which it does not obtain, where at every step we are in a position to wonder whether it obtains. The condition is therefore not luminous. The full version of the argument cashes out those spatial metaphors in epistemic terms, to ensure that they do not import unwarranted presuppositions. In particular, the full version is formulated in a way which does not presuppose perfect sharpness in the boundary between the cases in which the condition obtains and the cases in which it does not. The upshot of the argument is that the gap between what is true and what we are in a position to know is not a special feature restricted to some problematic areas of discourse; it is normal throughout discourse. Some may doubt the applicability of the argument against luminosity to mental states, on the grounds that it relies on a model of discrimination between independently constituted items, whereas one's mental states and one's judgements about them are held to be constitutively interdependent. But no such interdependence makes one's judgements about one's present mental states infallible. For instance, if my guru tells me that I shall feel intense pain at midnight and I am sufficiently gullible, I may judge at midnight that I am feeling intense pain; it does not follow that I
am feeling intense pain. Of course, I may be in a position to know that I do not feel intense pain; my failure may be to actualize that potential. But the example still shows a gap between judgement and truth, even if smaller than elsewhere, which the argument can use as the thin end of a wedge against luminosity. The full version proceeds by analysis of the gradually varying degrees of confidence with which one judges, in a way applicable to judgements about mental states.
For virtually no mental state S is the condition that one is in S luminous. The condition that one is not in S is equally non-luminous. For example, one can love someone without being in a position to know that one loves them, and one can fail to love someone without being in a position to know that one fails to love them. One can want something without being in a position to know that one wants it, and one can fail to want something without being in a position to know that one fails to want it. Granted that knowing is a mental state, one should therefore not be surprised that one can fail to know something without being in a position to know that one fails to know it.
Indeed, one can argue independently against luminosity for many mental states. They involve patterns of causal connections; sometimes one makes a judgement about one's present state which one is subsequently forced to retract, because one's intervening behaviour was in tension with the self-attributed pattern. One's judgements may be subject to systematic distortion. One's selfattributions of mental states are sometimes too unreliable to constitute knowledge. Mental states incompatible with one's self-image may be concealed from one. The difference between remembering an incident in one's early childhood and imagining it is a difference in mental state, but it is also one about which it is easy to be wrong.
None of this is to deny that in favourable cases one can know without observation whether one is in a given mental state. But knowledge meets that condition. You may know without observation whether you know that it rained two days ago, just as you may know without observation whether you believe that it rained two days ago. If you know that it rained two days ago, that knowledge (and belief) may result from past observations, but no further observations were needed to know that you know (and believe). Of course, subsequent observations indicating that it did not rain two days ago undermine the self-attribution of past knowledge that it rained two days ago without undermining the selfattribution of past belief that it rained two days ago. But if a judgement can be undermined by reasons of some kind, it does not follow that it was made on the basis of other reasons of the same kind. I can know without further observation that I know p even though observation can falsify a claim to know p.
Our extensive but not unlimited ability to know without further observation whether we know something is what enables us to use knowledge as evidence. It constitutes an extensive but not unlimited ability to know without further acquisition of evidence whether something is part of our present evidence. To complain that we are not always in a position to know whether we know something is to bankrupt the notion of evidence, for only luminous conditions meet that more stringent constraint, and luminous conditions are trivial. Although the constraint might drive us to suppose that one's evidence consists of appearances to oneself, the discrimination argument shows that not even the condition that things appear to one in a given way is luminous. For example, one may appear to oneself to be seeing a red patch even though one is not in a position to know that one appears to oneself to be seeing a red patch. Once the standard for the epistemic accessibility of evidence is set at an attainable level, knowledge meets the standard.
Chapter 8 traces the way in which excessive demands on the accessibility of evidence invite scepticism by diminishing evidence to an imaginary phenomenal substratum. If we presume to know too much about our evidence, we find ourselves knowing too little about the external world.
The best argument for supposing that we have no more evidence in ordinary cases than in their sceptical counterparts trades on the false premise that the condition for being evidence is luminous.
Since sceptics have not refuted the equation of evidence with knowledge, they are not entitled to assume that we have no more evidence in ordinary cases than in their sceptical counterparts, for on the view against which they are attempting to argue we do have more knowledge in ordinary cases than in their sceptical counterparts.
Since rationality requires one to conform one's beliefs to one's evidence, and one is not always in a position to know what one's evidence is, we need a conception of rationality on which we are not always in a position to know what it demands. Indeed, the anti-luminosity argument takes us more directly to the conclusion that one may be rationally required to do something even though one is not in a position to know that one is rationally required to do it. If we imagine that some candidate criterion of rationality is perfectly accessible, then we are always likely to prefer that criterion; but once we recognize that perfect accessibility is quite generally an unattainable ideal, we can learn to live with an imperfectly accessible criterion.
We have nothing else to live with. Provided that one's evidence is more accessible than the truthvalues of the hypotheses under investigation, the former can still serve as a useful guide to the latter. Real life is messy. Section 10.6 explores some unexpected implications of imperfect accessibility for decision theory. Imperfect accessibility has ethical implications too; we are not always in a position to know our duty.
For the same reason, one should expect not always to be in a position to know whether in asserting p one conforms to the rule of assertion. That the account of assertion based on the rule
'Assert only what you know' has that consequence is therefore no objection. An account based on the rule 'Assert only what you rationally believe' would have the same consequence. Our practice of assertion is workable because we often enough know whether we know something.
The imperfect accessibility of rationality casts light on the external individuation of mental content, mentioned earlier. For rationality has some relation to deductive logic, although the relation is not easy to spell out, and the external individuation of content makes the deductive validity of inferences imperfectly accessible. Whether the inference from 'It is hot here' and 'It is wet here' to 'It is hot and wet somewhere' is valid in a given context depends on whether the two occurrences of
'here' have the same content in that context. Someone who accepts the premises and rejects the conclusion avoids inconsistency only if the argument is invalid. If the content of 'here' is determined at least in part by the environment, one may not be in a position to know whether the inference is valid. Similarly, whether the inference from 'Everything changes' to 'Bourbaki changes' is valid depends on whether 'Bourbaki' has a content. If the content of 'Bourbaki' (if any) is determined at least in part by the environment, then one may not be in a position to know whether the inference is valid. These examples are only indicative; the argument from external individuation to imperfect accessibility is much less straightforward if the externally individuated content of a term is not identified with its referent. Nevertheless, if we accept on independent grounds that one is not always in a position to know what rationality demands, we should not object to an account that individuates content externally just on the grounds that it makes validity imperfectly accessible. Chapter 5 articulates the constraints on knowledge implicit in the argument against luminosity. Where one has only a limited capacity to discriminate between cases in which p is true and cases in which p is false, knowledge requires a margin for error: cases in which one is in a position to know p must not be too close to cases in which p is false, otherwise one's belief in p in the former cases would lack a sufficiently reliable basis to constitute knowledge. The kind and degree of closeness in question depend on the specific limitations of one's powers of discrimination in that context. Thus the area of conceptual space in which one is in a position to know p is separated from the surrounding area in which p is false by a border zone in which p is true but one is not in a position to know p. The implications of the model are explored for iterated knowledge. In particular, one has only a limited capacity to discriminate between cases in which one knows p and cases in which one does not know p, so one can know p without being in a position to know that one knows p. Further iterations of knowledge are even harder to achieve. Naturally, one has an even more limited capacity to discriminate between cases in which others know p and cases in which they do not know p, so it is even harder to achieve iterations of shared knowledge ('We all know that we all know that we all know . . . p'), and a fortiori to achieve the infinitely many levels of iteration required for common knowledge. Chapter 6 uses this difficulty to account for the Paradox of the Unexpected Examination and some paradoxical arguments in game theory which assume that it is common knowledge amongst the players that they are all rational.
Because we need margins for error, it is implicit in our practice of assertion that truth outruns warranted assertion. We are warranted in asserting p only if we know p; we know p only if p is true in nearby cases. To interpret our assertions as warranted, we must interpret their content as true in some cases in which we are not warranted in asserting it. Our ignorance is a precondition of our knowledge. Contrary to anti-realist theories, the gap between assertibility and truth is built into even the simplest kinds of assertion.
Chapter 7 exploits margins for error in another direction. Sometimes one knows p by believing p and leaving a large margin for error even though, if p were false, one would still believe p. For one's judgement concerning p may be almost completely accurate but subject to a very slight distortion: when p is false but very close to being true, one falsely believes p. Since one's belief in p leaves a wide margin for error, it would have been false only if things had been very different; it may well be that if p had been false, it would still have been very close to being true. For example, if someone is very much less than two metres tall, I may know by sight that she is less than two metres tall, even though, if she were not less than two metres tall, she would be only very slightly more than two metres tall, and I would falsely judge her by sight to be less than two metres tall. Such cases falsify accounts of knowledge on which a necessary condition for knowing p is that if p were false one would not believe p. Sophisticated modifications of such accounts are refuted by cases in which the distortion in judgement is slight but ubiquitous. This result bears on some sceptical arguments, for we can take p to be the proposition that I am not in a sceptical scenario α. If p were false I would be in α and (by construction of α) would believe that I was not in α, but that does not justify the sceptical claim 'I do not know that I am not in α', for the counterfactual condition is not necessary for knowledge.
Although it can still be insisted that a necessary condition for knowing p is that if p were false one would not believe p on the very same evidence, that counterfactual does not justify the sceptical claim, for the sceptic has not shown that one would have the very same evidence in the sceptical scenario. Given the account in chapter 9, in a sceptical scenario one's evidence is so radically impoverished that one is not in a position to know that it is impoverished at all.
Margins for error constitute a kind of epistemic friction. For some purposes it is useful to idealize them away in thought experiments, but a world in which there were no margins for error would be as different from our world as would a world in which there was no friction. We have no more reason to postulate that there really is a kind of knowledge of temporal matters without margins for error than we have to postulate that somewhere in space there really is a frictionless plane.
6 Unknowable Truths
When knowing p requires a margin for error, the cases in which p is known are separated from the cases in which p is false by a buffer zone, a protective belt of cases in which p is true but unknown. That belt has the peculiarity that one cannot know that one is in it. For to know that would be to know that p is true and unknown; but knowing that involves knowing that p is true
(since knowing a conjunction involves knowing its conjuncts); then p is not unknown, so it is not true that p is true and unknown, so it is not known that p is true and unknown (since only truths are known). Thus it is impossible to know that p is true but unknown. When p is in the protective belt, that is an unknowable truth. The limits on knowledge in question are of a stronger kind than anything established by the anti-luminosity argument of Chapter 4. A proposition requires a margin for error precisely so that it can be known; the point of the anti-luminosity argument is just that the cases in which p is available to be known do not exhaust the cases in which p is true. By contrast, the point about the conjunctive proposition that p is true and unknown is that, in virtue of its structure, it is not available to be known in any case whatsoever. The argument for this conclusion was first published by Fitch in
1963. Contrapositively, he showed that all truths are knowable only if all truths are known. This is sometimes known as the Paradox of Knowability, although why it should be thought to constitute a paradox is unclear. It is the topic of Chapter 12.
Attempts have been made to take the sting out of Fitch's argument. Although you cannot know today the conjunction that p is true and you do not know p today, you can know the conjunction that p is true and you did not know p yesterday, and you can know the conjunction that p is true and I do not know p today. Thus one might distinguish a context in which Fitch's conjunction is true from a context in which its truth in the former context is known. The immediate response is to generalize the second conjunct, as in 'p is true and no one ever knows p'. Fitch's argument shows that no one can ever know the conjunction that p and no one ever knows p. Many truths are never known by anyone. For example, either it is true that I had an even number of books in my office exactly a year ago or it is true that I had an odd number of books in my room exactly a year ago; no one will ever know which, because they were not counted at the time and it is now too late to find out. Nevertheless, one might try to distinguish a possible world w in which the conjunction (that p is true and no one ever knows p) is true from a possible world w* in which the truth of the conjunction in w is known. The trouble with this move is that it promises only trivial knowledge. We specify merely possible worlds by description; in w* we can describe a world as one in which p is true, and thereby know that p is true in such a world, but that is hardly a notable achievement. Section 12.5 argues that this knowledge of other possible worlds does not significantly relax the limits on knowability that Fitch's argument identifies.
Section 12.2 discusses a more direct challenge. Fitch's argument uses the distribution principle that knowledge of a conjunction implies knowledge of its conjuncts. Although the principle sounds compelling, a few accounts of knowledge are inconsistent with it. Probably that indicates something wrong with those accounts. As a precaution, ways are explored of modifying
Fitch's argument to avoid relying on the distribution principle. Limits on knowledge have counterparts in limits on action. On at least one interpretation, the relation between an agent and a proposition of making true shares the formal features of knowing needed for Fitch's argument: it distributes over conjunction (one makes a conjunction true only if one makes its conjuncts true) and is factive (if one makes something true then it is true). Thus no one can ever make this conjunction true: p and no one ever makes p true. For if one makes the conjunction true, one makes the first conjunct true, so the second conjunct is false, so the conjunction is false, so one did not make it true after all. If some truths were not made true by anyone, then some truths could not have been made true by anyone. Much of the world is outside both our control and our ken. We should find the limits on our knowledge scarcely more surprising than the limits on our action. Although knowledge and action are central to mind, mind is not central to world. 1 A State of Mind
1.1 Factive Attitudes
Knowing is a state of mind. That claim is central to the account of knowledge developed in this book. But what does it mean?
A state of a mind is a mental state of a subject. Paradigmatic mental states include love, hate, pleasure, and pain. Moreover, they include attitudes to propositions: believing that something is so, conceiving that it is so, hoping or fearing that it is so, wondering whether it is so, intending or desiring it to be so. One can also know that something is so. This book concerns such propositional knowledge. If p is a proposition, we will understand knowing p not as merely being acquainted with p but as knowing that something is so, something that is so if and only if p is true. For example, if p is the proposition that it is cold, then one is acquainted with p in merely wondering whether it is cold; to know p is to know that it is cold. Knowing in that sense is a factive attitude; one knows p only if p is true, although one can be acquainted with the proposition p even if it is false. Other factive attitudes include perceiving that something is so, remembering that it is so, and regretting that is so. If attitudes are relations of subjects to propositions, then the claim is that knowing itself is a mental relation such that, for every proposition p, having that relation to p is a mental state. Thus for some mental state S, being in S is necessary and sufficient for knowing p. We abbreviate that claim by saying that knowing is a mental state.
We may assume initially that knowing p entails believing p; section 1.5 considers that assumption in more depth. Someone might expect knowing to be a state of mind simply on the grounds that knowing p involves the paradigmatic mental state of believing p. If those grounds were adequate, the claim that knowing is a state of mind would be banal. However, those grounds imply only that there is a mental state being in which is necessary for knowing p. By contrast, the claim that knowing is a state of mind is to be understood as the claim that there is a mental state being in which is necessary and sufficient for knowing p. In short, knowing is merely a state of mind. This claim may be unexpected. On the standard view, believing is merely a state of mind but knowing is not, because it is factive: truth is a non-mental component of knowing.
Our initial presumption should be that knowing is a mental state. Prior to philosophical theory-building, we learn the concept of the mental by examples. Our paradigms should include propositional attitudes such as believing and desiring, if our conception of the mental is not to be radically impoverished. But factive attitudes have so many similarities to the non-factive attitudes that we should expect them to constitute mental states too; we expect a concept to apply to whatever sufficiently resembles its paradigms. It would be strange if there were a mental state of fearing but no mental state of regretting, or a mental state of imagining but no mental state of remembering.
Indeed, it is not clear that there are any pretheoretic grounds for omitting factive attitudes from the list of paradigmatic mental states. That the mental includes knowing and other factive attitudes is built into the natural understanding of the procedure by which the concept of the mental is acquired.
Of course, that does not exclude the subsequent discovery of theoretical reasons for drawing the line between the mental and the non-mental somewhere else. But the theory behind those reasons had better be a good one.
This chapter and the next eliminate some putative differences between knowing and nonfactive attitudes that might be thought to disqualify knowing as a mental state. The supposed disqualifications concern constitutive dependence on the environment, first-person accessibility, and causal efficacy. In each case, the differences dissolve on inspection. Naturally, this form of argument cannot provide conclusive proof. We survey the current candidates and find them wanting. We can still wonder whether our list of potential differences is complete. But without good theoretical reasons to demote knowing from its pretheoretical status as a central case of a mental state, demotion is surrender to mere special pleading. Indeed, conceptions on which knowing is the wrong kind of state to count as mental are objectionable on independent grounds. We can best understand knowing by classifying it with other mental phenomena.
In this chapter, section 1.2 orients the claim that knowing is a mental state with respect to some traditional issues about scepticism and self-knowledge. Section 1.3 explains an incompatibility between the view of knowing as a factive mental state and standard analyses of the concept knows as a conjunction of the concepts believes and true (predicated of the proposition) and of other concepts; it blames the analyses. Section 1.4 presents a modest positive account of the concept knows, distinguishes it from analyses of the traditional kind, and indicates the possibility of understanding epistemology in terms of the metaphysics of states. Section 1.5 discusses the relation between knowing and believing, and explores some implications for so-called disjunctive accounts of mental states.1
1.2 Mental States, First-Person Accessibility, and Scepticism
The conception of knowing as a mental state can look like a confusion between objective and subjective certainty. Someone might even diagnose that conception as Descartes' central mistake. Did he not seek a mental state sufficient for knowing p? Was not clearly and distinctly conceiving p his candidate? And does not the failure of his epistemological programme manifest the impossibility of a mental state of the required kind?
On the view to be developed here, if Descartes sought a mental state sufficient for knowing, his mistake lay elsewhere: perhaps in the view (if he held it) that one must always be in a position to know what mental state one is in. H. A. Prichard, who also took knowing to be a mental state, held that one is always in a position to know whether one knows or merely believes (Prichard 1950: 86).
Few would now claim such powers of discrimination. Indeed, one cause of denials that knowing is a mental state may be the assumption that one must always be in a position to know whether one is in a given mental state.
One is surely not always in a position to know whether one knows p (for almost any proposition p), however alert and conceptually sophisticated one is. The point is most vivid when the subject believes p falsely. Consider, for example, the situation of a generally well-informed citizen N.N. who has not yet heard the news from the theatre where Lincoln has just been assassinated. Since Lincoln is dead, he is no longer President, so N.N. no longer knows that Lincoln is President (knowing is factive). However, N.N. is in no position to know that anything is amiss.
He continues reasonably to believe that Lincoln is President; moreover, this seems to him to be just another item of general knowledge. N.N. continues reasonably to believe that he knows that Lincoln is President. Although N.N. does not know that Lincoln is President, he is in no position to know that he does not know that Lincoln is President (see also Hintikka 1962: 106 and section 8.2). The argument as stated assumes that no a priori reasoning demonstrates that it is impossible to have knowledge about the external world, for such reasoning would make it unreasonable for
N.N. to believe that he knows that Lincoln is President. Of course, if all knowledge is impossible then, for any proposition p whatsoever, one does not know p and is not in a position to know that one fails to know p; one is never in a position to know whether one knows p. A sceptic about the external world who is not a sceptic about everything might attempt to maintain that, for any informative proposition p about the external world, one is in a position to know that one does not know p. Let us assume for the time being that such a sceptic is wrong. Chapter 8 will reconsider scepticism.
We can also construct cases in which one knows p without being in a position to know that one knows p (see Chapter 5). They involve more delicate issues. It is enough for present purposes that one can fail to know p without being in a position to know that one fails to know p.
Let transparency be the thesis that for every mental state S, whenever one is suitably alert and conceptually sophisticated, one is in a position to know whether one is in S. Given transparency, knowing p is not a mental state, for almost any proposition p.
Transparency is false, however, and demonstrably so by reference to uncontentiously paradigmatic mental states. For example, one is sometimes in no position to know whether one is in the mental state of hoping p. I believe that I do not hope for a particular result to a match; I am conscious of nothing but indifference; then my disappointment at one outcome reveals my hope for another. When I had that hope, I was in no position to know that I had it. Indeed, it is hard to find a non-trivial mental state for which transparency holds. It fails for the state of believing p, for the difference between believing p and merely fancying p depends in part on one's dispositions to practical reasoning and action manifested only in counterfactual circumstances, and one is not always in a position to know what those dispositions are. Transparency is even doubtful for the state of being in pain; with too much self-pity one may mistake an itch for a pain, with too little one may mistake a pain for an itch. A form of argument will be developed in Chapter 4 to show that no nontrivial mental state satisfies transparency. But even if transparency does hold for a few mental states, it clearly fails for others; the premise of the argument from transparency to the denial that knowing p is a mental state is false. Given that knowing p is a mental state, we will not expect knowing whether one is in it to be always easy.
It does not follow that there is no asymmetry at all between knowledge of one's own mental states and knowledge of the mental states of others. Perhaps failures of transparency could not be the normal case, although that claim would require extensive argument. A more plausible claim is that we have some non-observational knowledge of our own mental states and not of the mental states of others. But then the same may be said of knowing: we have some non-observational knowledge of our own knowledge and ignorance and not of the knowledge and ignorance of others. Any genuine requirement of privileged access on mental states is met by the state of knowing p. Knowing is characteristically open to firstperson present-tense access; like other mental states, it is not perfectly open.
Some may object that knowing whether one knows p requires evaluating reasons for and against p in a way in which knowing whether one believes p does not. They distinguish knowing whether one currently believes p from deciding whether to continue believing p. Suppose for a moment that they are correct in taking knowing whether one believes p not to require one to evaluate reasons for and against p. Still, even on their view there is also the mental state of rationally believing p, on some appropriate concept of rationality. Knowing whether one rationally believes p does require one to evaluate reasons for and against p. Thus the need for such evaluation in order to know whether one knows p does not show that knowing p is not a mental state.
Could it be replied that knowing and rationally believing are not mental states in the way that believing is, because 'know' and 'rational' are normative terms? Belief attributions have a normative element too, for to have any mental attitude to a content one must in some sense grasp that content, and therefore have some minimal ability to deal rationally with it; the reply itself classifies 'rational' as a normative term. In any sense in which 'know' and 'rational' are normative terms, ascriptions of mental states can be normative.
A different objection is that one's belief about whether one knows p is defeasible by new information in a way in which one's belief about whether one believes p is not. For example, the new information might show that p is false. But is one's belief about whether one believes p really indefeasible by new information? Someone might believe that he believes that the world will end next year, because he has joined a religious sect in which there is strong pressure to believe that the world will end next year, but his unwillingness to cash in his pension may suggest that he does not really believe that the world will end next year. When he reflects on his unwillingness to cash in his pension, he may come to that conclusion himself. But even if we forget such examples and suppose that one's belief about whether one believes p is not defeasible by further evidence, we must still acknowledge mental states such as being alert or thinking clearly about a problem. One's belief about whether one is alert or thinking clearly about a problem is defeasible by new information, for example about what drugs had been slipped into one's drink. Thus the defeasibility of beliefs about whether one knows p does not show that knowing p is not a mental state.
Once we consider the full variety of acknowledged mental states, it is clear that any general requirements of privileged access on mental states are very mild. Knowing satisfies those mild requirements.
The failure of transparency helps to clarify the relation between the thesis that knowing is a mental state and a traditional pattern of sceptical argument. The sceptic argues that a subject with a true belief could have been in exactly the same mental state (that is, in the same total set of mental states) even if the belief had been false. He concludes that, since the belief fails to constitute knowledge in the latter case, it fails equally to do so in the former. The sceptical argument assumes something like this: if one's mental state is exactly the same in two situations, then one's knowledge is also the same. On the account to be developed here, that assumption is correct, although not quite in the way that the sceptic imagines.
The sceptic supposes that a difference in knowledge would require some prior difference in mental state, which the subject could detect. On the present account, a difference in knowledge would constitute a difference in mental state. This difference need not be detectable by the subject who lacks knowledge. Thus the sceptic's assumption is correct for reasons that undermine his argument. He claims to have constructed a case in which the belief is false although the mental state is exactly the same. But the most that he has really shown about the case is that the belief is false and one's situation is not discriminably different. He has not shown that one cannot be in different mental states in indiscriminable situations. Indeed, since we are sometimes in no position to know whether we are in a given mental state, as argued above, surely one can be in different mental states in situations between which one cannot discriminate (see Chapter 8 and McDowell 1982). If knowing is a mental state, then the sceptical argument is not compelling. Indeed, such a view of knowledge need only be defensible for the sceptical argument not to be compelling. Thus one route into scepticism is blocked. It is not the purpose of this chapter to argue that all are.
Chapter 8 will consider sceptical reasoning more carefully.
If someone has already taken the route into scepticism offered by that fallacious argument, before it was blocked, and has become genuinely undecided, at least in principle, as to whether she is in a sceptical scenario, then the blocking of the route now comes too late to rescue her. Nothing said here should convince someone who has given up ordinary beliefs that they did in fact constitute knowledge, for nothing said here should convince her that they are true. The trick is never to give them up. This is the usual case with philosophical treatments of scepticism: they are better at prevention than at cure. If a refutation of scepticism is supposed to reason one out of the hole, then scepticism is irrefutable. The most to be hoped for is something which will prevent the sceptic (who may be oneself) from reasoning one into the hole in the first place.
The purpose of these remarks has been to give a feel for the view that knowing is a state of mind. The content of the view must now be examined more explicitly. The notion of a mental state will not be formally defined, for that would require a formal definition of the mental. Rather, reflection on the intuitive notion of a mental state will help to clarify its workings. Section 1.4 will provide a less informal account.
1.3 Knowledge and Analysis
To call knowing a mental state is to assimilate it, in a certain respect, to paradigmatic mental states such as believing, desiring, and being in pain. It is also to contrast it with various nonexamples of mental states. Perhaps the most revealing contrast is between knowing and believing truly.
Believing p truly is not a mental state, at least, not when p is an ordinary contingent proposition about the external environment. Intuitively, for example, there is no mental state being in which is necessary and sufficient for believing truly that it is raining (that is, for believing while it is raining that it is raining), just as there is no mental state being in which is necessary and sufficient for believing while Rome burns that it is raining. There is a mental state of believing that it is raining, and there is—on the present account—a mental state of knowing that it is raining, but there is no intermediate mental state of believing truly that it is raining. Let S 1 be knowing that it is raining, S 2 be believing truly that it is raining, and S 3 be believing that it is raining. Then, we may assume, necessarily, everything that is in S 1 is in S 2 ; necessarily, everything that is in S2 is in S 3 .
Nevertheless, on the present account, although S 1 and S 3 are mental states, S 2 is not a mental state.
That something sandwiched between two mental states need not itself be a mental state is not as paradoxical as it may sound. Consider an analogy: the notion of a geometrical property. For these purposes, we can understand geometrical properties to be properties possessed by particulars in physical space. Let π1 be the property of being an equilateral triangle, π2 the property of being a triangle whose sides are indiscriminable in length to the naked human eye, and
π3 the property of being a triangle. Necessarily, everything that has π1 has π2, because lines of the same length cannot be discriminated in length; necessarily, everything that has π2 has π3.
Nevertheless, although π1 and π3 are geometrical properties, π2 is not a geometrical property, because it varies with variations in human eyesight. Something sandwiched between two geometrical properties need not itself be a geometrical property. Similarly, there is no structural reason why something sandwiched between two mental states should itself be a mental state.
The point is general. If S is a mental state and C a non-mental condition, there need be no mental state S* such that, necessarily, one is in S* if and only if one is in S and C obtains. The nonexistence of such an S* is quite consistent with the existence of a mental state S** such that, necessarily, one is in S** only if (but not: if) one is in S and C is met. A mental state can guarantee that conjunction only by guaranteeing more than that conjunction.
If the denial that believing truly is a mental state does not immediately convince, think of it this way. Even if believing truly is a mental state in some liberal sense of the latter term, there is also a more restrictive but still reasonable sense in which believing truly is not a mental state but the combination of a mental state with a non-mental condition. The present claim is that knowing is a mental state in every reasonable sense of that term: there is no more restrictive but still reasonable sense of 'mental' in which knowing can be factored, like believing truly, into a combination of mental states with non-mental conditions. A sense of 'mental' is reasonable if it is sufficiently close to an ordinary sense of the word in important respects. Although the present claim is therefore vague, it is at least clear enough to be disputed.
Strictly speaking, we must distinguish a conceptual and a metaphysical contrast. The conceptual contrast is that the concept knows is a mental concept while the concept believes truly is not a mental concept. The metaphysical contrast is that knowing is a mental state while believing truly is not a mental state.
The concept mental state can at least roughly be defined in terms of the concept mental concept of a state: a state is mental if and only if there could be a mental concept of that state. This definition does not in principle exclude the possibility of a non-mental concept of a mental state, for different concepts can be of the same state. We may reasonably assume that states S 1 and S 2 are identical if and only if necessarily everything is in S 1 if and only if it is in S 2 . In a given context, distinct concepts may be necessarily coextensive. For example, since gold is necessarily the element with atomic number 79, the state of having a tooth made of gold is the state of having a tooth made of the element with atomic number 79, but the concept has a tooth made of gold is not the concept has a tooth made of the element with atomic number 79. Similarly, for any mental state S, the concept is in S and such that gold is the element with atomic number 79 is necessarily coextensive with the concept is in S, so they are both concepts of S.
Of the conceptual and metaphysical contrasts, neither immediately entails the other. If the concept knows is mental while the concept believes truly is not, then it follows immediately that knowing is a mental state, but it does not follow immediately that believing truly is not a mental state, for perhaps there could also be a mental concept of the state of believing truly. Thus the conceptual contrast does not immediately entail the metaphysical contrast. If knowing is a mental state and believing truly is not a mental state, then it follows immediately that the concept believes truly is not mental, but it does not follow immediately that the concept knows is mental, for perhaps there could be a different concept of the state of knowing which was mental. Thus the metaphysical contrast does not immediately entail the conceptual contrast. Nevertheless, it is hard to see why someone should accept one contrast without accepting the other. If the concept believes truly is nonmental, its imagined necessary coextensiveness with a mental concept would be a bizarre metaphysical coincidence. If the concept knows were a non-mental concept of a mental state, its necessary coextensiveness with a mental concept would be an equally bizarre metaphysical coincidence. In practice, sloppily ignoring the distinction between the metaphysical and conceptual contrasts is unlikely to do very much harm. Nevertheless, it is safer not to ignore the distinction.
The concept believes truly is not a mental concept of a state. If the concept C is the conjunction of the concepts C 1 , . . . , C n , then C is mental if and only if each C i is mental. For example, the conjunctive concept is sad and such that gold is the element with atomic number 79 is non-mental, simply because it has the non-mental conjunct is such that gold is the element with atomic number 79, although it is a concept of the state of sadness. Even a logically redundant nonmental component concept would make C a non-mental concept, although it would then be logically equivalent to a mental concept. By contrast, non-mental concepts in the content clause of an attitude ascription do not make the concept expressed non-mental; the concept believes that there are numbers can be mental even if the concept number is not. At least, all that is so in a reasonable sense of 'mental', which one might express as 'purely mental'. Now the concept believed truly is the conjunction of the concepts believed and true.
The conjunct true is not mental, for it makes no reference to a subject. Therefore, the concept believed truly is non-mental. Similarly, the concept believes truly of subjects rather than propositions is non-mental. The metaphysical and conceptual contrasts turn on whether knowing is a mental state, and on whether knows is a mental concept.
Just as the concept believes truly is non-mental, so for a similar reason is the concept has a justified true belief. Indeed, such an argument applies to any of the concepts with which the concept knows is equated by conjunctive analyses of the standard kind. The argument can be generalized to analyses formed using logical connectives other than conjunction. It would not apply if those simpler concepts were all mental, but analyses of the concept knows of the standard kind always involve irredundant non-mental constituents, in particular the concept true. Consequently, the analysing concept is non-mental: that is, not purely mental. Given that the concept knows is mental, every analysis of it of the standard kind is therefore incorrect as a claim of concept identity, for the analysing concept is distinct from the concept to be analysed.
If a non-mental concept were necessarily coextensive with the mental concept knows, they would be concepts of the same mental state. The present account does not strictly entail that no analysis of the traditional kind provides correct necessary and sufficient conditions for knowing.
But once we accept that the concept knows is not a complex concept of the kind traditionally envisaged, what reason have we to expect any such complex concept even to provide necessary and sufficient conditions for knowing?
Experience confirms inductively what the present account implies, that no analysis of the concept knows of the standard kind is correct. Indeed, the candidate concepts turn out to be not merely distinct from, but not even necessarily coextensive with, the target concept. Since Gettier refuted the traditional analysis of knows as has a justified true belief in 1963, a succession of increasingly complex analyses have been overturned by increasingly complex counterexamples, which is just what the present view would have led one to expect.2
Even if some sufficiently complex analysis never succumbed to counterexamples, that would not entail the identity of the analysing concept with the concept knows. Indeed, the equation of the concepts might well lead to more puzzlement rather than less. For knowing matters; the difference between knowing and not knowing is very important to us. Even unsophisticated curiosity is a desire to know. This importance would be hard to understand if the concept knows were the more or less ad hoc sprawl that analyses have had to become; why should we care so much about that?3
On quite general grounds, one would not expect the concept knows to have a non-trivial analysis in somehow more basic terms. Not all concepts have such analyses, on pain of infinite regress; the history of analytic philosophy suggests that those of most philosophical interest do not.
'Bachelor' is a peculiarity, not a prototype. Attempts to analyse the concepts means and causes, for example, have been no more successful than attempts to analyse the concept knows, succumbing to the same pattern of counterexamples and epicycles. The analysing concept does not merely fail to be the same as the concept to be analysed; it fails even to provide a necessary and sufficient condition for the latter. The pursuit of analyses is a degenerating research programme.4
We can easily describe simple languages in which no necessary and sufficient condition for knowing can be expressed without circularity. Many fragments of English have that property. Why should we expect English itself to be different? Once 'know' and cognate terms have been removed, what remains of our lexicon may be too impoverished to frame necessary and sufficient conditions for knowing. The programme of analysis had its origin in great philosophical visions. Consider, for example, Russell's Principle of Acquaintance: 'Every proposition which we can understand must be composed wholly of constituents with which we are acquainted' (Russell 1910-11, at Salmon and Soames 1988: 23). Russell calls the principle 'the fundamental epistemological principle in the analysis of propositions containing descriptions'. There may well be a reading on which it is correct. However, when the principle is combined with Russell's extremely intimate conception of acquaintance, it forces analysis to go deeper than the surface constituents of the evidently intelligible propositions of science and common sense, for our acquaintance with those surface constituents is not perfectly intimate.5 In such a context, the programme of analysis has a philosophical point. Now the philosophical visions which gave it a point are no longer serious options. Yet philosophers continued to pursue the programme long after the original motivation had gone. Correct deep analyses would doubtless still be interesting if they existed; what has gone is the reason to believe that they do exist.
While the general point is conceded, it might nevertheless be claimed that we have special reason to expect an analysis of knows. For we already have the necessary condition that what is known be true, and perhaps also believed; we might expect to reach a necessary and sufficient condition by adding whatever knowing has which believing truly may lack. But that expectation is based on a fallacy. If G is necessary for F, there need be no further condition H, specifiable independently of F, such that the conjunction of G and H is necessary and sufficient for F. Being coloured, for example, is necessary for being red, but if one seeks a further condition whose conjunction with being coloured is necessary and sufficient for being red, one finds only conditions specified in terms of 'red': being red; being red if coloured.
There are other examples of the same phenomenon. Although x is a parent of y only if x is an ancestor of y, it does not follow that we implicitly conceptualize parenthood as the conjunction of ancestry with whatever must be added to ancestry to yield parenthood, or even that ancestry is conceptually prior to parenthood. Rather, x is an ancestor of y if and only if a chain of parenthood runs from x to y (more formally: if and only if x belongs to every class containing all parents of y and all parents of its members). Thus parents of y are automatically ancestors of y. If anything, parenthood is conceptually prior to ancestry; we use the necessary and sufficient condition for ancestry in terms of parenthood 6
to explain why ancestry is necessary for parenthood. Again, x is identical with y only if x weighs no more than y, but it does not follow that the concept is identical with is the conjunction of weighs no more than with whatever must be added to it to yield the former concept, or even that weighs no more than is prior to is identical with. In this case we explain the entailment by Leibniz's
Law: if x is identical with y, whatever holds of x holds of y too, so since x weighs no more than x, x weighs no more than y. We grasp Leibniz's Law without considering all its instances. In principle one could grasp it before having acquired any concept of weight. Necessary conditions need not be conjuncts of necessary and sufficient conditions in any non-trivial sense.
More generally, the existence of conceptual connections is a bad reason to postulate an analysis of a concept to explain them. For example, the axiom of extensionality says that sets with the same members are identical; it has as good a claim to conceptual truth as the proposition that knowledge entails belief. Nevertheless, the axiom is not explained by an analysis of the concept set, if an analysis provides a non-circular statement of necessary and sufficient conditions.
The working hypothesis should be that the concept knows cannot be analysed into more basic concepts.7 But to say that is not to say that no reflective understanding of it is possible.
1.4 Knowing as the Most General Factive Mental State
Knowing does not factorize as standard analyses require. Nevertheless, a modest positive account of the concept can be given, one that is not an analysis of it in the traditional sense. The one sketched below will appear thin by comparison with standard analyses. That may not be a vice.
Indeed, its thinness will clarify the importance of the concept as more complex accounts do not. The main idea is simple. A propositional attitude is factive if and only if, necessarily, one has it only to truths. Examples include the attitudes of seeing, knowing, and remembering. Not all factive attitudes constitute states; forgetting is a process. Call those attitudes which do constitute states stative. The proposal is that knowing is the most general factive stative attitude, that which one has to a proposition if one has any factive stative attitude to it at all. Apparent counterexamples to this conjecture are discussed below. The point of the conjecture is to illuminate the central role of the concept of knowing in our thought. It matters to us because factive stative attitudes matter to us.
To picture the proposal, compare the state of knowing with the property of being coloured, the colour property which something has if it has any colour property at all. If something is coloured, then it has a more specific colour property; it is red or green or . . . . Although that specific colour may happen to lack a name in our language, we could always introduce such a name, perhaps pointing to the thing as a paradigm. We may say that being coloured is being red or green or . . . , if the list is understood as open-ended, and the concept is coloured is not identified with the disjunctive concept. One can grasp the concept is coloured without grasping the concept is green, therefore without grasping the disjunctive concept. Similarly, if one knows that A, then there is a specific way in which one knows; one can see or remember or . . . that A. Although that specific way may happen to lack a name in our language, we could always introduce such a name, perhaps pointing to the case as a paradigm. We may say that knowing that A is seeing or remembering or
. . . that A, if the list is understood as open-ended, and the concept knows is not identified with the disjunctive concept. One can grasp the concept knows without grasping the concept sees, therefore without grasping the disjunctive concept.
We can give substance to the category of factive stative attitudes by describing its realization in a natural language. The characteristic expression of a factive stative attitude in language is a factive mental state operator (FMSO). Syntactically, an FMSO Φ has the combinatorial properties of a verb. Semantically, Φ is an unanalysable expression; that is, Φ is not synonymous with any complex expression whose meaning is composed of the meanings of its parts.
A fortiori, Φ is not itself such an expression. Φ also meets three further conditions. For simplicity, they are stated here as conditions on an FMSO in English, although the general category is realized in other languages too. First, Φ typically takes as subject a term for something animate and as object a term consisting of 'that' followed by a sentence. Second, Φ is factive, in the sense that the form of inference from 'S Φs that A' to 'A' is deductively valid (the scrupulous will read quotation marks as corner quotes where appropriate). Third, 'S Φs that A' attributes a propositional attitude to S. On the present view, 'know' and 'remember' are typical FMSOs. Even with the following glosses, these remarks do not constitute a rigorous definition of 'FMSO', but they should make its extension moderately clear.
First, 'S Φs that A' is required to have 'A' as a deductive consequence, not as a mere cancellable presupposition. There is a use of the verb 'guess' on which 'S guessed that A' in some sense presupposes 'A'. However, this presupposition is cancellable by context, as the logical and linguistic propriety of the following sentences shows:
(1) I guessed incorrectly that he was guilty.
(2) I guessed that he was guilty and you guessed that he was innocent.
In contrast, the substitution of 'knew' for 'guessed' in (1) or (2) yields a contradiction.
Incidentally, therefore, the implication from 'S does not know that A' to 'A' is not like that from 'S
knows that A' to 'A', for only the former is cancellable. The following sentences are logically and linguistically proper:
(3) I did not know that he was guilty, for he was innocent.
(4) I did not know that he was guilty and you did not know that he was innocent. In contrast, the substitution of 'knew' for 'did not know' in (3) or (4) yields a contradiction. If
Φ is an FMSO, the implication from 'S Φs that A' to 'A' is not cancellable (see Grice 1989: 44-6 and
279-80 for cancellability and the presuppositions of 'know' respectively).
Second, FMSOs are stative: they are used to denote states, not processes. This distinction is linguistically marked by the impropriety of progressive tenses. Consider:
(5) She is proving that there are infinitely many primes.
(6) The shoes are hurting her.
*(7) She is knowing that there are infinitely many primes.
*(8) She is believing that there are infinitely many primes.
*(9) The shoes are fitting her.
Sentences (7)-(9) are deviant because 'know', 'believe', and 'fit' (on the relevant reading), unlike 'prove' and 'hurt', are stative. Of course, a verb may have both stative and non-stative readings, as in (10): ?(10) She is remembering that there are infinitely many primes.
On the salient reading of 'remember', (10) is deviant, but it might correctly be used to say that she is in the process of recalling that there are infinitely many primes (see Vendler 1967: 104
for more on the linguistic marks of statives).
Third, an FMSO ascribes an attitude to a proposition to the subject. Thus 'S Φs that A'
entails 'S grasps the proposition that A'. To know that there are infinitely many primes, one must grasp the proposition that there are infinitely many primes, so 'know' passes the test. A verb with a sense like 'is responsible for its being the case that' would fail it. Thus, given that 'see' and
'remember' are FMSOs, one can see that Olga is playing chess or remember that she was playing chess only if one has a concept of chess. This is not to deny that one's perceptions and memories may have a content which one lacks the concepts to express; the point is just that the English constructions 'see that A' and 'remember that A' do not ascribe such content. Other constructions with those verbs behave differently; one does not need a concept of chess to see or remember Olga playing chess.
Fourth, an FMSO is semantically unanalysable. An artificial verb stipulated to mean the same as 'believe truly' would not be an FMSO. A semantically analysable expression has a more complex semantic role than that of simply denoting an attitude; its proper treatment would require an account of the meanings from which its meaning is composed. Thus it is best at this stage to concentrate on semantically unanalysable expressions. Verbs such as 'know' and 'remember' will be assumed to be semantically unanalysable. However, an FMSO is not required to be syntactically unanalysable. In English and some other languages, for example, the addition of the auxiliary 'can'
often forms an FMSO (Vendler 1967: 104-6). Consider the following pair:
(11) She felt that the bone was broken.
(12) She could feel that the bone was broken.
The 'could' in (12) is not the 'could' of ability; (12) does not mean anything like:
(13) She had the ability to feel that the bone was broken.
A rough paraphrase of the salient reading of (11) would be: 'She intuitively believed that the bone was broken.' A rough paraphrase of the salient reading of (12) would be: 'She knew by the sense of touch that the bone was broken'. Sentence (12), unlike (11), entails 'The bone was broken'.
Thus 'could feel' differs from 'felt' in two ways: it is factive, and it is perceptual. Neither of these differences would occur if 'could feel' were semantically analysable into 'could' and 'feel', for that would assimilate 'could feel' to 'had the ability to feel', which is neither factive nor perceptual. 'Could feel' is semantically fused. It is an FMSO;
'feel' is not.
'Hear' is like 'feel' in this respect. Consider:
(14) She heard that the volcano was erupting.
(15) She could hear that the volcano was erupting. A rough paraphrase of the salient reading of (14) would be: 'She heard a report that the volcano was erupting.' A rough paraphrase of the salient reading of (15) would be: 'She knew by the sense of hearing that the volcano was erupting.' Sentence (15), unlike (14), entails 'The volcano was erupting'. Thus 'could hear' differs from 'heard' in two ways: it is factive, and it is more directly perceptual. Neither of these differences would occur if 'could hear' were semantically a compound of 'could' and 'hear'. 'Could hear' is an FMSO; 'hear' is not.
'Could see' differs from 'see' in only one of the two ways. Consider:
(16) She saw that the stock market had crashed.
(17) She could see that the stock market had crashed.
Both (16) and (17) entail 'The stock market had crashed'; there is no difference in factiveness. However, they are naturally read in such a way that (16) would be true and (17) false if she simply saw a newspaper report of the crash; (17) might be true if she saw investors lining the window ledges. In such cases, one could insert 'the news' before 'that' in (16) but not in (17)—not even when she has inferred the crash from newspaper reports of other events. In this way, 'could see' is more directly perceptual than 'saw'. This does not prevent both from being FMSOs.
The notion of an FMSO should by now be clear enough to be workable; it can be projected onto new cases. Moreover, it has been explained without essential reference to the notion of knowing, although 'know' is an example of an FMSO. It will now be proposed that 'know' has a special place in the class of FMSOs.
The proposal is that if Φ is any FMSO, then 'S Φs that A' entails 'S knows that A'. If you see that it is raining, then you know that it is raining. If you remember that it was raining, then you know that it was raining. Such entailments are plausible but not uncontroversial (see Unger 1972
and 1975: 158-83 for useful discussion).
It is sometimes alleged that one can perceive or remember that A without knowing that A, because one fails to believe or to be justified in believing that A.
Other evidence may give one reason to think that one is only hallucinating what one is in fact perceiving, or only imagining what one is in fact remembering. One abandons the belief, or retains it without justification; either way, it is alleged, one fails to know (Steup 1992 is a recent example of such a view). However, such cases put more pressure on the link between knowing and believing or having justification than they do on the link between perceiving or remembering and knowing. If you really do see that it is raining, which is not simply to see the rain, then you know that it is raining; seeing that A is a way of knowing that A. You may not know that you see that it is raining, and consequently may not know that you know that it is raining, but neither condition is necessary for knowing that it is raining (see Chapter 5). Similarly, if you really do remember that it was raining, which is not simply to remember the rain, then you know that it was raining; remembering that A is a way of knowing that A. You may not know that you remember that it was raining, and consequently may not know that you know that it was raining, but neither condition is necessary for knowing that it is raining. But it is far from obvious that you do see or remember that it is or was raining in the cases at issue, and an account will now be suggested on which you do not.
There is a distinction between seeing that A and seeing a situation in which A. One difference is that only the former requires the perceiver to grasp the proposition that A. A normal observer in normal conditions who has no concept of chess can see a situation in which Olga is playing chess, by looking in the right direction, but cannot see that Olga is playing chess, because he does not know what he sees to be a situation in which Olga is playing chess. The present cases suggest another difference between the two notions of seeing. By looking in the right direction, you can see a situation in which it is raining. In the imagined case, moreover, you have enough concepts to grasp the proposition that it is raining. Nevertheless, you cannot see that it is raining, precisely because you do not know what you see to be a situation in which it is raining (given the unfavourable evidence). On this account, the case is a counterexample to neither the claim that seeing implies knowing nor the claim that knowing implies believing. Similarly, there is a distinction between remembering that A and remembering a situation in which A. One difference is that only the former requires the rememberer to grasp the proposition that A. Someone whose memory is functioning normally but who has no concept of chess can remember a situation in which Olga was playing chess, but cannot remember that Olga was playing chess, because he does not know what he remembers to be a situation in which Olga was playing chess. The present cases suggest another difference between the two notions of remembering. You can remember a situation in which it was raining. In the imagined case, moreover, you have enough concepts to grasp the proposition that it was raining. Nevertheless, you cannot remember that it was raining, precisely because you do not know what you remember to be a situation in which it was raining (given the unfavourable evidence). On this account, the case is a counterexample to neither the claim that remembering implies knowing nor the claim that knowing implies believing.
The discussion of FMSOs may be summarized in three principles:
(18) If Φ is an FMSO, from 'S Φs that A' one may infer 'A'.
(19) 'Know' is an FMSO.
(20) If Φ is an FMSO, from 'S Φs that A' one may infer 'S knows that A'.
The latter two principles characterize the concept of knowing uniquely, up to logical equivalence, in terms of the concept of an FMSO. For let 'schnow' be any term governed by (19′)
and (20′), the results of substituting 'schnow' for 'know' in (19) and (20) respectively. By (19) and
(20′), from 'S knows that A' one may infer 'S schnows that A'. Similarly, by (19′) and (20), from 'S
schnows that A' one may infer 'S knows that A'. Thus 'schnow' is logically equivalent to 'know'.
Note that this argument would fail if (20) held only for most FMSOs. In simple terms, 'know' is the most general FMSO, the one that applies if any FMSO at all applies.
In the material mode, the claim is that knowing is the most general stative propositional attitude such that, for all propositions p, necessarily if one has it to p then p is true. This is not quite to claim that, for all propositions p, knowing p is the most general mental state such that necessarily if one is in it then p is true. The latter claim fails for necessarily true propositions: every mental state is such that necessarily if one is in it then 5 + 7 = 12, but it does not follow that every mental state is sufficient for knowing that 5 + 7 = 12.
It is vital to this account of 'know' that 'believe truly' does not count as an FMSO. If it did,
(20) would permit the invalid inference from 'S believes truly that A' to 'S knows that A'. The mental state is believing that A, not believing truly that A. To entail knowing, the mental state itself must be sufficient for truth. The condition of semantic unanalysability ensures that 'believe truly'
does not count as an FMSO.
On this account, the importance of knowing to us becomes as intelligible as the importance of truth. Factive mental states are important to us as states whose essence includes a matching between mind and world, and knowing is important to us as the most general factive stative attitude. Of course, something needs to be said about the nature and significance of this matching, but that is a further problem. Someone who denied that the concept characterized by (18)-(20) is our concept knows might even think that it was more useful than the latter.
The states in question are general: different people can be in them at different times. No claim is made about the essences of their tokens; indeed, the idea of a token state is of doubtful coherence (Steward 1997: 105-34). With respect to general states, the claims of necessity are de re, not just de dicto. Given that 'knowing p' rigidly designates a mental state, the de dicto claim that the truth of p is necessary for knowing p implies the de re claim that for some mental state S the truth of p is necessary for S.
The account is explicitly not a decomposition of the concept knows; if 'know' were semantically analysable, it would not be an FMSO. It would certainly be quite implausible to claim that everyone who thinks that John knows that it is raining thereby thinks that John has the most general stative propositional attitude such that, for all propositions p, necessarily if one has it to p then p is true, to the proposition that it is raining. What, then, is the status of the account?
Consider an analogy. Identity is uniquely characterized, up to logical equivalence, by the principles of reflexivity and Leibniz's Law, just as knowing is uniquely characterized, up to logical equivalence, by (19) and (20). However, it would be quite implausible to claim that everyone who thinks that Istanbul is Constantinople thereby thinks that Istanbul bears to Constantinople the reflexive relation that obeys Leibniz's Law. The metalogical concepts used in formulating Leibniz's
Law are far more sophisticated than the concepts we use in thinking that Istanbul is Constantinople.
In order to have the concept is (of identity), one must somehow be disposed to reason according to
Leibniz's Law, but that does not require one to have the metalogical concepts used in formulating
Leibniz's Law. If it did, there would be an obvious danger of an infinite regress. Similarly, in order to have the concept knows, one must somehow be disposed to reason according to (18)-(20), but that does not require one to have the metalinguistic concepts used in formulating (18)-(20).
It is no straightforward matter to say what it is for a subject to be disposed to reason according to rules which the subject cannot formulate. Such a subject may even consciously reject the rules; philosophers who mistakenly deny Leibniz's Law do not thereby cease to understand the 'is' of identity. Nevertheless, some such notion does seem to be needed, independently of the account of knowing; the latter account can avail itself of that notion, whatever exactly it proves to be. The present account of knowing is consistent with the main features of a theory of concepts such as that of Peacocke 1992, on which an account of a concept gives necessary and sufficient conditions for possession of the concept without any need to decompose the concept itself.
However, the account is not committed to any general programme of Peacocke's kind in the theory of concepts.
The present account of knowing makes no use of such concepts as justified, caused, and reliable. Yet knowing seems to be highly sensitive to such factors over wide ranges of cases. Any adequate account of knowing should enable one to understand these connections. This challenge is not limited to the present account: standard accounts of knowing in terms of justification must enable one to understand its sensitivity to causal factors, and standard accounts of knowing in terms of causal factors must enable one to understand its sensitivity to justification; none of these tasks is trivial.
One way for the present account to meet the challenge is by exploiting the metaphysics of states. For example, a form of the essentiality of origins may apply to states; a necessary condition of being in some states may be having entered them in specific ways. States of perceiving and remembering have this feature, requiring entry along a specific kind of causal path. Thus the importance of causal factors in many cases of knowing is quite consistent with this account. More obviously, having an inferential justification of a specific kind may be essential to being in some mental states; having a proof is clearly a factive mental state. Thus the importance of justification in many cases of knowing is equally consistent with this account. Of course, these remarks merely adumbrate a strategy, without carrying it out. Chapters 2 and 3 explore the connections between epistemology and the nature of mental states further. We can see epistemology as a branch of the philosophy of mind. If we try to leave epistemology out of the philosophy of mind, we arrive at a radically impoverished conception of the nature of mind.
1.5 Knowing and Believing
The account of knowing above makes no essential mention of believing. Formally, it is consistent with many different accounts of the relation between the two concepts. Historically, however, the view of knowing as a mental state has been associated with the view that knowing entails not believing.
Prichard is a case in point (1950: 86-8). On standard analyses of knowing, in contrast, knowing entails believing. On some intermediate views, knowing is consistent both with believing and with not believing. It is therefore natural to ask how far the present account of knowing constrains the relation between knowing and believing.
We have two schemas to consider:
(21) If S knows that A then S believes that A.
(22) If S knows that A then S does not believe that A.
If (21) is invalid, then the programme of analysing the concept knows as a conjunction of believes with true and other concepts is stillborn. Once the programme has been abandoned, (21)
can be examined without prior need for its vindication.
The schema (22) is quite implausible. Whether I know that A on being told that A depends constitutively on whether my informant knew that A (amongst other factors). Whether I believe that
A on being told that A does not depend constitutively on whether my informant knew that A; it would have to if knowing excluded believing. Of course, when one can describe someone as knowing that A, it is conversationally misleading simply to describe her as believing that A, but that is not to say that it is false. Not all believing is mere believing. We should reject (22).
The schema (21) does not sound trivially valid, as the schema 'If S knows that A then A'
does. When the unconfident examinee, taking herself to be guessing, reliably gives correct dates as a result of forgotten history lessons, it is not an obvious misuse of English to classify her as knowing that the battle of Agincourt was in 1415 without believing that it was. But intuitions differ over such cases; it is not very clear whether she knows and not very clear whether she believes. In a case in which she was taught incorrect dates and repeats them with equal unconfidence, she is in an at least somewhat belief-like state, which she is also in when she was taught the correct dates. We have no clear counterexamples to (21) (see Radford 1966, Armstrong 1973: 138-49, and Shope
1983: 178-87 for further discussion of such cases).
There is a wide grammatical divergence between the verbs 'know' and 'believe' not suggestive of closely connected terms. For example, in a context in which I have predicted that it will rain, 'You know what I predicted' has a reading on which it is true if and only if you know that I
predicted that it will rain, whereas 'You believe what I predicted' has no reading on which it is true if and only if you believe that I predicted that it will rain. There are many further grammatical differences between 'know' and 'believe' (see Austin 1946, Vendler 1972: 89-119, and Shope 1983: 1718, 191-2). One explanation of such facts, proposed by Vendler, is that 'know' and 'believe' take different objects: what one knows is a fact, what one believes a proposition, where a fact is not a true proposition. A contingently true proposition, unlike a contingent fact, could have been false and still have existed. If so, then knowing is not a propositional attitude, and much of the terminology of this book might need revision, although the substance of the account would remain.
Vendler's explanation makes it hard to see why (21) should be valid. However, it is not strictly inconsistent with the validity of (21), since 'that A' may refer to a fact in the antecedent and to a proposition in the consequent.
If 'that A' refers to a fact in the context 'S knows that A', then we might expect 'that A' to suffer reference failure when 'A' is false. Consequently, we might expect 'S knows that A' and 'S
does not know that A' not to express propositions. But if 'A' is false, 'S knows that A' expresses a false proposition and 'S does not know that A' a true one. Perhaps we could treat 'that A' as elliptical for 'the fact that A' and analyse it by a Russellian theory of definite descriptions. The reference of
'fact that A' in the definite description is presumably determined by the proposition p expressed by
'A'; it is therefore some function f of p. Thus to know that A is to know the f(p), and hence to stand in a complex relation expressed by 'know', 'the', and 'f' to the proposition expressed by 'A'. But then with only a slight change of meaning we could use the word 'know' for that complex relation to a proposition. Thus, even on a view like Vendler's, knowing would still involve a propositional attitude. However, it is very doubtful that there are any such things as facts other than true propositions (see Williamson 1999 for an argument). Moreover, the propriety of remarks like 'I always believed that you were a good friend; now I know it' and 'Long before I knew those things about you I believed them' suggest that 'believe' and 'know' do take the same kind of object.
Vendler's account is not accepted here.
The present account of knowing might be thought inconsistent with the validity of (21), on the grounds that it provides no basis for a conceptual connection between believing and knowing.
That would be too quick. Section 1.3 already noted that not every conceptually necessary condition is a conjunct of a conjunctive analysis. It is a mistake to assume that (21) is valid only if that connection is explicable by an analysis of knows in terms of believes. Consider an analogy: it may be a priori that being crimson is sufficient for being red, but that implication need not be explained by an analysis of one colour concept in terms of the other. One can grasp either concept without grasping the other, by being shown examples of its application and non-application. Neither concept relies on the other in demarcating conceptual space. Nevertheless, the area demarcated by one concept might be so safely within the area demarcated by the other that one could know by a priori reflection that the former is sufficient for the latter. Similarly, the area demarcated by the concept knows might be so safely within the area demarcated by the concept believes that one could know (21) by a priori reflection. That is quite consistent with, although not entailed by, the account of knowing in section
1.4.
An alternative proposal is to reverse the direction of analysis, and validate (21) by an analysis of believes in terms of knows. The simplest suggestion is that the concept believes is analysable as a disjunction of knows with other concepts. The word 'opine' will be used here as a term of art for the rest of the disjunction. On this analysis, one believes p if and only if one either knows p or opines p. Given that opining p is incompatible with knowing p, it follows that one opines p if and only if one believes p without knowing p. A similar view has been proposed by John
McDowell (1982), building on the disjunctive account of perceptual experience developed by J. M.
Hinton (1967 and 1973) and Paul Snowdon (1980-1 and 1990; see also Child 1994: 143-64, Dancy
1995, and Martin 1997). In McDowell's terminology, believing is not the highest common factor of knowing and opining. There is no such common factor. Rather, knowing and opining are radically different, mutually exclusive states, although instances of the latter are easily mistaken for instances of the former. Given a distinction between facts and true propositions, one could contrast knowing and opining somewhat as Vendler contrasts knowing and believing: to know is to be acquainted with a fact; to opine is to be acquainted with no more than a proposition. But the disjunctive conception does not require such an ontology of facts.
Not all those who advocate a disjunctive conception would claim that it provides a conceptual analysis. That claim faces difficulties additional to the generally dim prospects for conceptual analysis evoked in section 1.3. If the concept believes is the disjunction of knows and opines, then it must be possible to grasp the concept opines without previously grasping the concept believes. For otherwise, since grasping a disjunction involves grasping its disjuncts, it would be impossible to grasp the concept opines for the first time. Now 'opine' was introduced as a term of art; how is it to be explained? The natural explanation is that to opine a proposition p is to have a mere belief p, which is presumably to believe p without knowing p, but that explanation uses the concept believes. It does not permit one to grasp opines without already grasping believes. The explanation that to opine p is to be of the opinion p does no better, for
'be of the opinion' as ordinarily understood is just a rough synonym of 'believe'. In particular, once it is conceded—as it is by the disjunctive conception—that 'know' implies 'believe', little reason remains to deny that 'know' implies 'be of the opinion', too.
Can we explain 'opine' in terms of 'know'? A first attempt is this: one opines the proposition p if and only if one is in a state which one cannot discriminate from knowing p, in other words, a state which is, for all one knows, knowing p. That cannot be quite right, for if one cannot grasp the proposition p then one cannot discriminate one's state from knowing p; but one does not believe p, and therefore does not opine it. To avoid that problem, we can revise the definition thus: one opines p if and only if one has an attitude to the proposition p which one cannot discriminate from knowing, in other words, an attitude to p which is, for all one knows, knowing. However, that definition does not help a disjunctive analysis of believing. For if one knows p, then trivially one has an attitude to p which one cannot discriminate from knowing; one cannot discriminate something from itself. Thus the first disjunct, 'One knows p', entails the second disjunct, 'One opines p'. The whole disjunction would therefore be equivalent to its second disjunct, and the disjunctive form of the definiens would be a mere artefact of conceptual redundancy. To tack the qualification 'but does not know p' onto the end of the definition of 'opine' would make no significant difference, for since 'One either knows p or has an attitude to p which one cannot discriminate from knowing but does not know p' is still equivalent to 'One has an attitude to p which one cannot discriminate from knowing p', the disjunctive form would remain a mere artefact.
Alternatively, 'opine' might be explained as the disjunction of several more specific disjuncts, such as 'be under the illusion', 'be irrationally certain' and so on. However, it is very doubtful that, without using the concept believes, one could extend such a list to include all the different ways in which someone can believe without knowing. Those ways seem to be indefinitely various. How could one even specify, without using the concept believes, all the states in which someone can believe p falsely? If the list of disjuncts is open-ended, one could not grasp how to go on without realizing that one must list the ways in which someone can believe without knowing.
Thus the explanation of 'opine' illicitly relies on a prior grasp of the concept believes.
The phenomenon just noted also threatens more metaphysical disjunctive accounts which do not attempt conceptual analysis, instead making their claims only about the underlying facts in virtue of which the concepts apply. Such an account of believing might deny that believing is itself a unified state, insisting that it is necessary but not a priori that one believes p if and only if one is in either the state of knowing p or the state of opining p. Since conceptual analysis is no longer in question, the replacement of 'opining' by 'merely believing' is not objectionable on grounds of circularity. The trouble is rather that there is no more reason to regard merely believing p as a unified mental state than to regard believing p as such. What unifies Gettier cases with cases of unjustified false belief is simply that in both, the subject believes without knowing; a good taxonomy of believing would not classify them together on the basis of some positive feature that excludes knowing. Moreover, it is hard to see how such a taxonomy could describe every species of believing without using the concept believes. But if a good taxonomy of believing does use the concept believes, that undermines the denial that believing is a unified state. Similar objections apply to disjunctive accounts of perception, appearance, and experience. For example, there is no reason to postulate a unified mental state equivalent to its appearing to one that A while one does not perceive that A.
A strictly disjunctive account of belief is not correct at either the conceptual or the metaphysical level. However, the disjunctive account was brought into play as a simple means to reconcile the account of knowing in section 1.4 with the supposed validity of (21) (knowing entails believing). There are other means to that end. A non-disjunctive analysis of believes might also validate (21). For example, (21) is a corollary of an analysis of believes itself on the lines of the definition of opines above: one believes p if and only if one has an attitude to the proposition p which one cannot discriminate from knowing, in other words, an attitude to p which is, for all one knows, knowing. That definition suggestively makes knowing central to the account of believing.
One attraction of such an account is that it opens the prospect of explaining the difficulty, remarked by Hume, of believing p at will in terms of the difficulty of knowing p at will. The analysis is also consistent with the account of knowing in section 1.4.
Although that analysis provides a reasonable approximation to our concept believes, it does not fully capture the concept. It incorrectly classifies as believing that food is present a primitive creature which lacks any concept of knowing and merely desires that food is present; for all the creature knows, its attitude to the proposition that food is present is knowing. Equally incorrectly, the account classifies as not believing that there is a god someone who consciously takes a leap of faith, knowing that she does not know that there is a god. Both examples, however, are compatible with the variant idea that to believe p is to treat p as if one knew p—that is, to treat p in ways similar to the ways in which subjects treat propositions which they know. In particular, a factive propositional attitude to a proposition is characteristically associated with reliance on it as a premise in practical reasoning, for good functional reasons; such reliance is crucial to belief. A creature which lacks a concept of knowing can still treat a proposition in ways in which it treats propositions which it knows. The primitive creature does not treat the proposition that food is present like that when merely desiring that food is present; it does not use the proposition as a premise in practical reasoning. By contrast, the person who genuinely believes that there is a god by a leap of faith does rely on that premise in such reasoning. The unconfident examinee who tentatively gives p as an answer is little disposed to rely on p as a premise, and for that reason does not clearly believe p, but for the same reason does not clearly know p. Although a full-blown exact conceptual analysis of believes in terms of knows is too much to expect, we can still postulate a looser connection along these lines.
If believing p is, roughly, treating p as if one knew p, then knowing is in that sense central to believing. Knowledge sets the standard of appropriateness for belief. That does not imply that all cases of knowing are paradigmatic cases of believing, for one might know p while in a sense treating p as if one did not know p—that is, while treating p in ways untypical of those in which subjects treat what they know. Nevertheless, as a crude generalization, the further one is from knowing p, the less appropriate it is to believe p. Knowing is in that sense the best kind of believing.
Mere believing is a kind of botched knowing.8 In short, belief aims at knowledge (not just truth).
These rather cryptic remarks will be developed in Chapters 9 and 10, which argue that knowledge is the evidential standard for the justification of belief.
Although the letter of disjunctive accounts has been rejected, the spirit may have been retained. For on the account in section 1.4, believing is not the highest common factor of knowing and mere believing, simply because it is not a factor of knowing at all (whether or not it is a necessary condition). Since that point is consistent with the claim that believing is common to knowing and mere believing, the claim is harmless. It no more makes the difference between knowing and mere believing extrinsic to a state than the point that continuity is common to straight and curved lines makes the difference between straight and curved extrinsic to a line. To know is not merely to believe while various other conditions are met; it is to be in a new kind of state, a factive one. What matters is not acceptance of a disjunctive account of believing but 9
rejection of a conjunctive account of knowing. Furthermore, the claim that belief is what aims at knowledge is consonant with the suggestion in disjunctive accounts that illusion is somehow parasitic on veridical perception. Properly developed, the insight behind disjunctive theories leads to a non-conjunctive account of knowledge and a non-disjunctive account of belief.
While belief aims at knowledge, various mental processes aim at more specific factive mental states. Perception aims at perceiving that something is so; memory aims at remembering that something is so. Since knowing is the most general factive state, all such processes aim at kinds of knowledge. If a creature could not engage in such processes without some capacity for success, we may conjecture that nothing could have a mind without having a capacity for knowledge. 2 Broadness
2.1 Internalism and Externalism The thesis that knowing is a mental state faces a further series of challenges. They come from a picture of the mind known in current jargon as internalism, in a sense of the term more prevalent in the philosophy of mind than in epistemology.
When I attribute a mental state to you in ordinary language, the implications of my statement can easily outrun your boundaries. I say that you see paper; as every sceptic knows, you could be in the same internal state as someone who sees paper without seeing paper yourself: my statement is true only if paper is there before your eyes, outside you. In some sense, my statement is not purely about you. For theoretical purposes, would it not be more perspicuous to resolve the mixture into its underlying elements, by separating a statement purely about you from another purely about the environment external to you? After all, causation is local—no action at a distance—so does not the causal explanation of your actions require the isolation of what is local to you from background conditions on the environment? This resolution might amount to an analysis, giving a necessary and sufficient condition for the truth of my original statement. Alternatively, it might replace that statement without being equivalent to it, by doing its causal-explanatory work better. Either way, internal and external factors are separated. Such a picture is internalist.
In the present sense, internalists hold that one's mental states are determined by one's internal physical states; the mind is in the head. As a characterization of internalism, that is not fully general, for it neglects radically dualist versions, but the form of the argument below would be little changed if 'physical state' were replaced by 'phenomenal state', understood as designating states constitutively independent of the environment. For simplicity, we can focus on the currently most popular version of internalism.
Internalism provides a deeper motive for denials that knowing is a mental state. For since knowing is factive, whether one knows p constitutively depends on the state of one's external environment whenever the proposition p is about that environment. Consequently, whether one knows p is not determined by one's internal physical state. For example, whether one knows that it is raining is not determined by one's internal physical state, for it also depends on the weather. If it is not raining then one does not know that it is raining, whatever one's internal physical state. Thus, for the internalist, knowing is not a mental state. Jerry Fodor drew just such a conclusion from his formality condition, according to which mental states and processes defined over representations apply to them in virtue of the syntax of the representations: 'Since, on that assumption [that you can't know what's not the case], knowledge is involved with truth, and since truth is a semantic notion, it's going to follow that there can't be a psychology of knowledge (even if it is consonant with the formality condition to hope for a psychology of belief)' (1981: 228). By contrast, an externalist conception frees us to affirm that knowing is a mental state.
The issue ramifies. On the internalist picture, knowing is a metaphysical hybrid, a mixture of mental states with mind-independent conditions on the external world. Even Tyler Burge, who has done as much as anyone to develop an externalist understanding of the mental, writes that factive verbs like 'know', 'regret', 'realize', 'remember', 'foresee' and 'perceive' 'suggest an easy and clearcut distinction between the contribution of the individual subject and the objective, "veridical"
contribution of the environment to making the verbs applicable' (1979: 85). Burge wisely adds in parentheses, 'Actually the matter becomes more complicated on reflection'. The internalist naturally tries to break the supposed mixture down into its elements, to analyse knowing in terms of believing, truth, and further factors. Even so-called externalist analyses of knowledge, where the further factors are causal or counterfactual, concede the internalist assumption that believing is somehow more basic than knowing. Thus internalism also provides a deeper motive for attempts to analyse knowing in terms of believing, truth, and other factors. We may call such attempts the reductionist programme for knowledge.
Internalists who regard knowing itself as complex do not thereby commit themselves to the same view of the concept knows. A simple concept might be defined by ostension of complex exemplars. Thus internalism motivates the reductionist programme for knowledge more strongly at the metaphysical than the conceptual level. The emphasis in this chapter will therefore be on metaphysical rather than conceptual issues.
We may assume that all attempts so far to carry out the reductionist programme for knowledge have failed. That suggests that it is misconceived. Its failure also suggests that internalism itself is misconceived, insofar as it motivates the reductionist programme. A conception of knowing that is thoroughly externalist in the present sense will dispense with the programme. On such a conception, as developed in the previous chapter, knowing is not a metaphysical hybrid, because it cannot be broken down into such elements.
Section 2.2 briefly illustrates the nature of the case for externalism, without attempting to state it in detail. The aim is rather to draw a comparison between more familiar disputes between internalists and externalists, over the contents of propositional attitudes, and the present dispute, over the attitudes to those contents, and to suggest that the case for externalism about mental attitudes is as good as the case for externalism about mental contents. The main target of criticism in sections 2.3 and 2.4 is the idea that there are good grounds for combining externalism about the contents of the attitudes with internalism about the attitudes themselves. One overall argumentative strategy is to show that objections to the involvement of factive attitudes in genuine mental states are sound only if corresponding objections to the involvement of broad contents in genuine mental states are also sound. For example, cases in which a difference in the external environment constitutes a difference in knowing hardly show that knowing is not a mental state, unless cases in which a difference in the external environment constitutes a difference in broad content show that believing a broad content is not a mental state. Externalism about factive mental attitudes is as well placed as externalism about mental content. Chapter 3 will state a deeper case for externalism on both fronts.
2.2 Broad and Narrow Conditions
We can define the issues in more rigorous terms to address them more effectively. What exactly is the distinction between the internal and the external? The boundaries of the agent which our attributions of mental states outrun are spatio-temporal boundaries. The spatial boundary is naturally identified with that of the agent's body, although for present purposes it could just as well be identified with that of the brain (or the head). But only what goes on within the agent's body at the time of action counts as internal, for past bodily goings on are not local in the sense in which causation is supposed to be local. The internal will be identified with the total internal physical state of the agent at the relevant time, the external with the total physical state of the external environment. Everything said here will be consistent with the mildly physicalist assumption that the internal and the external are jointly exhaustive as well as mutually exclusive, in the sense that the total internal physical state of the subject and the total physical state of the external environment jointly determine the total state of the world: no difference in the latter without a difference in at least one of the former.
Some terminology will help. A case is a possible total state of a system, the system consisting of an agent at a time paired with an external environment, which may of course contain other subjects. A case is like a possible world, but with a distinguished subject and time: a 'centred world' in the terminology of David Lewis (1979). Different cases can distinguish different subjects and times. Whatever is nomically possible counts as 'possible' in the relevant sense; whether anything else does can be left open for present purposes.
A condition obtains or fails to obtain in each case. Conditions are specified by 'that' clauses.
The pronoun 'one' and the present tense in such clauses refer to the distinguished agent and time respectively. Thus the condition that one is happy obtains in a case α if and only if in α the agent of
α is happy at the time of α. A condition C entails a condition D if and only if for every case α, if C obtains in α then D
obtains in α. The conditions C and D are identical if and only if for every case α, C obtains in α if and only if D obtains in α. Truth-functions of conditions are defined in the obvious way; for example, the conjunction of C and D obtains in α if and only if both C and D obtain in α. The criterion of identity for conditions ensures that such truth-functions have unique values.
A case α is internally like a case β if and only if the total internal physical state of the agent in α is exactly the same as the total internal physical state of the agent in β. A condition C is narrow if and only if for all cases α and β, if α is internally like β then C obtains in α if and only if C
obtains in β. In other terminology, narrow conditions super-vene on or are determined by internal physical state: no difference in whether they obtain without a difference in that state. C is broad if and only if it is not narrow. A state S is narrow if and only if the condition that one is in S is narrow; otherwise S is broad. Internalism is the claim that all purely mental states are narrow; externalism is the denial of internalism.
When we attribute mental states to each other in ordinary language, the conditions of which we speak are often broad. That one sees Naples, that one remembers Naples, that one keeps referring to Naples—all are broad conditions, because none obtains in cases in which one lacks even indirect causal connection with Naples, whereas one's internal physical state has no such necessary dependence on a city. Similarly, that one loves Mary and that one hates Mary are broad conditions, for they depend on a relation to the particular individual named.
The semantics of ascriptions of content to propositional attitudes in natural languages is a notorious source of broad conditions. In retrospect we can trace the idea back to Hilary Putnam
(1973), as interpreted in the light of Burge's work, such as his 1979, 1986a, and 1986b. For example, the sentence 'One believes that there are tigers' expresses a broad condition. To check that it does, consider a counterfactual world like ours except that the only tiger-like creatures, although similar in appearance to tigers, are quite different in evolutionary ancestry and internal constitution.
The differences are in respects about which ordinary non-zoologists are ignorant. Call the tiger-like creatures schmigers. Clearly, schmigers do not belong to the same species as tigers; they are not tigers. In the counterfactual world I have a doppelgänger, twin-TW, who is in exactly the same internal physical state as I am. I believe truly that there are tigers. I express my belief by saying
'There are tigers'. Twin-TW expresses his belief by saying 'There are tigers', too. If he believes that there are tigers then he is wrong, for in his circumstances there are no tigers; there are only schmigers. But twin-TW is no more mistaken on this matter than I am; both of us are ignorant rather than mistaken about those specific features that differentiate tigers from schmigers. Since twin-TW believes truly, he does not believe that there are tigers. Rather, his belief is true if and only if there are schmigers. Thus I differ from twin-TW in believing that there are tigers, even though we are in exactly the same internal physical state. John McDowell (1977) and Gareth Evans (1982)
identify a similar phenomenon in relation to singular thoughts. I believe that this screen flickers; someone could be in exactly the same total internal physical state without believing that this screen flickers, because what (if anything) he believes flickers is not this screen but another with the same appearance in front of him. Thus the condition that one believes that this screen flickers is broad.
Similar arguments apply to a vast range of contents, and of attitudes to those contents. We may say derivatively that a content is broad if, for every attitude, the condition that one takes that attitude to that content is broad. Most contents ascribed in natural language are broad.
The internalist is obliged to concede that content ascriptions in natural languages express broad rather than narrow conditions, but nevertheless insists that they consequently fail to reflect the structure of the underlying facts. On this view, such ascriptions characterize the subject by reference to a mixture of genuinely mental states and conditions on the external environment. The challenge to such an internalist is to make good this claim by isolating a level of description of contentful attitudes that is both narrow and genuinely mental, not merely neuro-physiological. If there is such a mixture of the internal and the external, it should be possible to separate out its constituents. The broadness of content ascriptions in natural languages shows that the required level of description does not simply lie to hand, but must be constructed; its effect is therefore to put the burden of proof on the internalist.
Parallel considerations apply to internalism about the attitudes themselves. Factive propositional attitudes are a source of blatantly broad conditions, whether or not their contents are broad. Even when the sentence 'One believes that A' does not express a broad condition, the conditions expressed by 'One knows that A', 'One sees that A', and 'One remembers that A' are almost always broad. While conceding this, the internalist nevertheless insists that such constructions fail to reflect the structure of the underlying facts. Factive constructions are held to characterize the subject by reference to a mixture of genuinely mental states and conditions on the external environment. As before, the challenge to the internalist is to make good this claim by isolating a level of description that is both narrow and genuinely mental. The effect of the broad natural language semantics is again to put the burden of proof on the internalist. On the view developed in Chapter 1, the factive states are as genuinely mental as any states are. The internalist disagrees, and tries to find a narrow non-factive attitude that exhausts the mental reality underlying the broad factive attitude. The next section examines such attempts; they all prove to be inadequate.
2.3 Mental Differences Between Knowing and Believing
The argument from internalism to the denial that knowing is a mental state can now be stated in more detail. First, assume that knowing is a mental state:
(1) For every proposition p, there is a mental state S such that in every case α, one is in S if and only if one knows p.
Given (1), any difference in knowing involves a difference in mental states. That is, (1)
entails that knowing p supervenes on one's (total) mental state in this sense: (2) For all propositions p and cases α and β, if one is in exactly the same mental state in α as in β, then in α one knows p if and only if in β one knows p.
The argument from (1) to (2) is immediate if one defines 'one is in exactly the same (total)
mental state in α as in β' as 'for all mental states S, in α one is in S if and only if in β one is in S'.
Whether, conversely, (2) entails (1) depends on whether what supervenes on one's mental state is itself a mental state, a question which need not be settled here. Statement (2) could also stand on its own, without such an analysis of the equivalence relation of exact sameness of mental state; then, unlike (1), it would involve no commitment to an ontology of mental states or any consequent problems in individuating states.
Whether or not it is derived from (1), (2) is commensurable with the internalist premise that one's mental state supervenes on one's physical state, in other words, that the condition that one is in a given mental state is narrow:
(3) For all cases α and β, if α is internally like β, then one is in exactly the same mental state in α as in β.
Together, (2) and (3) entail that knowing p supervenes on one's internal state, for supervenience is transitive:
(4) For all propositions p and cases α and β, if α is internally like β, then in α one knows p if and only if in β one knows p.
According to (4), the condition that one knows p is narrow. But (4) is uncontroversially false. Of two people in exactly the same internal physical state, one may know that it is raining while the other, as the result of an elaborate hoax, believes falsely that it is. One can know p, all but for the state of the environment, without knowing p, in the sense that one can be in exactly the same internal physical (not: mental) state as someone who knows p without oneself knowing p. Since internalists accept (3), they deny (2), the other premise from which (4) was deduced. Since (1)
entails (2), they also reject (1). Having denied that knowing is a mental state, internalists naturally seek to factorize it into mental and non-mental components. Since believing may appear to be determined by one's internal physical states, and therefore to qualify as a mental state by internalist lights, it is an obvious candidate constituent. The idea that the mental (or psychological) component of knowing is simply believing seems to be expressed in a remark by Stephen Stich, endorsed by Jaegwon Kim: 'what knowledge adds to belief is psychologically irrelevant' (Stich 1978: 574, quoted in Kim 1993: 188; Kim 1993: 175-93 is a clear statement of the kind of view opposed here).
Because believing is such an obvious candidate, even those who concede externalism about mental content may be inclined to internalism about the attitude of knowing, regarding it as a mixture of mental and non-mental elements.
In present terms, the claim that knowing p adds nothing mental to believing p comes to this:
(5) For all propositions p and cases α, if in α one believes p then in some case β one is in exactly the same mental state as in α and one knows p.
For if (5) is false, one can believe p while in a total mental state T incompatible with knowing p; but then the information that one knows p adds something mental to the information that one believes p, for it implies that one is in a total mental state other than T. Thus if knowing p adds nothing mental to believing p, then (5) holds. Conversely, if (5) holds, then knowing p imposes no constraints on one's mental state beyond those already imposed by believing p, so knowing p adds nothing mental to believing p.
Now (5) implies that knowing p is not a mental state, given that not knowing p is compatible with believing p. For if knowing p is a mental state, then anyone in exactly the same mental state as someone who knows p also knows p. More precisely, (1) formalizes the claim that knowing p is a mental state; (1) entails (2); (2) and (5) entail that in every case if one believes p then one knows p.
Since not knowing p is compatible with believing p, knowing is a mental state only if (5) is false.
However, (5) fails, for reasons independent of internalism. One kind of case involves false propositions about the subject's own mental state. For example, let p be the proposition that someone is alert. Suppose that in case α one falsely believes that someone is alert solely on the basis of one's false first-person present-tense belief that one is alert. If in case β one is in exactly the same mental state as in α, then in β one also believes that someone is alert solely on the basis of one's first-person present tense belief that one is alert; since one's level of alertness is itself a feature of one's mental state, then in β one is not alert, so one's belief that one is alert is false; since that false belief is the only basis for one's belief that someone is alert, one does not know that someone is alert. Thus (5) fails. Counter-examples also occur when someone believes a necessarily false proposition. It is possible falsely to believe that 79 + 89 = 158; it is impossible to know that 79 + 89
= 158. These examples do not depend on any externalist assumptions about the contents of the beliefs.
Since those counterexamples involve false beliefs, the internalist might suppose the remedy to lie in the revised claim that knowing p adds nothing mental to believing p truly:
(6) For all propositions p and cases α, if in α one believes p truly then in some case β one is in exactly the same mental state as in α and one knows p.
Statement (6) implies that knowing p is not a mental state, given that not knowing p is compatible with believing p truly.
Even (6), however, is subject to counterexamples which are independent of externalism.
Someone may believe truly that garlic is healthy to eat for reasons so confused and irrational as to be incompatible with knowing that garlic is healthy to eat; since his confusion and irrationality is an aspect of his mental state, no one could be in exactly the same mental state and know that garlic is healthy to eat. Attempts to rule out such cases will be plagued by notorious difficulties in stating a correct justification condition on knowledge (see Shope 1983: 45-118). Even if (6) had been defensible, it would not have solved the original problem, which was, in internalist terms, to isolate the mental component of knowing, to say what mental state knowing adds nothing mental to. By specifying that the belief be true, (6) fails to do that. This latter objection is not met by a justification condition added to (6).
Believing p is in any case too unspecific a state to constitute the mental component of knowing p. Knowing p excludes: believing p solely for sufficiently confused and irrational reasons.
The supposed narrow mental component of knowing p must include not just believing p but doing so without those kinds of confusion and irrationality. We must therefore consider the suggestion that the mental component of knowing is rationally believing (Fricker 1999). 'Rationally' here need not imply the ability to articulate reasons, but only the avoidance of irrationality; languageless animals and young children may still count as knowing. In place of 'rationally believes' we could also write 'has a justified belief'. Now if rationally believing is the mental component of knowing, then the latter adds nothing mental to the former:
(7) For all propositions p and cases α, if in α one rationally believes p then in some case β
one is in exactly the same mental state as in α and one knows p.
Now (7) may also escape the original counterexamples to (5), for the internalist might count as not believing rationally the subject who believes that 79 + 89 = 158 or that someone is alert solely on the basis of a false belief that he is alert. Moreover, (7) implies that knowing p is not a mental state, given that not knowing p is compatible with rationally believing p.
Perhaps (7) looks congenial to externalism about the contents of one's attitudes but not to externalism about one's attitudes to those contents. It is not. Suppose that it looks and sounds to me as though I see and hear a barking dog; I believe that a dog is barking on the basis of the argument
'That dog is barking; therefore, a dog is barking'. Unfortunately, I am the victim of an illusion, my demonstrative fails to refer, my premise sentence thereby fails to express a proposition, and my lack of a corresponding singular belief is a feature of my mental state, according to the content externalist. If I rationally believe that a dog is barking, then by (7) someone could be in exactly the same mental state as I actually am and know that a dog is barking. But that person, too, would lack a singular belief to serve as the premise of the inference, and would therefore not know that a dog is barking. Contrapositively, according to (7), I do not rationally believe that a dog is barking, even though there need be nothing internal wrong with my thought processes. Consequently, if the contents of beliefs depend like that on the external environment, then so too does the attitude of rational belief to a given content. In brief, (7) combined with content externalism makes rational belief an externalist mental attitude. If taking the externalist attitude of rational belief to a given content can contribute to one's mental state, why cannot taking the externalist attitude of knowledge to that content also contribute to one's mental state? The combination of (7) and content externalism makes the denial that knowing is a mental state ill-motivated.
My belief that a dog is barking may easily be true in the example, so to replace 'rationally'
by 'rationally and truly' would gain nothing.
Indeed, (7) faces a further problem, one independent of content externalism. We could make
(7) trivially true by defining 'in case α one rationally believes p' as 'in some case β one is in exactly the same mental state as in α and one knows p'. If knowing p entails believing p and believing p is a mental state, then such a definition would ensure that believing p was a necessary condition for rationally believing p. But it would neither isolate the mental component of knowing in independent terms nor provide any reason to suppose the mental component to fall short of knowing itself. If (7)
is to give positive support to the hybrid conception of knowing as a mixture of mental and nonmental components, as (5) was supposed to do, then we should be able to grasp the relevant concept of rationality independently of grasping the concept of knowledge. Can we? Consider a case α in which one believes that ticket #666 will not win the lottery solely on the basis that its probability of winning is only one in a million. In any case β in which one is in the same mental state as in
α one believes that ticket #666 will not win the lottery only on the same probabilistic grounds; thus in β one does not know that ticket #666 will not win the lottery. If one had known that the ticket would not win, one would not have bought it. Consequently, by (7), in α one does not rationally believe that the ticket will not win the lottery. But in α one's belief is not irrational in any obvious sense independent of considerations of knowledge. It is based on relevant reasons; the problem is just that they are not of a kind that would permit the belief to constitute knowledge. Chapter 8 will argue that considerations of rational belief depend on considerations of knowledge.
Given the failure of (5)-(7), someone might try to capture the idea that the difference between knowing and believing is not mental in the claim that not knowing p adds nothing mental to believing p. By analogy with (5), the claim is formalized thus:
(8) For all propositions p and cases α, if in α one believes p then in some case β one is in exactly the same mental state as in α and one does not know p.
For if (8) is false, someone can believe p while in a total mental state T incompatible with not knowing p; but then not knowing p adds something mental to believing p, as the former but not the latter is sufficient, given that one believes p, for being in a total mental state other than T. Thus if not knowing p adds nothing mental to believing p, then (8) holds. Conversely, if (8) holds, then not knowing p imposes no constraints on one's mental state beyond those already imposed by believing p, so not knowing p adds nothing mental to believing p.
Now (8) implies that knowing p is not a mental state, given that knowing p is compatible with believing p. For if knowing p is a mental state, then anyone in exactly the same mental state as someone who knows p also knows p. More precisely, (1) formalizes the claim that knowing p is a mental state; (1) entails (2); (2) and (8) entail that in every case if one believes p then one does not know p. Since knowing p is compatible with and perhaps entails believing p, knowing is a mental state only if (8) is false.
However, (8) is implausible even from an internalist perspective. For example, the proposition p may concern the subject's own mental state, or be a necessary truth. Internalists will classify direct awareness that one is in pain as a mental state, holding it to depend on nothing external. Presumably, being directly aware that one is in pain is sufficient for both knowing and believing that one is in pain. Thus if one is directly aware that one is in pain, one believes that one is in pain, and could not be in exactly the same mental state without being directly aware, and therefore knowing, that one is in pain. Consequently, (8) fails. Similarly, internalists will classify grasping a proof that 79 + 89 = 168 as a mental state, holding it to depend on nothing external. Presumably, they will also hold it to be sufficient for both knowing and believing that 79 + 89 = 168. Thus if one grasps a proof that 79 + 89 = 168, then one believes that 79 + 89 = 168, and could not be in exactly the same mental state without grasping the proof that 79 + 89 = 168, and therefore knowing that 79
+ 89 = 168. Again, (8) fails. From a strongly externalist perspective, direct awareness that one is in pain may depend on something external; for example, it may depend on the use of a word in the language community as a whole to mean pain rather than something more specific that excludes one's current sensation. Similarly, grasping a proof that 79 + 89 = 168 may depend on the mathematical practice of the community as a whole. But for the full-blooded externalist, these external dependencies do not suggest that being directly aware that one is in pain and grasping a proof that 79 + 89 = 168 are not mental states. They can stand as counterexamples to (8). A
defender of (8) would have to take an intermediate position, on which knowing p always has nontrivial external necessary conditions not constitutive of the subject's mental state, no matter how trivial the proposition p. Although this combination of claims is not obviously incoherent, it also has no obvious motivation; (8) lacks the independent plausibility to provide a good reason not to classify knowing as a mental state.
Since the subject rationally and truly believes p in the examples that are problematic for (8), qualifying 'believes' by 'rationally' or 'truly' in (8) would not help.
The supposed mental component of knowing short of knowing itself is a postulate of philosophical theory, not something provided by our understanding of the relations between knowing and believing. We have no good reason to accept the theory which makes that postulate.
The internalist has no head start in the attempt to fence off the mental implications of knowing. That is not yet to say that the attempt cannot succeed; just that we have no reason independent of any case for internalism in general to expect it to succeed.
2.4 The Causal Efficacy of Knowledge
One motive for internalism is the combination of the idea that genuine states are causally efficacious with the idea that mental states are causally efficacious only if narrow. No action at a distance: causation is viewed as local, involving only narrow mental states. Since the property of judging that there is a tiger ahead is broad (because its content is broad), such an internalist denies that the property is causally efficacious, locating causal efficacy in properties that supervene on the subject's internal physical state. After all, they determine the subject's immediate physical movements. Similarly, the internalist will deny that the broad state of knowing that there is a dangerous animal ahead is causally efficacious, locating causal efficacy in the supposedly narrow state of believing that there is a dangerous animal ahead, the state which the knower shares with the victim of a sceptical scenario. For example, according to
Harold Noonan (1993: 291-2), knowledge 'is best regarded not as a psychological state, but as a complex consisting of a psychological state (belief) plus certain external factors-not because its status as knowledge is causally irrelevant in action explanation, but because it does not have to be cited, as such, in the psychological explanation of action at all'.
Much needs to be probed and questioned in these internalist ideas. We should not assume that the notion of causal efficacy is clear, or derived from fundamental science, or known to apply only to local connections. Nevertheless, suspicion is legitimate of a purported mental state, reference to which never plays an essential role in causal explanation. In the case of broad contents, a standard externalist move is to argue that attributions of them do play an essential role in causal explanations whose explananda are themselves characterized in broad terms. For example, a hunter shoots a tiger while his counterfactual doppelgänger shoots a schmiger. These descriptions of the actions are not capricious, for they are the very ones under which the actions were intended, and therefore the ones to be used when we are trying to see how the actions made sense from the subjects' point of view. Since our explanandum is that the hunter shot the tiger, our explanans will naturally involve broad descriptions of him not true of his doppelgänger, such as 'He believed that shooting a tiger would make him popular'.
Similar considerations apply to the role of factive attitudes in causal explanation. Consider a causal explanation as simple as 'He dug up the treasure because he knew that it was buried under the tree and he wanted to get rich'. Note that the explanandum ('He dug up the treasure') makes reference to objects in the environment (the treasure) as well as to the subject's immediate physical movements. The internalist cannot substitute 'believe' for 'know' in the explanation without loss, for the revised explanans, unlike the original, does not entail that the treasure was where he believed it to be; the connection between explanans and explanandum is therefore weakened. The explanans does less to raise the probability of the explanandum. As usual, the internalist may react by substituting 'believe truly' for 'believe'. The new explanation is 'He dug up the treasure because he believed truly that it was buried under the tree and he wanted to get rich'. That may be deemed as satisfactory as the original explanation, although it sounds much less natural. However, even the substitution of 'believe truly' for 'know'
sometimes involves explanatory loss.
A burglar spends all night ransacking a house, risking discovery by staying so long. We ask what features of the situation when he entered the house led to that result. A reasonable answer is that he knew that there was a diamond in the house. To say just that he believed truly that there was a diamond in the house would be to give a worse explanation, one whose explanans and explanandum are less closely connected. For one possibility consistent with the new explanans is that the burglar entered the house with a true belief that there was a diamond in it derived from false premises. For example, his only reason for believing that there was a diamond in the house might have been that someone told him that there was a diamond under the bed, when in fact the only diamond was in a drawer. He would then very likely have given up his true belief that there was a diamond in the house on discovering the falsity of his belief that there was a diamond under the bed, and abandoned the search. In contrast, if he knew that there was a diamond in the house, his knowledge was not essentially based on a false premise. Given suitable background conditions, the probability of his ransacking the house all night, conditional on his having entered it believing truly but not knowing that there was a diamond in it, will be lower than the probability of his ransacking it all night, conditional on his having entered it knowing that there was a diamond in it. It follows that the probability of his ransacking the house all night, conditional on his having entered it believing truly that there was a diamond in it, is lower than the probability of his ransacking it all night, conditional on his having entered it knowing that there was a diamond in it. In this case, the substitution of 'believe truly' for 'know' weakens the explanation, by lowering the probability of the explanandum conditional on the explanans. The substitution of 'believe' without 'truly' for 'know'
would do even worse. The argument does not assume that lowering the probability of the explanandum conditional on the explanans strictly entails loss of explanatory power: just that it results in such a loss when, as here, there are no compensating gains.
One might be puzzled for a moment by the thought that, in the circumstances, the burglar's true belief constituted his knowledge. Were the effects not the same whatever one calls it? However, this thought does not address the original problem, which concerned the causal efficacy of a general state. Different people can share the state of knowing that there was a diamond in the house; this state cannot be equated with, since it is not necessary for, believing truly that there was a diamond in the house. No doubt the particular circumstances that in some sense realize the state in a given case can be described in many different ways; what matters is how relevant those descriptions are to an understanding of the effect in question. It emerged above that the description 'knows p' is sometimes more relevant than the description 'believes truly p'.
In order to prove that reference to states of knowing is essential to the power of a causal explanation, one would need to show that it could not be eliminated in favour of any combination of believing, truth, and so on. There are infinitely many potential substitutes which might be proposed.
All that can be done here is to sketch a general strategy for dealing with them; we must not expect to prove that the strategy cannot fail. Given a potential substitute for 'knows', suppose that it does not provide a necessary and sufficient condition for knowing. One then constructs possible cases in which the failure of necessity or sufficiency makes a causal difference, making the proposed substitute not even causally equivalent to knowing. The potential substitute avoids this problem only if it does provide a necessary and sufficient condition for knowing. Thus the search for a substitute for knowing in causally explanatory contexts is forced to recapitulate the history of attempts to analyse knowing in terms of believing, truth, and so on, a history which shows no sign of ending in success.
For example, the substitution of 'believe truly without reliance on false lemmas' for 'know'
can bring causal-explanatory loss. Variants of the previous case can be constructed in which the burglar enters the house believing truly that there is a diamond in it without reliance on false lemmas, yet fails to know in virtue of misleading evidence which he does not then possess, but may discover in the course of his search, in which case he will abandon the search. The argument for explanatory loss runs as before. Although knowing is not invulnerable to destruction by later evidence, its nature is to be robust in that respect. Stubbornness in one's beliefs, an irrational insensitivity to counterevidence, is a different kind of robustness; it cannot replace knowing in all causal-explanatory contexts, for the simple reason that those who know p often lack a stubborn belief in p. The burglar's beliefs need not be stubborn. Similarly, he need not feel certain of them; subjective certainty cannot always replace knowing. The same applies to believing truly on the best possible evidence, for the example can be so constructed that the burglar's evidence, although good, is not the best possible. When one works through enough examples of this kind, it becomes increasingly plausible that knowing can figure ineliminably in causal explanations. It is causally efficacious in its own right if any mental state is (see Pettit 1986 and Child 1994: 204-16
for related discussion).1
This chapter has stated a preliminary case for externalism about both mental contents and factive mental attitudes to those contents. The next chapter deepens the case and places it in a wider context. 3 Primeness
3.1 Prime and Composite Conditions
The previous chapter argued, in a preliminary way, that internalism is false and that, on the externalist alternative, knowing is a genuine mental state. This chapter deepens the critique of internalism. It argues on structural grounds that the envisaged separation of internal and external factors is impossible. Many ordinary mental states are not equivalent to conjunctions of something purely internal with something purely external. This inequivalence is essential to the causalexplanatory work which their attribution can do. The internal does not play the distinctive role in the explanation of action that internalism predicts. On an externalist understanding of mental states, knowing is a central exemplar.
Here is a sketch of an internalist line of thought:
The causing of my present action is here and now. Only narrow conditions supervene on the here and now; so narrow conditions must play a privileged role in the causal explanation of action.
If a causal explanation of action cites a broad mental condition, an underlying narrow condition must do the real work. We can isolate that narrow condition by subtracting from the broad mental condition the environmental accretions that make it broad. We can recover the original broad mental condition from the narrow condition by adding back those accretions.1
The internalist conceives the original broad mental condition as the conjunction of the narrow condition and a condition as purely external as the former is purely internal—for instance, the condition that one believes truly that it is raining as the conjunction of the narrow condition that one believes that it is raining and the environmental condition that it is raining. Let us state the matter more formally. Recall that a case α is internally like a case β if and only if the total internal physical state of the agent in α is exactly the same as the total internal physical state of the agent in β. A condition C is narrow if and only if for all cases α and β, if α is internally like β, then C obtains in α if and only if C obtains in β. C is broad if and only if it is not narrow. We can define external likeness on the model of internal likeness: a case α is externally like a case β if and only if the total physical state of the external environment in α is exactly the same as the total physical state of the external environment in β. A condition C is environmental if and only if for all cases α and β, if α is externally like β, then C obtains in α if and only if C obtains in β. In other terminology, environmental conditions supervene on or are determined by the physical state of the external environment. A condition C is composite if and only if it is the conjunction of some narrow condition D with some environmental condition E. As a special case, a narrow mental condition is trivially composite, for it is the conjunction of itself with the environmental condition that holds in all cases whatsoever. C is prime if and only if it is not composite. The line of thought that began with the here-and-nowness of causation led to the conclusion that mental conditions are composite. That internalist line of thought is inconclusive, not least because it uses ill-defined notions of adding and subtracting conditions. The next section will show its conclusion to be false; many of the mental conditions which we attribute to each other in ordinary language are prime. It begins with a preliminary exploration of primeness, compositeness, and some related notions.
3.2 Arguments for Primeness
A broad mental condition entails various narrow conditions. Indeed, there is a strongest narrow condition which it entails, that is, a narrow condition which it entails and which entails every such narrow condition. To see this, let virtual-C be the condition which obtains in a case α if and only if C obtains in some case internally like α. Virtual-C is narrow because internal likeness is transitive and symmetric. C entails virtual-C because internal likeness is reflexive. Moreover, virtual-C entails every narrow condition which C entails; for if C entails a narrow condition D, and virtual-C obtains in a case α, then C obtains in some case β internally like α, so D obtains in β (since
C entails D), so D obtains in α (since D is narrow); hence virtual-C entails D. Thus virtual-C is the strongest narrow condition which C entails. When C is a broad mentalistic condition ascribed in natural language, internalists regard virtual-C as the purely mental reality underlying C.
In particular, when C is the condition that one knows p, they are tempted to identify virtual-C with the condition that one believes p, or the condition that one rationally believes p. Section 2.3 argued that those identifications are incorrect.
We can define the dual notion of the weakest narrow condition that entails C by substituting
'every' for 'some' in the definition of 'virtual-C'; it obtains in a case α if and only if C obtains in every case internally like α. However, the resulting condition will usually be impossible when C is broad. For what case α does the condition that one believes that tigers growl obtain in every case internally like α? Virtual-C, the strongest narrow condition which C entails, is the condition of interest to the internalist.
Given a condition C, there is also a condition—call it outward-C—which stands to the external as virtual-C stands to the internal. Outward-C obtains in a case α if and only if C obtains in some case externally like α. Just as virtual-C is the strongest narrow condition which C entails, so outward-C is the strongest environmental condition which C entails.
We can now identify narrow and environmental conditions of which a given condition, if composite, is the conjunction: they are virtual-C and outward-C respectively. If C is any conjunction of narrow and environmental conditions at all, then it is the conjunction of virtual-C
and environmental-C. We can prove that as follows. Let C be the conjunction D & E of a narrow condition D and an environmental condition E. Since C entails D, virtual-C entails D; similarly, outward-C entails E. Thus the conjunction of virtual-C and outward-C entails D & E, that is, C.
Conversely, C entails the conjunction of virtual-C and outward-C, whether or not C is composite.
Consequently, C, if composite, is the conjunction of virtual-C and outward-C. To argue that C is prime is in effect to argue that C can fail to obtain when both virtual-C and outward-C obtain.
How can we show that a condition C is prime? Suppose that C obtains in two cases α and β.
Consider a case γ internally like α but externally like β; we may assume that such a case is possible because otherwise that interdependence of the internal and the external would itself undermine the idea that they can be separated (see section 3.3 for more on this assumption). Now suppose that C is the conjunction of a narrow condition D with an environmental condition E. Then C obtains in γ.
For since C entails D, D obtains in α; since D is narrow, D also obtains in γ, which is internally like
α. Similarly, since C entails E, E obtains in β; since E is environmental, E also obtains in γ, which is externally like β. Since C
obtains whenever both D and E obtain, and they both obtain in γ, C obtains in γ, as required. Thus we can show that C is prime simply by exhibiting three cases α, β, and γ, where γ is internally like α
and externally like β, and C obtains in α and β but not in γ. We shall see below how to do that for most ordinary mental conditions. Conversely, the condition C is composite if no such triple of cases exists, for then C obtains in γ whenever both virtual-C and outward-C obtain in γ, so the conjunction of virtual-C and outward-C entails C, and the converse entailment is automatic. Thus it is necessary as well as sufficient for C to be prime that it obtains in two cases but not in a case internally like one and externally like the other.
A picture may help (Fig. 1). The horizontal axis represents total internal physical states; the vertical axis represents physical states of the external environment. The point representing γ is in the same position on the horizontal axis as the point representing α (because γ is internally like α)
and in the same position on the vertical axis as the point representing β (because γ is externally like
β).

Figure 1
The area between the two vertical lines represents a narrow condition; the area between the two horizontal lines represents an environmental condition. The rectangle formed by their intersection represents a composite condition. The area enclosed by the curve represents a prime condition.
A structural analogy may also clarify what is going on. Suppose that a property P is the conjunction of a colour property Co and a shape property Sh, and that both a black sphere and a white cube have P. Then a black cube also has P: it has Co because it is the same colour as the black sphere, which has Co, and it has Sh because it is the same shape as the white cube, which has Sh.
By contraposition, if a black sphere and a white cube have a property which a black cube lacks, then that property is not the conjunction of a colour property and a shape property.
Given a mental state S, how can we find three cases α, β, and γ of the required kind to show that the condition that one is in S is prime? We can construct them to a common pattern. We imagine circumstances in which S can be realized in just two ways, which need not be mutually exclusive. One is in S if and only if one is in S in either way 1 or way 2. Each way involves a channel with an internal and an external part; one is in S in way i if and only if both the internal and the external parts of way i are open (at this level of simplification, we may treat the condition that one is in S in way i as composite). In case α, both the internal and the external parts of way 1 are open but neither the internal nor the external part of way 2 is open; thus one is in S in way 1 although not in way 2; therefore one is in S. Case β reverses the two ways in status. In β, neither the internal nor the external part of way 1 is open but both the internal and the external parts of way 2 are open; thus one is in S in way 2 although not in way 1; therefore one is in S. In case γ, the internal part of way 1 but not the internal part of way 2 is open, because γ is internally like α, and the external part of way 2 but not the external part of way 1 is open, because γ is externally like
β; thus one is in S in neither way 1 (because its external part is not open) nor in way 2 (because its internal part is not open); therefore one is not in S. The relations between α, β, and γ ensure that the condition that one is in S is prime. This structure can be represented diagrammatically (Fig. 2).
Case Way Internal External Joint Result
9
9
9
9
α
1
8
8
8
2
8
8
8
9
β
1
9
9
9
2
9
8
8
8
γ
1 2

8

9

8

Figure 2
Thus, as a first example, we can argue that the condition that one sees water is prime. Let α
be a case in which one sees water normally with one's right eye. One's left eye receives light rays that by chance are like those it would receive from water, but they are all emitted by a waterless device just in front of that eye; however, a head injury prevents further processing of input from one's left eye. Let β be a case which differs from α by reversing the roles of the two eyes. In β, one sees water normally with one's left eye. One's right eye receives light rays that by chance are like those it would receive from water, but they are all emitted by a waterless device just in front of that eye; however, a head injury prevents further processing of input from one's right eye. Now consider a case γ internally like α and externally like β. In γ, a head injury prevents further processing of input from one's left eye, because it does so in α, and γ is internally like α. Equally, in γ, one's right eye does not receive light rays from water, because it does not do so in β, and γ is externally like β. Thus, in γ, neither eye both receives light rays from water and has its input to the brain subject to further processing.
Consequently, in γ, one does not see water. Yet, in α and β, one does see water. By the earlier argument, the condition that one sees water is prime. Obviously, for almost any x, the example can be modified to show that the condition that one sees x is prime; it is not the conjunction of a narrow condition and an environmental condition.
That the example exploits the binocularity of vision is inessential. We could make the same point by supposing that in α there is water on the right and gin (which looks just like water) on the left, and a brain lesion causes one visually to register only what is on the right. In β there is gin on the right and water on the left, and a brain lesion causes one visually to register only what is on the left; in the case γ internally like α and externally like β, there is gin on the right and water on the left
(as in β), and the brain lesion causes one visually to register only what is on the right (as in α).
Thus, given appropriate background conditions one sees water in α and β but not in γ. This example is consistent with monocular vision.
For an aural analogue, suppose that, in α, Mary emits sound waves only of frequency f while
John emits sound waves only of frequency g, and a brain lesion causes one aurally to register sound waves only of frequency f. In β, John emits sound waves only of frequency f while Mary emits sound waves only of frequency g, and a brain lesion causes one aurally to register sound waves only of frequency g. In the case γ internally like α and externally like β, John emits sound waves only of frequency f while Mary emits sound waves only of frequency g (as in β), and a brain lesion causes one aurally to register sound waves only of frequency f (as in α). Thus, given appropriate background conditions one hears Mary in α and β but not in γ. Examples of this type can be constructed for the other senses.
We can demonstrate the primeness of the condition that one believes that this screen flickers by substituting this screen for water in the first example. For we can assume that in α and β one's belief that this screen flickers concerns this screen only in virtue of one's visual link to this screen; in γ, since one fails to see this screen, one lacks the belief. The point generalizes to other object-dependent contents and other propositional attitudes.
Consider the condition that one believes that tigers growl. Let α be a case in which tigers inhabit the mountains while schmigers (which appear just like tigers) inhabit the jungle; one remembers one's encounters with tigers in the mountains but totally forgets one's encounters with schmigers in the jungle. One believes that tigers growl; since one has no recollection of schmigers, one does not believe that schmigers growl. Let β be a case in which tigers inhabit the jungle while schmigers inhabit the mountains; one remembers one's encounters with tigers in the jungle but totally forgets one's encounters with schmigers in the mountains. One believes that tigers growl; since one has no recollection of schmigers, one does not believe that schmigers growl. Now consider a case γ internally like α and externally like β. In γ, tigers inhabit the jungle while schmigers inhabit the mountains; one remembers one's encounters with schmigers in the mountains but totally forgets one's encounters with tigers in the jungle. One believes that schmigers growl; since one has no recollection of tigers, one does not believe that tigers growl. Thus the condition that one believes that tigers growl is prime.
We can make the example more vivid by supposing that one believes propositions by storing sentences in a language of thought which express them in a belief box, although it should be clear that nothing in the underlying structure of the example really requires a language of thought or a belief box. In each case, encounters with animals of a suitable appearance in the mountains cause one in a standard way to use a word T1 in one's language of thought (if at all) as a natural kind term for those animals. Encounters with animals of a suitable appearance in the jungle cause one in a standard way to use a word T2 in one's language of thought (if at all) as a natural kind term for those animals. One's language of thought also has a word G that means growl. In α, T1 means tigers and has the appropriate causal connections with tigers; one believes that tigers growl because one stores the sentence T1G in one's belief box. T2 does not mean tigers, because it lacks the appropriate causal connections with tigers; one does not store the sentence T2G in one's belief box.
β differs from α by reversing the roles of T1 and T2. In β, T2 means tigers and has the appropriate causal connections with tigers; one believes that tigers growl because one stores T2G in one's belief box. T1 does not mean tigers, because it lacks the appropriate causal connections with tigers; one does not store T1G in one's belief box. In γ, one does not store T2G in one's belief box, because one does not do so in α and γ is internally like α. Equally, in γ, T1G does not express the proposition that tigers growl, because T1 does not mean tigers, since T1 lacks the appropriate causal connections with tigers in β and γ is externally like β. Thus, in γ, neither T1G nor T2G both expresses the proposition that tigers growl and is stored in the belief box. We can legitimately assume that in none of the three cases does any sentence in the language of thought other than T1G
and T2G express the proposition that tigers growl. Consequently, in γ, one stores no sentence which expresses the proposition that tigers growl in one's belief box; one therefore fails to believe that tigers growl. Yet, in α and β, one does believe that tigers growl. Again, the point generalizes to other externally individuated contents and other propositional attitudes.
We can argue that epistemic conditions are also prime. The previous example might even suffice, for in some cases α and β of the specified kind one knows that tigers growl; in α, one fails to know that tigers growl because one fails to believe that tigers growl. However, it is more illuminating to pick an example in which the belief is held constant and what varies is its epistemic status. Let α be a case in which one knows by testimony that the election was rigged; Smith tells one that the election was rigged, he is trustworthy, and one trusts him; Brown also tells one that the election was rigged, but he is not trustworthy, and one does not trust him. Let β be a case which differs from α by reversing the roles of Smith and Brown; in β, one knows by testimony that the election was rigged; Brown tells one that the election was rigged, he is trustworthy, and one trusts him; Smith also tells one that the election was rigged, but he is not trustworthy, and one does not trust him. Now consider a case γ internally like α and externally like β. In γ, one does not trust
Brown, because one does not trust him in α, and γ is internally like α. Equally, in γ, Smith is not trustworthy, because he is not trustworthy in β, and γ is externally like β. Thus, in γ, neither Smith nor Brown is both trustworthy and trusted. We can legitimately assume that in none of the three cases does one have any other way of knowing that the election was rigged. Consequently, in γ, one does not know that the election was rigged. Yet, in α and β, one does know that the election was rigged. Thus the condition that one knows that the election was rigged is prime. Since the example does not turn on the specific content of the knowledge, it can be modified to show for almost any proposition p that the condition that one knows p is prime. Endless examples can be constructed to the foregoing pattern. Henceforth, mental conditions will therefore be assumed to be characteristically prime. They are not conjunctions of narrow conditions and environmental conditions. 3.3 Free Recombination
When we construct triples of cases α, β, and γ to establish the primeness of a mental condition, the possibility of a case like γ depends on the principle that given cases α and β, there is a case internally like α and externally like β. Call that principle free recombination. It allows us to treat the internal and the external in a sense as independent variables.
Free recombination is not wholly unproblematic. If the internal and the external are nomically connected, then γ might violate nomic constraints even though α and β do not. For example, if determinism holds and the external includes the past (as it must for the treatment of issues about reference), then the external nomically determines the internal. Although a nomically impossible case might not be metaphysically impossible, such a case would not show very much, for if mental conditions coincided with conjunctions of internal and external conditions across all nomically possible cases that would be a significant vindication of the internalist picture of the mind. Moreover, the internal and the external are constitutively interdependent in other physical ways too. They are supposed to cover mutually exclusive and jointly exhaustive spatial regions; thus the region occupied by one determines the region occupied by the other. When the spatiotemporal interface between the internal and the external is contoured differently in α and β, mismatches threaten the construction of γ. Variations in the physical state of one include variations in the shape of the region it occupies, and therefore constrain variations in the physical state of the other.2
Nevertheless, free recombination may still hold to a first approximation, just as colour and shape can be treated to a first approximation as independent properties of an object, even if its colour ultimately depends on its microscopic geometry. We might handle the interdependence of the internal and the external just noted by minor modifications of the framework, for example, by restricting what aspects of the past count as environmental. Furthermore, counterexamples to free recombination are really a problem for the attempt to separate the internal and external under attack in this chapter. It is therefore fair to assume recombination in criticizing that attempt.
Consider, for example, Jerry Fodor's claim, 'identity of causal powers has to be assessed across contexts, not within contexts' (1987: 35), which he uses in defence of an individualistic conception of the mental (he has subsequently changed his position in his 1994). The proposal is roughly that individuals have the same causal powers if and only if for every context c, they can do the same things in c. Of course, an individual's causal powers depend on its internal state, which must therefore be held fixed while the context varies. Thus a more precise formulation of
Fodor's proposal is that an individual in an internal state I in some context has the same causal powers as an individual in an internal state J in a possibly different context if and only if for every context c, an individual in I in c can do the same things as an individual in J in c. Suppose that in case α one is in internal state I α and context c α ; in case β one is in internal state I β in context c β .
Are one's causal powers the same in α and β? By Fodor's criterion, a necessary (but insufficient)
condition for sameness is that one can do the same things in I α in c β as one can do in I β in c β .
This comparison breaks down, independently of what one can do in any case, unless one can be in I
α in c β . But to be in I α in c β is to be in a case γ internally like α and externally like β, for internal likeness is sameness in one's internal state and external likeness is sameness in one's context. Thus the relevant comparisons can be made only if free recombination holds. Where recombination fails,
Fodor's test does not grant sameness of causal powers, no matter what one can do in any case.
Suppose, for instance, that any case internally like α and externally like β is discounted because it would violate the nomic constraints relative to which causal powers are being assessed; then one would not count as having the same causal powers in α and β. The same result follows if a case internally like α and externally like β is impossible because the spatio-temporal interface between the internal and the external is contoured differently in α and β. Yet these grounds for withholding the verdict of sameness of causal powers do not even mention what one can do; intuitively, they are inadequate. Fodor's test serves its purpose only if free recombination holds. Since his test is implicit in the internalist picture of mental causation, that picture requires free recombination. Thus an argument against the internalist picture can legitimately assume free recombination, for without it the picture fails anyway.
The dialectical position is similar for more general doubts about the distinction between the internal and the external. We should not assume without argument that subatomic physics will embody locality principles of a kind that would guarantee a clearcut distinction between those features which contribute to internal physical states and those which do not. The arguments for primeness are not restricted to mental conditions; they apply to other sorts of physical condition too
(see also section 3.7). We may therefore find unexpected difficulty in defining the initial set of unproblematically internal physical conditions. That would destabilize the very distinction between the internal and the external. Such destabilization is bad news for the internalist conception of the mental under attack in this chapter, for that conception depends on separating the contributions of narrow and environmental conditions, which makes only as much sense as the distinction between the internal and the external itself does. If the distinction is unclear, the externalist can still insist on the negative point that no clarification of it counts ordinary mental conditions as composite. The present conception of the mental does not require a clearcut distinction between the internal and the external; we merely grant such a conception to its internalist rivals for the sake of argument, and then show that, even so, mental conditions cannot be decomposed into narrow and environmental conditions as they envisage.
3.4 The Explanatory Value of Prime Conditions
Do concepts of prime conditions serve any theoretical purpose? In the examples that demonstrate primeness, what is the point of classifying case γ separately from cases α and β? This section argues that we need concepts of prime conditions for the same reasons for which we need concepts of broad conditions generally.
Consider seeing. What is the point of classifying a case in which one sees water separately from a case in which one is in exactly the same internal physical state but sees only a mirage? The difference may not matter for one's action at the next instant, if the action is itself individuated by its internal physical nature. If it were individuated broadly, we should still be wondering about the point of broad individuation. But our interest is not confined to action at the next instant—if there is one; if time is dense, there is not. One is thirsty; how likely is one to be drinking soon? Likely enough, if one sees water. Much less likely, if what one sees is a mirage. Even if drinking is individuated narrowly, its explanation in terms of the earlier state of the system involves the presence of water in the environment, not just the earlier internal physical state of the agent.
Concepts of broad mental conditions give us a better understanding of connections between present states and actions in the non-immediate future, because the connections involve interaction with the environment (see also Burge 1986b and Peacocke 1993 on broad explanations of action).
The need to think about connections between earlier mental states and later actions is largely a need to think about connections between mental states and actions separated by seconds, days, or years. The causal explanation of action is frequently concerned with the structure of the agent's deliberation. But deliberation frequently occurs some time before the moment of action. In deliberating, one assesses alternative courses of action in the light of one's beliefs and desires, decides which is best, and forms the intention to pursue it; one puts the intention into effect only when the time for action comes. How and whether one puts the intention into effect depend on one's interaction with the environment in the intervening period. At the moment of action, one may not even remember one's deliberations in any detail. To confine the explanation of action to the instant before action is to omit much of what makes action rational. Historical explanation is certainly not confined to the instant before action;
'Why did Napoleon invade Russia?' is not a question about his state an instant before the invasion began, after months of planning.3 Moreover, most actions take time; one cannot instantaneously eat an apple, write a letter, or go for a walk. Extended actions involve complex interaction with the environment.
Could we analyse each action into basic physical actions, and then explain each basic action in terms of the agent's internal state at the preceding instant? Conjoining those proximal explanations of the basic actions would not yield a good explanation of the original non-basic action. Suppose, for example, that we wish to explain why someone went for a walk. Perhaps we can analyse the walk into a sequence of steps. But for each step, the proximal explanation of his taking it will not mention what explains why he went for a walk: that he desired exercise.
For the reasons for which we need concepts of broad conditions, we need concepts of prime conditions. The relevance of seeing water now to drinking soon is not exhausted by the agent's internal state and the presence of water. Before one can drink the water, one must get oneself to it.
Typically, one will steer one's way by keeping the water in sight and making a complex series of adjustments to one's position in a feedback loop. The present coincidence of one's internal physical state with the state in which one would be if one saw the water from that perspective is not enough; the coincidence must continue until one reaches the water. The kind of causal relation in which one stands to something when one sees it often enables one to keep it in sight. By contrast, if the matching of internal state and external environment is mere coincidence, then there is no reason why it should continue.
We can find just this contrast in the cases which demonstrated the primeness of the condition that one sees water. Other things being equal, one can keep the water in sight with one's right eye in case
α and with one's left eye in case β; in case γ, one has no means of maintaining the match between internal state and external environment. The match might continue, but that would be good luck.
Even if it does continue, that is not seeing; whether one sees now does not depend like that on what happens in the future. Thus the need to understand the connection between present states and action in the non-immediate future gives us reason to classify case γ separately from cases α and β. To classify in that way is to use a concept of a certain prime condition.
We should not expect such considerations to yield a definition of seeing. As already noted, attempts to provide non-circular necessary and sufficient conditions for ordinary concepts have a miserable record of failure. The concept of seeing is the resultant of very many forces. The forces considered here make the concept of seeing a concept of a prime condition; they need not determine that condition uniquely.
The argument generalizes to other prime conditions. Sometimes, the content of a propositional attitude depends on a perceptual link to an object, as when one believes that this screen flickers; the foregoing considerations apply immediately. At other times, our thought of an individual or kind depends on a causal link independent of present perception. Nevertheless, such a link is typically renewable: it enables us to have further causal interactions with the individual or kind, or at least further causal dependencies on it if it no longer exists, for example, by finding out more about it and acting on that information—none of which implies that reference could be defined in terms of renewable causal links. Of the cases that demonstrated the primeness of the condition that one believes that tigers growl, such renewability is likely to be available in α and β
but not in γ. In each case, one can test one's attribution of growling by going to the places where
(some of) the creatures to which one attributes it were encountered; that takes one to the habitat of tigers in α and β and to the habitat of schmigers in γ. In encountering them there, one renews the causal link. If tigers really do growl while schmigers do not, one's belief is likely to survive in α and
β but not in γ (we may suppose that in each case the tigers or schmigers were not growling when encountered but looked disposed to growl). Thus the need to understand the connection between present states and action in the non-immediate future gives us reason to use concepts of conditions that are prime because the content constitutively depends on a causal link with an individual or kind.
We can extend the argument to knowledge in more detail, taking a hint from Plato. In the
Meno (97A-98A), Socrates raises a question about the value of knowledge. Knowing that this road goes to Larissa is useful to you if you want to go to Larissa. But merely believing truly that this road goes to Larissa seems to be equally useful to you, for you will get there just the same. Why should we value knowledge more than mere true belief? Socrates responds by a comparison with the statues of Daedalus, which run away unless they are tethered. True beliefs are liable to be lost, unless they are so anchored that they constitute knowledge.4
What does Plato mean? Surely he recognized that mere true beliefs can be held with dogmatic confidence, and knowledge lost through forgetting. But belief can also be sensitive to evidence. One can lose a mere true belief by discovering the falsity of further beliefs on which it had been essentially based; quite often, the truth will out. One cannot lose knowledge that way, because a true belief essentially based on false beliefs does not constitute knowledge. For example,
I might derive the true belief that this road goes to Larissa from the two false (but perhaps justified)
beliefs that Larissa is due north and that this road goes due north; when dawn breaks in an unexpected quarter and I realize that this road goes south, without having been given any reason to doubt that Larissa is due north, I abandon the belief that this road goes to Larissa. Since that true belief was essentially based on false beliefs, it did not constitute knowledge. The case is an obvious variation on Gettier's counterexamples to the analysis of knowledge as justified true belief.5
In other cases, a true belief not essentially based on false beliefs still fails to constitute knowledge, because misleading evidence against that true belief is rife in one's environment, although one happens to be unaware of it oneself. For example, I might correctly classify a dog by sight as friendly; in ordinary circumstances I might thereby come to know that it is friendly.
However, this one behaves in ways which, if observed, would justify the false suspicion that it is hostile. So far it happens to have behaved like that only when my back was turned, and I have not yet formed any such suspicion. But my true belief that it is friendly does not constitute knowledge, and could be lost at any moment. To know that it is friendly, I must not be surrounded by such misleading counterevidence, and my true belief must not be too vulnerable to this kind of overturning. The case is a variation on Harman's examples of the undermining of knowledge by evidence one does not possess (Harman 1973: 143-4 and 1980: 1645; see also Goldman 1976: 772-3).
Present knowledge is less vulnerable than mere present true belief to rational undermining by future evidence, which is not to say that it is completely invulnerable to such undermining. If your cognitive faculties are in good order, the probability of your believing p tomorrow is greater conditional on your knowing p today than on your merely believing p truly today (that is, believing p truly without knowing p).6 Consequently, the probability of your believing p tomorrow is greater conditional on your knowing p today than on your believing p truly today.7 Of course, profoundly dogmatic beliefs which are impervious to future evidence and do not constitute knowledge may be even more likely to persist than beliefs that are rationally sensitive to future evidence and do constitute knowledge, but then the subject's cognitive faculties are not in good order. Since the difference between your present knowledge and your present true beliefs matters for predicting your future beliefs, it matters for predicting your future actions, because they will depend on your future beliefs.
The evidence which may undermine mere present belief needs time to emerge. As argued in section 2.3, the difference between knowledge and belief can make a present psychological difference; for instance, knowledge excludes various kinds of irrationality that belief does not. If C
is the condition that one knows p, virtual-C can fail in several ways to be the condition that one believes p. However, the present argument concerns only delayed impact, not action at the 'next'
instant. We do not value knowledge more than true belief for instant gratification.
We should not expect to define knowledge in terms of persistent true belief, still less in terms of subsequent action. What the argument does suggest is that when a condition stated in noncircular terms (belief, truth, justification, causation, . . . ) fails to be necessary and sufficient for knowledge, that divergence will yield a divergence in implications for future action; the task of stating non-circularly a condition equivalent to knowledge with respect to implications for future action is no easier than the task of stating non-circularly a condition necessary and sufficient for knowledge. On the view defended in chapter 1, both tasks are impossible. Consequently, the mental state of knowing makes a distinctive contribution to the causal explanation of action.
These considerations apply to the cases that demonstrated the primeness of epistemic conditions. In α and β, one knows p by testimony, and one's belief in p is correspondingly stable; one has also been told p by someone untrustworthy whom one distrusts, but that does not make one's belief less stable, for it does not rest on that testimony. In γ, one believes p because one trusts the untrustworthy informant who tells one p; one distrusts the trustworthy informant who tells one p. One's belief is less stable, for in the long run one may recognize the untrustworthiness of the informant on whom one relies. That one may also recognize the trustworthiness of one's other informant is only partial compensation. The description of γ involves a specific threat to one's belief. The descriptions of α and β involve no such specific threat; although one might come to distrust the trustworthy informant, no reason has emerged why one should. On mildly cheerful assumptions about normal background conditions, there is at least some tendency for the truth on such matters to out, so one's belief in p is more stable in α and β than in γ. The need to understand the connection between present states and action in the non-immediate future gives us reason to use concepts of prime epistemic conditions.
3.5 The Value of Generality
Some may nevertheless claim that prime conditions are theoretically redundant. For let α be any case in which a prime condition C obtains, and D and E respectively the strongest narrow condition and the strongest environmental condition which obtain in α. Then it is plausible that the conjunction D & E entails C. For D completely specifies the internal physical state of the subject, and E completely specifies the physical state of the rest of the world, so, unless some physical relations fail to qualify as either internal or external (for example, for holistic reasons), D & E
completely determines the physical state of the world in α; and if the total state of the world supervenes on its total physical state, then D & E entails C. Although the assumptions just made are not uncontroversial, let us allow them for the sake of argument. Thus, in any particular case, all the consequences we want of a prime condition follow from a compound condition obtaining in that case. Why should our best theory bother with the prime condition?
Let F be the condition that one subsequently performs a certain action. Suppose that F
obtains in α; we want to know why. If the prime condition C makes F highly probable, given background conditions, we are tempted to cite C in explaining why F obtains. But D & E
presumably makes F certain, so why not cite D & E rather than C? Doesn't it give the real causal explanation?
The answer to the would-be rhetorical questions is this. Our best theory is intended to capture significant generalizations. The action would have been performed in many cases other than
α, in which D & E does not obtain; D & E is sufficient but nothing like necessary for F. A theory which relies on conditions like D & E may leave uncaptured a significant generalization relating F
to C. What has not been shown is that significant generalizations about prime conditions can be replaced by significant generalizations about compound conditions. Good explanations have an appropriate generality. If one cites a sufficient condition for the condition to be explained, or one near enough so for the purpose in hand, the purported explanation can nevertheless fail because the condition to be explained would still have obtained in the same way even if the cited condition had not obtained. For example, one can explain why someone died by saying that he was run over by a bus; the explanation becomes worse, not better, if one specifies that the bus was red, for its colour had nothing to do with his death. If all metals have a certain property, one will be unhappy with attempts to explain why gold has it which cite properties of gold not shared by other metals. Again, if a condition obtains necessarily, then to explain why it obtains by deriving it from conditions which obtain only contingently is to miss its modal generality (as conventionalist explanations characteristically do).8
Many features of the maximally specific condition D & E will be quite irrelevant to the obtaining of F. They will concern physical events that form no part of the causal chain between the agent's initial mental state and the final performance of the action. The agent would have performed the action anyway, even if those features had been different. Their inclusion is a defect in the explanation. A highly specific account may constitute a good explanation of how something happened without constituting a good explanation of why it happened.9
Reductionist strategies of explanation risk providing bad explanations by citing highly specific conditions and thereby missing the generality of the conditions to be explained. Successful reductions involve no loss of generality. Something common to all genuine instances of the given phenomenon is identified in lower-level terms. The present argument does not undermine the explanatory value of those reductions. But that value is not shared by explanations which use no such generalization about the phenomenon, and merely provide—or rather gesture towards—a maximally specific description in lower-level terms of the particular case at hand.10
Defences of narrow content often treat the total state of the external environment
('circumstances', 'context') as one component of the favoured explanations of action, the other comprising attitudes to narrow contents. On the face of it, this is to give up generality across different states of the environment. Yet such accounts do not allow the internal component of the explanation to be similarly unarticulated; the condition that one has a certain attitude to a certain
'narrow content' is supposed to be a general one, obtaining in a range of different cases. Once generality is acknowledged as an explanatory virtue, the question arises whether it can best be achieved by explanations that factorize in the envisaged way.
We need concepts of prime conditions to achieve appropriate generality in explaining action. Consider again the cases that demonstrated primeness: α and β were mutually symmetric; the best explanation of the agent's subsequent actions might well generalize across α and β, citing a condition that obtains in both. But if it also obtained in γ, the explanation would be weakened, for then the cited condition would not rule out a range of cases in which the agent's subsequent actions in α and β are much less likely (see section 3.4). Thus the cited condition should obtain in α and β
but not in γ, and therefore be prime.
Of course, generality is only one of many explanatory virtues. Some purported explanations achieve spurious generality by using disjunctive concepts. For example, if someone was crying because she was bereaved, it does not improve the explanation to say that she was crying because she was bereaved or chopping onions. But ordinary mental concepts of prime conditions (such as the concept of seeing) are not disjunctive (see also section
1.5). To argue that such concepts do not express genuine common properties on grounds of explanatory uselessness would be viciously circular, for such concepts give generality to our explanations. Unless they are already assumed not to express common properties, nothing has been done to undermine their apparent explanatory usefulness.
When we explain why a condition C obtains by citing a prior condition D, the generality of our explanation varies inversely with P[C|~D], the probability of C conditional on ~D; in that sense, we lack generality to the degree to which D fails to be necessary for C.11 The converse explanatory virtue is sufficiency, which varies with P[C|D], the probability of C conditional on D. We can combine these into a single explanatory virtue, the degree to which C is correlated with D. The higher the correlation, the better the answer to the question 'Does D obtain?' as a guide to the answer to the question 'Will C obtain?'; correlation is also a predictive virtue.
Correlation is itself only one of many explanatory virtues, but it is the one of present interest. A more rigorous framework for discussing it will be expounded, and then applied to the use of prime conditions in the causal explanation of action.
3.6 Explanation and Correlation Coefficients
In probability theory, the standard measure of correlation is the correlation coefficient, which takes values between +1 (perfect positive correlation) and -1 (perfect negative correlation;
Appendix 1 gives technical details). Formally, this coefficient measures the correlation between random variables, which themselves take numerical values. For present purposes, what matter are correlations between conditions. We can adapt the standard concept in a natural way to speak of the correlation coefficient of two conditions by associating each condition with its indicator random variable, which takes the value 1
when the condition obtains and 0 otherwise, and defining the correlation coefficient of two conditions as the correlation coefficient of their associated indicator random variables. The coefficient α[C,D] of correlation between the conditions C and D can then be calculated in terms of their probabilities and that of their conjunction. The result is a slightly unperspicuous formula:
P[C|D] – P[C] P[D]
√(P[C] (1 – P[C]) P[D] (1 – P[D]))
The probabilities here are objective properties (chances) of the conditions, for the degree to which two conditions are correlated is an objective matter. But they are not single-case probabilities, for conditions are general, like properties; they can obtain in many actual cases. The relevant probability space comprises both actual and merely possible cases; they will be circumscribed by a set of background conditions, which vary with the explanatory context.
One can easily check that C and D are positively correlated (ρ[C,D] > 0) if and only if the probability P[C|D] of C conditional on D exceeds the unconditional probability P[C] of C
(Appendix 1, proposition 2): one condition raises the probability of the other. The conditions are perfectly positively correlated (ρ[C,D] = 1) if and only if P[C|D] = 1 and P[C|~D] = 0 (Appendix 1, proposition 5): C is certain to obtain if D obtains and certain not to obtain if D does not obtain, so whether C obtains can be predicted with certainty on the basis of whether D obtains.
In explaining action, our concern is with imperfect positive correlations (0 < ρ[C,D] < 1).
For example, the condition that one will perform a certain action in the future may be imperfectly positively correlated with both the condition that one presently knows some proposition and the condition that one believes that proposition truly (we can treat the relevant desires as background conditions). The question was: with which of the latter two conditions is the former condition better correlated? More generally, which of two conditions D and E, both positively correlated with C, is more highly correlated with C? It turns out that ρ[C,D] ≤ ρ[C,E] if and only if
(P[C|D] – P[C])(P[C] – P[C|~D]) ≤ (P[C|E] – P[C])(P[C] – P[C|~E])
(Appendix 1, proposition 3). Thus both the degree to which D helps us to predict C (P[C|D] P[C], the degree to which D raises the probability of C) and the degree to which ~D helps us to predict ~C (P[C] P[C|~D], the degree to which ~D lowers the probability of
C) are relevant. In particular, if E raises the probability of C more than D does and ~E lowers the probability of C more than ~D does, then C is better correlated with E than with D (Appendix 1, proposition 4). A completely schematic example may clarify the picture. We can take the example of knowledge, and develop the account in section 2.4 of its explanatory value. Similar points can be made about other prime conditions. Let C be the condition that one will perform a certain action, D
the condition that one believes truly a proposition p, and E the condition that one knows p. The background conditions may include the agent's desires and other beliefs. Suppose that just three equiprobable possibilities have non-zero probability: one believes p truly and knows p and will perform the action; one believes p truly without knowing p and will not perform the action; one neither believes p truly nor knows p and will not perform the action. Hence P[C & D & E] = P[~C
& D & ~E] = P[~C & ~D & ~E] = 1/3. Thus it is certain that one will perform the action if and only if one knows p; P[C|E] = 1 and P[C|~E] = 0. The two conditions are perfectly positively correlated;
ρ[C,E] = 1. It is also certain that one will perform the action only if one believes p truly, so P[C|~D]
= 0. However, if one believes p truly, one may or may not perform the action, depending on whether one knows p; P[C|D] = 1/2. These two conditions are imperfectly positively correlated; calculation shows that ρ[C,D] = 1/2. Realistic examples have none of this simplicity. But since the correlation coefficient is a continuous function of the relevant probabilities, small enough changes in the latter make small changes in the former. Thus we can introduce some of the messy complexity of real life into the example and still have performing the action better correlated with knowing than with believing truly (ρ[C,D] < ρ[C,E]). In particular, this comparative ranking is consistent with non-zero probabilities for the possibilities that one performs the action without knowing p, with or without believing p truly (C & D & ~E and C & ~D & ~E) and that one fails to perform it while knowing p (~C & D & E). Although in most realistic examples we cannot expect to calculate exact probabilities or correlation coefficients, such comparative rankings can still be plausible. In very crude terms, if the probability of performing the action conditional on knowing p exceeds the probability of performing it conditional on believing p truly without knowing p by much more than the latter exceeds the probability of performing it conditional on failing to believe p truly, then performing the action is more highly correlated with knowing p than with believing p truly. A precise statement of the principle would take into account the prior probabilities of knowing p and believing p truly.
Action is often more highly correlated with belief or with true belief than with knowledge.
But not always. You see someone coming to your door; he is about to knock loudly. You are tempted not to reply. How would he react? You ask yourself, 'Does he know that I am in?' not,
'Does he believe that I am in?' If before knocking he does know that you are in, then he is unlikely to abandon his belief if you fail to reply; he will probably take offence. If before knocking he believes (truly) without knowing that you are in, then he is much more likely to abandon his belief if you fail to reply; he will probably not take offence. If before knocking he fails even to believe that you are in, then he is even less likely to take offence. Whether he would take offence is better predicted by whether he knows than by whether he believes. His taking offence is more highly correlated with knowing that you are in than with believing (truly) that you are in.
The point is not that knowing exceeds believing in implied degree of confidence; it need not.
I know many things without being prepared to bet my house on them. The example works even if the degree of confidence required for belief is stipulated to be the same as the degree of confidence required for knowledge. The visitor who merely believes (truly) when he knocks that you are in may be exceedingly confident that you are in, but abandon the belief when to his astonishment you do not reply, for he is even more confident that if you do not reply you are not in.12 But someone who knows that you are in has grounds that will not be undermined just by your failure to reply.
Clearly, all this is a matter of probability; if your visitor merely believes that you are in, he may retain the belief when you do not reply, and take offence; equally, if he knows that you are in, he may abandon the belief in a fit of self-doubt when you do not reply. Nevertheless, the probabilities are often as indicated above.
Consider a variation on an example used in section 2.4, this time involving the attribution of beliefs to non-human animals. How long would we expect a fox to be willing to search for a rabbit in the wood before giving up, assuming initially (a) that the fox knows that there is a rabbit in the wood, or (b) that the fox believes truly that there is a rabbit in the wood? In (b) but not (a), the fox's initial true belief may fail to constitute knowledge because the true belief is essentially based on a false one, for instance, a false belief that there is a rabbit in a certain hole in the wood. When the fox discovers the falsity of that belief, the reason for the search disappears. That will not happen in (a), because a true belief essentially based on a false one does not constitute knowledge. Thus, given plausible background conditions, more persistence is to be expected in (a) than in (b). In many such cases, lengthy persistence is better explained by initial knowledge than by initial true belief.
Sometimes the predictive difference between knowledge and true belief is mediated by the cultural significance of knowledge. A notorious criminal may try to eliminate all those who know that he killed the policeman, because they are potential witnesses against him in court. He will not bother to eliminate those who merely believe truly that he did it, because their confidence that he did it, however great, is no threat to him, given the rules of forensic evidence. If we want to predict whether someone will soon be fleeing for her life, 'Does she know that he shot the policeman?' is a better question than 'Does she believe that he shot the policeman?'. It is better even than the question 'Does she believe that she knows that he shot the policeman?' when flight is contingent on the criminal's behaviour and he believes that the testimony of anyone who mistakenly believes themselves to know that he did it will not stand up in court. The danger is knowing too much, not believing too much.
We can also use a schematic example to reinforce the conclusion of section 3.5, by showing in detail how a very specific condition strictly sufficient for the condition to be explained can nevertheless fail to be highly correlated with it. Let C be the condition that one will perform a certain action, D the very specific condition obtaining in the case at hand (for example, completely determining the agent's internal physical state and the physical state of the environment), and E the condition that one knows p. The background conditions include the agent's desires. Assume that D
is sufficient for both C and E, which leaves just five possibilities. Suppose that they have these probabilities:
P[C & D & E] = 1/10
P[C & ~D & E] = 3/10
P[C & ~D & ~E] = 1/10
P[~C & ~D & E] = 1/10
P[~C & ~D & ~E] = 4/10
Thus it is certain that one will perform the action if the specific condition obtains (P[C|D] =
1) and not certain that one will perform it if one knows p (P[C|E] = 4/5). However, one is much more likely to perform it if the specific condition does not obtain than if one does not know p (P[C|~D] = 4/9 > 1/5 =
P[C|~E]). The latter disparity in favour of E more than compensates for the former disparity in favour of D; calculation shows that ρ[C,D] = 1/3 < 3/5 = ρ[C,E]. Performing the action is better correlated with knowing p than with the strictly sufficient specific condition.
3.7 Primeness and the Causal Order
A high correlation does not guarantee a direct causal connection. When the condition that one knows p is highly correlated with the condition that one will perform a certain action, the reason might be that both the knowledge and the action are effects of a common cause, without the knowledge causing the action. What would it be for the knowledge not to cause the action?
Presumably, the condition that one knows would not be causally relevant in the right sense to the condition that one will perform the action. But then we should not focus on the former in explaining why the latter obtains. Does this seriously threaten the role of prime conditions in the explanation of action?
High correlations are an indispensable though fallible guide to causal structure. Where a high correlation misleads us into falsely postulating a causal connection, more detailed information about further correlations should correct our mistake. The high correlations between prime mental conditions and conditions on subsequent action constitute defeasible evidence for the causal effectiveness of the prime conditions. Higher correlations constituting a genuinely rival explanation would be needed to defeat that evidence.
Given deterministic laws, we might define a present condition D perfectly correlated with the condition C that one will perform the action, by stipulating that D obtains in a case α if and only if the total present state of the system (agent and environment) in α and the deterministic laws entail that one will perform the action. C and D obtain in exactly the same nomically possible cases. Thus, if the laws have probability 1, C and D are perfectly correlated (if P[C] > 0; otherwise ρ[C,D] is ill defined). D is not defined disjunctively. However, the definition of D unifies the cases in which D
obtains by what happens later (the performance of the action), not by the present state of the system.
In many contexts, such a correlation will not give us the kind of understanding we seek. It certainly does not give us what we need for purposes of prediction and control, but that is not quite the same thing. We seek a correlation between a condition given by a concept that unifies the cases in which it obtains in terms of the present state of the system and a condition given by a concept that unifies the cases in which it obtains in terms of the future state of the system; we are willing to sacrifice some degree of correlation in order to achieve such unification.
Even if we can replace the conditions conceived by folk psychology by conditions more highly correlated than they are with the condition that one subsequently performs the action, those new conditions will themselves be prime (as D is above), for reasons already indicated. Moreover, such explanations may well constitute refinements rather than refutations of the folk psychological explanations.
Discussions of broadness have tended to concentrate on intentional content. Since intentional content is a mental phenomenon, the causal efficacy of broad conditions, and specifically of prime conditions, can appear to require special pleading on behalf of the mental. It does not. The considerations of this chapter are not confined to the mental. For example, one can demonstrate in the style of section 3.2 the primeness of the condition that a ship is anchored to the seabed; it is not the conjunction of a condition on the internal physical state of the ship and a condition on the physical state of its external environment. Clearly, the condition that a ship is anchored to the seabed can be causally effective with respect to the ship's subsequent motion or rest.
Primeness is no bar to causal efficacy. It derives its significance from our interest in causal explanatory connections between states of objects and their subsequent behaviour (in the widest sense) after an interval long enough to permit intervening interaction with their environment. That is the normal case, not the exception, in causal explanation.
3.8 Non-Conjunctive Decompositions
The arguments in section 3.2 for the primeness of various mental conditions were not supposed to show that those conditions cannot be analysed somehow as functions of narrow and environmental conditions. A composite condition is the conjunction of a narrow condition with an environmental condition. How far do the problems identified in this chapter for conjunctive analyses generalize to analyses of other forms?
Conjunction is not the only truth-function. Disjunction is a simple alternative. Call a condition non-trivial if and only if it obtains in some cases but not in all. Then we can easily show, given free recombination, that the (inclusive) disjunction of a non-trivial narrow condition with a non-trivial environmental condition is always prime.13 Thus an argument for the primeness of a mental condition does not automatically show that it is not such a disjunction.
Of course, given free recombination, we should not expect a mental condition to be the disjunction of a non-trivial narrow condition with a non-trivial environmental condition. For if it were, and the environmental condition obtained in a case β, then for any case α, some case γ would be internally like α and externally like β. Since the environmental condition would obtain in γ, the mental condition would too (because a disjunction is entailed by its disjuncts); and thus the mental condition would be consistent with any non-trivial narrow condition whatsoever (sawdust in the head, . . . ), which is implausible. We could also argue that a mental condition C is not the disjunction of a narrow condition D and an environmental condition E by arguing that the contradictory condition ~C is prime, for if C were D V E then ~C would be ~(D V E), which is ~D
& ~E; since the contradictory of a narrow condition is itself narrow, and the contradictory of an environmental condition is itself environmental, ~D & ~E is composite. But the possibility that a mental condition is a more complex function of narrow and environmental conditions cannot be dismissed so easily.
Suppose, for example, that a mental condition C involves some kind of matching between one's internal state and the state of the external environment, although it does not fix those states separately. Then a simple hypothesis would be that C is a possibly infinite disjunction (D 1 & E 1 )
V(D 2 & E 2 ) V. . . , where D 1 , D 2 , . . . are narrow conditions, E 1 , E2, . . . are environmental conditions, and D i matches E i in the appropriate sense. Although each disjunct D i & E i is composite, disjunctions of composite conditions are not themselves usually composite. The required matching between internal and external states may occur in cases α and β separately without occurring in a case γ internally like α and externally like β; D i & E i and D j & E j may each entail matching while Di & E j does not. Equally, the matching may occur in γ without occurring in α or β, so the disjunction of composite conditions is not even the contradictory of a composite condition. Thus, more realistically prime conditions can be constructed as quite simple truth-functions of narrow conditions and environmental conditions.
A less unsophisticated proposal is that the mental condition requires some causal relation between one's internal state and the matching state of the external environment. That would only strengthen the argument for primeness. Of course, causal relations to the environment are often conceived as themselves on the external side, in which case they could be subsumed under the environmental conditions; but since they also implicate their internal relata, that conception of them endangers free recombination. The causal relation is better conceived as bridging the internal and the external.
Since a prime condition may be a truth-function or some subtler function of narrow and environmental conditions, the arguments for the primeness of various mental conditions do not show that our concepts of those conditions cannot be analysed into concepts of narrow and environmental conditions. The arguments for unanalysability are different; as in section 1.3, they advert to the long history of failed analyses, the lack of any good reason to expect analysability, and the availability of an alternative understanding of the mental. Nevertheless, the arguments for primeness are needed to fix the role of the mental in the causal explanation of action. For even if a mental condition C were a disjunction (D 1 & E 1 ) V(D 2 & E 2 ) V. . . of conjunctions of non-trivial narrow conditions D i with non-trivial matching environmental conditions, it would not follow that
C could be replaced in causal explanations by corresponding narrow and environmental conditions; a composite condition can be so replaced. Given free recombination, the strongest narrow and environmental conditions entailed by the disjunction are D1 VD 2 V. . . and E 1 V E 2 V. . .
respectively.14 But if (D 1 & E 1 ) V(D 2 & E 2 ) V . . . is prime, then it is not entailed by its composite consequence (D 1 VD 2 V. . . ) & (E 1 V E 2 V. . . ). Only the former requires one's internal state to match the state of the external environment. When the causal explanation depends on the primeness of (D 1 & E 1 ) V(D 2 & E 2 ) & . . . , as section 3.4 argued that it often will, the extractable narrow condition D1 VD 2 V. . . typically plays no explanatory role; it is a sort of epiphenomenon. What would give the narrow condition an explanatory role is compositeness, not analysability; the arguments for primeness therefore tell against such an explanatory role for the narrow condition.
If an explanation specified an environmental condition E j , we might combine that with the disjunction (D 1 & E 1 ) V(D 2 & E 2 ) V. . . to derive the corresponding specific narrow condition D
j (if E j were incompatible with E i for every i distinct from j), which then would play a distinctive explanatory role. But specificity is lack of generality; sections 3.5 and 3.6 showed how lack of generality can be an explanatory vice. An explanation at an appropriate level of generality will be neutral between the disjunct D j & E j and some alternative disjunct D i & E i , while still excluding
D i & E j and D j & E i ; the unspecific narrow condition . . . VD i V. . . V Dj . . . extractable from that explanation plays no distinctive explanatory role therein. Non-conjunctive decompositions of the mental into narrow and environmental conditions do not save the internalist picture of the mind, for they do not give narrow conditions the explanatory role which it predicts for them. 4 Anti-Luminosity
4.1 Cognitive Homes
One source of resistance to the conception of knowing as a mental state is the idea that one is guaranteed epistemic access to one's current mental states. According to that idea, one must be in a position to know whether one is in a given mental state, at least when one is attending to the question. When one asks oneself whether one knows a given proposition, one is not always in a position to know the answer. Section 1.2 responded to the objection by arguing that many uncontentious examples of mental states are the same as knowing in this respect. Nevertheless, some are inclined to think that a central core of mental states must be different. If S belongs to that core, then whenever one attends to the question one is in a position to know whether one is in S. In that sense, knowing would not be a core mental state. This chapter argues that there is no central core of mental states in that special sense. That conclusion will be a corollary of a far more general result about the limits of knowledge.
There is a constant temptation in philosophy to postulate a realm of phenomena in which nothing is hidden from us. Descartes thought that one's own mind is such a realm. Wittgenstein enlarged the realm to everything that is of interest to philosophy.1 That they explained this special feature in very different ways hardly needs to be said; what is remarkable is their agreement on our possession of a cognitive home in which everything lies open to our view. Much of our thinking—
for example, in the physical sciences—must operate outside this home, in alien circumstances. The claim is that not all our thinking could be like that.
To deny that something is hidden is not to assert that we are infallible about it. Mistakes are always possible. There is no limit to the conclusions into which we can be lured by fallacious reasoning and wishful thinking, charismatic gurus and cheap paperbacks. The point is that, in our cognitive home, such mistakes are always rectifiable. Similarly, we are not omniscient about our cognitive home. We may not know the answer to a question simply because the question has never occurred to us. Even if something is open to view, we may not have glanced in that direction.
Again, the point is that such ignorance is always removable.
The aim of this chapter is to argue that we are cognitively homeless. Although much is in fact accessible to our knowledge, almost nothing is inherently accessible to it. However, it is first necessary to sharpen the issue, to make it more susceptible to argument.
4.2 Luminosity As in previous chapters, it is convenient to frame the discussion in terms of conditions, which obtain or fail to obtain in various cases. A case depends on a subject (referred to by 'one'), a time (referred to by the present tense), and a possible world. Although conditions are expressed by sentential clauses, they are not propositions as the latter are usually conceived, just because they are open with respect to person, place, and perhaps other circumstances, too. We often use clauses like that, as in 'When it rains, it pours'. The domain of cases will be taken to include counterfactual as well as actual possibilities. Since the cases on which the arguments below rely are physically and psychologically feasible, issues about the bounds of possibility are not pressing.
Conditions are coarsely individuated by the cases in which they obtain: they are identical if they obtain in exactly the same cases. This raises a delicate issue when we say that someone knows that a condition C obtains, for C may be presented in different guises. Under which guise is C
known to obtain? If the condition that one is drinking water is the condition that one is drinking H 2
O, because they obtain in the same cases, it does not seem to follow that one knows that the condition that one is drinking water obtains if and only if one knows that the condition that one is drinking H 2 O obtains, for one may not know that water is H 2 O. Fortunately, in a context in which the only relevant presentation of the condition C is as the condition that one is F, knowing that C obtains can be identified with knowing that the condition that one is F obtains, which is in turn only trivially different from knowing that one is F. We can therefore often leave the reference to guises tacit.
We will also use the notion of being in a position to know. To be in a position to know p, it is neither necessary to know p nor sufficient to be physically and psychologically capable of knowing p. No obstacle must block one's path to knowing p. If one is in a position to know p, and one has done what one is in a position to do to decide whether p is true, then one does know p. The fact is open to one's view, unhidden, even if one does not yet see it. Thus being in a position to know, like knowing and unlike being physically and psychologically capable of knowing, is factive: if one is in a position to know p, then p is true. Although the notion of being in a position to know is obviously somewhat vague and context-dependent, it is clear enough for present purposes. The vagueness and context-dependence are in any case primarily the result of fudging in attempts to defend the views to be criticized below.
A condition C is defined to be luminous if and only if (L) holds:
(L) For every case α, if in α C obtains, then in α one is in a position to know that C obtains.
Since being in a position to know is factive, the converse of (L) holds for any condition C, so the conditional in (L) could just as well be a biconditional. The picture is that a luminous condition always shines brightly enough to make its presence visible. However, (L) does not say that C must obtain independently of our dispositions to judge that C obtains; for all (L) says, the condition might obtain in virtue of those dispositions.
A realm in which nothing is hidden is a realm in which all conditions are luminous. Our question is: what conditions, if any, are in fact luminous?
Some examples will help. Pain is often conceived as a luminous condition, in the sense that if one is in pain, then one is in a position to know that one is in pain (for a recent discussion see
McDowell 1989). The definition of luminosity gives scope to finesse some of the more obvious objections to claims of this kind. Thus people who lack the concept of pain—perhaps because their concepts carve up the space of possible sensations in an alternative way—and so never know that they are in pain, may still count as being in a position to know that they are in pain. Perhaps more primitive creatures are sometimes in pain without possessing any concepts at all; if they count as not even being in a position to know that they are in pain, a counterexample to luminosity might still be avoided by a stipulation that the subject of a case must be a possessor of concepts. Two claims of luminosity are implicit in the following passage from Michael Dummett
(1978: 131): It is an undeniable feature of the notion of meaning—obscure as that notion is—that meaning is transparent in the sense that, if someone attaches a meaning to each of two words, he must know whether these meanings are the same.2

Thus if two words have the same meaning for one, then one is in a position to know that they have the same meaning; if the words have different meanings for one, then one is in a position to know that they have different meanings. Dummett does not even make the qualification 'in a position to'; what of a subject who has never compared the two words? The two claims of luminosity are genuinely distinct, for the premise that whenever a condition C obtains one is in a position to know that C obtains does not entail the conclusion that whenever C does not obtain one is in a position to know that C does not obtain. If whenever one is awake one is in a position to know that one is awake, it does not follow that whenever one is not awake one is in a position to know that one is not awake (such asymmetries are discussed in Chapter 8). Strictly, of course, having the same meaning and having different meanings are contraries, not contradictories, since both require the words to be meaningful.
Other conditions for which luminosity is often claimed are those of the form: it appears to one that A. When there really is an oasis ahead, one may not be in a position to know that there really is an oasis ahead but, it is supposed, when there at least appears to one to be an oasis ahead, one must be in a position to know that there at least appears to one to be an oasis ahead.
4.3 An Argument Against Luminosity
Consider the condition that one feels cold. It appears to have about as good a chance as any non-trivial condition of being luminous. Nevertheless, there is reason to think that it is not really luminous at all. This section presents the argument, and section 4.6 generalizes it. Sections 4.4 and
4.5 discuss objections.
Consider a morning on which one feels freezing cold at dawn, very slowly warms up, and feels hot by noon. One changes from feeling cold to not feeling cold, and from being in a position to know that one feels cold to not being in a position to know that one feels cold. If the condition that one feels cold is luminous, these changes are exactly simultaneous. Suppose that one's feelings of heat and cold change so slowly during this process that one is not aware of any change in them over one millisecond. Suppose also that throughout the process one thoroughly considers how cold or hot one feels. One's confidence that one feels cold gradually decreases. One's initial answers to the question 'Do you feel cold?' are firmly positive; then hesitations and qualifications creep in, until one gives neutral answers such as
'It's hard to say'; then one begins to dissent, with gradually decreasing hesitations and qualifications; one's final answers are firmly negative.
Let t 0 , t 1 , . . . , t n be a series of times at one millisecond intervals from dawn to noon. Let
α i be the case at t i (0 ≤ i ≤ n). Consider a time t i between t 0 and t n , and suppose that at t i one knows that one feels cold. Thus one is at least reasonably confident that one feels cold, for otherwise one would not know. Moreover, this confidence must be reliably based, for otherwise one would still not know that one feels cold. Now at t i +1 one is almost equally confident that one feels cold, by the description of the case. So if one does not feel cold at t i +1 , then one's confidence at t i that one feels cold is not reliably based, for one's almost equal confidence on a similar basis a millisecond later that one felt cold is mistaken. In picturesque terms, that large proportion of one's confidence at t i that one still has at t i +1 is misplaced. Even if one's confidence at t i was just enough to count as belief, while one's confidence at t i +1 falls just short of belief, what constituted that belief at t i was largely misplaced confidence; the belief fell short of knowledge. One's confidence at t i was reliably based in the way required for knowledge only if one feels cold at t i +1 . In the terminology of cases, we have this conditional:
(1 i ) If in α i one knows that one feels cold, then in α i+1 one feels cold. Note that (1 i ) is merely a description of a stage in a specific process; it does not purport to be a general principle about feeling cold. Statement (1 i ) is asserted for each i from 0 to n 1, which is not to say anything about cases other than α0, . . . , α n.
Suppose that the condition that one feels cold is luminous. Then in any case in which one feels cold, the condition that one feels cold obtains, so one is in a position to know that the condition that one feels cold obtains, so one is in a position to know that one feels cold; since by hypothesis one is actively considering the matter, one therefore does know that one feels cold. We therefore have this conditional: (2 i ) If in α i one feels cold, then in α i one knows that one feels cold.
Now suppose:
(3 i ) In α i one feels cold.
By modus ponens, (2 i ) and (3 i ) yield this:
(4 i ) In α i one knows that one feels cold.
By modus ponens, (1 i ) and (4 i ) yield this:
(3 i+1 ) In α i+1 one feels cold.
The following is certainly true, for α0 is at dawn, when one feels freezing cold:
(3 0 ) In α0 one feels cold.
By repeating the argument from (3 i ) to (3 i+1 ) n times, for ascending values of i from 0 to n
1, we reach this from (3 0 ):
(3 n ) In α n one feels cold.
But (3 n ) is certainly false, for α n is at noon, when one feels hot. Thus the premises (1 0 ),
. . . , (1 n 1), (2 0 ), . . . , (2 n 1), and (3 0 ) entail a false conclusion. Consequently, not all of (1 0 ),
. . . , (1 n 1), (2 0 ), . . . , (2 n 1), and (3 0 ) are true. But it has been argued that (1 0 ), . . . , (1 n 1) and
(3 0 ) are true. Thus not all of (2 0 ), . . . , (2 n 1) are true. By construction of the example, one knows that one feels cold whenever one is in a position to know that one feels cold, so (2 0 ), . . . , (2 n 1)
are true if the condition that one feels cold is luminous. Consequently, that condition is not luminous. Feeling cold does not imply being in a position to know that one feels cold.
4.4 Reliability
Since (1 0 ), . . . , (1 n 1) are the key premises in the argument of the last section against luminosity, it is prudent to pause and reconsider the argument for (1 i ).
The argument applies reliability considerations to degrees of confidence. These degrees should not be equated with subjective probabilities as measured by one's betting behaviour. For assigning a very high subjective probability to a false proposition does not by itself constitute any degree of unreliability at all, in the sense relevant to knowledge. Suppose that draws of a ball from a bag have been made. The draws are numbered from 0 to 100. You have not been told the results; your information is just that on each draw i, the bag contained i red balls and 100i black balls. You reasonably assign a subjective probability of i/100 to the proposition that draw i was red (produced a red ball), and bet accordingly. You know that draw 100 was red, since the bag then contained only red balls, even if the proposition that draw 99 was red—to which you assign a subjective probability of 99/100—is false. That does not justify a charge of unreliability against you. Intuitively, for any i less than 100, your bets do not commit you to believing outright that draw i was red. Your outright belief may be just that the probability on your evidence that draw i was red is i/100, which is true. On draw 100, unlike the others, you can form the belief on non-probabilistic grounds that it was red. What incurs the charge of unreliability is believing a false proposition outright, not assigning it a high subjective probability.
What is the difference between believing p outright and assigning p a high subjective probability? Intuitively, one believes p outright when one is willing to use p as a premise in practical reasoning. Thus one may assign p a high subjective probability without believing p outright, if the corresponding premise in one's practical reasoning is just that p is highly probable on one's evidence, not p itself. Outright belief still comes in degrees, for one may be willing to use p as a premise in practical reasoning only when the stakes are sufficiently low. Nevertheless, one's degree of outright belief in p is not in general to be equated with one's subjective probability for p; one's subjective probability can vary while one's degree of outright belief remains zero. Since using p as a premise in practical reasoning is relying on p, we can think of one's degree of outright belief in p as the degree to which one relies on p. Outright belief in a false proposition makes for unreliability because it is reliance on a falsehood. The degrees of confidence mentioned in the argument for (1 i ) should therefore be understood as degrees of outright belief.
The argument for (1 i ) assumes that the underlying basis on which one believes that one feels cold changes at most slightly between t i and t i +1 , for otherwise an error in the belief at t i +1
might not threaten the reliability of the belief at t i . For example, if one believes inferentially at t i +1
and not at all inferentially at t i , false belief at t i +1 might well be consistent with knowledge at t i .
Apparent gradualness in the process does not guarantee gradualness at the underlying level (Wright
1996: 937). Nevertheless, we can choose an example in which there is gradualness at the underlying level too, and that will suffice for a counterexample to (L). The basis on which one judges that one feels cold need not change suddenly as one gradually becomes colder.
The invocation of reliability does not presuppose that whether one feels cold is independent of one's dispositions to judge that one does. Luminosity is often supposed to rest on a constitutive connection between the obtaining of the condition and one's judging it to obtain, but the effect of such a connection would be to make reliability less contingent, not to make unreliability consistent with knowledge.
The concept of reliability is notoriously vague. If one believes p truly in a case α, in which other cases must one avoid false belief in order to count as reliable enough to know p in α? There is no obvious way to specify in independent terms which other cases are relevant. This is sometimes known as the generality problem for reliabilism. Some have argued that the generality problem is insoluble and that reliabilist theories in epistemology should therefore be abandoned (Conee and
Feldman 1998). Let us concede for the sake of argument that the generality problem is indeed insoluble. It does not follow that appeals to reliability in epistemology should be abandoned. For the insolubility of the generality problem means that the concept of reliability cannot be defined in independent terms; it does not mean that the concept is incoherent. Most words express indefinable concepts; 'reliable' is not special in that respect. Irrespective of any relation to the concept knows, we clearly do have a workable concept is reliable; for example, historians sensibly ask which of their sources are reliable. The concept is certainly vague, but most words express vague concepts;
'reliable' is not special in that respect either. The concept is reliable need not be precise to be related to the concept knows; it need only be vague in ways that correspond to the vagueness in knows. No reason has emerged to doubt the intuitive claim that reliability is necessary for knowledge.
If one believes p truly in a case α, one must avoid false belief in other cases sufficiently similar to α in order to count as reliable enough to know p in α. The vagueness in 'sufficiently similar' matches the vagueness in 'reliable', and in 'know'. Since the account of knowledge developed in Chapter 1 implies that the reliability condition will not be a conjunct in a non-circular analysis of the concept knows, we need not even assume that we can specify the relevant degree and kind of similarity without using the concept knows. To suppose that reliability is necessary for knowledge is not to suppose that the concept knows can be analysed in terms of the concept is reliable, for it may be impossible to frame other necessary conditions without use of the concept knows whose conjunction with reliability is a necessary and sufficient condition for knowledge (see section 1.3).
We cannot expect always to apply a vague concept by appeal to rigorous rules. We need good judgement of particular cases. Indeed, even when we can appeal to rigorous rules, they only postpone the moment at which we must apply concepts in particular cases on the basis of good judgement. We cannot put it off indefinitely, on pain of never getting started. The argument for (1 i ) appeals to such judgement. The intuitive idea is that if one believes outright to some degree that a condition C
obtains, when in fact it does, and at a very slightly later time one believes outright on a very similar basis to a very slightly lower degree that C obtains, when in fact it does not, then one's earlier belief is not reliable enough to constitute knowledge. The earlier case is sufficiently similar to the later case. One's earlier reliance on C has too much in common with one's later reliance on it. The use of the concept is reliable here is a way of drawing attention to an aspect of the case relevant to the application of the concept knows, just as one might use the concept is reliable in arguing that a machine ill serves its purpose. The aim is not to establish a universal generalization but to construct a counterexample to one, the luminosity principle (L). As with counterexamples to proposed analyses of concepts, we are not required to derive our judgement as to whether the concept applies in a particular case from general principles.
Within the limits just explained, we can nevertheless see how a reliability condition on knowledge is consonant with the role of knowledge in the causal explanation of action, as described in sections 2.4 and 3.4. Knowledge is superior to mere true belief because, being more robust in the face of new evidence, it better facilitates action at a temporal distance. Other things being equal, given rational sensitivity to new evidence, present knowledge makes future true belief more likely than mere present true belief does. This is especially clear when the future belief is in a different proposition, that is, when the future belief can differ in truth-value from the present belief.
Some hunters see a deer disappear behind a rock. They believe truly that it is behind the rock. To complete their kill, they must maintain a true belief about the location of the deer for several minutes. But since it is logically possible for the deer to be behind the rock at one moment and not at another, their present-tensed belief may be true at one moment and false at another. By standard criteria of individuation, a proposition cannot change its truth-value; the sentence 'The deer is behind the rock' expresses different propositions at different times. In present terminology, it is logically possible for the unchanging condition that the deer is behind the rock to obtain at one moment and not at another. If the hunters know that the deer is behind the rock, they have the kind of sensitivity to its location that makes them more likely to have future true beliefs about its location than they are if they merely believe truly that it is behind the rock. If we are to explain why they later succeeded in killing the deer, given the foregoing situation, then it is more relevant that they know that the deer is behind the rock than that they believe truly that it is behind the rock.
The role of knowledge in the explanation of action exploits a kind of reliability. If at time t on basis b one knows p, and at a time t* close enough to t on a basis b* close enough to b one believes a proposition p* close enough to p, then p* should be true. The argument of section 4.3
allows us to pick t*, b*, and p* arbitrarily close to t, b, and p respectively. We can make the time interval between t i and t i +1 as short as we like. Since the relevant beliefs are in the obtaining of the same condition at those times, they will be correspondingly close. Since, as noted above, the beliefs can also be assumed to change in basis only gradually, their bases too will be correspondingly close.
A well-chosen example will verify (1 0 ), . . . , (1 n 1) and thereby provide the required counterexample to (L). A reliability condition on knowledge facilitates the role that knowledge does in fact play in the causal explanation of action. The appeal to such a condition does not depend only on brute intuition; it fits the independently motivated conception of knowing as a mental state.
4.5 Sorites Arguments
An obvious doubt arises about the argument of section 4.3. The reasoning is very reminiscent of that in sorites paradoxes. If with 0 hairs on one's head one is bald, and, for every natural number i, with i hairs on one's head one is bald only if with i + 1 hairs on one's head one is bald, then for any natural number n, however large, it follows that with n hairs on one's head one is bald. The reasoning may therefore be suspected of concealing a mistake just like the concealed mistake in sorites reasoning, whatever that is. Does the argument illicitly exploit the vagueness of
'feels cold' or 'know'?
The doubt can be made more specific. If the conclusion of the argument is false, then either not all the premises are true or the reasoning is invalid. Given (1 0 ), . . . , (1 n 1) and the straightforwardly true (3 0 ) as auxiliary premises, the argument derives (2 0 ), . . . , (2 n 1) from the supposed luminosity of the condition at issue and uncontested background assumptions, and then uses modus ponens to reach the straightforwardly false (3 n ). By reductio ad absurdum, luminosity is rejected. On any reasonable view of vagueness, this reasoning shows that the luminosity claim is less than perfectly true, given that (1 0 ), . . . , (1 n 1) are perfectly true. On some accounts, the rule of modus ponens fails to preserve less than perfect truth, because it sometimes leads from almost perfectly true premises to a conclusion that is not even almost perfectly true. But modus ponens should still preserve perfect truth. Within degree-theoretic semantics, a pseudo-conditional can be defined for which a conditional statement is perfectly true if and only if its consequent is at worst slightly less true than its antecedent (Peacocke 1981: 127). For present purposes, however, we can legitimately stipulate that the conditional to be used in the argument is of the more conventional kind for which the conditional statement is perfectly true if and only if the consequent is at least as true as the antecedent.
On other accounts, the rule of reductio ad absurdum is problematic because an assumption can have perfectly false consequences without itself being perfectly false, and therefore without having a perfectly true negation. Nevertheless, an assumption with perfectly false consequences is still less than perfectly true. Moreover, it is arguable that vagueness requires no revision of classical logic at all.3
For the purposes of this chapter, it would suffice to argue that the luminosity claim is less than perfectly true, for then it will have perfectly false consequences, which should discourage its application to philosophy. Thus the way for the defender of (perfect) luminosity to use the connection with sorites paradoxes is by arguing that not all of (1 0 ), . . . , (1 n 1) are perfectly true, and using the vagueness of some relevant term to explain away their plausibility. Of course, the argument for (1 i ) would remain to be addressed. Fortunately, however, the strategy can be tested more directly. For if (1 0 ), . . . , (1 n 1) are in effect the premises of a sorites paradox, then sharpening the relevantly vague expressions should make at least one of them clearly false, just as sharpening the term 'bald' by stipulating a cut-off point gives the conditional 'With i hairs on one's head one is bald only if with i + 1 hairs on one's head one is bald' a clearly false instance. Does the same happen here?
The relevantly vague expressions in (1 i ) are 'feels cold' and 'knows'. We can sharpen 'feels cold' by using a physiological condition to resolve borderline cases. Let us assume that the subject of the process has no access to the technology needed to determine whether the physiological condition obtains, and so is not in a position to know whether it does. These stipulations in no way weaken the argument for (1 i ). The considerations about reliability remain as cogent as before, for they were based on our limited powers of discrimination amongst our own sensations, not on the vagueness of 'feels cold'. It might be objected that the sharpening violates the intended meaning of
'feels cold'. However, that would not undermine the contrast between (1 i ) and the major premise of a sorites paradox. For any complete sharpening of 'bald' yields a clearly false instance of the principle 'With i hairs on one's head one is bald only if with i + 1 hairs on one's head one is bald', even if it violates the intended meaning of 'bald' by, for example, falsifying the converse downwards principle 'With i + 1 hairs on one's head one is bald only if with i hairs on one's head one is bald'. By definition, the sharpened term applies wherever the unsharpened term clearly applied and fails to apply wherever the unsharpened term clearly failed to apply; thus, on any sharpening, 'With 0 hairs on one's head one is bald' is true and 'With i hairs on one's head one is bald' is false for a suitably large number n, so for some number i the conditional 'With i hairs on one's head one is bald only if with i + 1 hairs on one's head one is bald' is false. Thus even the truth of (1 0 ), . . . , (1 n 1) on a sharpening of the vague terms that violates their intended meaning is enough to differentiate them from the premises of a sorites paradox.
The vague expression 'knows' remains. Sharpen it by tightening up its conditions of application: in the new sense it is not to apply in borderline cases for knowing in the old sense. It does not matter whether it applies in borderline cases of borderline cases for the old sense. If anything, this strengthens the argument for (1 i ), by building more into its antecedent. It does not help one to know whether one feels cold. Indeed, one need not even be aware of the stipulation about 'know', for it is made by the theorist, not by the subject.
The stipulations will not make 'feels cold' and 'knows' perfectly precise; no feasible sharpening could do that. Fortunately, perfect precision is not necessary. We need only sharpen those expressions enough to resolve the finitely many borderline cases that actually arise in the argument. Such sharpening has the opposite effect to that predicted by the assimilation of the argument against luminosity to sorites reasoning; (1 i ) becomes more not less plausible. The argument is not just another sorites paradox.
Nevertheless, the argument against luminosity might be thought to commit a subtler fallacy of vagueness. A defender of (2 i ) might take the vagueness of its constituent terms to be essential to its truth, and explain the plausibility of (1 i ) by assigning it a status short of perfect truth, while conceding that all of (1 0 ), . . . , (1 n-1 ) are true on some sharpenings, such as those considered above. The critic might take any sharpening that falsifies (2 i ) to violate the intended meanings of the vague terms, on the grounds that those meanings make (2 i ) analytic. On such a view, some unsharpened (1 i
) would be almost but not quite perfectly true, because its consequent would be almost but not quite as true as its antecedent. The reliability conditions adduced in favour of (1 i ) would be treated as almost but not quite perfectly correct. No justification has been provided for not treating them as perfectly correct, but let that pass. For the concession is in any case inadequate. The defender of (2 i
) must reject the following variation on (1 i ):
(1P i )If it is perfectly true that in α i one knows that one feels cold, then it is perfectly true that in α i+1 one feels cold.
For if (2 i ) is perfectly true, then the perfect truth of its antecedent implies the perfect truth of its consequent:
(2P i )If it is perfectly true that in α i one feels cold, then it is perfectly true that in α i one knows that one feels cold.
Statements (1P i ) and (2P i ) give an argument from the perfect truth of (3 i ) to the perfect truth of (3 i+1 ), and therefore from the uncontested perfect truth of (3 0 ) to the perfect truth of (3 n ); but the falsity of (3 n ) is uncon-tested.
The critic will presumably treat (1P i ) like (1 i ), claiming that for some number i, it can be perfectly true that in α i one knows that one feels cold, but slightly less than perfectly true that in α
i+1 one feels cold. Can there be such an i? If it is less than perfectly true that in α i+1 one feels cold, then there is a strict standard by which it is false in α i+1 that one feels cold; so, by that standard, in
α i+1 one is fairly confident of what is false, that one feels cold. If so, it is less than perfectly true that in α i one knows that one feels cold, if the reliability considerations are to be assigned any positive weight at all. To put the argument more directly, if it is perfectly true that in α i one knows that one feels cold, then it is perfectly true that one achieves the level of reliability necessary for knowing, and therefore perfectly true that in α i+1 one feels cold. Thus the objection to (1P i ) fails, and (1P 0 ), . . . , (1P n 1) suffice for an argument that not all of (2 0 ), . . . , (2 n-1 ) are perfectly true.
Invoking degrees of truth will not protect claims of perfect luminosity.
The point is reinforced by the observation that, once the luminosity assumption is dropped,
(3 n ) does not follow in classical logic from (1 0 ), . . . , (1 n 1) and (3 0 ). To see this, pick j and k such that 0 ≤ j < k< n; for each i, evaluate 'One feels cold' as true in α i if and only if i ≤ k, and otherwise as false; evaluate 'One knows that one feels cold' as true in α i if and only if i ≤ j, and otherwise as false. On this evaluation, (1 i ) is always true, for if the antecedent is true, then i ≤ j < k, so i + 1 ≤ k, so the consequent is true. Statement (3 0 ) is true because 0 < k. Statement (3 n ) is false because k <
n. We can extend this evaluation in the manner of the standard semantics for modal logic by treating cases like possible worlds and 'One knows that . . . ' like 'It is necessary that . . . '. The foregoing evaluation results if one defines a case α h to be accessible from a case α i if and only if | h i| ≤ k j, evaluates 'One knows that A' as true at a case α i if and only if 'A' is true at all cases accessible from
α i, and evaluates 'one feels cold' as before. Since a classical evaluation makes (1 0 ), . . . , (1 n 1)
and (3 0 ) true and (3 n ) false, the latter does not follow from the former in classical logic. Contrast the sorites paradox: for any n, 'With n hairs on one's head one is bald' does follow in classical logic from 'With 0 hairs on one's head one is bald' and conditionals of the form 'With i hairs on one's head one is bald only if with i + 1 hairs on one's head one is bald'. Once luminosity is denied, conditionals of the form (1 i ) generate no paradox.
Consistently with all this, we can postulate a more general phenomenon of which both vagueness and failures of luminosity independent of vagueness are special cases (Williamson 1994b and below). On such a view, the epistemological principles underlying (1 i ) are important for vagueness too, but it does not follow that all their manifestations involve vagueness. Indeed, the epistemological principles by themselves imply no specific theory of vagueness.
4.6 Generalizations
Section 4.3 argued that a specimen condition—that one feels cold—is not luminous. How far does the argument generalize?
The argument assumed nothing specific about the condition of feeling cold. It extends to the examples of supposedly luminous conditions mentioned in section 4.2. Since pain sometimes gradually subsides, for example, an argument against the luminosity of the condition that one is in pain can be modelled on the argument against the luminosity of the condition that one feels cold, without any structural revisions. It is not perfectly true that whenever one is in pain, one is in a position to know that one is in pain. That one is in pain does not imply that one is in a position to know that one is in pain. Similarly, two synonyms can gradually diverge in meaning, as a mere difference in tone grows into a difference in application. The structure of the argument against luminosity is just as before. That two words have the same meaning for one does not imply that one is in a position to know that they have the same meaning for one. Equally, that they have different meanings for one does not imply that one is in a position to know that they have different meanings for one. The argument also applies to the condition that things appear to one in some way, for example, that it looks to one as though there is a purple patch ahead. Cases in which things appear to one in some way can gradually give way to cases in which they do not appear to one in that way. That they appear to one in that way does not imply that one is in a position to know that they appear to one in that way.
The condition that things appear to one in some way is often supposed to be a paradigm of what is called response-dependence. Unfortunately, that phrase is used in many senses, few of them clear. If the response-dependence of a condition means only that whether it obtains has some constitutive dependence on whether one is disposed to judge that it obtains, then responsedependence does not entail luminosity, although non-luminosity does constrain what forms of dependence a condition can exhibit (see Williamson 1994b: 180-4 for the case of colour). But if
'response-dependent' is so defined that a response-dependent condition must be luminous, then the conditions that are standardly taken as paradigms of response-dependence are none of them response-dependent. Further applications of the argument involve conditions on one's knowledge. Since one can gain or lose knowledge gradually, we can use the argument to show that, for most propositions p, neither the condition that one knows p nor the condition that one does not know p is luminous. One can know p without being in a position to know that one knows p, and one can fail to know p without being in a position to know that one fails to know p. Chapters 5 and 8 respectively discuss these applications in more detail.
On what general features of a condition does the argument against luminosity depend? As it stands, it requires the condition to obtain in some cases and not in others. Thus it is ineffective against a condition that obtains in all cases or in none. Given a sufficiently restrictive understanding of what a case is, that might include the Cartesian condition that one exists, or even that one thinks.
It does not include the condition that one is thinking about one's existence, for one does that in some cases and not in others on any reasonable understanding of what a case is.
A condition that obtains in no case, the impossible condition, is automatically luminous; (L)
holds vacuously. Is a condition that obtains in every case, the necessary condition, luminous too? It is luminous as presented in a simple tautological guise, if cases are restricted to those in which the subject has the concepts to formulate the tautology. It is not luminous as presented in the guise of an a posteriori necessity, or an unproved mathematical truth, or if the cases include some in which one lacks appropriate concepts.
The argument also requires the possibility of a change from cases in which the condition obtains to cases in which it does not. Thus it would not be effective against an eternal condition, which always obtains if it ever obtains: for example, the condition that one felt cold at midnight on
New Year's Eve 1999. However, many eternal conditions, including that one, permit a change from cases in which one is in a position to know that they obtain to cases in which one is not in a position to know that they obtain. Such a condition cannot be luminous, for since it obtains in the earlier cases in which one is in a position to know that it obtains (because being in a position to know is factive), it also obtains in the later cases in which one is not in a position to know that it obtains
(because the condition is eternal). Thus an eternal condition is luminous only if one cannot change from being in a position to know that it obtains to not being in such a position. There are candidates for such conditions. For example, if a subject S is always in a position to know that she is S—which is not to say that she must know her own name—then anyone who is ever in a position to know that the condition that one is S obtains is always in a position to know that it obtains, because the only such person is S herself. Perhaps the argument could be extended to show that not even this condition is luminous, by consideration of a science-fiction process in which someone else is gradually replaced by S. However, no such extension will be attempted here. Such examples do not seriously threaten the idea that only trivial conditions are luminous.
The argument also assumes that one is considering the relevant condition under the relevant guise throughout the process. Consequently, it does not apply to some conditions on one's considerations. For example, let C be the condition that one is entertaining the proposition that it is raining, and let G be the guise under which C has just been presented here. To consider C under G
is to consider as such the condition that one is entertaining the proposition that it is raining; in so doing, one thereby entertains the proposition that it is raining, so C obtains. Thus one cannot gradually pass from cases in which C obtains to cases in which C does not obtain while considering
C under G throughout the process. Although one can gradually pass from cases in which C obtains to cases in which C does not obtain, one does not consider C under G in the late stages of the process. For all the argument shows, C is luminous: if one is entertaining the proposition that it is raining, then one is in a position to know that one is entertaining the proposition that it is raining. When one is entertaining a slightly different proposition p, one does not have a high degree of false belief that one is entertaining the proposition that it is raining; one has a high degree of true belief that one is entertaining p, since the belief derives its content from p itself. Thus the argument does not apply to examples in which one considers the condition only when it obtains. Such examples constitute a very minor limitation on the generality of the argument. In any case, we may conjecture that, for any condition C, if one can move gradually to cases in which C obtains from cases in which C does not obtain, while considering C throughout, then C is not luminous. The conjecture is discussed further in section 5.2.
Luminous conditions are curiosities. Far from forming a cognitive home, they are remote from our ordinary interests. The conditions with which we engage in our everyday life are, from the start, non-luminous. 4.7 Scientific Tests
To be physically and psychologically capable of knowing p is not sufficient, even given p, for being in a position to know p; one may be in the wrong place. Thus it does not follow from the non-luminosity of a condition that there are cases in which, although it obtains, one is not physically and psychologically capable of knowing that it obtains. Nevertheless, it is natural to ask, if one is not in a position to know in a case α that one then feels cold, how is one to know in some other case
β that in α one feels cold? Must or can there be such a case β? Analogous questions arise about other non-luminous conditions. The argument of section 4.3 leaves them open. It is consistent with, but does not entail, the possibility of a physiological technique by which one could subsequently discover that one had been feeling cold in α.
The hypothetical technique faces difficulties. Suppose that feelings of cold and hot are found generally to be correlated with a measurable physiological variable V. We must discover which values of V are associated with the condition that one feels cold. They include the values associated with the condition that one is in a position to know that one feels cold. But if they included only those values, the condition that one feels cold would be luminous, which it is not. We are not in a position to know which further values of V are associated with that condition. Our problem is that we cannot calibrate the physiological measurement of feeling cold. Even if measurements of V
were perfectly precise—which they will not be—they would not answer the original question. Attempts to measure other ordinary conditions face similar problems. Their non-luminosity prevents us from perfectly calibrating instruments to detect whether they obtain.
It might still be held to be metaphysically possible to find out whether one feels cold by the testimony of a literal or metaphorical deus ex machina. But it certainly cannot be assumed without argument that if an ordinary condition obtains in a case α, then in some possible case it is known that the condition obtains in α. Section 12.5 discusses the issue further.
4.8 Assertibility Conditions
The failure of luminosity impinges on Michael Dummett's arguments for an anti-realist theory of meaning, which explains meanings in terms of the conditions under which speakers are warranted in using sentences assertively, by contrast with a realist theory of meaning, which explains meanings in terms of the conditions under which sentences express truths. Of course,
Dummett's anti-realist does not make the extreme claim that every condition is luminous. All parties can accept that stone age men lived when the moon caused the tides, although they were not in a position to know that the moon caused the tides. The connection between luminosity and antirealism is a subtler one.
Dummett objects to the realist's truth-conditional theory of meaning that it violates a necessary connection between meaning and use. To understand a sentence is to know what it means. If, as Dummett's realist holds, meanings are truth-conditions, then speakers of a language know the truth-conditions of its sentences.4 Knowing the truth-condition of a sentence s cannot consist merely in being disposed to say something of the form 's is true if and only if P'; one must also understand the biconditional, and an infinite regress looms. In the basic case, one's knowledge of the truth-condition must be implicit. If one could always recognize whether it obtained, then knowledge of the truth-condition of s might consist in a willingness to assert s just when the truth-condition obtained. Dishonesty, shyness, and other complications are assumed to have been somehow filtered out. However, the realist insists that the truth-conditions of some sentences obtain even though no speaker of the language can recognize that they obtain. Dummett argues that the realist has no substantial explanation of what knowing that sentences have those truth-conditions consists in. The proposed remedy is that the meaning of a sentence should be given by its assertibility-condition rather than by its truth-condition. Thus to understand a sentence is to know its assertibility-condition, and this knowledge can consist in a willingness to assert the sentence just when the assertibility-condition obtains.5
The remedy fails if the objection to truth-conditional theories of meaning applies equally to assertibility-conditional theories of meaning. Thus Dummett's argument requires that when an assertibility-condition obtains, competent speakers of the language can recognize that it obtains. He acknowledges that requirement: 'The conditions under which a sentence is recognized as true or false . . . have, by the nature of the case, to be conditions which we can recognize as obtaining when they obtain' (1981: 586; compare 1991: 317 and 1993: 45-6). That is, when a recognition-condition obtains, we can recognize that the recognition-condition obtains. Dummett evidently intends the recognition-condition for the truth of a sentence to be its assertibility-condition, which yields the thesis that when an assertibility-condition obtains, we can recognize that it obtains. But recognizing is coming to know, and Dummett's 'can' may be glossed as 'is in a position to'. Thus Dummett requires assertibility-conditions to be luminous.
The argument against luminosity in section 4.3 generalizes to assertibility-conditions. For example, it can gradually cease to be assertible that it is raining. By the argument, that it is assertible that it is raining does not imply that one is in a position to know that it is assertible that it is raining. Even in the mathematical case, in which Dummett uses the proof-based intuitionistic semantics as a paradigm of an assertibility-conditional theory of meaning, proofs can be understood or forgotten gradually.6 By the argument, that one has a proof of a mathematical assertion does not imply that one is in a position to know that one has a proof of it. Thus assertibility-conditions have the very feature that is supposed to lay truthconditions open to Dummett's attack.7
An assertibility-conditional theory of meaning is likely to distinguish between canonical and non-canonical warrants for assertion, for example, between having a proof and having been told by a reliable informant that there is one. The recursive semantics will be formulated in terms of canonical warrants; a non-canonical warrant will be explained as an entitlement to believe that there is a canonical warrant. The argument applies whether or not 'warrant' is qualified by 'canonical'.
The anti-realist might reply that one's understanding of a sentence can consist in the fact that one is willing to assert it when and only when its assertibility-condition obtains, even if one does not know that it obtains. This reply concedes that assertibility-conditions fail Dummett's luminosity constraint; but then something is wrong with his argument for assertibility-conditional theories of meaning, which treats that constraint as binding.
A different reply is that if Dummett intends recognizability to be assertibility, then what he requires is only that when p is assertible, it is assertible that p is assertible. If misleading evidence sometimes warrants false assertions, then it might be assertible that p is assertible even when one is not in a position to know that p is assertible, so Dummett would not require assertibility-conditions to be luminous. This reply fails because the argument of section 4.3 can be generalized to an argument that no non-trivial condition obtains only when it is assertible that it obtains.8 Dummett presents his argument as a challenge to the realist to explain what knowledge of realist truth-conditions consists in. He does not claim to prove that the realist cannot meet the challenge, although he denies that it has been met so far. He allows that it might be met in some areas and not in others. But he assumes that the anti-realist can easily meet the corresponding challenge, to explain what knowledge of assertibility-conditions consists in. If the foregoing argument is correct, that assumption is false; the anti-realist faces the same sort of difficulty as the realist does. The contrast between truth-conditions and assertibility-conditions is off the point.
Both truth-conditional and assertibility-conditional theories of meaning find it hard to meet
Dummett's challenge because both truth-conditions and assertibility-conditions are non-luminous.
They share this feature with every other kind of non-trivial condition that might be offered as the meaning of a sentence. Since trivial conditions are not serious candidates for the meanings of most sentences, a serious X-conditional theory of meaning will find it hard to meet Dummett's challenge, for any X. If any systematic theory of meaning can be cast as X-conditional for some X, then any systematic theory of meaning will find it hard to meet Dummett's challenge. If 'hard' turns out to be
'impossible', then failure to meet the challenge eliminates truth-conditional theories of meaning only if it eliminates all systematic theories of meaning. The challenge embodies extreme demands on a theory of meaning. We should not assume the possibility of a reductive explanation of what knowledge of meaning 'consists in' of the kind that Dummett demands.
On an anti-realist picture, thought initially engages with conditions whose esse is their percipi; if it later finds its laborious way to conditions of greater depth, it must do so from the starting point of that cognitive home. Assertibility-conditions are pictured as forming a cognitive home in language. They do not. Thought engages with conditions whose esse is distinct from their percipi as soon as it engages with any conditions at all; even perception does. Trivialities aside, there is nothing else to engage with. We have no cognitive home. 5 Margins and Iterations
5.1 Knowing That One Knows
One can know something without being in a position to know that one knows it. We reached that conclusion using the form of argument developed in the previous chapter, for by a gradual process one can gain or lose knowledge. Similarly, one can know that one knows something without being in a position to know that one knows that one knows it, for by a gradual process one can gain or lose knowledge that one knows. This chapter explores such limits to our ability to iterate knowledge. They stem from our need of margins for error in much of our knowledge. Those limits make problems for common knowledge, in which everyone knows that everyone knows that everyone knows that . . . . Chapter 6 will apply the results to suggest a diagnosis of the paradox of the Surprise Examination and related puzzles.
We first consider in some detail a variant argument against the luminosity of the condition that one knows something. One can know without being in a position to know that one knows.
Looking out of his window, Mr Magoo can see a tree some distance off. He wonders how tall it is. Evidently, he cannot tell to the nearest inch just by looking. His eyesight and ability to judge heights are nothing like that good. Since he has no other source of relevant information at the time, he does not know how tall the tree is to the nearest inch. For no natural number i does he know that the tree is i inches tall, that is, more than i 0.5 and not more than i+0.5 inches tall.
Nevertheless, by looking he has gained some knowledge. He knows that the tree is not 60 or 6,000
inches tall. In fact, the tree is 666 inches tall, but he does not know that. For all he knows, it is 665
or 667 inches tall. For many natural numbers i, he does not know that the tree is not i inches tall.
More precisely, for many natural numbers i, he does not know the proposition expressed by the result of replacing 'i' in 'The tree is not i inches tall' by a numeral designating i. We are not concerned with knowledge of propositions expressed by sentences in which i is designated by a definite description, such as 'the height of the tree in inches', for he may not know which number fits the description. To know that the tree is i inches tall, Mr Magoo would have to judge that it is i inches tall; but even if he so judges and in fact it is i inches tall, he is merely guessing; for all he knows it is really i 1 or i+1 inches tall. He does not know that it is not. Equally, if the tree is i 1 or i+1 inches tall, he does not know that it is not i inches tall. Anyone who can tell by looking that the tree is not i inches tall, when in fact it is i+1 inches tall, has much better eyesight and a much greater ability to judge heights than Mr Magoo has. These reflections do not depend on the value of i. For no natural number i is the tree i+1 inches tall while he knows that it is not i inches tall. In this story, Mr Magoo reflects on the limitations of his eyesight and ability to judge heights. Mr Magoo knows the facts just stated. Consequently, for each relevant natural number i: (1 i )Mr Magoo knows that if the tree is i+1 inches tall, then he does not know that the tree is not i inches tall.
We could make the case for (1 i ) even stronger by reducing the interval of an inch to something much smaller, perhaps a millionth of an inch, but that should not be necessary. To make the conditional 'If the tree is i+1 inches tall, then he does not know that it is not i inches tall' as uncontentious as possible, we can read 'if' as the truth-functional conditional, the weakest of all conditionals. In effect, it merely denies the conjunction 'The tree is i+1 inches tall and he knows that it is not i inches tall'.
Suppose, for a reductio ad absurdum, that the condition that one knows a proposition is luminous: if one knows it, then one is in a position to know that one knows it. We may also assume that, in the case at hand, for each proposition p pertinent to the argument, Mr Magoo has considered whether he knows p. Consequently, if he is in a position to know that he knows p, he does know that he knows p. Thus:
(KK) For any pertinent proposition p, if Mr Magoo knows p then he knows that he knows p.
Statement (KK) is a special case of the general 'KK' principle that if one knows something then one knows that one knows it, but sufficiently restricted to avoid many of the objections to the latter (for some of which see Sorensen 1988: 242). For example, (KK) does not imply by iteration that if p is pertinent then Mr Magoo has every finite number of iterations of knowledge of p, for it has not been granted that if p is pertinent then so too is the proposition that he knows p. The pertinent propositions are just those that occur in the argument below, which form a strictly limited set. Statement (KK) is also immune to the objection that a simple creature without the concept knows might still know, but would not know that it knew, for Mr Magoo has the concept knows. We may legitimately assume that in the example Mr Magoo has been reflecting on the height of the tree and his knowledge of it so carefully that he has drawn all the pertinent conclusions about its height that follow deductively from what he knows; he has thereby come to know those conclusions. Let us consider a time at which that process is complete. We can therefore assume:
(C) If p and all members of the set X are pertinent propositions, p is a logical consequence of X, and Mr Magoo knows each member of X, then he knows p.
Of course, (C) is not justified by some general closure principle about knowledge. We often fail to know consequences of what we know, because we do not know that they are consequences.
Statement (C) is simply a description of Mr Magoo's state once he has attained reflective equilibrium over the propositions at issue, by completing his deductions. Since Mr Magoo's deductive capacities do not fully enable him to overcome the limitations of his eyesight and ability to judge heights, and he knows that they do not, (1 i ) remains true for all i.
By (KK), we can infer (3 i ) from (2 i ):
(2 i ) Mr Magoo knows that the tree is not i inches tall.
(3 i ) Mr Magoo knows that he knows that the tree is not i inches tall.
Now, let q be the proposition that the tree is i+1 inches tall. By (1 i ), Mr Magoo knows q ⊃
~(2 i ); by (3 i ), he knows (2 i ). Now, ~q is a logical consequence of q ⊃ ~(2 i ) and (2 i ).
Consequently, by (C), (1 i ) and (3 i ) imply that Mr Magoo knows ~q:
(2 i+1 ) Mr Magoo knows that the tree is not i+1 inches tall.
Consequently, from (KK), (C) and (2 i ) we can infer (2 i+1 ). By repeating the argument for values of i from 0 to 665, starting from (2 0 ) we reach the conclusion (2 666 ):
(2 0 ) Mr Magoo knows that the tree is not 0 inches tall.
(2 666 ) Mr Magoo knows that the tree is not 666 inches tall.
Statement (2 666 ) is false, for the tree is 666 inches tall and knowledge is factive. Thus, given the premises (1 0 ), . . . , (1 665 ), (2 0 ), (C), and (KK), we can deduce the false conclusion (2
666 ). Therefore, at least one of (1 0 ),. . . , (1 665 ), (2 0 ), (C), and (KK) is to be rejected. Premise (1 i
) has already been defended for all i, and (2 0 ) is obviously true. Consequently, either (C) or (KK)
is to be rejected.
Could we reject the assumption (C) that Mr Magoo's knowledge of the pertinent propositions is deductively closed? Assumption (C) is true if deduction is a way of extending one's knowledge: that is, if knowing p1, . . . , p n , competently deducing q, and thereby coming to believe q is in general a way of coming to know q. Call that principle intuitive closure. Since by hypothesis
Mr Magoo satisfies the conditions for the intuitive closure principle to apply, rejecting (C) is tantamount to rejecting intuitive closure. Robert Nozick's counterfactual analysis of knowledge is famously inconsistent with intuitive closure, but that is usually taken as a reason for rejecting the analysis, not for rejecting closure. Chapter 7 will provide arguments against counterfactual conditions on knowledge even of quite a weak kind; a fortiori they are arguments against Nozick's analysis.
A different objection occasionally made to intuitive closure is that even if one's premises are individually probable enough to count as known, one's conclusion might not be. For a logical consequence of several propositions may be less probable than each of them. If there are a million tickets in the lottery and only one wins, each proposition of the form 'Ticket i does not win' has a probability of 0.999999, yet the conjunction of all those propositions has a probability of 0. But that objection misconceives the relation between probability and knowledge; however unlikely one's ticket was to win the lottery, one did not know that it would not win, even if it did not (see also section 11.2). No probability short of 1 turns true belief into knowledge. Chapter 10 provides a very different understanding of the connection between knowledge and probability; it does not threaten intuitive closure.
The appeal to probability is in any case unavailing, for the argument can be reworked so that
(C) is applied only to single-premise inferences; if q is a logical consequence of p then q is at least as probable as p. For the considerations that supported (1 i ) also support:
(40) Mr Magoo knows that (for all natural numbers m (if the tree is m+1 inches tall then he does not know that it is not m inches tall) and (the tree is not 0 inches tall)).
Parentheses have been inserted to clarify scope. Now suppose, for some given i:
(4i) Mr Magoo knows that (for all natural numbers m (if the tree is m+1 inches tall then he does not know that it is not m inches tall) and (the tree is not i inches tall)).
By (KK) we have: (5i) Mr Magoo knows that he knows that (for all natural numbers m (if the tree is m+1
inches tall then he does not know that it is not m inches tall) and (the tree is not i inches tall)).
But Mr Magoo knows with certainty that if he knows a conjunction then the first conjunct is true and he knows the second. Thus:
(6i) Mr Magoo knows that (for all natural numbers m (if the tree is m+1 inches tall then he does not know that it is not m inches tall) and (he knows that the tree is not i inches tall)).
But (C) for single-premise deductions applied to (6 i ) gives:
(4i+1) Mr Magoo knows that (for all natural numbers m (if the tree is m+1 inches tall then he does not know that it is not m inches tall) and (the tree is not i+1 inches tall)).
The inference from (4 i ) to (4 i+1 ) is the required sorites step. If we iterate it for each i from
0 to 665, starting with (4 0 ), we reach:
(4666) Mr Magoo knows that (for all natural numbers m (if the tree is m+1 inches tall then he does not know that it is not m inches tall) and (the tree is not 666 inches tall)).
Statement (4 666 ) is false, for the tree is 666 inches tall. Thus the problem does not depend on applying (C) to deductions with more than one premise.
We should in any case be very reluctant to reject intuitive closure, for it is intuitive. If we reject it, in what circumstances can we gain knowledge by deduction? Moreover, the closely related anti-luminosity argument in section 4.3 did not assume closure in any form, which suggests that it is not the crucial premise. A different objection to the argument is that vagueness is somehow to blame. Section 4.5
discussed the same objection. Since the reasons for dismissing it are the same as before, they will not be repeated in detail here. The crucial point is that the premises of the argument are not justified by vagueness in 'know' but by limits on Mr Magoo's eyesight and his knowledge of them. In checking that (1 i ) remains true when 'know' is sharpened, we must be careful because 'know'
occurs twice in (1 i ), which ascribes to Mr Magoo knowledge that he could express in the words 'If the tree is i+1 inches tall, then I do not know that the tree is not i inches tall'. But if we sharpen
'know' by stipulating a high standard for its application, we make that conditional harder to falsify and therefore easier to know, because the only occurrence of 'know' in the sentence is negative.
Since (1 i ) was clearly true prior to the sharpening, it therefore remains true afterwards; we may legitimately assume that Mr Magoo has considered the sharpened sense of 'know'. That will not improve his eyesight.
The argument does not rely on the vagueness of 'know'.
Given (C) and (KK) as auxiliary premises, there is a valid argument with otherwise true premises and a false conclusion. Premise (C) is accepted. Therefore, (KK) is to be rejected. Mr
Magoo knows something pertinent without knowing that he knows it. Since (KK) follows from the assumption that the condition that one knows a proposition is luminous and background assumptions about Mr Magoo, the luminosity assumption is false. As in section 4.5, we can check that rejecting luminosity really does meet the difficulty by constructing a formal model of (C), (1 0
), . . . , (1 i ), . . . , (2 0 ) and the negation of (2 666 ) (Appendix 2 has more details).
Mr Magoo cannot identify the particular proposition for which (KK) fails. In general, one cannot knowingly identify a particular counterexample to the KK principle in the first person present tense. If I know that I both know p and do not know that I know p, I must know the first conjunct of that conjunction (since knowing a conjunction entails knowing its conjuncts), that is, I
must know that I know p, so the second conjunct is false, so I do not know the conjunction after all
(since knowledge is factive); Chapter 12 discusses this kind of argument in more depth. The point may help to explain the seductiveness of the KK principle.
The crucial features of the example are common to virtually all perceptual knowledge. Thus the argument generalizes to show that our knowledge is pervaded by failures of the KK principle.
To the informed observer, hearing gives some knowledge about loudness in decibels, and touch about heat in degrees centigrade. When I smell the milk I have some knowledge of the number of minutes since it was opened; when I taste the tea I have some knowledge of how many grains of sugar were put in. The point generalizes to knowledge from sources beyond present perception, such as memory and testimony. This is partly because they pass on inexact knowledge originally derived from past perception, partly because they add further ignorance themselves. How long was my last walk in steps? How long was someone else's walk, described to me as 'quite long'? In each case the possible answers lie on a scale, which can be divided so finely that if a given answer is in fact correct, then one does not know that its neighbouring answers are not correct, and one can know that one's powers of discrimination have that limit. The argument then proceeds as in the case of the distant tree.1 5.2 Further Iterations
We can generalize the argument of section 5.1 to further iterations of knowledge. We define them inductively. One knows0 p if and only if p is true. For any natural number k, one knowsk+1 p if and only if one knowsk that one knows p. To know1 p is to know p, to know2 p is to know that one knows p, and so on.
For any k, we can argue in parallel with section 5.1 that one can knowk something without being in a position to know that one knowsk it. For if we make suitably modified assumptions about the height and distance of the tree, Mr Magoo's eyesight, his knowledge of its limitations, and his powers of reflection, we can construct a situation in which these modified assumptions are true for a given k and all i:
(1 i k)Mr Magoo knowsk that if the tree is i+1 inches tall, then he does not know that the tree is not i inches tall.
(20k) Mr Magoo knowsk that the tree is not 0 inches tall.
(Ck) If p and all members of the set X are pertinent propositions, p is a logical consequence of X, and Mr Magoo knowskeach member of X, then he knowsk p.
Now make these two assumptions, for a given number i:
(2 i k) Mr Magoo knowsk that the tree is not i inches tall.
(KKk) For any proposition p, if Mr Magoo knowsk p then he knowsk+1 p.
Since knowingk+1 is equivalent to knowingk that one knows, (2 i k) and (KKk) entail:
(3 i k) Mr Magoo knowsk that he knows that the tree is not i inches tall.
Assumptions (1 i k), (3 i k), and (Ck) entail: k k
(2 i+1 ) Mr Magoo knows that the tree is not i+1 inches tall.
Suppose that the tree is in fact n inches high. By repeated application of the argument from
(2 i k) to (2 i+1 k), starting with 2( 0 k), we reach:
(2 n k) Mr Magoo knowsk that the tree is not n inches tall.
Since knowledgek is as factive as knowledge, (2 n k) is false. It was deduced from the assumptions (1 0 k), . . . , (1 n-1 k), (2 0 k), (Ck), and (KKk). By construction of the example, (1 0 k),
. . . , (1 n-1 k), (2 0 k), and (Ck) are true; therefore (KKk) is false. The replies to objections to the argument follow the pattern of section 5.1. Thus one can knowk something without being in a position to knowk+1 it. In other words, one can knowk something without being in a position to know that one knowsk it.
By contrast, some other objections to the general KK thesis do not threaten the corresponding generalization of (KKk) for k>1. For example, a simple creature might know that it was snowing without knowing that it knows that it was snowing because the latter, unlike the former, requires it to have a concept of knowledge, which it lacks. But if k≥2 and one knowsk p, then one knows something concerning knowledge and so has the concepts needed for knowingk+1 p.
Can we combine all finite iterations of knowledge? One knowsω p if and only if for every natural number k one knowsk p. Can we mimic the foregoing argument with ω in place of k? The premises of the reductio ad absurdum are these:
(1 i ω)Mr Magoo knowsω that if the tree is i+1 inches tall, then he does not know that the tree is not i inches tall.
ω
(2 0 ) Mr Magoo knowsω that the tree is not 0 inches tall.
(Cω) If p and all members of the set X are pertinent propositions, p is a logical consequence of X, and Mr Magoo knowsω each member of X, then he knowsω p.
(KKω) For any proposition p, if Mr Magoo knowsω p then he knowsω that he knows p.
For some n, the false conclusion is this:
(2 n ω) Mr Magoo knowsω that the tree is not n inches tall.
We might conclude on the basis of (1 0 ω), . . . , (1 n-1 ω), (2 0 ω), and (Cω) that Mr Magoo is a counterexample to (KKω). But that is the wrong moral to draw from this example, for (KKω) is a logical truth. If Mr Magoo knowsω p, then for each natural number k he knowsk+1 p, which is to knowk that he knows p, so he knowsω that he knows p. Thus (1 0 ω), . . . , ω
ω
ω
ω
(1 n-1 ), (2 0 ), and (C ) entail the false conclusion (2 n ) by themselves; one of them is false. Given a natural number k, we can construct an example in which (1 0 k), . . . , (1 n-1 k), and (2 0
k
) are true, by finite adjustments of the original case, which are clearly possible. An infinite adjustment turns out to be impossible. That does not undermine the morals drawn from the earlier versions of the argument. The crude point is that iterating knowledge is hard, and each iteration adds a layer of difficulty. Knowledgeω involves infinitely many layers of difficulty. Under some conditions, that amounts to impossibility. The next section develops these remarks more systematically.
Knowledgeω presents an interesting challenge to the generalized argument against luminosity in Chapter 3. Since it seems possible in principle to gain or lose knowledgeω, one might expect the argument to show that one can knowω without being in a position to know that one knowsω. But that conclusion is problematic. For if one knowsω p, then one knows each member of the set containing the proposition that one knowsk p for each natural number k; thus one knows the premises of a deductively valid argument to the conclusion that one knowsω p; one is therefore in some sense in a position to know that one knowsω p. The condition that one knowsω p seems to be luminous.
The argument might be challenged on the grounds that we are not in a position to make inferences with infinitely many premises. Indeed, even when an inference has only finitely many premises, it is not obvious that we are always in a position to know that which follows deductively from what we know. Only in a rather attenuated sense are we in a position to know all the consequences of the axioms of Peano Arithmetic. However, this response is not wholly satisfying, for the original argument against luminosity made no appeal to limits on powers of inference. If the condition that one knowsω p is luminous in the attenuated sense, why does the original argument not generalize to this case?
Knowingω may fail the gradualness requirement. Although someone can gain or lose knowledgeω, the change may necessarily be sudden. After all, it is the change from finitely many iterations of knowledge to infinitely many or vice versa; how could it be gradual? If knowingω does fail the gradualness requirement, it will be a hard state to enter or leave: how is one to jump instantaneously from the finite to the infinite or back again? The kind of common knowledge that we are supposed to have of conventions is usually defined in a way that requires us to knowω. For example, if John knows that Jane knows that John knows that Jane knows that John knows p, then
John knows that John knows that John knows p, if he is sufficiently reflective. Common knowledge would therefore be a convenient idealization, like a frictionless plane. The convenience need not be confined to the theoretician. Perhaps some everyday practices of communication and decision-making depend on a pretence that we have common knowledge.
That hardly comes as a surprise, for infinitely many of the propositions involved in common knowledge are too complex for humans to be psychologically capable of entertaining them. The present point is that the obstacles to entertaining them are not the only obstacles to knowing them.2
5.3 Close Possibilities
A reliability condition on knowledge was implicit in the argument of section 5.1 and explicit in sections 4.3 and 4.4. We have seen that such a condition generates an obstacle to iterating knowledge. We can better understand the nature of the obstacle by considering reliability in the more general context of a family of related notions such as safety, stability, and robustness.
Imagine a ball at the bottom of a hole, and another balanced on the tip of a cone. Both are in equilibrium, but the equilibrium is stable in the former case, unstable in the latter. A slight breath of wind would blow the second ball off; the first ball is harder to shift. The second ball is in danger of falling; the first ball is safe. Although neither ball did in fact fall, the second could easily have fallen; the first could not. The stable equilibrium is robust; the unstable equilibrium, fragile.
Reliability and unreliability, stability and instability, safety and danger, robustness and fragility are modal states. They concern what could easily have happened. They depend on what happens under small variations in the initial conditions. If determinism holds, it follows from the initial conditions and the laws of nature that neither ball falls. But it does not follow that both balls were in stable equilibrium, safe from falling, for the initial conditions themselves could easily have been slightly different. There is a danger in a given case that an event of type E will occur (for example, that the ball will fall) if and only if in some sufficiently similar case an event of type E does occur. The danger is slight if E occurs in very few sufficiently similar cases, but that is not the same as a distant danger, which occurs only in insufficiently similar cases. The relevant similarity is in the initial conditions, not in the final outcome (with the laws presumably held fixed). 'Initial' here refers to the time of the case, not to the beginning of the universe; I may be safe once I have caught the last flight out of the besieged city, even though I
could easily have been a few minutes late and missed the flight, in which case I should now have been in danger. Safety and danger are highly contingent and temporary matters. Just how similar the case must be to one in which an event of type E occurs for the term 'danger' to apply depends on the context in which the term is being used.3
Reliability resembles safety, stability, and robustness. These terms can all be understood in several ways, of course. For present purposes, we are interested in a notion of reliability on which, in given circumstances, something happens reliably if and only if it is not in danger of not happening. That is, it happens reliably in a case α if and only if it happens (reliably or not) in every case similar enough to α. In particular, one avoids false belief reliably in α if and only if one avoids false belief in every case similar enough to α. When the danger is a matter of degree, reliability involves a trade-off between the degree to which the danger is realized and the closeness of the case in which it is realized. A very high degree of realization in a not very close case and a lower degree of realization in a closer case both make for unreliability. The argument of section 4.3 involved such a trade-off, the closeness of case ai+1 to case α i compensating for the slightly lower degree of belief in α i+1.
On a topological conception, a point x counts as safely in a region R if and only if x is in the interior of R. If R is a region in a metric space defined by some real-valued measure of distance, x is in the interior of R if and only if for at least one positive real number c, every point whose distance from x is less than c belongs to R. More generally, x belongs to the interior of R if and only if x belongs to some open subset of R. There is no difficulty in iterating safety on this conception, for the interior of the interior of R is just the interior of R. Thus x is safely safely in R—that is, safely in the region that contains all and only the points that are safely in R—if and only if x is safely in R.
For if x is safely in R, then, for some non-zero distance c, every point less than c from x is in R, so every point less than c/2 from a point less than c/2 from x is in R, so every point less than c/2 from x is safely in R, so x is safely safely in R. On a corresponding conception of stability, a ball balanced in an indentation on the tip of the cone is in stable equilibrium, no matter how small and shallow the indentation.
For most practical purposes, the topological conception is not the one we need. The indentation must be of a certain size and depth for the ball not to be blown off by prevalent light breezes. To be safe on the top of a cliff, a young child must be at least three feet from the edge; it is not enough to be some positive distance or other, no matter how small, from the edge. Naturally, features of the context may contribute to fixing the margin for something to count as 'safe': for example, the severity of the consequences if one succumbs. Suppose that in some context a point is safely in a region if and only if every point less than three feet away is in the region. Then a point can be safely in a region R without being safely safely in R, for if the nearest point to x not in R is four feet away, x is safely in R but only two feet from a point two feet from a point not in R, so x is two feet from a point not safely in R, so x is not safely safely in R. The notion of what could easily happen behaves like the dual of safety; 'It could easily have been F' is close to
'It was not safely not F'. If it could easily have happened that an event of type E could easily have happened, it does not follow that an event of type E could easily have happened. For example, if exactly i humans were now alive, then it would be the case that it could easily have happened that exactly i+1 humans were now alive, but for some sufficiently large number k it would not be the case that it could easily have happened that exactly i+ k humans were now alive. If the actual number is i, then it could easily have happened that it could easily have happened . . . [k times] . . . that exactly i+ k humans were alive now, but it could not easily have happened that exactly i+ k humans were alive now. Thus iterations of 'it could easily have happened that' do not collapse.
The failures of knowledge to iterate observed in sections 5.1 and 5.2 are closely related to the failure of safety and reliability to iterate. One can be safe without being safely safe. In particular, one can be safe from error without being safely safe from error. One can be reliable without being reliably reliable. Since knowledge requires reliability, it is hardly surprising that one can know without knowing that one knows.
Safety is hard to iterate. For each natural number k, we can define x to be safelyk in R if and only if x is safely safely . . . [k times] . . . in R; x is safelyω in R if and only if x is safelyk in R for every natural number k. Suppose that for some fixed non-zero distance c, a point is safely in a region if and only if every point less than c from the point is in the region. In n-dimensional
Euclidean space, any two points are linked by a finite sequence of intermediate points each less than c from the next. Thus, unless R is the whole space, no point is safelyω in R. A luminous condition resembles a region every point in which is safely in it; consequently, every point in such a region is safelyω in it. In this instance, the only such regions of Euclidean space are the whole space and the null region. Similarly, we might think of a formula A as luminous in a system of epistemic logic if and only if A ⊃ KA is a theorem. The analogous feature would then be that A ⊃ KA is a theorem only if either A is a theorem (A corresponds to a region that is the whole space) or its negation is a theorem (A corresponds to the null region). Some natural systems have that property (see Appendix
2 and Williamson 1992a).
If R is the complement in full Euclidean space of a non-null bounded region (a sphere, for example), then for every natural number k some points are safelyk in R, even though no point is safelyω in R. But if R itself is a bounded region, then for some natural number k no point is even safelyk in R.
Euclidean space is not the only kind of space, of course. We should not assume without argument that the space of possibilities in which we are interested has a Euclidean structure. In principle, it might consist of several disconnected regions. Every point in one of those regions might be safely in it; consequently, every point in the region is safelyω in it. We also cannot assume that the required margin for safety c is uniform throughout the space. Prevailing winds may be stronger in some areas than in others. If they have a prevailing direction, one may be more easily blown from x to y than from y to x. Suppose, for example, that the closer one comes to a fixed point z 0 the more conditions favour stability. We can imagine contexts in which the required margin for safety at each point is its distance from z 0 . Thus, unless x is z 0 itself, any point y is easily accessible from x if and only if y is closer to x than z 0 is; x is safely in a region R if and only if every point easily accessible from x is in R. If we fix a margin for safety at z 0 too, every point has a margin for safety. But since z 0 is accessible from no point other than itself, every point in the region consisting of the whole space except for z 0 is safely in that region. Thus every point in that region is safelyω in it. Formally, such examples model non-trivial luminous conditions. Chapter 4
indicates that such a model would not be an accurate representation of knowledge.
Suppose that one is in a position to know only if one is safe from error in the relevant respect. We might try to deduce that, if a condition C can obtain without safely obtaining, then C
can obtain even if one is not in a position to know that C obtains, and therefore that C is not luminous. The idea would be that one is in a position to know that C obtains only if one is safe from error in believing that C obtains, which requires C to obtain safely. But that is too quick. To be safe from error in believing that C obtains is to be safe from falsely believing that C obtains. Thus in a case α one is safe from error in believing that C obtains if and only if there is no case close to α in which one falsely believes that C obtains. But even if in α one believes that C obtains and is safe from error in doing so, it does not follow that C obtains in every case close to α, for there may be cases close to α in which C does not obtain and one does not believe that it obtains. One can believe that C obtains and be safe from error in doing so even if C does not safely obtain, if whether one believes is sufficiently sensitive to whether C obtains. For example, one may be safe from error in believing that the child is not falling even though she is not safe from falling, if one is in a good position to see her but not to help her.
We need a further assumption to generate an argument against luminosity. If we combine the safety from error requirement on knowledge with limited discrimination in the belief-forming process and some plausible background assumptions, then we can deduce failures of luminosity.
That is not intended to formalize the anti-luminosity argument of Chapter 4, which depends on applying reliability considerations in a subtler way to degrees of confidence. The argument below models those considerations under highly simplified assumptions, which permit us to restrict our attention to the binary contrast between believing and not believing. It explains how the model falsifies luminosity and verifies a margin for error principle.
Suppose that for some parameter v, such as the height of the tree, for every case α, whether the condition C obtains in α depends only on the value v(α) of v in α. For example, C might be the condition that the tree is at most fifty feet high. We may assume for simplicity that v takes nonnegative real numbers as values. To be explicit:
(7) For all cases α and β, if v(α) = v(β) then C obtains in α if and only if C obtains in β.
In many examples, something like the following will hold, for some small positive real number c:
(8) For all cases α and non-negative real numbers u, if | uv(α)|< c and in α one believes that
C obtains then, for some case β close to α, v(β)= u and in β one believes that C obtains.
Less formally: if one has the belief, then one could easily still have had it if the parameter had taken a given slightly different value. One's belief is not perfectly discriminating. As already noted, iterations of close possibility do not collapse, so (8) does not entail that, if one has the belief, then one could easily still have had it if the parameter had taken a very different value. If one believes that the tree is at most fifty feet high, then one could easily still have believed that if the tree had been an inch higher, but not if it had been one hundred feet higher. Now assume a connection between knowledge and safety from error:
(9) For all cases α and β, if β is close to α and in α one knows that C obtains, then in β one does not falsely believe that C obtains.
In a more careful version of (9), we might qualify both 'know' and 'believe' by 'on a basis B'.
Knowledge on one basis (for example, seeing an event) is quite consistent with false belief in a close case on a very different basis (for example, hearing about the event). We might also relativize
(8) and (9) to a subclass of cases by restricting the quantifiers over cases to that subclass. The argument below will still go through if we modify the other propositions in the same way. For simplicity, we may ignore these complications.
We must also articulate a connection between knowing and being in a position to know. One is in a position to know something determined by the value of a parameter only if one can know without changing the value of the parameter:
(10) For all cases α, if in α one is in a position to know that C obtains then, for some case β, v(α)= v(β) and in β one knows that C obtains.
Statement (10) can be understood as a stipulation about the meaning of 'in a position to know'.
Finally, we assume that knowledge implies belief:
(11) For all cases α, if in α one knows that C obtains then in α one believes that C obtains.
From (7)-(11) and the assumption (L) that C is a luminous condition, we can deduce this:
(12) For all cases α and β, if | v(α) v(β)|< c then C obtains in α if and only if C obtains in β.
For suppose that C obtains in α and | v(α) v(β)|< c. By (L), in α one is in a position to know that C obtains. By (10), for some case α*, v(α)= v(α*) and in α* one knows that C obtains. Thus |
v(α*) v(β)|< c and, by (11), in α* one believes that C obtains. Consequently, by (8), for some case β* close to α*, v(β*) = v(β) and in β* one believes that C obtains. Since β* is close to α* and in α*
one knows that C obtains, by (9) in β* one does not falsely believe that C obtains. Therefore, C
obtains in β*. Since v(β*) = v(β), C obtains in β by (7). This shows that if| v(α) v(β)|< c then C
obtains in α only if C obtains in β. The converse is similar. Statement (12) is a disastrous conclusion if the parameter v can vary continuously in this sense:
(13) For all non-negative real numbers u, for some case α, v(α)= u.
For (12) and (13) entail:
(14) For all cases α and β, C obtains in α if and only if C obtains in β.
For any real number can be reached from any other in a series of arbitrarily short steps; there will be a sequence of non-negative real numbers, . . . , u n such that u 0 = v(α), u n = v(β), and, for all i, (0≤ i< n), | u i u i +1 |< c. By (13), there is a corresponding sequence of cases α0, . . . , α n such that v(α i)= u i for all i (0≤ i≤ n), where α0 = α and α n = β. Consequently, for all i (0≤ i< n), | v(α i) v(α
i+1)|< c, so, by (12), C obtains in α i if and only if C obtains in α i+1. By the transitivity of the biconditional, C obtains in α if and only if C obtains in β. Thus C obtains in all cases or in none; it is trivial. Contrapositively, if C is not trivial and the assumptions (7)-(11) and (13) hold, then C is not luminous.
If we like, we can replace the assumption (13) that the parameter v varies continuously by the weaker assumption that v varies in an approximately continuous way, in the sense that for every non-negative real number u there is a case α such that | uv(α)|< c/3.
When we drop the luminosity assumption (L), we can still deduce this consequence from
(7)-(11):
(15) For all cases α and β, if | v(α) v(β)|< c and in α one is in a position to know that C
obtains then C obtains in β.
The argument for (15) is like the argument for (12), but without the initial application of (L).
Statement (15) is a margin for error principle: one knows that a condition obtains only if it obtains in all cases in which the relevant parameter differs at most slightly in value. The disastrous conclusion (14) that C is trivial follows easily from (13), (15), and (L). Since (13) or a suitable weakening of it is usually uncontentious, the margin for error principle usually blocks luminosity.
The margin for error c may depend on the condition C. However, if conditions C 0 , . . . , C k satisfy (15) with respect to margins for error c0,. . . , c k respectively (for the same parameter v), then of course C 0 ,. . . , all satisfy (15) with respect to the minimum of c 0 , . . . , c k . But an infinite class of conditions each with a positive margin for error might not have a common positive margin for error, for the greatest lower bound of their individual margins for error might be 0. The argument of this section does not justify us in believing that every condition satisfies a principle like (15). The argument for (15) depends on the premise (8), that one's belief is not perfectly discriminating with respect to the underlying parameter. That assumption is not obvious, especially if the underlying parameter itself constitutively depends on one's belief, as some philosophers postulate for phenomena that they would classify as response-dependent. For example, they hold that the intensity of one's pain constitutively depends on one's beliefs about the intensity of one's pain. Such cases require the subtler argument of Chapter 4. Nevertheless, the assumptions
(7)-(11) and (13) are plausible in a wide range of cases; they explain margins for error and the failure of luminosity. In particular, if the condition that one knows (or that one knowsk) that C
obtains satisfies anything like (15) in place of C—naturally, with a parameter v that encodes enough about the case to determine whether one knows—then one will expect just the kind of difficulty in iterating knowledge that sections 5.1 and 5.2 observed. In particular, the crucial premises (1 i ) and
(1 i k) simply attribute to Mr Magoo knowledge of a contraposed instance of the margin for error principle (15). Every iteration requires a further margin. 5.4 Point Estimates
I might reach my belief about the height of a tree by estimating its height and then applying an upper bound on the inaccuracy of my estimate.4 For example, I estimate that the tree is 55 feet high, and come to believe that it is between 50 and 60 feet high, on the grounds that in these circumstances my estimate will not be out by more than 5 feet. In effect, I deduce (18) from the premises (16) and (17):
(16) I estimated that the tree is fifty-five feet high.
(17) My estimate of the height of the tree differs from the height of the tree by at most five feet.
(18) The tree is between fifty and sixty feet high.
Since I reached the conclusion (18) by inference from (16) and (17), I know (18) if and only if I know (16) and (17). Suppose that in these circumstances my estimates are never out by more than five feet, but are sometimes out by as much as five feet. Thus I might estimate that the tree is fifty-five feet high when it is in fact fifty feet high. In that case, it may appear, I can know (18) without satisfying any principle like (15). If the tree were even slightly less tall, my belief would be false.
The objection assumes that I can know that my estimate was out by at most five feet when it was in fact out by exactly five feet. That is in effect to assume that I need no margin for error in my knowledge of the accuracy of my own estimates. But my belief about my own accuracy has no more exact basis than my perceptual beliefs. If I were further away from the tree, or the light were worse, my estimate could be out by more than five feet. My judgement that my estimate of the height of this tree is out by at most five feet depends on my perceptual beliefs about my distance from the tree and the quality of the light. If I believe that my estimate is out by at most five feet, when in fact it is out by exactly five feet, then I could easily have formed that belief in slightly different circumstances in which my estimate was out by slightly more than five feet. Certainly the objector has not shown that one can know in the envisaged circumstances that one's estimate is out by at most five feet when in fact it is out by exactly five feet. There is almost no limit to how far out my estimates can be on a really bad day.
If my estimate is more than five feet out, I cannot know that it is at most five feet out, simply because knowledge is factive. A margin for error principle exhibits a further way in which my knowledge of the accuracy of my estimate depends on the accuracy of that estimate.
Naturally, we can imagine situations in which one knows exactly how far out one's estimate can be, just as we can imagine situations in which one knows exactly how tall the tree is. But those situations involve ways of knowing quite different from those we actually employ. The objector has done nothing to show that our actual methods enable us to dispense with margins for error. When C
is the condition that one's estimate is out by at most five feet, the premises of the argument for (15)
remain plausible. If one's knowledge of upper bounds on the inaccuracy of one's estimate of the height of the tree satisfies margin for error principles, then one's derivative knowledge of the height of the tree will satisfy a corresponding margin for error principle.
5.5 Iterated Interpersonal Knowledge
Iterating knowledge is hard, whether it is knowing about one's own knowledge or knowing about another's. Do margin for error principles make it too hard? Imagine Steven, Anna, and John looking at a tree. It is in fact fifteen feet high. They satisfy a margin for error principle with a margin of five feet:
(19) If Steven, Anna or John knows that the tree is at most n+5 feet high then the tree is at most n feet high. Statement (19) depends on their eyesight and visual judgement, the distance of the tree and the quality of the light. Steven judges out loud that the tree is at most twenty-five feet high. Anna hears him and judges out loud that Steven knows that the tree is at most twenty-five feet high. John hears Anna and Steven and judges that Anna knows that Steven knows that the tree is at most twenty-five feet high.
We might be tempted to argue that (19) implies the implausible restriction on common knowledge that John does not know that Anna knows that Steven knows that the tree is at most twenty-five feet high. For, by (19), if Steven knows that the tree is at most twenty-five feet high then it is at most twenty feet high. Given that Anna knows that conditional and that her knowledge is closed under deduction, if Anna knows that Steven knows that the tree is at most twenty-five feet high then Anna knows that it is at most twenty feet high. By (19), if Anna knows that the tree is at most twenty feet high then the tree is at most fifteen feet high. Consequently, if Anna knows that
Steven knows that the tree is at most twenty-five feet high then it is at most fifteen feet high. Given that John knows that conditional and that his knowledge is closed under deduction, if John knows that Anna knows that Steven knows that the tree is at most twenty-five feet high then John knows that it is at most fifteen feet high. By (19), if John knows that the tree is at most fifteen feet high then it is at most ten feet high. Consequently, if John knows that Anna knows that Steven knows that the tree is at most twenty-five feet high, then it is at most ten feet high. But by hypothesis the tree is fifteen feet high, so John does not know that Anna knows that Steven knows that the tree is at most twenty-five feet high.
The argument applies (19) to Anna's knowledge when she has heard Steven and to John's knowledge when he has heard Anna. Thus we must read (19) as describing the knowledge that
Steven, Anna, and John have once they have considered the others' judgements, not their unaided knowledge. That consideration might reduce the required margin for error.
The argument also tacitly assumes that John, Anna, and Steven have common knowledge of their final margins for error. If Anna does not know (19), because for all she knows Steven is much better at judging heights than he really is, then Anna may know that Steven knows that the tree is at most twenty-five feet high without herself knowing that it is at most twenty feet high. Similarly, even if both Anna and John do know (19), John may not know that Anna knows
(19); perhaps John does not know how well Anna is acquainted with Steven. So although we can argue, given deductive closure and Anna's knowledge of (19), to the conclusion that if Anna knows that Steven knows that the tree is at most twenty-five feet high then it is at most fifteen feet high, in those circumstances John may know (19) without knowing that conditional. Thus even if John knows that Anna knows that Steven knows that the tree is at most twenty-five feet high, John may not know that it is at most fifteen feet high, contrary to the objector's argument.
The objector assumes something like common knowledge of (19). Since margin for error principles undermine much purported common knowledge, an argument against them cannot legitimately assume common knowledge of (19). Steven, Anna and John do not merely have limited knowledge of the height of the tree; they have limited knowledge of the limits on their own and others' knowledge of the height of the tree. For they have limited knowledge of their eyesight and visual judgement, the distance of the tree, and the quality of the light. Their second-order knowledge may therefore be expected to satisfy further margin for error principles such as this:
(20) If Anna knows that Steven's margin for error for the height of the tree is at least i feet then Steven's margin for error for the height of the tree is at least i+ j feet.
But (19) does not entail that (20) holds when j = 5; the required value may be smaller. To make (20) rigorous, we should define just what it means to speak of someone's margin for error; that can be done in more than one way, but something like (20) will hold on all of them.
Steven, Anna, and John may spend so much time together that they know each other as judges of height as well as they know themselves. That reduces the intersubjective case to the intrasubjective case. Analogous considerations apply. Even if I conduct experiments to test my reliability, my knowledge of my own margins for error will remain inexact and subject to further margin for error principles. Indeed, the margin for error varies with the height of the tree—it is smaller for trees less than ten feet high—which is just what I am trying to judge. Moreover, since the width of the margin required to satisfy a margin for error principle depends on the vague concept of knowledge, we have no means of measuring margins for error accurately even given the height of the tree. Statement (19) does not entail that Anna cannot know that she knows that she knows that the tree is at most twenty-five feet high. In the simplest models of margin for error principles, we can treat those principles as common knowledge. We can then derive tight constraints on the number of iterations of knowledge.
Such models exhibit some of the main structural features of knowledge subject to margin for error principles. For every natural number n, n iterations of knowledge are insufficient for n+1 iterations.
But such models are not intended to be realistic; they embody many oversimplifications. To complain that they have unrealistic consequences is pointless. If we want to give a more realistic model of margins for error, we can do so in various ways discussed in section 5.3 (see also
Appendix 2). If the width of the margin varies from point to point, non-trivial conditions can be commonly known to obtain. Nevertheless, the crude moral remains: every iteration of knowledge, intrasubjective or intersubjective, adds a new layer of difficulty. These difficulties manifest themselves in some notorious paradoxes, such as the Surprise Examination, discussed in the next chapter. Section 10.5 generalizes margin for error principles from knowledge to non-factive cognitive notions, such as high probability on one's evidence. 6 An Application
6.1 Surprise Examinations
We can present a structural analogue of the argument in section 5.1 about the distant tree as a paradox.1 The Glimpse, as we may call it (#1 below), stands at one corner of a two-dimensional array of paradoxes, with the notorious Surprise Examination (###4) at the diagonally opposite corner. This connection will enable us to appreciate the relevance of the ideas developed in Chapter
5 to the Surprise Examination, and to suggest a solution. The term 'paradox' is not intended to imply insolubility.
Let n be the number of days in a school term.
#1. A teacher's pupils know that she rings all and only examination dates on the calendar in her office. At the beginning of term, the only knowledge they have of examination dates this term comes from a distant glimpse of the calendar, enough to see that one and only one date is ringed and that it is not very near the end of term, but not enough to narrow it down much more than that. The pupils recognize their situation. They know now that for all numbers i, if the examination is i+1
days from the end of term then they do not know now that it will not be i days from the end (0≤ i<
n). In particular, they know now that if it is on the penultimate day then they do not know now that it will not be on the last day. But they also know now from their glimpse of the calendar that it will not be on the last day. They deduce that it will not be on the penultimate day. They also know now that if it is on the antepenultimate day then they do not know now that it will not be on the penultimate day. They deduce that it will not be on the antepenultimate day. And so on. They rule out every day of term as a possible date for the examination. #2. Like #1, but it is the school caretaker, not the pupils, who catches a glimpse of the calendar. He tells them that the (one and only) ringed date is not very near the end of term. They know him to be a trustworthy observer and informant. In circumstances like these, reliable testimony is a channel for the communication of knowledge. Since the caretaker knows that the ringed date is not very near the end of term, the pupils know it too. They reason as in #1. #3. Like #2, but it is the teacher, not the caretaker, who gives the pupils information. She tells them just that the examination will not be very near the end of term. They know her to be a trustworthy informant. They reason as in #1.
#4. Like #3, but what the teacher tells the pupils is that, for all i, if the examination is i+1
days from the end of term then they do not know now that it will not be i days from the end (0 ≤ i <
n). What the teacher says is true, for the date she has fixed is not very near the end of term, she is the pupils' only source of information about the date, and what she has told them is only what they worked out for themselves in #1-#3: for all i, if the examination is i+1 days from the end then they do not know now that it will not be i days from the end, for they did not know that in #3, and they know no more about the date in #4 than they did in #3. The teacher knows all this, so she knows the truth of what she tells the pupils. As in #3, they know the truth of what she tells them. They reason as in #1.
##1. Like #1, but the pupils reason slightly differently. They know now that, for all i, if the examination is i+1 days from the end of term, they will not know then, on the morning of the examination, that it will not be i days from the end, for they know: it will not be very near the end of term; on no day not very near the end of term will their glimpse of the calendar and their memory of examinationless days enable them to know that it will not be the day after; they will not acquire further relevant information between now and then (by chance there has been a general tightening of school security). In particular, they know that if it is on the penultimate day, then they will not know then that it will not be on the last day. But they will know that then, for they will remember their glimpse of the calendar. They deduce that it will not be on the penultimate day. They also know that if it is on the antepenultimate day, they will not know then that it will not be on the penultimate day. But they will remember the previous conclusion. They deduce that it will not be on the antepenultimate day. And so on. Their conclusion is as in #1. ##2. The pupils' source is as in #2; they reason as in ##1.
##3. The pupils' source is as in #3; they reason as in ##1.
##4. The teacher tells the pupils what in ##1-##3 they worked out for themselves, that, for all i, if the examination is i+1 days from the end, they will not know then that it will not be i days from the end, just as in #4 she tells them what in #1-#3 they worked out for themselves; they reason as in ##1.
###1. Like ##1, but the knowledge the pupils use is that they will not know on the morning of the examination that it will be on that day. For, as in ##1, they will not know that it will not be the day after. They reason as in ##1, except that they need the additional premise that on the morning of the examination they will remember that it was not on any earlier day.
###2. The pupils' source is as in #2; they reason as in ###1.
###3. The pupils' source is as in #3; they reason as in ###1.
###4. The teacher tells the pupils what in ###1-###3 they worked out for themselves: that they will not know on the morning of the examination that it will be on that day. They reason as in
###1.
The twelve arguments differ in two dimensions. The source of knowledge in #1-###1 is perception; in #3-###3 and #4-###4 it is testimony; #2-###2 are mixed cases. The reasoning in #1#4 concerns present knowledge; in ##1-##4 and ###1-###4 it concerns future knowledge.
Nevertheless, the pupils' reasoning is unsound in every case, and the cases are similar enough to make this unlikely to be mere coincidence. A common error should be sought. More specifically, the pupils' reasoning does not seem to get any better as one moves from #1 to ###4. If they commit a fallacy in #1, they commit an analogous fallacy in ###4. Arguments ##1-##4 and ###1-###4 are the more complex cases, for the pupils are reasoning about future knowledge on the basis of present knowledge. The gap between what they know at the beginning of term and what they know later leaves room for mistakes that are not at issue in #1-#4, where the pupils reason about present knowledge on the basis of present knowledge. However, their reasoning is unsound in the simpler cases too: their error there is unlikely to have been corrected in the more complex ones. Thus any diagnosis of one or more of ##1-##4 and ###1-###4 which does not extend to #1-#4, although perhaps correct as far as it goes, should be presumed incomplete, not having identified the common error. Since
###4 is the usual paradox of the Surprise Examination, any adequate diagnosis of the Surprise
Examination should extend to the Glimpse (#1).
Some diagnoses of the Surprise Examination depend on the gap between what the pupils know at the beginning of term and what they know later, or at least on the epistemic possibility of such a gap (see Wright and Sudbury 1977 and Jackson 1987). Now some variant paradoxes with the same structure concern what different people know at the same time, rather than what the same people know at different times, so the diagnosis is best generalized as depending on any gap between cognitive standpoints (Sorensen 1988: 317-18). The underlying point is the same. In ruling out a last-day examination, the pupils assume that they will still know on the last morning that there will be a surprise examination, defined as an examination on a day when the pupils do not know in the morning that there will be an examination that day. But even if they know that at the beginning of term, they could lose the knowledge later. The point is not that memory is fallible; the pupils may be assumed to know that they will not forget the teacher's announcement. Rather, their memory of examinationless days would undermine their earlier knowledge of the truth of the announcement, like misleading evidence. For them, to know on the last day that there will be a surprise examination, when there has been none so far, is in effect to know 'There will be an examination tomorrow and we do not know that there will be an examination tomorrow'. Such knowledge is impossible, for their knowledge of the first conjunct is inconsistent with the truth of the second
(Chapter 12 discusses this kind of reasoning). Thus if the examination is on the last day, then the pupils will have lost their knowledge of the truth of the teacher's announcement by the last morning.
Moreover, they can know that conditional in advance. Thus the reasoning by which they rule out a last-day examination is unsound, for it assumes that knowledge will be retained in trying to refute a supposition on which it would not be retained.
The foregoing diagnosis can be elaborated in a variety of ways. There is clearly something to it. Nevertheless, it is incomplete. It yields no objection to the reasoning in the Glimpse, which is an equally unsound simplification of the reasoning in the Surprise Examination. What is wrong in the Glimpse is wrong in the Surprise Examination too, yet unmentioned in the diagnosis.
The analogy with the Glimpse reinforces other points about the Surprise Examination. The teacher's announcement corresponds to the claim in the Glimpse that if the examination is i+1 days from the end, then the pupils do not know that it is not i days from the end. Thus to say that the announcement is false or truth-valueless corresponds to saying that that attempted expression of the content of the pupils' knowledge in the
Glimpse is false or truth-valueless. To say that in the Surprise Examination the pupils cannot know in advance that the announcement is true corresponds to saying that in the Glimpse the pupils cannot know the limitation on their knowledge by reflecting on the poverty of their perceptual knowledge in that case. The obvious implausibility of these claims for the Glimpse points up their implausibility for the Surprise Examination too. Advance knowledge that there will be a test, fire drill, or the like of which one will not know the time in advance is an everyday fact of social life, but one denied by a surprising proportion of early work on the Surprise Examination. Who has not waited for the telephone to ring, knowing that it will do so within a week and that one will not know a second before it rings that it will ring a second later? Any adequate diagnosis of the Surprise
Examination should allow the pupils to know that there will be a surprise examination.
Other points about the Glimpse generalize to the Surprise Examination. For example, the problem does not depend on self-reference or ungroundedness in the teacher's announcement or the pupils' knowledge of it. For the problem in the Glimpse is not of that kind. Of course, a viciously self-referential twist can be given to the teacher's announcement; that does not mean that it must be. As noted above, claims like the teacher's are often true, and known to be so. The Glimpse is not a
Liar paradox, nor is the Surprise Examination on its natural reading.2 That vagueness is not to blame is even clearer in the Surprise Examination than in the Glimpse (see also sections 4.5 and
5.1).3
The paradox of the Glimpse depends on a concealed use of the KK principle. The pupils know now, at the beginning of term, that if the examination is on the penultimate day then they do not know now that it will not be on the last day. They also know now that it will not be on the last day. Let p be 'The examination will be on the penultimate day' and l be 'The examination will be on the last day'. The assumptions may therefore be formalized as K(p ⊃ ~K~ l) and K~ l respectively.
We must distinguish between the pupils' reasoning and the reasoning of the theorist who propounds the paradox. The theorist reasons about the pupils' reasoning. The theorist infers from the premises K(p ⊃ ~K~ l) and K~ l the conclusion K~ p. That inference is supposed to apply an assumption about the closure of the pupils'
knowledge under their deductions to some reasoning that they perform. The pupils' conclusion is
~p. But if their premises are p ⊃ ~K~ l and ~l, then their conclusion does not follow from their premises, for if the examination were on the penultimate day and they knew that it would not be on the last day, their premises would be true and their conclusion false. To deduce ~p from the conditional premise p ⊃ ~K~ l, they need the extra premise K~ l. But the theorist can apply the closure principle to that reasoning to infer that they know the conclusion ~p only on the assumption that they know the premises, and in particular that they know K~ l. In other words, the theorist can conclude K~ p only given the extra premise KK~ l. But the theorist's original premise was only K~
l. An instance of the KK principle is needed to bridge the gap. A corresponding instance is needed for each step of the backwards induction. Thus if the KK principle fails systematically for the reason explained in Chapter 5, the paradox of the Glimpse is dissolved.
Does that diagnosis of the Glimpse generalize to the Surprise Examination? The argument in the Surprise Examination can be reconstructed as using the KK principle; but it need not be.4 A
careful analysis shows that what the theorist really needs is the assumption that the pupils know on the first morning of term that they will know on the second morning that . . . they will know on the penultimate morning that they will know on the last morning the truth of the teacher's announcement. Similar iterations of knowledge are needed of the propositions that they will continue to be rational (deduce and come to know relevant consequences of what they know) and remember (know) on each morning before the examination that there has been no examination so far. The Glimpse too can be reconstructed with premises attributing the same number of iterations of knowledge to the pupils, but all concerning present knowledge, in place of the KK principle. The chief difference between the paradoxes is that in the Surprise Examination each iteration of knowledge involves a change in cognitive standpoint, whereas the Glimpse (like the KK principle)
involves a fixed cognitive standpoint. Fortunately, the underlying objection to the KK principle in section 5.3 shows how both ascriptions of iterated knowledge can easily fail. The iteration of knowledge operators leads sooner or later to falsity through a process of erosion resulting from the need for margins for error. This applies just as much when the knowledge operators refer to different cognitive standpoints. If anything, it applies with more force: knowledge of future knowledge is usually less exact than knowledge of present knowledge, so wider margins for error are needed. The same point applies when the cognitive standpoints vary in other respects: I usually know less about your knowledge than about my own. Although section 5.5 revealed some unexpected complexities in the erosion process as margins for error are iterated, the general point remains that multiple iterations of knowledge are far harder to achieve than is usually recognized. Since the argument of both the
Glimpse and the Surprise Examination make hidden assumptions of multiply iterated knowledge, the diagnosis from section 5.3 applies to both. The diagnosis passes the test that it should allow the pupils to know the truth of the teacher's announcement. Since knowledge operators do not iterate automatically, it is consistent to suppose that the pupils know at the beginning of term that there will be a surprise examination. If it were inconsistent, it would remain so if one ignored the distinction between what the pupils know at the beginning of term and what they know later: but it is provably consistent in the latter case. This result can be strengthened in various ways (see Appendix 2). This reinforces the earlier point that variation in cognitive standpoint is not essential to the problem, which can be raised and resolved even if it is axiomatic that the pupils never lose any knowledge, or if the argument is formulated with respect just to what they know at the start of term, as in #4. Since the pupils are more than one margin for error away from cases in which the teacher's announcement is false, they can know it to be true, but they are within a finite number of margins of such cases, so the number of iterations of knowledge they can have is limited.
Someone might object that the pupils can be idealized to a point where they do not need margins for error. Formally, 'the pupils know that' might be treated as an operator for provability from a fixed stock of assumptions in such a way that the KK principle holds. However, the paradox loses much of its interest under that idealization. In everyday cases, the pupils know that there will be a surprise examination, and this is what must be explained in the face of an apparent proof of its impossibility. In the idealized cases in which the KK principle holds, there is no presumption that the pupils can know that there is to be a surprise examination, so there is nothing to be explained.
The paradox of the Glimpse disappears in the same way under the assumption that the pupils have perfect eyesight. Although variation in cognitive standpoint may sometimes allow the pupils to know that there will be a surprise examination even when the KK thesis holds, this does not apply in #1-#4, and it is probably not what makes it obvious that they can have the knowledge in
##1-##4 and ###1-###4.
The margins for error around the pupils' knowledge are part of the message of the Surprise
Examination, not distracting noise. Some evidence for this is that the intuitive datum is not all-ornothing but a matter of degree. Most people are simply confused by the one-day version of the paradox, 'There will be an examination today and you do not know it'. The more days are involved, the clearer it is that the pupils can know the truth of the teacher's announcement. We can explain this effect by supposing that a small difference between actual pupils and idealized ones is magnified by each stage of the reasoning until it is clearly visible. That difference is the margin for error.
The Surprise Examination is closely related to a number of paradoxes in decision theory.5
The most prominent is Iterated Prisoner's Dilemma. Suppose that it is common knowledge for two agents that they are rational and face a series of ten thousand Prisoner's Dilemmas. Orthodox game theory 'proves' by a backward induction argument that they will never cooperate, for it is rational to cooperate at round i only if it is not then common knowledge that there is no round after i at which it is rational to cooperate. Defection dominates cooperation unless the latter makes future cooperation more probable. The result is highly unrealistic: ordinarily reasonable players are likely to cooperate for all but the last few rounds. Although such paradoxes will not be analysed in detail here, they all seem amenable to the present approach. In every case the argument assumes something like common knowledge of the agents' rationality: they are rational, both know that they are rational, both know that both know it, both know that both know that both know it, and so on. A
standard game-theoretic backward induction argument invokes a further iteration of this knowledge for each round of the game. But any players we can envisage have less than perfectly accurate epistemic capacities, and know only if they leave a margin for error. The usual erosion may be expected to continue until falsity is reached after finitely many iterations of 'both know that'. Real agents may typically lack strict common knowledge of their rationality. The inexactness of their knowledge permits ordinarily reasonable players to cooperate in Iterated Prisoner's Dilemma.6 6.2 Conditionally Unexpected Examinations The Surprise Examination and Iterated Prisoner's Dilemma differ slightly in structure. The pupils' argument assumes that there will be an examination on some day; if they did not assume this, a surprise examination could easily be held on the last day. The backward induction argument in Iterated Prisoner's Dilemma has no need to make the corresponding assumption: that the players will cooperate on some round. The purpose of this section is to eliminate the existential assumption from the Surprise Examination, and with it attempted solutions that treat it as essential.7
Consider first Mr Magoo. The existential assumption in the argument of section 5.1 is that the tree is some number of inches tall. However, this assumption is inessential to the argument.
Suppose that Mr Magoo loses sight of the tree and hears tree-fellers at work. The tree is in danger of being felled. He does not know whether it still exists. If it does not, count every proposition of the form 'The tree is i inches tall' as simply false. Mr Magoo still knows that if the tree is i+1 inches tall then he does not know that it is not the case that the tree is i inches tall. Moreover, he knows that it is not the case that the tree is 0 inches tall, for he knows that if it still exists it is much taller than that. Given the KK principle and the background assumptions, the inductive argument in section 5.1
still 'shows' for any number i that Mr Magoo knows that it is not the case that the tree is i inches tall, and in particular that it is not the case that the tree is 666 inches tall. That is absurd. In fact, the tree still exists and is 666 inches tall. The existential assumption is irrelevant.
Now consider #1, the Glimpse. Suppose that the teacher is known to ring all examination dates and her family's birthdays on the calendar. The pupils do not know whether the ring they glimpsed is round an examination date or a birthday. As before, their glimpse is enough to see that one and only one date is ringed and that it is not very near the end of term but not to narrow it down much more than that. They still know now that, for all i, if there is an examination i+1 days from the end of term then they do not know now that there will be no examination i days from the end.
They reason as before, concluding that there will be no examination. That is absurd, for we may stipulate that in fact the ring on the calendar does indicate an examination not very near the end of term. The existential assumption is irrelevant to the Glimpse. Similar remarks apply to the other paradoxes in the array. Suffice it to eliminate the existential assumption from ###4, the Surprise Examination. Call an examination conditionally expected if on the morning of it the pupils know that if there is an examination at all, it will be that day. The teacher announces just that there will be no conditionally expected examination. The pupils argue from this that there will be no examination at all. If there has been no examination by the last morning, the pupils will certainly then know that if there is an examination at all it will be that day. For simplicity, we may assume that at most one examination can be held each term; the assumption can be eliminated from a more rigorous presentation of the argument. Thus a last-day examination would be conditionally expected, and so will not occur. The pupils will know this on the penultimate morning, so if there has been no examination by then, they will then know that if there is an examination at all, it will be that day. Thus a penultimate-day examination would be conditionally expected, and so will not occur. And so on. The pupils conclude that there will be no examination. That is absurd, for we may stipulate that in fact quite some time before the end of term there will be an examination that is not conditionally expected.
The Surprise Examination does not depend on the existential assumption. Indeed, it is a stronger paradox without it. The original argument was in effect a reductio ad absurdum (relative to background assumptions) of the supposition that the pupils know on the first morning that they know on the second morning that . . . they know on the last morning that there will be an unexpected examination. It would be obviously irrational to treat such an argument as justifying confidence that there will not be an examination. The new argument uses the supposition that the pupils know on the first morning that they know on the second morning that . . . they know on the last morning that there will be no conditionally expected examination to show that there will be no examination at all. This does not contradict the supposition; if there is no examination, the teacher's announcement is vacuously fulfilled. If the teacher and the pupils' memory and rationality are sufficiently reliable, why should they not treat the argument as justifying confidence that there will be no examination? It would be a quite inadequate response to remind the pupils that if there is an examination on the antepenultimate day (for example), then they do not know on the first morning that they know on the second morning that . . . they know on the last morning that there will be no conditionally expected examination. For why should they not treat the argument as justifying confidence that the antecedent of that conditional is false? Similarly, if I believe that my great-uncle died long after I was born on the grounds that I remember talking to him, it would be a quite inadequate response to remind me that if he died before I was born then I do not remember talking to him.
The point can be seen from the pupils' perspective. In the original version, the passage of day after day with no examination gradually undermines the pupils' justification for believing the teacher's announcement. It does no such thing in the new version. That there will be no examination looks increasingly likely: but this is the increasing likelihood of one way for the teacher's announcement to be fulfilled. As day after day passes with no examination, the pupils appear to remain justified in believing the teacher's announcement.
Consider, for instance, the pupils' situation on the penultimate morning, with no examination so far. The teacher's announcement now reduces to 'There will be no conditionally expected examination tomorrow and there will be no conditionally expected examination today'. Since any examination tomorrow will be conditionally expected for the trivial reason that no examination can be held after the end of term, the first conjunct boils down to 'There will be no examination tomorrow'. An examination today is conditionally expected just in case the pupils know that if there is an examination at all, it will be today, which in the circumstances is just for them to know that there will be no examination tomorrow; thus the second conjunct boils down to 'Either there will be no examination today or we do not know that there will be no examination tomorrow'. In the circumstances, the pupils know the truth of the teacher's announcement if and only if they know:
(!) There will be no examination tomorrow and either there will be no examination today or we do not know that there will be no examination tomorrow.
In symbols, (!) has the form p & (q V ~K p). Suppose that the pupils know (!). Thus they know its first conjunct; they know that there will be no examination tomorrow. Moreover, the second conjunct of (!) is true; either there will be no examination today or they do not know that there will be no examination tomorrow. By disjunctive syllogism, there will be no examination today. Thus if there is an examination today, the pupils do not know (!) and therefore do not know the truth of the teacher's announcement. However, (!) is not intrinsically unknowable. It follows logically from the straightforward conjunction 'There will be no examination tomorrow and there will be no examination today'. In the epistemic logic KT (see Appendix 2), K(p & (qV ~K p))
entails p & q and is entailed by K(p & q); (!) might be called a contingent blindspot, or a contingently Moorean proposition. If the pupils knew the conjunction 'There will be no examination tomorrow and there will be no examination today', then they would know (!) and therefore the truth of the teacher's announcement. It is not illogical for the pupils to suppose themselves to know (!) in the way in which it would be illogical for them to suppose that they know 'There will be an examination today and we do not know that there will be an examination today' on the last morning of the original Surprise Examination.
Suppose that the very reliable teacher announces 'There will be no conditionally expected examination' at the beginning of a two-day 'term' during which there is in fact no examination. It is quite coherent to suppose that at the beginning of term the pupils know that they know the truth of the announcement, know that they know (!), and therefore know that there will be no examination.
Nor is any incoherence introduced when the number of days in term and the number of iterations of knowledge is increased, provided that there is no examination. It just becomes ever more implausible that the pupils have the ever greater number of iterations of knowledge of the truth of the announcement needed to rule out its non-vacuous truth. This is precisely the erosion effect that margin for error principles predict.
Consider again Mr Magoo. Here the new version of the argument shows that if Mr Magoo has enough iterations of knowledge of (C), instances of (1 i ), and some upper bound on the height of the tree (given its continued existence), then the tree does not exist and he knows it. But even if it does not exist, Mr Magoo cannot know that merely by reflecting on the limitations of his eyesight and ability to judge heights. So in the circumstances he cannot have that many iterations of knowledge of those propositions. In this case, the non-existence of the tree makes no more iterations of knowledge available to him than were already available when he knew that it existed.
That is because the source of his knowledge is independent of the continued existence of the tree. In the Surprise Examination, by contrast, the source of the pupils' knowledge is the teacher who determines whether there will be an examination: if there is no examination as a result of her reliability, more iterations of knowledge may be available to the pupils. This difference is quite compatible with the assumption that margin for error principles govern both cases. 7 Sensitivity
7.1 Preview
The argument of Chapters 4 and 5 connected knowledge and safety. If one knows, one could not easily have been wrong in a similar case. In that sense, one's belief is safely true. There is also a counterfactual notion of sensitivity to the truth, the simplest version of which requires that if the proposition were false, one would not believe it. Safety does not entail sensitivity. If p could not easily have been false, then one could not easily have falsely believed p; but that is consistent with the counterfactual that if p had been false, one would (or might) still have believed p. At first sight, that counterfactual looks like a reason for denying that one knows p. We might therefore conjecture that 'One knows p' entails 'If p were false, one would not believe p'; various more sophisticated conjectures can be made along similar lines. We might then wonder whether sensitivity should supplement or replace safety as a requirement on knowledge. This chapter argues that it should not.
The hypothesis that knowledge entails simple sensitivity has sceptical consequences. I
believe that no evil demon is tricking me into believing that there are no evil demons. If an evil demon were tricking me into believing that there were no evil demons I would still believe that no evil demon was tricking me into believing that there were no evil demons. By the sensitivity hypothesis, I do not know that no evil demon is tricking me into believing that there are no evil demons. Is it bad faith to deny such sceptical consequences? Do they even confirm the general principle that knowledge requires sensitivity, since they allow it to explain the unwillingness which many feel to claim without qualification that they know that they are not in a sceptical scenario?
To simplify the story: famously, Robert Nozick once built 'If p were false, S would not believe p' as a conjunct into a conjunctive analysis of 'S knows p', thereby maintaining the entailment (Nozick 1981: 167-288). Problems dogged his account. In finely crafted recent work,
Keith DeRose has argued for a pragmatic connection between knowledge attributions and such counterfactuals (DeRose 1995, 1996). Some of the problems that beset Nozick turn out to have analogues for DeRose. This chapter will examine attempts to draw limited sceptical consequences from such counterfactual conditions on knowledge. To give those attempts their best chance, we must isolate them from the project of stating necessary and sufficient conditions for 'S knows p'. Attempts to provide jointly sufficient conditions for knowledge lead to conditions which are not individually necessary. For present purposes, what matters is only the more modest claim that a counterfactual condition is necessary for knowledge. As section 1.3 noted, that does not imply that knowledge is analysable. One upshot of the discussion will be that a sensitivity condition must keep the actual basis for the belief fixed in a way which undermines the sceptical argument from the sensitivity requirement. 7.2 Counterfactual Sensitivity
Consider the principle:
(1) Necessarily, if S knows p then if p were false, S would not believe p.
If we write the counterfactual 'If q were true, r would be true' as q □ → r, we can symbolize
(1) as □ (K S p□ ⊃(~ p □ → ~B S p)).1 Let 'S sensitively believes p' abbreviate 'S believes p, and if p were false, S would not believe p'. Given that S knows p only if S believes p (as will be assumed throughout this chapter), (1) implies that S knows p only if S sensitively believes p. Any counterfactual conditional entails the corresponding material conditional, so in particular ~p □ →
~B S p entails ~p □ ⊃ ~B S p. Thus 'If p were false, S would not believe p' is inconsistent with 'p is false and S believes p', so S sensitively believes p only if p is not false. Given that p is true or false,
S sensitively believes p only if p is true.
The most familiar semantics for the counterfactual conditional is that given by David Lewis
(1973), on which q□ → r is true at a possible world w if and only if either q is true at no possible world (the vacuous case) or, for at least one possible world x, q is true at x and r is true at every possible world at least as close in the relevant respects as x is to w. Nozick accepts something like this account when q is false at the world of evaluation w. But when q is true at w, Lewis's account implies that q □ → r is true at w if and only if r is true at w, for the only world at least as close to w as w is w itself; thus q□ & r entails q → r. Nozick cannot accept that part of Lewis's account, for Nozick's analysis of knowledge includes a fourth conjunct (in addition to truth, belief, and the counterfactual linking falsity to unbelief) of the form 'If p were true, S would believe p' (Nozick 1981: 176). Lewis's account makes that conjunct redundant in the presence of the truth-and belief-conditions. In order to defeat some potential counterexamples to his analysis,
Nozick interprets the fourth conjunct differently; its truth at a world w at which p is true requires S
to believe p not just at w but at all worlds close to w at which p is true. On the corresponding modification of Lewis's account, if q is true at w then q □ → r is true at w if and only if r is true at every world close to w at which q is true. This notion of closeness is not Lewis's comparative notion; it is more like the notion discussed in section 5.3. Indeed, on a Nozickian semantics for counterfactuals, one could express safety—the avoidance of false belief at close worlds—by contraposing the counterfactual in (1): 'If S were to believe p, p would be true'. Given that S does believe p, the Nozickian semantics makes that counterfactual true if and only if p is true at all close worlds at which S believes p. That counterfactual is not equivalent to the uncontraposed version, for
B S p □ → p can be true and ~p □ → ~B S p false if p is true at every close world but S believes p at the closest (but not close) world at which p is false. Equally, ~p □ → ~B S p can be true and BS p □
→ p false if S believes p at some close but not closest worlds at which p is false. Ernest Sosa has argued for something like the 'safety' conditional B S p □ → p as a condition on knowledge (Sosa
1996, 2000). A more elaborate account on such lines would qualify 'S believes p' in the conditional to exclude cases in which S believes p on a quite different basis from the basis on which S believes p in the case in which S putatively knows p. Of course, the closeness account in Chapter 5 does not itself involve such a deviant account of counterfactuals; it is neutral on that issue, because it can be expressed in other terms. However, our present concern is with Nozick's original counterfactual ~p
□ → ~B S p, for that is the one which differs most seriously from the closeness condition.
A slight variant of (1) in the same spirit says that 'S knows p' is incompatible with the opposite counterfactual 'If p were false, S would believe p'. It corresponds to replacing the counterfactual in (1) with the negation of the opposite counterfactual; in symbols: □ (K S p ⊃ ~(~ p□
→ B S p)). If 'might' is the dual of 'would', that is equivalent to the claim that, necessarily, if S
knows p then if p were false, S might not believe p. On both Lewis's semantics and a Nozickian modification of it, the opposite counterfactuals ~p □ → B S p and ~p □ → ~B S p are both false at the same world if S believes p at some but not all of the very closest worlds at which p is false. In such cases, S satisfies the 'might' condition for knowing but not the original 'would' condition in (1). Thus ~p □ → B S p and ~p □ → ~B S p are not jointly exhaustive; they are almost mutually exclusive, for they are both true at the same world only if p is a necessary truth. In that case, S satisfies the 'would' condition for knowing in (1) vacuously, but automatically fails the
'might' condition. Thus if counterfactuals with impossible antecedents are vacuously true, the unrestricted generalization that 'S knows p' is incompatible with 'If p were false, S would believe p'
has the absurd consequence that it is impossible to know necessary truths. In that respect, the original 'would' condition in (1) is more attractive. In any case, the difference between the 'would'
and 'might' conditions does not matter for most of the subsequent discussion.
The appeal to possible worlds in the semantics of counterfactuals is controversial.
Nevertheless, Lewis's semantics or a Nozickian modification of it will often be used in what follows, for it imposes a useful discipline on the discussion, and it informs the thinking of those who defend counterfactual conditions on knowledge. If another semantics of counterfactuals is preferred, the arguments below could be modified accordingly.
7.3 Counterfactuals and Scepticism
Let the good case be an ordinary situation in which things appear to be as they are, and the bad case be a sceptical scenario in which one falsely appears to oneself to be in the good case. In the good case, one believes truly that one is not in the bad case. In the bad case, one believes falsely that one is not in the bad case. Thus in the good case one does not sensitively believe that one is not in the bad case, for if that belief were false, one would be in the bad case and would still have that belief. Given (1), in the good case one does not know that one is not in the bad case. Right now, we do not know that we are not in a sceptical scenario.
That result depends on no specific theory of counterfactuals. We can individuate the bad case finely enough to determine what one believes in it, so that, necessarily, one is in the bad case only if one believes that one is not in the bad case. Then the antecedent of the counterfactual 'If one were in the bad case, one would not believe that one was not in the bad case' is metaphysically possible, but not compossible with the consequent. On any reasonable account, including Lewis's and Nozick's, a counterfactual strictly implies that if the antecedent is possible, it is compossible with the consequent; in symbols, □ ((q □ → r) ⊃ (◊q ⊃ ◊ (q & r))). On all such accounts, the counterfactual
'If one were in the bad case, one would not believe that one was not in the bad case' is therefore false.
If one knows that which one deduces from what one knows, then by (1) one also fails to know in the good case any ordinary proposition p from which one deduces that one is not in the bad case, for if one knew p one would thereby know that one was not in the bad case, which by (1) one cannot. This holds even if in the good case one sensitively believes p; the problem is that one insensitively believes a consequence of p. If I were not typing I would be telephoning and I would not believe that I was typing; but from the proposition that I am typing I have deduced that I am not a brain in a vat falsely believing that I am typing. If I were a brain in a vat falsely believing that I
was typing I would not believe that I was such a brain. By (1), I do not know that I am not a brain in a vat falsely believing that I am typing; if my knowledge is closed under my deductions, then I do not know that I am typing. Nozick rescues the possibility of knowing that I am typing, but not the possibility of knowing that I am not a brain in a vat falsely believing that I am typing, by embedding the consequent of (1) as a necessary condition in an analysis of knowledge on which the closure principle fails.2 But accepting (1) commits one to neither Nozick's analysis nor non-closure; sceptics can consistently accept (1) while insisting on closure and rejecting the analysis. Accepting
(1) commits one to a significant dose of scepticism. Accepting (1) with closure commits one to a massive dose of scepticism. Thus (1) commits one to the disjunction of non-closure and rampant scepticism. DeRose has a subtler view, on which (1) is not universally true. He accepts a closure principle and regards many utterances of the form 'S knows p' in ordinary contexts as expressing truths. Nevertheless, he holds, such utterances generate contextual standards for the correct application of 'know' high enough to verify the corresponding instances of (1). Roughly speaking, 'S
knows p' is true in a given context only if one avoids falsely believing p in the worlds relevant to that context; when that sentence is under consideration, the closest worlds in which p is false tend to become contextually relevant (as do worlds closer than they are to the original world). On DeRose's view, closure holds within contexts but not across them. Once the predicate 'know oneself to be in the bad case' is in play, the bad case becomes contextually relevant, standards for the correct application of 'know' rise accordingly, and sentences of the form 'S knows p' which expressed true propositions as uttered in ordinary contexts now express different and false propositions.
DeRose's account disagrees with Nozick's over the truth-values of utterances such as 'He knew that he was typing' said by you about me when sceptical possibilities have been raised to relevance in your context of utterance. For DeRose, you spoke falsely because my epistemic position was not good enough by the standards relevant to the context of your utterance. For
Nozick, your utterance is true because I met his standards for knowledge and raising sceptical possibilities does not alter those standards; ~p □ →~B S p can be true even if ~p & B S p is true at some contextually relevant possible worlds, provided that they are not the closest worlds at which
~p is true. For example, 'If I were not typing, I would not believe that I was typing' may be true even if in some contextually relevant sceptical possibility I falsely believe that I am typing, because in closer possible worlds in which I am not typing I believe that I am telephoning, not typing.
On a view intermediate between Nozick and DeRose, something like (1) is universally true but the truth of the counterfactual requires the truth of its consequent at all contextually relevant worlds at which the antecedent is true. For on a contextualist account of counterfactuals themselves, q □ → r as uttered in a context c is true as evaluated with respect to a world w if and only if □ (p c ⊃
(q ⊃ r)) is true at w, where p c is true at all and only the worlds relevant to c. This view makes q □
→ r equivalent to its contrapositive ~r □ → ~q in any given context, although of course the contextual effects of uttering those counterfactuals may differ. In particular, Nozick's counterfactual
~p □ → ~B S p would be logically but not pragmatically equivalent to the safety conditional BS p □
→ p in any given context on the contextualist view of counterfactuals.3
7.4 Methods
Nozick himself gives a counterexample to (1):
A grandmother sees her grandson is well when he comes to visit; but if he were sick or dead, others would tell her he was well to spare her upset. Yet this does not mean she doesn't know he is well (or at least ambulatory) when she sees him. (1981: 179)

The falsity of the grandmother's belief that her grandson is well in the bad case is consistent with her knowledge that he is well in the good case, because she does not believe that he is well by the same method in the two cases. In the good case, her belief is based on perception, in the bad case on testimony.
In response, Nozick reworks his analysis in terms of the technical notion of knowing via a method (or way of believing). We can extract a putative necessary condition for knowing via method M which stands to Nozicks's analysis of that notion as (1) stands to his original analysis of knowledge:
(2) Necessarily, if S knows p via method M, then if p were false and S were to use M to arrive at a belief whether p, S would not believe p via M.
If the grandson were not well and the grandmother were to use the method of visual inspection to arrive at a belief as to whether he was well, then she would not believe that he was well via that method. We should note that for Nozick, knowing p via some method or other is insufficient for knowing p simpliciter when one believes p via more than one method. Nozick sometimes writes as though methods were reasonably general. But if they are, then
(2) is false. To adapt an example from Goldman (1976: 779), I might know that I am seeing a dog when I look at a nearby dachshund in good light. In the circumstances, if I had not been seeing a dog, I would have been seeing a wolf, and would have falsely believed myself to be seeing a dog.
My tendency to mistake wolves for dogs is consistent with my ability to recognize dachshunds as dogs, although it may impugn my ability to recognize alsatians as dogs. Let p be the proposition that I am seeing a dog. I believe p by the same general method in the two cases; I judge on the basis of sight, at the same distance and in the same light. If that is method M, then (2) is false.
Can we distinguish the methods by the specific difference in my visual evidence, as
Goldman in effect does in his treatment of perceptual knowledge? Nozick sometimes mentions finely individuated methods, for instance, when he suggests inference from a specific proposition q as a method (1981: 189). Let E be the grandmother's particular evidence, and M the method of judging on the basis of E. In some possible situation, is her grandson unwell while she uses M to judge whether he is well? If not, then using M to judge whether he is well guarantees that he is well, perhaps because using M entails having E as part of one's evidence, E is part of one's evidence only if its constituent propositions are true, and those constituent propositions entail that her grandson is well. On that view, if her grandson is ill and she is presented with a perfect lookalike of him to keep her happy, then E is not part of her evidence, although she does not know the difference (see Chapters 8 and 9). That is not how Nozick wishes to individuate methods:
The method used must be specified as having a certain generality if it is to play the appropriate role in subjunctives. This generality is set by the differences the person would notice; the methods are individuated from the inside. (1981: 233)

As Nozick individuates M, in some possible situation the grandson is unwell while the grandmother uses M to judge whether he is well. In that situation, she will presumably believe that he is well, because she is judging on the same internal evidence E as she actually has. Thus the counterfactual in (2) is false, and (2) still counts the grandmother as not knowing that her grandson is well, contrary to the intuition which prompted Nozick to invoke methods.
We can avoid the counterintuitive result by deleting the second conjunct from the antecedent of the counterfactual in (2):4
(3) Necessarily, if S knows p via method M then if p were false, S would not believe p via
M.
Now, (2) entails (3) on most theories of counterfactuals, but (3) does not entail (2).5 For (3)
is consistent with the grandmother's knowing that her grandson is well via the method of judging on the basis of internally individuated perceptual evidence E. In the circumstances, if he were unwell her evidence would be distinguishably different from E. Likewise in the Goldman case: (3) is consistent with my knowing that I am seeing a dog via the method of judging on the basis of internally individuated perceptual evidence F.
Sometimes S does not know p via M and the counterfactual in (2) is false while that in (3) is true, so (2) but not (3) might explain why S does not know via M. For example, I cannot distinguish
Tweedledee from Tweedledum by sight. I see them equally often. When I see either, I believe that
Tweedledum is around. When I see neither, I form neither the belief that Tweedledum is around nor the belief that he is not. Even when I believe truly via the method of sight that Tweedledum is around, I do not know via that method that he is around. Suppose that on this occasion if
Tweedledum had been absent, so would Tweedledee have been. Since I would have formed no belief either way, the counterfactual in (3) is true for 'Tweedledum is around' in place of 'p'. By contrast, the counterfactual in (2) is false, for if Tweedledum had not been around and I had formed a belief one way or the other on the basis of sight, it would have been by seeing Tweedledee, and I
would falsely have believed that Tweedledum was around. Of course, such cases do not show that
(3) is false, just that it cannot explain every failure to know. We are not assessing (3) as a candidate for use in a supposedly necessary and sufficient condition for knowledge, such as Nozick sought. Unlike (1), (3) does not automatically generate sceptical consequences. Everything depends on the individuation of methods. Suppose that in the good case one believes via M that one is not in the bad case. Then (3) forbids this true belief to constitute knowledge that one is not in the bad case via M only if in the bad case one believes via M that one is not in the bad case. For example, if one's belief that one is not in the bad case derives in the good case but not in the bad case from seeing one's body, why should that not constitute a difference in the method used? Nozick and others will object that such a difference does not count because it is inaccessible to the subject. But that externally individuated methods are inaccessible to the subject is far from obvious. The anti-sceptic will insist that in the good case one does know that one is seeing one's body, even if in the bad case one falsely believes that one is seeing one's body. To assume in deriving sceptical consequences from (3) that in the good case one does not know that one is seeing one's body would beg the question. To serve its dialectical purpose, the accessibility claim should be that the method M must be so individuated that in every possible case
(not just every case in which one knows via M) one is in a position to know whether one is using M.
But the argument of Chapter 4 suggests that no principle of individuation yields that result.
However methods are individuated, one is not always in a position to know whether one is using M.
If methods are individuated internally, so that whether one is using method M supervenes on the physical state of one's brain, then (3) will indeed have some sceptical consequences. But why should one accept (3) on those terms? The internal individuation of methods appears gerrymandered precisely to make trouble for our claims to knowledge of the external world. Moreover,
(3) is implausible in some examples when methods are individuated internally. My knowing by sight in the ordinary way that a mountain stands here seems compatible with the assumption that if no mountain had stood here, a bizarre chain of circumstances would have occurred as a result of which I would have hallucinated a mountain of just this appearance. That type of hallucination occurs only in worlds very unlike the actual world, we may suppose, and the mechanism that produces it is absent from the actual world. I actually satisfy (3) for knowing by sight many other things about my present environment, including that there is an icy mountain here; my eyesight is actually working perfectly and I have every ordinary reason to believe that it is. To block the unwarranted consequence of (3) that I do not know that a mountain stands here, one must individuate methods externally rather than internally.6 The next two chapters develop the argument for the external individuation of methods and evidence.
7.5 Contextualist Sensitivity
DeRose avoids internalist gerrymandering. He responds to Nozick's grandmother without appealing to internally individuated methods.
DeRose first suggests that we might defend the unmodified (1) in Nozick's example by giving heavy weight to similarity in method of belief formation in the overall similarity measure between possible worlds which we use to evaluate the counterfactual. In determining what would be true if p were false we concentrate on worlds in which S believes via the same method (1995: 20-1). The grandmother knows that her grandson is well; if he were ill she would not believe that he was well, because she could see that he was not well. One might also try to analyse the example of the counterfactually hallucinated mountain by assessing worlds at which there is no hallucination and no mountain as more similar than worlds in which there is a hallucination and no mountain to the actual world in which there is a mountain and no hallucination, on the grounds that the introduction of a highly unusual causal mechanism makes a highly significant difference to the method of belief formation. Thus 'If no mountain stood here, I would not believe that a mountain stood here' might be forced to come out true. But loading the similarity relation is less likely to help with Goldman's dog. If seeing the grandson well and seeing him ill make for relevantly similar methods of belief formation, why not seeing a dachshund and seeing a wolf?
DeRose does not claim that weighting the similarity relation can handle every example. For instance, if p is the proposition that I don't falsely believe that I have hands, then the counterfactual in (1) is false whatever reasonable similarity relation is used. If I falsely believed that I had hands, I
would believe that I had hands and believe the logical consequence that I didn't falsely believe that I
had hands. Intuitively, however, this example hardly threatens my knowledge that I don't falsely believe that I have hands; (1) is false in this instance. The same goes for my knowledge that I am not an intelligent dog who is always incorrectly thinking that it has hands (1995: 22).
DeRose proposes a rough qualification of (1):
We don't . . . judge ourselves ignorant of p where ~p implies something we take ourselves to know to be false, without providing an explanation of how we came to falsely believe this thing we think we know. Thus, I
falsely believe that I have hands implies that I don't have hands. Since I do take myself to know that I have hands (this belief isn't insensitive), and since the above italicized proposition doesn't explain how I went wrong with respect to my having hands, I'll judge that I do know that proposition to be false. (1995: 23; symbolism modified)

The passage suggests that the consequence of ~p we take ourselves to know to be false ('I
don't have hands') is falsely believed to be false if p is false, and that ~p does not explain why. From a third-personal perspective, we presumably judge S to know p in these cases only if S believes p at least in part because ~p has the consequence which we take S to know to be false. S does not know p if S believes p only on different and bad grounds.
This reference to the grounds on which S believes is a step in the direction of Nozick's methods, but not far enough to block the account's partially sceptical consequences. The negation of the proposition that I am not a brain in a vat induced to appear to itself to have hands does explain how
I could falsely believe that I have hands, because that sceptical scenario has enough detail to be explanatory.7
DeRose's account as just stated is insufficiently general. For example, let α be a case in which I am climbing a mountain and appear to myself to be climbing a mountain; things appear to me as they are. In case β, I am a brain in a vat, but things appear to me generally just as they do in
α. If I were in β, I should believe that I was not in β. If p is the proposition that I am not in β, then I
do not sensitively believe p. Nevertheless, in my present case, I know that I am not in β, because I
am in neither α nor β; things do not appear to me at all as they would in β. I appear to myself to be sitting in front of a computer screen in my office. I do not appear to myself to be climbing a mountain, as I would in β.8 No matter what my situation, I cannot sensitively believe p. Thus (1) is false. Moreover, my false beliefs when I am in β are just as explicable as in other sceptical scenarios, while the example does not involve false beliefs when I am in either α or my actual case.
Thus the example does not involve unexplained false belief at all, contrary to the apparent suggestion in the quoted passage.
A small modification of DeRose's suggestion does handle the example. For let q be the proposition that I do not appear to myself to be climbing a mountain. Thus q entails p (that I am not in β), so ~p entails ~q. If I am in β, then I appear to myself to be climbing a mountain. I take myself to know q; it is just a belief about how things appear to me, and I am mistaken about q in none of the relevant cases. I sensitively believe q, for if I appeared to myself to be climbing a mountain I
would not believe that I did not appear to myself to be climbing a mountain. Moreover, in β I do not falsely believe q; I believe ~q, truly. Thus ~p does not explain how I could falsely believe q. One might therefore modify DeRose's suggestion thus: when we judge (1) false, we do so because S sensitively believes a proposition q which entails p, and ~p does not explain how S could falsely believe q.
When S does sensitively believe p, p is itself such a proposition q, granted that ~p does not explain how one could falsely believe p when one would not believe p if p were false. We might therefore modify (1) thus: (4) Necessarily, if S knows p then, for some proposition q: q entails p, S sensitively believes q, and ~p does not explain how S could falsely believe q.
Further modifications could be made. We might require that S believes p because S believes q. We might allow the link between q and p to be looser than entailment. The discussion below will not depend on these details. The contextualist motivation for replacing (1) by (4) is that when we evaluate 'S knows p' we need not consider cases in which S falsely believes q, because we have no contextually relevant explanation of how S could do so. The quoted passage suggests in addition the converse of something like (4), since DeRose speaks of circumstances where '[w]e don't . . . judge ourselves ignorant of p', but our present concern is not with sufficient conditions for knowledge. Of course, the contextualist's interest in (4) not as a universal principle but as a form instances of which tend to come out true when the corresponding instance of 'S knows p' is uttered.
How does (4) handle Goldman's dog? The obvious proposal is that although my belief that I
am seeing a dog is insensitive, it is derived from a sensitive belief that I am seeing a dachshund.
The hypothesis that I am not seeing a dog does not explain how I could falsely believe that I am seeing a dachshund. This proposal raises the question: even if I do have the intermediate belief that
I am seeing a dachshund, why should it be sensitive? Perhaps I tend to mistake another similar breed of dog for dachshunds; I never mistake anything but dogs for dachshunds. Yet, when I see a dachshund, I still know that I am seeing a dog. Knowledge seems to be compatible with very widespread slight insensitivity of this kind. We can confirm the suspicion with another example.
I tend slightly to underestimate the distances I see. When I see a distance of twenty-one metres I judge it to be less than twenty metres, although when I see a distance of twenty-three metres I do not judge it to be less than twenty metres. This may mean that when I see a distance of nineteen metres and correctly judge it to be less than twenty metres, I do not know it to be less than twenty metres. It surely does not mean that when I see a distance of one metre and correctly judge it to be less than twenty metres, I do not know it to be less than twenty metres. A distance of one metre and a distance of twenty-one metres look quite different to me. My unreliability in answering the question 'Is it less than twenty metres?' when presented with one distance does not imply unreliability in answering it when presented with the other. Suppose that a mark on the side of a ship is one metre above the waterline, in circumstances in which if it had not been less than twenty metres above the waterline it might have been less than twenty-one metres above the waterline.9 I judge by sight whether the mark is less than twenty metres above the waterline. Let p be the proposition that the mark is less than twenty metres above the waterline. If p had been false, I might still have believed p. I believe p insensitively. Surely I can still know p, because I believe p on quite different evidence from that on which I would have believed it had it been false. By (4), I must sensitively believe a proposition q entailing p, where ~p does not explain how I could falsely believe q. What is q? An obvious candidate is the proposition that the mark is less than two metres above the waterline. For that entails that it is less than twenty metres above the waterline; the hypothesis that the mark is not less than twenty metres above the waterline does not explain how I could falsely believe that it is less than two metres above the waterline. But I can know p even if I do not derive p from anything like the proposition that the mark is less than two metres above the waterline; p may be the only proposition which I entertain about the distance in metres. Even if I do believe that the mark is less than two metres above the waterline, that belief too may be insensitive. I have a general tendency to underestimate distances; if the mark were not less than two metres above the waterline, it might be only slightly more than two metres above, and I
would still judge it to be less than two metres above the waterline. Even so, I can know that it is less than twenty metres above. Alternatively, I might derive p from the premises that the distance has a look L and that only distances of less than twenty metres have L. But do I believe the latter premise sensitively? Very likely not. If distances of slightly more than twenty metres had L, I would or might still believe that only distances of less than twenty metres have L. But I still know that the mark is less than twenty metres above the waterline. Thus (4) is vulnerable to widespread slight insensitivity of a kind compatible with knowledge. Appendix 3 gives a formal model to show how the slightest systematic inaccuracy can make one almost totally insensitive. A different proposal is to take degree of belief into account. The idea is that if the mark had been slightly more than twenty metres above the waterline, I would still have believed that it was less than twenty metres above the waterline, although with less confidence than I believe it when the distance is only one metre. But what if I am not like that? Suppose that once I form a belief in a marginal case, I stick to it; perhaps a macho mechanism causes me to feel an aggressive confidence in it even greater than I feel in non-marginal cases. Regrettable though that may be, when the distance is one metre it does not prevent me from knowing that it is less than twenty metres.
Creatures whose beliefs are all or nothing in degree can have such knowledge.
The problem arises however small the inaccuracy is, if non-zero. Even if the only distances which I falsely believe to be less than n metres are less than a millimetre more than n metres, that belief is insensitive when, if the distance had been greater, it might have been less than a millimetre greater.
Naturally, individual examples do not refute the hypothesis that most ordinary cases conform to (4), or even to (1). DeRose prudently avoids advancing such principles as exceptionless generalizations; context-dependence is an unruly phenomenon. Nevertheless, he does not dismiss recalcitrant cases as statistically insignificant; he accepts the responsibility to explain them, as his willingness to replace (1) by something like (4) shows. It is quite unclear how to explain the counterexamples to (4) within a counterfactual framework without appeal to finely individuated methods, as in (2) or (3).10
7.6 Sensitivity and Broad Content
The use of something like condition (4) to explain the appeal of scepticism faces a further problem, from the external individuation of content.
Hilary Putnam (1981) famously denied that a brain in a vat believes falsely that it is not a brain in a vat, arguing that it lacks the kind of causal connections to brains and vats needed to refer to them. If I were a brain in a vat, I might think 'I am not a brain in a vat', but would not thereby express the proposition that I am not a brain in a vat. If in the bad case one lacks the causal or conceptual resources to grasp the proposition that one is not in the bad case, then whenever one believes that one is not in the bad case one does so both truly and sensitively.
Putnam's treatment of scepticism looks insufficiently general. If I have only recently been envatted, I retain enough causal connection with my previous environment to formulate the proposition that I have not been envatted (Smith 1984, Wright 1992a: 86; DeRose 1995: 1).
Nevertheless, more limited forms of content externalism threaten any attempt to extract sceptical consequences from (4).
Let the bad case be a moderate sceptical scenario in which content externalism does not prevent me from grasping my predicament. Let p be the proposition that I am not in the bad case.
Then, in the bad case, I grasp p; I falsely believe p. Therefore, in the corresponding good case, in which things are as they appear to be in the bad case, I believe p truly but insensitively. Does (4)
imply that I do not know p? In the good case I may believe sensitively a proposition q from which I
deduce p, and content externalism may prevent me from grasping q in the bad case. For instance, let q be the proposition that I see this pen; q entails p. In the bad case, I cannot see this pen and have never had any contact with it, however indirect. I am not thinking about this pen, even if I am thinking about pens in general, and perhaps about a particular pen-image. Although I know the linguistic meaning of the words 'I see this pen', I cannot grasp the proposition that I see this pen. It is not expressed by that sentence in this context. Since I cannot believe q when p is false, ~p does not explain how I could falsely believe q. In the good case, I believe sensitively that I see this pen. If I did not see it, I would presumably be in some other ordinary situation and would not believe that I saw it. Even if I would or might be in the bad case if q were false, I would still not believe q; loading the similarity relation cannot help DeRose here. In the good case, I deduce that, since I see this pen, I am not in the bad case, and believe that I am not in the bad case. In the bad case, I still have the premise token 'I see this pen', and go through a process superficially like deduction, but my premise token lacks content. Thus the consequent in (4) is true for the specified values of 'p' and 'q'.
For all (4) implies, 'I know that I am not in the bad case' is true after all. But that is a paradigm of the kind of knowledge claim which the contextualist account was supposed to falsify. Contextualists argue for contextualism by citing its ability to explain the appeal of scepticism, because it predicts the truth of many sceptical utterances. Those predictions follow from (1); they do not follow from
(4). Indeed, the opposite predictions follow if content externalism and the converse of (4) are added to the theory. Nozick might handle the example by insisting that I believe p via the same internally individuated method M in the two cases, whether or not I grasp q. Thus in the good case, although I
truly believe p via M, if p had been false I would still have believed p via M; by (3), even in the good case I do not know p. But that sceptical result depends on a principle for individuating methods which was seen to be problematic in section 7.3.
Could DeRose handle the problem by modifying (4) to speak of quasi-propositions rather than propositions, where quasi-propositions are like propositions except for being individuated narrowly? That is easier said than done, for we need to be told which narrow criterion is to individuate quasi-propositions; which internal differences are consistent with thinking the same quasi-proposition? Furthermore, the appeal to quasi-propositions looks suspiciously ad hoc. It needs some independent motivation if it is not to be a mere device for rigging (4) in favour of the sceptic.
Such a regression to internalist modes of thought also looks foreign to the otherwise externalist spirit of DeRose's account. The argument of the next chapter further undermines those modes of thought. In any case, we must recall that (4) remains defeated by the examples in section 7.5 of knowledge combined with systematic slight insensitivity. 8 Scepticism
8.1 Plan
Rational thinkers respect their evidence. Properly understood, that is a platitude. But how can one respect one's evidence unless one knows what it is? So must not rational thinkers know what their evidence is? If so, then for rational subjects the condition that one has such-and-such evidence should be non-trivial yet luminous. But how can it be, given the anti-luminosity argument of section 4.3?
The assumption that rational thinkers know (or are in a position to know) what their evidence is has implications for sceptical arguments. Non-sceptics postulate a special asymmetry between the good and bad cases in a sceptical argument (section 8.2). Sceptics try to undermine the asymmetry by claiming that the subject has exactly the same evidence in the two cases, but this claim is not obvious (section 8.3). We can argue from the premise that rational thinkers know what their evidence is to the conclusion that their evidence is the same in the two cases (section 8.4). That conclusion forces one into a phenomenal conception of evidence (section 8.5). But the premise that rational thinkers know what their evidence is leads by a parallel argument to a clearly false conclusion (section 8.6). This is another variation on the arguments of sections 4.3 and 5.1. Rational thinkers are not always in a position to know what their evidence is; they are not always in a position to know what rationality requires of them (section 8.7). These conclusions generalize to sceptical arguments in which the sceptic does not claim sameness of evidence between the good and bad cases (section 8.8). One upshot is that sceptical arguments may go wrong by assuming too much knowledge; by sacrificing something in self-knowledge to the sceptic, we stand to gain far more in knowledge of the world.
8.2 Scepticism and the Non-Symmetry of Epistemic Accessibility
For simplicity, we can treat the sceptic as a generic figure, without attempting to track the protean variety of sceptical argument. Scepticism is a disease individuated by its symptoms (such as immoderate protestations of ignorance); we should therefore not assume that it can be caused in only one way. The present aim is to identify one main such way, not to eliminate the disease entirely.
For the sake of argument, let us assume that the constraints of the content externalism discussed in sections 2.2 and 3.2 are consistent with grasping the relevant propositions in sceptical scenarios. A recently envatted brain can still think about the external world. Even for such a brain, the assumption remains problematic as applied to propositions expressed by means of perceptual demonstratives (see also section 7.6). Suppose, for example, that I am looking at a cloud and think that that cloud is dark. A brain envatted before the advent of that cloud, with experience in some sense indistinguishable from mine, does not think that that cloud is dark, although it may think the words 'That cloud is dark' and be in no position to know that it does not thereby express a singular proposition concerning some cloud to the effect that it is dark. Similar issues arise for much less extravagant sceptical scenarios, involving mere hallucinations and the like. We assume for the sake of argument, perhaps over-generously, that the sceptic has some way of absorbing such implications of content externalism.
The sceptic compares a good case with a bad one. In the good case, things appear generally as they ordinarily do, and are that way; one believes some proposition p (for example, that one has hands), and p is true; by ordinary standards, one knows p. In the bad case, things still appear generally as they ordinarily do, but are some other way; one still believes p, but p is false; by any standards, one fails to know p, for only true propositions are known. As far as externalism permits, things appear to one in exactly the same way in the good and bad cases. The sceptic argues that because one believes p falsely in the bad case, one does not know p (even though p is true) in the good case. Let us postpone asking why the sceptic should think that false belief in one case precludes knowledge in the other, and consider the bad case.
Uncontroversially, if one is in the bad case then one does not know that one is not in the good case. Even if one pessimistically believes that one is not in the good case, one's true belief does not constitute knowledge; one has no reason to suppose that the appearances are misleading to that extent. More generally, it is consistent with everything one knows in the bad case that one is in the good case. For even if in the bad case one believes some true propositions which entail that
(contrary to the appearances) one is not in the good case, those true beliefs do not all constitute knowledge. Part of the badness of the bad case is that one cannot know just how bad one's case is.
For the sceptic, the two cases are symmetrical: just as it is consistent with everything one knows in the bad case that one is in the good case, so it is consistent with everything one knows in the good case that one is in the bad case. One simply cannot tell which case one is in. For the sceptic's opponent, the two cases are not symmetrical: although it is consistent with everything one knows in the bad case that one is in the good case, it is not consistent with everything one knows in the good case that one is in the bad case. For in the good case, according to the sceptic's opponent, one knows p (for example, that one has hands), and also (by description of the bad case) that if one is in the bad case then p is false. These three propositions are jointly inconsistent:
(a) One is in the bad case.
(b) If one is in the bad case then p is false.
(c) p. That argument does not assume that one knows that which is a logical consequence of what one knows, for the anti-sceptic's conclusion was merely that it is inconsistent with what one knows in the good case that one is in the bad case, not that one knows in the good case that one is not in the bad case. Although the anti-sceptic may hold that in the good case one also knows that one is not in the bad case, the asymmetry does not require that further knowledge claim.
We can state the asymmetry in the terminology of epistemic logic (see also section 10.4). A
case β is said to be epistemically accessible from a case α if and only if everything which one knows in α is true in β. Then, according to the anti-sceptic, although the good case is epistemically accessible from the bad case, the bad case is not epistemically accessible from the good case.
Some refinements may be needed to handle the issues raised by the broad content of indexical expressions. As uttered in any case α, the sentence 'This case obtains' expresses a content true in α and in no other case. Perhaps one can know that content in α without knowing everything about α; we might allow cases other than α to be epistemically accessible from α, on the grounds that 'This case obtains' expresses (different) true contents in them. This complication does not affect the main arguments to come.
As is well known, asymmetries of epistemic accessibility yield counterexamples to the epistemic version of the 'Brouwersche' thesis in modal logic, the principle that if p is false then one knows that one does not know p (~ p ⊃ K ~K p; 'K' for 'one knows that'), and consequently to the epistemic version of the S5 thesis, the principle that if one does not know p then one knows that one does not know p (~K p ⊃ K~K p). The latter principle entails the former because knowledge is factive (K p ⊃ p holds). Like epistemic S4 (the KK principle), epistemic S5 embodies a luminosity claim. But the failure of the epistemic S5 principle on non-sceptical assumptions was already noted in section 1.2, independently of general anti-luminosity arguments. For in the bad case, p is false and one does not know p, but one does not know that one does not know p. If one knew in the bad case that one did not know p, then according to the sceptic's opponent it would not be consistent with everything one knew in the bad case that one was in the good case, since these three propositions are jointly inconsistent:
(d) One is in the good case.
(e) If one is in the good case then one knows p.
(f) One does not know p.
According to the sceptic's opponent, one can know (e) even in the bad case by description of the good case and one's appreciation that it meets the conditions for one to know p. The failure to know that one fails to know is characteristic of the bad case. Although the sceptic will try to argue that the postulated asymmetry between the two cases is ultimately unstable, there is at least no immediate incoherence.1
A common means of slurring over the epistemic asymmetry is to speak of the two cases as indiscriminable. Surely, if x is indiscriminable from y then y is indiscriminable from x. But even indiscriminability embodies a concealed asymmetry. For one may be able to discriminate between x and y when they are presented in one way and not when they are presented in another (Williamson
1990a: 14-20). A case can be presented in two relevant ways. When one is in a case, one can present it indexically to oneself, as 'my present case'. Alternatively, whether one is in a case or not, one can present it descriptively to oneself, for example, the good case as 'the good case' and the bad case as 'the bad case'. Since we have two cases and two modes of presentation of each of them, we have the four possibilities in Table 1 to consider.
Possibility II does not arise, because a case can be presented indexically as 'my present case'
only if one is in it; since one cannot be in both the good and bad cases simultaneously, one cannot be faced with the task of discriminating between them, each presented indexically as 'my Table 1. Presentation of Cases
PossibilityPresentation of good case Presentation of bad case II
Indexical: 'my case'
Indexical: 'my case'
ID
Indexical: 'my case'
Descriptive: 'the bad case'
DI
Descriptive: 'the good case'Indexical: 'my case'
DD
Descriptive: 'the good case'Descriptive: 'the bad case'
present case'. DD discrimination is trivial, for one is merely required to discriminate conceptually between them presented as 'the good case' and 'the bad case', with no need to discover which case one is in. The interesting possibilities are ID and DI. Sceptics and anti-sceptics agree that in the bad case one cannot discriminate the bad case, presented indexically as 'my present case', from the good case, presented descriptively as 'the good case'. Thus it is uncontentious that the cases are DI indiscriminable. The issue is whether they are ID indiscriminable. Indiscriminability is symmetric in the sense that if x presented under mode M is indiscriminable from y presented under mode N, then y presented under mode N is indiscriminable from x presented under mode M, but it obviously does not follow that x presented under mode N is indiscriminable from y presented under mode M. DI indiscriminability does not imply ID indiscriminability. The anti-sceptic claims that in the good case one can discriminate the good case, presented indexically as 'my present case', from the bad case, presented descriptively as 'the bad case', for that is just to know in the good case that one is not in the bad case. The sceptic claims that one cannot make that discrimination, but since that is in effect to claim that in the good case one cannot know that one is not in the bad case, ID
indiscriminability is tantamount to the sceptic's conclusion. The sceptic cannot use it as a premise without begging the question.
In a more complex version of the argument, the sceptic may postulate a subject whose case oscillates over time between the good case and the bad case. Such a subject may indeed be incapable of discriminating between the good case, presented indexically as 'my present case', and the bad case, presented indexically as 'my case five minutes ago', and therefore lack the relevant knowledge. It does not follow that one lacks that knowledge even if one's case is not in fact oscillating, or in danger of doing so. Thus the oscillation example does not achieve the sceptic's purpose. Alternatively, the sceptic may prefer to work with identity of appearance rather than with indiscriminability. The ultimate uselessness of such an appeal will emerge in the course of the argument below. 8.3 Difference of Evidence in Good and Bad Cases
The sceptic typically insists that one has exactly the same evidence in the two cases.
Therefore, since one believes p with that evidence in the bad case, believing p with the evidence one has in the good case is insufficient for the truth of p. If the sceptic allowed that one had different evidence in the two cases, false belief in the bad case would be a far less pressing threat to knowledge in the good case: the possibility of falsely believing p on the basis of bad evidence is quite compatible with the possibility of knowing p on the basis of good evidence. Scepticism about the external world has more intuitive force than scepticism about one's own sensations because we do not usually envisage beliefs about one's own sensations as based on evidence insufficient for their truth.
The sceptic cannot simply stipulate that one has the same evidence in the good and bad cases. For the notion of evidence will serve the sceptic's purposes only if it has non-trivial connections with other epistemic notions, such as the notion of knowledge. Some externalists about evidence (although not all) will argue that those connections force a difference in evidence between the two cases. If the sceptic tries to stipulate that the bad case is a case in which one falsely believes p while having the same evidence as one has in a case in which by externalist standards one knows p, those externalists will reply that, so defined, the bad case is impossible, and the sceptic's argument does not get off the ground. Rather, the sceptic should define the bad case in less contested terms, so that its possibility is agreed, and then argue for the lemma that one has the same evidence in it as in the good case. Many contemporary nonsceptics accept that lemma in the sceptic's overall argument. They concede that when we have empirical knowledge, we could have had false belief in the same proposition with exactly the same evidence. Many hold that, at least in some contexts, the bad case is in some sense irrelevant to the attribution of knowledge in the good case.2 For present purposes, what matters is simply the claim that one has the same evidence in the two cases. How can that claim be supported?
A natural argument is by reductio ad absurdum. Suppose that one has different evidence in the two cases. Then one can deduce in the bad case that one is not in the good case, because one's evidence is not what it would be if one were in the good case. But even the sceptic's opponent agrees that it is consistent with everything one knows in the bad case that one is in the good case. Therefore, one has the same evidence in the two cases.
The argument assumes that in the bad case one knows what one's evidence is, otherwise one would lack a premise for the deduction. Now, surely one can be rational even in the bad case; misleading evidence sometimes makes false beliefs rational. So one can know what one's evidence is, granted the assumption that rational thinkers are in a position to know what their evidence is.
The appeal of that assumption is by no means limited to sceptics; after all, it says that rational thinkers are in a position to know something. The idea, already mentioned, is that rationality requires one to respect one's evidence, which one cannot expect to do without knowing what it is.
8.4 An Argument for Sameness of Evidence
Let us analyse the argument for sameness of evidence in detail. For simplicity, we may concentrate on cases in which one is rational, possesses all the relevant concepts, and is currently reflecting on one's evidence and its implications; one is epistemically active enough to know whatever one is in a position to know about one's evidence. If the sceptic can show that under these conditions one's evidence is the same in the two cases, the anti-sceptic would have little to gain by insisting that it is different when one is less epistemically active.
We start with the premise that one knows what one's evidence is. 'Evidence' here and throughout means one's total body of evidence. To know what one's evidence is in the relevant sense, one must do better than merely to think of it as 'my evidence'. To be in a position to respect one's evidence, one must identify its specific content in a more perspicuous and intrinsic way. One need not compress the identification into a single item of knowledge. The content can be specified by a class of appropriate properties, each of which one knows one's evidence to have under some canonical specification of the property. We assume on behalf of the sceptic that for each appropriate property a unique canonical specification is given. Let us concede for the sake of argument that such a notion of the canonical can be worked out in detail. We may also assume that if a property is appropriate, so is its complement. The first premise is therefore: (1) For any appropriate property π, in any case in which one's evidence has π, one knows that one's evidence has π.
If we wanted to generalize (1) and the rest of the argument beyond cases in which one is rational, possesses all the relevant concepts, and is currently reflecting on one's evidence and its implications, we could replace 'knows' by 'is in a position to know'. One might wonder whether (1)
generates an infinite regress, as Richard Fumerton (2000) has suggested. It does if being known to have π counts as an appropriate property whenever π does, but defenders of (1) should not concede that assumption. The appropriate properties are intrinsic to the content of one's evidence; being known to have such a property need not itself be intrinsic to the content of the evidence.
Whereas the first premise concerns first-personal knowledge of one's own case, the second concerns third-personal knowledge of one case from within another. For the argument to work, in the bad case one must know what one's evidence would be if one were in the good case, where the good case is presented descriptively. We can quite fairly assume that the terms 'the good case' and
'the bad case' abbreviate descriptions in which, for each appropriate property, if one's evidence in a case has an appropriate property then that is specified in the description of the case; likewise if one's evidence lacks an appropriate property. For the sceptic will insist that however much information one has about what would be so if one were in a given case, that still does not enable one to work out which case one is in. We may assume that one can refer to the appropriate properties, for that is already implicit in (1): if one's evidence has the appropriate property π, then one knows that it has π
and so can refer to π; if it lacks π, then it has the appropriate complementary property not-π, so one knows that it has not-π, so one can refer to not-π, so one can refer to π. Thus one can attain trivial conceptual knowledge in the bad case about the appropriate properties of one's evidence in the good case simply by unpacking one's descriptive concept of 'the good case':
(2) For any appropriate property π, if in the good case one's evidence lacks π, then in the bad case one knows that in the good case one's evidence lacks π.
The third premise articulates the badness of one's predicament in the bad case. From premises each of which one knows in the bad case, one cannot deduce that one is not in the good case.
(3) It is consistent with what one knows in the bad case that one is in the good case. Now restrict 'π' to appropriate properties and assume:
(4) In the bad case one's evidence has π.
Suppose further, as an assumption for reductio ad absurdum:
(5) In the good case one's evidence lacks π.
Premises (2) and (5) entail:
(6) In the bad case one knows that in the good case one's evidence lacks π.
Premises (1) and (4) entail:
(7) In the bad case one knows that one's evidence has π.
From 'In the good case one's evidence lacks π' and 'One's evidence has π' one can deduce
'One is not in the good case'. By (6) and (7), in the bad case one knows each premise of that deduction; hence:
(8) It is inconsistent with what one knows in the bad case that one is in the good case.
Now (8), which rests on assumptions (1), (2), (4), and (5), contradicts (3). Thus on assumptions (1)-(4) we can deny (5) by reductio ad absurdum:
(9) In the good case one's evidence has π.
We can conditionalize (9) on assumption (4):
(10) If in the bad case one's evidence has π, then in the good case one's evidence has π.
Here (10) rests on assumptions (1)-(3). Since the appropriate properties were assumed to be closed under complementation, we can run through the argument (1)-(10) with 'not-π' in place of 'π', yielding:
(11) If in the bad case one's evidence has not-π, then in the good case one's evidence has not-π.
Contraposition on (11) yields the converse of (10). Therefore, generalizing on 'π' in (10) and
(11), we have:
(12) One's evidence in the good case has the same appropriate properties as one's evidence in the bad case.
The conclusion (12) rests on assumptions (1), (2), and (3). It may be restated as the claim that one's evidence is the same in the good and bad cases, where evidence is individuated by the appropriate properties. If something like this argument is not the reason for which sceptics and others think that one has the same evidence in the two cases, it is not at all clear what is.
8.5 The Phenomenal Conception of Evidence That one has the same evidence in the good and bad cases is a severe constraint on the nature of evidence. It is inconsistent with the view that evidence consists of true propositions like those standardly offered as evidence for scientific theories. For example, the good case in which I
see that the dial reads 0.407 corresponds to a bad case in which the dial does not read 0.407 but I
hallucinate and it is consistent with everything I know that the dial reads 0.407. Since the proposition that the dial read 0.407 is false in the bad case, it is not evidence in the bad case. If my evidence is the same in the two cases, then that the dial read 0.407 is not evidence in the good case either. For similar reasons, (12) does not permit my evidence to include perceptual states individuated in part by relations to the environment. No matter how favourable my epistemic circumstances, I am counted as having only as much evidence as I have in the corresponding sceptical scenarios, no matter how distant and bizarre. Retinal stimulations and brain states fare no better as evidence, for in some sceptical scenarios they are unknowably different too. Thus (12)
drives evidence towards the purely phenomenal.
We should not assume ourselves to grasp the concept of the phenomenal quite independently of (12). Instead, the phenomenal may be postulated as comprising those conditions, whatever they are, which rational subjects can know themselves to be in whenever they are in them.
Such conditions may be supposed to comprise conditions on present memory experience as well as on present perceptual experience (Lewis 1996: 553). That such conditions exist is supposedly guaranteed by the argument that rationality requires one to respect one's evidence and cannot require one to respect something unless one is in a position to know what it is.3 The argument for (12) is not vulnerable to a distinction between relevant and irrelevant alternatives to the good case, for it in no way assumes the relevance of the bad case to the good case. It does not use the sceptical claim that it is consistent with what one knows in the good case that one is in the bad case; it uses only the uncontested claim (3) that it is consistent with what one knows in the bad case that one is in the good case. Although that may be to assume the relevance in some sense of the good case to the bad case, that assumption is uncontroversial, since the good case is the sort of case one believes oneself to be in and appears to oneself to be in if one is in the bad case. Even if in the good case one properly ignores the bad case, the argument to (12) still shows
(given its premises) that one's evidence in the good case cannot exceed one's evidence in the bad case.
Does a distinction between relevant and irrelevant alternatives make trouble for the sceptic's further claim that false belief in the bad case precludes knowledge in the good case? Perhaps falsely believing p with given evidence in a case β precludes knowing p with the same evidence in a case α
only if β is a relevant alternative to α in some sense of 'relevant' in which the bad case is not a relevant alternative to the good case. Although that is not the present issue, it is difficult not to feel sympathy for the sceptic here. If one's evidence is insufficient for the truth of one's belief, in the sense that one could falsely believe p with the very same total evidence, then one seems to know p in at best a stretched and weakened sense of 'know'. We might contrast it with a more robust sense in which one knows the evidence itself, if evidence can be conceived propositionally. But all these questions presuppose that one's evidence is indeed the same in the good and bad cases. How compelling is the argument for (12)? In particular, how compelling is the justification of its crucial premise (1)?
8.6 Sameness of Evidence and the Sorites
We can undermine the argument for (12), and in particular its crucial premise (1), by constructing a parallel argument from (1) to a clearly false conclusion. Whatever the nature of evidence, rational thinkers do not always know what their evidence is. The argument exploits ordinary limits to one's powers of discrimination. It is an application of the anti-luminosity argument of section 4.3, with some modifications to clarify its relation to the argument presented in section
8.4. The argument shows that the condition that one's evidence has the appropriate property π is not luminous; it can obtain even when one is not in a position to know that it obtains.
Let t 0 , t 1 , t 2 , . . . , t n be a long sequence of times at one-millisecond intervals. Imagine that one's experience very gradually changes from t 0 to t n ; for example, one watches the sun slowly rise. One loses exact track of time. One's evidence at the beginning of the process (pitch darkness) is quite different from one's evidence at the end (bright daylight). Some of the appropriate properties of one's evidence are different; for purposes of this argument, it does not matter whether the appropriate properties exhaust the content of one's evidence. We may assume that the complement of an appropriate property is itself an appropriate property, although the purpose of the argument could be achieved without that assumption. For 0 ≤ i ≤ n, let 'α i' abbreviate a description of the case one is in at t i ; the description specifies the time t i in clock terms and lists the appropriate properties which one's evidence then has and those which it then lacks. As with the sceptic's original argument, we may assume that one can refer to the appropriate properties, for that is implicit in (1). Thus one can attain trivial conceptual knowledge in one case about the appropriate properties of one's evidence in another case simply by unpacking one's descriptive concept of the latter case; in particular:
(2 i )For any appropriate property π, if in α i 1 one's evidence lacks π, then in α i one knows that in α i 1 one's evidence lacks π.
The justification of (2 i ) is just like the justification of (2) above.
Now consider the description of what is in fact the case one was in a millisecond ago. Given one's limited powers of discrimination, one does not know propositions from which one can deduce that that description does not apply to one's own case:
(3 i ) It is consistent with what one knows in α i that one is in α i 1.
Since the purposes of this chapter require only one example in which (1) has false consequences, any readers lucky enough to have perfect discrimination amongst their own states should consider the less fortunate example of the present author, who is frequently in a predicament like (3 i ). In such cases, (3 i ) is obvious in roughly the way in which it is obvious that it is consistent with what I know by sight when I am in fact looking at a distant tree i millimetres high that I am looking at a tree only i 1 millimetres high. From premises which I know on the basis of sight to the conclusion that I am not looking at a tree only i 1 millimetres high, there is no hope of constructing a valid deduction, not even one which I am somehow not in a position to carry out. Similarly, from premises which I know in α i to the conclusion that I am not in α i 1, there is no hope of constructing a valid deduction, not even one which I am somehow not in a position to carry out.
The argument proceeds as before. Restrict 'π' to appropriate properties and assume:
(4 i ) In α i one's evidence has π.
Suppose further, as an assumption for reductio ad absurdum:
(5 i ) In α i-1 one's evidence lacks π.
Premises (2 i ) and (5 i ) entail:
(6 i ) In α i one knows that in α i 1 one's evidence lacks π.
Premises (1) and (4 i ) entail:
(7 i ) In α i one knows that one's evidence has π.
From 'In α i-1 one's evidence lacks π' and 'One's evidence has π' one can deduce 'One is not in α i 1'. By (6 i ) and (7 i ), in α i one knows each premise of that deduction; hence:
(8 i ) It is inconsistent with what one knows in α i that one is in α i-1.
Now (8 i ), which rests on assumptions (1), (2 i ), (4 i ), and (5 i ), contradicts (3 i ). Thus on assumptions (1) and (2 i )-(4 i ) we can deny (5 i ) by reductio ad absurdum:
(9 i ) In α i 1 one's evidence has π.
We can conditionalize (9 i ) on assumption (4 i ): (10 i ) If in α i one's evidence has π, then in α i 1 one's evidence has π.
Here (10 i ) rests on assumptions (1), (2 i ), and (3 i ). Since the appropriate properties were assumed to be closed under complementation, we can run through the argument (1)-(10 i ) with 'notπ' in place of 'π', yielding:
(11 i ) If in α i one's evidence has not-π, then in α i 1 one's evidence has not-π.
Contraposition on (11 i ) yields the converse of (12 i ). Thus, generalizing on 'π' in (10 i ) and
(11 i ), we have:
(12 i ) One's evidence in α i 1 has the same appropriate properties as one's evidence in α i. Proposition (12 i ) rests on assumptions (1), (2 i ), and (3 i ). But the relation between the cases in (12 i ) is transitive; if one's evidence in case β has the same appropriate properties as one's evidence in case γ and one's evidence in case γ has the same appropriate properties as one's evidence in case δ, then one's evidence in β has the same appropriate properties as one's evidence in
δ, for what is in question is exact sameness in all properties from a fixed class. Although (3 i )
claims only that α i 1 and α i are indiscriminable, and indiscriminability is a non-transitive relation, we have deduced from it and the other premises the transitive relation of exact sameness of evidence in the appropriate respects. Thus (12 1 ), . . . , (12 n ) together yield:
(13) One's evidence in α0 has the same appropriate properties as one's evidence in α n.
The conclusion (13) rests on assumptions (1), (2 1 ), . . . , (2 n ), (3 1 ), . . . , (3 n ). But (13) is obviously false. One's evidence at the end of the process is grossly different from one's evidence at the beginning; it differs in many of its appropriate properties. Since (2 1 ), . . . , (2 n ), (3 1 ), . . . , (3 n
) are true, for reasons already given, (1) is false.
Even if we drop the assumption that the complements of appropriate properties are themselves appropriate, we still have the argument to (10 i ), and therefore by transitivity to the conclusion that if in α n one's evidence has an appropriate property, then in α0 one's evidence already had that property. That is obviously false, too. One does not always know the appropriate properties of one's evidence; one does not always know what one's evidence is.
To the objection that the argument is undermined by its obvious similarity to a sorites paradox, the reply is just as in section 4.5, and will not be repeated here. In brief, the argument in a sorites paradox has an obviously false premise when the vague terms at issue are sharpened; here that is not so.
Fumerton (2000) points out that the sorites argument would show that (1) can fail in a small way; it would not show that (1) can fail in a large way, as is held to occur in the bad case. However, one's evidence in the bad case can appear exactly similar to one's evidence in the good case, not because it is almost exactly similar, but because it is so radically impoverished that one lacks evidence of its impoverishment. Moreover, the usual reasons for claiming that one is always in a position to know exactly what one's evidence is do not naturally evolve into reasons for claiming that one is always in a position to know approximately what one's evidence is. We are often in a position to know approximately what our evidence is; that our position should occasionally be much worse than that, as in the bad case, is no surprise.4
8.7 The Non-Transparency of Rationality
The argument against (1) does not depend on any specific theory of evidence. The crucial assumption about evidence is just that its appropriate properties can vary between the endpoints of a spectrum of cases, as they must if we are to learn from experience. Whatever evidence is, one is not always in a position to know what one has of it. Thus nothing would be gained by a retreat to the fallback claim that one always knows (or is in a position to know) what one's evidence appears to be. For we can replace the words 'one's evidence has [lacks] π' in the preceding argument by 'one's evidence appears to have [lack] π'. Under this modification, (1) expresses the fallback claim, (2 1 ),
. . . , (2 n ) can be justified in the same way as before, (3 1 ), . . . ,(3 n ) are unchanged, and (13) remains hopelessly implausible, so the argument refutes the fallback claim, too. One does not always know what one's evidence appears to be.
If the phenomenal is postulated as comprising those conditions of the subject, whatever they are, which are accessible to the subject whenever they obtain, and therefore satisfy something like desideratum (1) for evidence, then the phenomenal is empty. We have the illusion of coming ever closer to a phenomenal core of experience by progressively eliminating every feature which can fail to be accessible to the subject, but, like the sequence of open intervals (0,1), (0,1/2), (0,1/4), . . . , this sequence of approximations converges to the empty set.
We could modify (1) by relativizing appropriateness to cases. The modified variant of (1)
would claim that, for any case α and any property π appropriate to α, if in α one's evidence has π, then one knows in α that one's evidence has π. We could then no longer argue to (13), because
'appropriate' in the modified (12 i ) would have different relativizations for different values of i. But the argument for sameness of evidence in the good and bad cases would fail, for although we could show that one's evidence in the good case had the same properties appropriate to the bad case as one's evidence in the bad case, we could not show that one's evidence in the good case had the same properties appropriate to the good case as one's evidence in the bad case. Indeed, we could not show that one was always in a position to know which properties of evidence were appropriate to one's own case. The proposed relativization plays into the hands of the present strategy.
The problem remains: how can rational thinkers respect their evidence if they do not know what it is? If rationality requires one to respect one's evidence, then it is irrational not to respect one's evidence. But how can failing to respect one's evidence be irrational when one is not in a position to know that one is failing to respect one's evidence? More generally, how can φ-ing be irrational when one is not in a position to know that one is φ-ing?
The standard conception of rationality depends on a distinction between the aims and methods of cognitive activity. On that conception, truth is an aim. We cannot attain it directly; we cannot follow the rule 'Believe truly!' when we do not know what is true. Therefore we must use methods to reach the truth. Rationality is a method. We can follow rules of rationality because we are always in a position to know what they require. If the argument of section 8.6 is correct, this picture of rationality is mistaken. Just as one cannot always know what one's evidence is, so one cannot always know what rationality requires of one. Just like evidence, the requirements of rationality can differ between indiscriminable situations. Rationality may be a matter of doing the best one can with what one has, but one cannot always know what one has, or whether one has done the best one can with it. If something is a method only if one is always in a position to know whether one is complying with it, then there are no methods for learning from experience. But that standard is too exacting to be useful. We can use something as a method in contexts in which one is usually in a position to know whether one is complying with it, even if in other contexts one is not usually in a position to know whether one is complying with it. In that sense, we can use even believing truly as a method in contexts in which one is usually in a position to know what is true: for example, when forming beliefs in normal conditions about the spatial arrangement of mediumsized objects in one's immediate environment. In more difficult contexts, believing truly becomes an aim and we fall back on the method of believing rationally. Rationality becomes a sub-goal on the way to truth. That does not require one always to be in a position to know what rationality requires of one; it requires merely that one often knows what rationality requires when one does not know what truth requires. Nothing has been said here to undermine that requirement. In still more problematic contexts, paradoxes throw our very standards of rationality into doubt, and we fall back still further on what workable methods we can find. Cognition is irremediably opportunistic.
There is a pragmatist and subjective Bayesian project to operationalize epistemology by working only with concepts whose application is always accessible to the agent. The argument of this chapter implies that the project is doomed to failure. Uncertainty about evidence does not generate an infinite regress of evidence about evidence about . . . . In order to reflect adequately on one's evidence, one might need evidence about one's evidence, and in order to reflect adequately about the latter evidence, one might need evidence about it, and so on. But this regress is merely and harmlessly potential. We cannot in fact realize infinitely many levels of adequate reflection; at best, further reflection enables us to realize finitely many further stages. At some stage one must rely on unreflective causal sensitivity to evidence (see section 9.3).
One can be causally sensitive to a factor without being in a position to have exact knowledge of it, as when one is causally sensitive through unaided perception to the distances between objects in one's environment. One can be causally sensitive to appropriate properties of one's evidence without being in a position to know them exactly. Causal sensitivity need not be perfect to be genuine. Sufficiently bad cognitive circumstances may involve obstacles even to causal sensitivity to one's evidence. The bad case in a sceptical argument may be a case in point.
One's cognitive circumstances may be so bad that one is in no position to know how impoverished one's evidence is in comparison to the good case. Our causal insensitivity to any difference in evidence between the two cases does not show that there is no difference in evidence between them.
It has not been shown that the good and bad cases do differ in evidence. That requires a positive account of evidence, which Chapters 9 and 10 will develop. They defend the view that one's total evidence (not one's evidence for p alone) is simply one's total knowledge, on which the assumption that one has the same total evidence in the two cases is tantamount to the sceptic's conclusion. For since, uncontroversially, in the bad case one fails to know p, p would not be part of one's total evidence in the bad case, and would therefore not be part of one's total evidence in the good case either; so in the good case, too, one would not know p. A sceptic who assumes that one's total evidence is the same begs the question against a non-sceptic who takes that view of evidence.
Of course, the argument of this chapter does not assume the equation of one's total evidence with one's total knowledge; rather, it lays the groundwork for the equation.5
For present purposes, what matters is that sameness of evidence has not been established, and a salient argument for it has turned out to rest on a false premise. For all that the sceptic has shown, one has more evidence in the good case than in the bad case, and knowledge in the former is unthreatened by false belief in the latter.
The problem is not confined to the sceptic. It also affects those nonsceptics who argue that in the good case we know p even though we falsely believe p in some cases in which we have the same evidence as in the good cases, because those bad cases are irrelevant (at least in this context).
Such theorists have not eliminated the hypothesis that one knows p only if one does not falsely believe p on the same evidence in any case at all, relevant or irrelevant. That hypothesis does not entail scepticism.
Contextualists may argue that the extension of 'evidence' waxes and wanes with the context of utterance just as they suppose the extension of 'knowledge' to do. But then they cannot use 'the same evidence' as a fixed standard against which to measure contextual variation in standards of relevance. 'One knows p' is supposed to count as true in the good case when the bad case is irrelevant; but if (speaking in such a context) the bad case also counts as differing from the good case in non-pragmatic respects such as evidence, why invoke pragmatic respects such as relevance?
8.8 Scepticism Without Sameness of Evidence
Sometimes the good and bad cases in a sceptical argument have a different structure from that considered so far. Scepticism about p does not always require the (metaphysical) possibility of a bad case in which one falsely believes p. Let p be a mathematical truth, and therefore a necessary truth. Thus no case in which one falsely believes p is possible; yet one can still doubt p, by doubting the reliability of the methods which led one to believe p. After all, someone with great faith in a certain coin might decide to believe p if it comes up heads and to believe ~p if it comes up tails; if he believes p because the coin came up heads, he does not know p, although he could not have believed p falsely. His belief fails to be knowledge because the method by which he reached it could just as easily have led to a false belief in a different proposition (see also section 4.4). His evidence in the bad case includes the proposition that the coin came up tails, and therefore differs from his evidence in the good case. Even when false belief in p is possible, one's evidence in the bad case which motivates scepticism about p need not be the same as in the good case. Incoherent dreams feel coherent; one might therefore doubt the coherence of one's present experience, even though it feels, and in fact is, coherent. Since one's experience is coherent in the good case and incoherent in the bad case, one's evidence presumably differs between the two cases. The sceptic need not claim that in some possible case, one's experience is incoherent and one has the same evidence which one actually has, for that would be too close to asserting dogmatically that one's actual experience is incoherent. Rather, the locus of the doubt is the method by which one reaches the belief that one's experience is coherent.
Does the discussion of sceptical arguments in sections 8.2-8.7 generalize to these examples?
One might think not. 'Method' has replaced 'evidence' as the crucial term, and they seem to be crucially disanalogous: we are far more strongly tempted to assume that one is always in a position to know what one's evidence is than to assume that one is always in a position to know what method one is using. The sceptic will happily allow that our beliefs may have inaccessible, unconscious causes, and argue that for all we know such causes are quite insensitive to whether the beliefs they cause are true. What if we are in fact using a method which cannot yield false beliefs? The sceptic will point to cases in which we merely appear to be using that method and our resulting beliefs are false. Such cases are supposed to falsify our knowledge claims. For the sceptic, the methods on whose reliability the epistemic status of our beliefs depends are individuated by appearances; the falsity of beliefs reached in cases which appear the same as the actual case in respect of one's method constitutes unreliability in one's actual apparent method.
In effect, the sceptic distinguishes the process by which one's belief was caused from the rule which one used in reaching the belief. Processes are at the subpersonal level, rules at the personal level. One can take responsibility for one's rules in a way in which one cannot for the processes. One's rationality depends on the rules which one uses rather than the processes which go on in one. One is typically not in a position to know what process caused one's belief, but we are tempted to suppose that one is always in a position to know what rules one used in reaching it. For if one was not in a position to know what rules one was using, and one's rationality depended on the rationality of one's rules, how could one be required to be rational? The requirement that one is always in a position to know what rules one is using forces us into individuating them phenomenally, just as the corresponding epistemic requirement on evidence forced us into individuating it phenomenally. If a rule were individuated non-phenomenally, one could to all appearances be using it while not in fact be doing so; in which case one would not be in a position to know that one was not using that rule. An argument similar to (1)-(12) concludes that one is using the same rule in the good and bad cases. According to the sceptic, what matters for knowledge is the reliability of the rule, not of the process, so one's false belief in the bad case makes one's rule in the good case unreliable, and therefore undermines knowledge in the good case.
The sceptic's conception of a rule collapses. By an argument parallel to (1)-(13) (via (2 i )(12 i )), only trivial rules meet the epistemic requirement. For a series of indiscriminable differences links a case in which one uses a given rule to a case in which one uses a quite different rule. For example, one initially believes p for reason R while giving no weight to reason R*; gradually one gives less weight to R and more to R*, until finally one believes p for reason R* while giving no weight to R. R and R* differ so much in kind that believing for reason R and believing for reason R* amount to using different rules. An argument just like that of section 8.6 refutes the assumption that in every case one is in a position to know what rule one is using. Even when the sceptic does not assume identity of evidence between the good and bad cases, the underlying dialectic is the same.
We can fall into scepticism if we attribute too much self-knowledge to the subject in bad cognitive circumstances, for the asymmetry in knowledge between the good and bad cases requires an asymmetry in self-knowledge. Once we relax our claims to self-knowledge, we strengthen our claim to knowledge of the external world. Sceptical arguments fail when they depend on exempting an internal world of appearances, for they depend on misconceiving appearances as just what they appear to be. The ruthless sceptic grants no exemptions. If the sceptic must argue that we never even know how things appear to us, should we still harbour the sneaking suspicion that scepticism is right after all? 9 Evidence
9.1 Knowledge as Justifying Belief
Tradition has it that the main problems of philosophy include the nature of knowledge. But, in recent decades, questions of knowledge seem to have been marginalized by questions of justification. Thus, according to Crispin Wright, knowledge is not really the proper central concern of epistemologico-sceptical enquiry. . . . We can live with the concession that we do not, strictly, know some of the things we believed ourselves to know, provided we can retain the thought that we are fully justified in accepting them. (1991: 88; Wright's italics)

Similarly, John Earman argues that accounts of knowledge are irrelevant to the philosophy of science, because in it 'the main concern is rarely whether or not a scientist 'knows' that some theory is true but rather whether or not she is justified in believing it' (1993: 37).1 Once Gettier showed in 1963 that justified true belief is insufficient for knowledge, and therefore that knowledge is unnecessary for justified true belief, it became natural to ask: if you can have justified true beliefs, why bother with knowledge?2
The argument of Chapter 3 indicated that if one is disposed to respond rationally to future evidence, then one's future prospects are better if one now has knowledge than if one now has mere justified true belief. But even if we restrict the comparison between knowledge and justified true belief to what they do for one in the present, there is still a lacuna in the case for the unimportance of knowledge. Grant, for the sake of argument, that knowledge is important now only if it is somehow 3
essential to the present justification of belief. Although it has been shown that what is justified need not be knowledge, even when it is true, it has not been shown that what justifies need not be knowledge. Only one end of the justification relation has been separated from knowledge.
Suppose that knowledge, and only knowledge, justifies belief. That is, in any possible situation in which one believes a proposition p, that belief is justified, if at all, by propositions q 1 , . . . , q n
(usually other than p) which one knows. On that supposition, if justified belief is central to epistemologico-sceptical inquiry and the philosophy of science, then so too is knowledge. Now assume further that what justifies belief is evidence (this assumption is briefly discussed in section
9.8). Then the supposition just made is equivalent to the principle that knowledge, and only knowledge, constitutes evidence. This chapter defends that principle; it equates S's evidence with
S's knowledge, for every individual or community S in any possible situation. Call this equation E
= K.4
As usual, 'knowledge' is understood as propositional knowledge. The communal case is needed: science depends on public evidence, which is neither the union nor the intersection of the evidence of each scientist. We can ascribe such knowledge by saying that p is known in community
S, or that we know p, which is not equivalent to saying that some, many, most, or all of us know p. The proposed account uses the concept of knowledge in partial elucidation of the concepts of evidence and justification. To some people it will therefore seem to get things back to front. For although knowledge is more than justified true belief, many philosophers still expect to use concepts such as evidence and justification in a more complex explanation of the concept knows; it would then be circular to use the latter to explain the former. Others prefer to use concepts of a different kind, such as causation or reliability, to explain the concept knows; but even they are likely to regard the concept knows as so much in need of explanation itself that its pre-theoretic use would lack explanatory value.
That order of explanation has been reversed in this book. The concept knows is fundamental, the primary implement of epistemological inquiry. Chapter 1 rejected the programme of understanding knowledge in terms of the justification of belief. That frees us to try the experiment of understanding the justification of belief in terms of knowledge. Of course the concept knows is vague; so is the concept justified.
For those who remain sympathetic to the orthodox order of explanation, some more irenic points can be made. The equation E = K could be true without being knowable a priori. As a universal generalization over all metaphysically possible situations, it is necessarily true, if true at all (by the S4 principle that a necessary truth is necessarily necessary); but we cannot presume that a necessary truth is knowable a priori. E = K equates the extensions of the concepts knowledge and evidence in any possible situation; that is enough to make it an informative thesis. By itself, E = K
does not equate the concepts themselves; nor is it to be read as offering an analysis of either the concept evidence or the concept knowledge, or as making one concept prior to the other in any sense. Of course, in offering arguments of a broadly a priori kind for E = K, like those below, one commits oneself at least to its a priori plausibility; in the best case for those arguments, they would provide a priori knowledge of E = K. But even if the concepts are equivalent a priori, it does not follow that one is prior to the other.
More positively, we may speculate that standard accounts of justification have failed to deal convincingly with the traditional problem of the regress of justifications—what justifies the justifiers?—because they have forbidden themselves to use the concept knowledge. E = K suggests a very modest kind of foundationalism, on which all one's knowledge serves as the foundation for all one's justified beliefs. Perhaps we can understand how something could found belief only by thinking of it as knowledge.
9.2 Bodies of Evidence
When is e evidence for the hypothesis h, for a subject S? Two conditions seem to be required. First, e should speak in favour of h. Second, e should have some kind of creditable standing. At least as a first approximation, we can model the first condition in probabilistic terms: e should raise the probability of h. That is, the probability of h conditional on e should be higher than the unconditional probability of h; in symbols, P(h| e) > P(h). The conditional probability P(h | e) is defined as the ratio P(h & e)/P(e) when P(e) ≠ 0, and is otherwise undefined. Thus the condition that
P(h| e) > P(h) obtains if and only P(h & e)>P(h)P(e). What kind of probability is P? It is not a priori, for whether e raises the probability of h may depend on background information. For example, the proposition that John belongs to a certain club might raise the probability that he is single relative to the background information that it is a club for singles, but lower it relative to the background information that it is a club for spouses. However, e itself should not be built into the background information, for that would give P(e) the value 1, in which case P(h| e) and P(h) would be equal and e would not be evidence for anything. Let us leave the nature of P underspecified until the next chapter. Now, e may raise the probability of h in the sense that P(h| e) > P(h) even if S
knows that e is false or has no idea whether e is true; but then, for S, e would not be evidence for h.
That is why we need the second condition, that e should have a creditable standing. A natural idea is that S has a body of evidence, for use in the assessment of hypotheses; that evidence should include e. The probability distribution P is informed by some but not all of S's evidence. We can therefore formulate a simple schematic proposal:
EV e is evidence for h for S if and only if S's evidence includes e and P(h| e) > P(h).
One consequence of EV is that e is evidence for h only if e is evidence for itself. For if P(h|
e) > P(h), then P(e) is neither 0 (otherwise P(h| e) is ill defined) nor 1 (otherwise P(h| e) = P(h)).
Hence P(e| e) is well defined with the value 1, which is greater than P(e), so e is evidence for e, by
EV with 'e' substituted for 'h'. But is it not circular for anything to be evidence for itself? A critic might therefore argue that one's evidence does not consist of a fixed body of propositions; either it depends on the hypothesis under assessment, where no proposition belongs to the evidence relative to its own assessment, or it does not consist of propositions.
The critic is not entitled to assume without argument that classifying e as evidence for itself involves circularity of any vicious kind. Certainly EV does not make it trivially easy to have evidence for e, for e is evidence for itself for S only if S's evidence includes e. By E = K, that requires S to know e, which may not be easy. The result that e is evidence for itself may be as harmless as the consequence of a standard definition of provability in a formal system that every axiom has a one line proof, consisting of the axiom itself. Of course, if someone asks 'What is the evidence for h?', one is not expected to cite h itself, but the reason might be that it would be conversationally inappropriate rather than false to do so. In answer to the question 'Who lives in the same house as Mary?' it would be conversationally inappropriate to cite Mary herself; nevertheless, it is true that Mary lives in the same house as Mary (Grice 1989). The question 'What is the evidence for h?' is often a challenge to the epistemic standing of h and related propositions. In some contexts the challenge is local, restricted to propositions derived in some way from h. In other contexts the challenge is global, extending to all propositions with the same kind of pedigree as h. In answering the question, one is expected not to cite propositions under challenge, since their status as evidence has been challenged. Thus when the question 'What is the evidence for e?' is meant as a challenge to the epistemic standing of e, one is expected not to cite e in response.
Could we treat the claim that e is evidence for itself as false rather than conversationally inappropriate by treating 'evidence' as a context sensitive term? The idea would be that the question
'What is the evidence for e?', meant as a challenge, creates a context in which e falls outside the extension of 'S's evidence'. But that seems too drastic. For example, suppose that a doctor asks you,
'Do you feel a tingling sensation?' and you answer, 'No.' If you were asked 'What is your evidence for the proposition that you do not feel a tingling sensation?', you might be at a loss to answer, for the question seems to expect some further evidence for the proposition, and you might look in vain for such further evidence. Nevertheless, when we assess the status of your claim that you did not feel a tingling sensation on your evidence, we do not exclude that proposition from your evidence.
Its presence justified your claim. This is not to deny that the extension of 'evidence' may vary slightly with context, perhaps corresponding to slight contextual variation in the extension of
'knowledge' (and therefore, presumably, in the extension of 'mental state' too, by section 1.4). The point is just that challenging e by itself is not enough to exclude e from the extension of 'evidence'.
One sceptical strategy is to exploit the dialectical effects of challenging propositions. If one is never entitled to rely on something under challenge, one will very soon be left with very little.
For example, the sceptic can challenge the belief that there are good reasons, and then charge any attempt to provide a good reason for it with begging the question. We should be sceptical of such a sceptic's reliance on the power of challenge. The sceptic relies uncritically on rules of dialectical engagement which evolved to serve more practical purposes, without questioning their appropriateness to the radical questions which scepticism raises. If challenging something thereby makes it dialectically unusable, then the power of challenge might hinder rather than help the pursuit of truth if it is not used with restraint. By refusing to associate questions of evidence too closely with questions of dialectical propriety, we can preserve EV. EV concerns the evidence-for relation, as do most discussions of evidence.5 The focus of this chapter is elsewhere. It concerns the nature of the first relatum e of the evidence-for relation rather than its relation to the second relatum h. Whether EV needs revision will be left open; the present aim is to investigate its constituent 'S's evidence includes e'. Chapter
10 develops a theory of evidential probability to address the relation between evidence and what it supports.
Why does it matter what counts as evidence? Consider the idea that one should proportion one's belief in a proposition to one's evidence for it. How much evidence one has for the proposition depends on what one's evidence is. More precisely, a theory of evidence is needed to give bite to what Carnap calls the requirement of total evidence:
[I]n the application of inductive logic to a given knowledge situation, the total evidence available must be taken as a basis for determining the degree of confirmation. (1950: 211; compare Hempel 1965: 63-7)

If too much or too little is counted as evidence, inductive principles will be misapplied.
Given the requirement of total evidence, disputes between different theories of evidence are not merely verbal; they involve disagreements as to which inductive conclusions are warranted.
Formulations of the total evidence requirement in terms of knowledge encourage E = K, which identifies the total evidence available with the total knowledge available. For example, Peirce writes:
I cannot make a valid probable inference without taking into account whatever knowledge I have (or, at least, whatever occurs to my mind) that bears on the question. (1932: 461)

Carnap himself describes the evidence as (observational) knowledge. Given E = K, the original idea becomes something like this: one should proportion one's belief in a proposition to the support which it receives from one's knowledge.
The total evidence available must not be built into the probability distribution P in EV, otherwise no part of that evidence could confirm any hypothesis. In general, the total evidence must not be taken as a basis for determining the degree to which an individual piece e of that evidence increases the confirmation of a hypothesis h, for if e is part of the total evidence available then the confirmation of h prior to the acquisition of the total evidence presently available is also relevant.
This is a form of the problem of old evidence (Glymour 1980: 85-93, Earman 1992: 119-35,
Howson and Urbach 1993: 403-8, Maher 1996), which is discussed in the next chapter. But that does not undermine the point that the total evidence now available must be taken as the basis for determining the degree to which h is now confirmed in the non-comparative sense.
Theories of evidence also play a role when theses of the underdetermination of theory by data are assessed, for the data in question are the actual or potential evidence. If too much or too little is counted as evidence, then the standard for underdetermination is set uninterestingly high or uninterestingly low. E = K implies that undetermination theses of the relevant kind must count all knowable facts as data. Although this condition does not automatically make any argument for underdetermination circular, it is not easily met. Consider, for example, the underdetermination thesis that the theoretical facts do not supervene on the evidential facts: two possible worlds can differ in the former without differing in the latter.6 One cannot establish this claim just by showing that the theoretical facts do not supervene on the facts which are in some sense observable; one must also show that they do not supervene on all the knowable facts. The gap would be filled by an argument that the knowable facts supervene on the observable facts, for then whatever failed to supervene on the observable facts would fail to supervene on the knowable facts too, by the transitivity of supervenience. But any such argument risks begging the question against the view that at least some theoretical facts are knowable.
9.3 Access to Evidence Chapter 8 argued that we are not always in a position to know what our evidence is.
Consequently, a theory of evidence cannot be expected to provide a decision procedure which will always enable us to determine in practice whether our evidence includes a given item. In general, a philosophical theory of a concept is not required to provide a decision procedure which will always enable us to determine in practice whether it applies to a given item. The concept of evidence might have been expected to be special in this respect, for if it were problematic whether one's evidence included something, one would need evidence to decide whether one's evidence included it, and an infinite regress looms. It is therefore tempting to suppose both that it must be unproblematic whether one's evidence includes any given item, and that an adequate theory of evidence must explain how it manages to be so unproblematic. By the argument of Chapter 8, however, no correct theory of evidence can have that upshot. Certainly the equation E = K does not, but since that does not distinguish it from other theories of evidence, it constitutes no objection to E = K. In obvious symbolism, E = K equates E p and K p. The transparency of evidence would make E p equivalent to KE p. Given E = K, that is tantamount to making K p equivalent to KK p. But we saw in section 5.1 that K p does not entail KK p. This section explores our limited access to our evidence in the light of the equation E= K.
There is no infallible recipe for deciding in practice whether we know a proposition p.
Sometimes we reasonably believe ourselves to know p, when in fact we do not know p, because p is false. Reputable authorities assert that Henry V died in 1422; I have no grounds for doubting them, and reasonably believe myself to know by testimony that Henry V died in 1422. But it is not inconceivable that he died in 1423, some elaborate conspiracy being responsible for present evidence to the contrary. According to E = K, if I do know that Henry V died in 1422, then my total evidence includes the proposition that Henry V died in 1422; but if Henry V died in 1423, then my belief that my total evidence includes that proposition is mistaken—my total evidence includes only the proposition that reputable authorities assert that Henry V died in 1422. E = K is an externalist theory of evidence, in at least the sense that it implies that one's evidence does not supervene on one's internal physical states. But if knowing is a mental state, as argued in Chapter 1, then one's evidence does supervene on one's mental states.
How does E = K avoid the threatened regress of evidence? The regress comes if evidencebased belief in a proposition p must always be preceded by evidence-based belief in a proposition about the evidence for p. We can distinguish two senses of 'evidence-based'. Call one's belief in p explicitly evidence-based if it is influenced by prior beliefs about the evidence for p. Explicitly evidence-based beliefs may be more common in science than in everyday life. Call one's belief in p implicitly evidence-based if it is appropriately causally sensitive to the evidence for p. A belief can be both explicitly and implicitly evidence-based. Now, explicitly evidence-based belief in p is not always preceded by explicitly evidence-based belief in a proposition about the evidence for p; this is consistent with E = K and most other theories of evidence. An explicitly evidence-based belief is influenced by a prior state of belief in a proposition about the evidence for p, and something has gone wrong if the latter belief is not at least implicitly evidence-based; but it need not be explicitly evidence-based. Thus there is no regress of explicitly evidence-based belief. There would be a different regress if implicitly evidence-based belief in p were always preceded by implicitly evidence-based belief in a proposition about the evidence for p. But the causal sensitivity of the belief in p to the evidence for p need not be mediated by further beliefs about the evidence for p. There need be no such beliefs.
How can a belief in p be implicitly evidence-based, if we are liable to misidentify the evidence for p? If the real evidence differs from the apparent evidence, will not the belief be causally sensitive to the latter rather than the former? But, as noted in section 8.7, we are liable to misidentify the apparent evidence, too. Causal sensitivity need not be perfect to be genuine. There can be a non-accidental rough proportionality between the strength of the belief and the strength of the evidence, even if distortions sometimes occur. Similar questions arise about explicitly evidence-based belief. How can one follow the rule
'Proportion your belief in p to your evidence for p' when one doesn't know exactly what one's evidence is? Given E = K, the rule becomes 'Proportion your belief in p to the support that p receives from your knowledge': but is one not at best following the rule 'Proportion your belief in p to the support that p receives from what you believe to be your knowledge'? Consider an analogy.
We can follow the rule 'Proportion your voice to the size of the room'. This is not because we are infallible about the size of the room. We sometimes make mistakes; but it does not follow that we are really following the rule 'Proportion your voice to what you believe to be the size of the room'.
After all, it is often quite hard to know what beliefs one has about the size of a room; we are fallible in our beliefs about such beliefs. That one believes p is not a luminous condition. In general, if the fallibility of our beliefs about X posed a problem, it would not be solved by the move to our beliefs about our beliefs about X, because they are fallible too. But fallibility does not pose a problem here.
To make a mistake in following a rule is not to follow a different rule. The rule is a standard of correctness for action, not a description of action. To have applied the rule 'Proportion your voice to the size of the room', one needs beliefs about the size of the room, but they need not have been true—although if they were false, one's application was faulty. Similarly, to have applied the rule
'Proportion your belief in p to the support that p receives from your knowledge', one must have had beliefs about how much support p received from one's knowledge, and therefore about one's knowledge, but those beliefs need not have been true—although if they were false, one's application was faulty.
None of this would be much consolation if our beliefs about our knowledge were hopelessly unreliable. Sceptics say that those beliefs have no rational basis, but they say the same about most of our other beliefs, too. We have found their reasons for saying so to be inadequate. Although we have no infallible procedure for determining whether we know p, in practice we are often in a position to know whether we know p.
The ways in which we decide whether we know p are not simply the ways in which we decide whether we believe that we know p. If I want to check whether I now really know that Henry
V died in 1422, it would be relevant to return to my sources; it would be irrelevant to do that if I
merely wanted to check whether I now really believe that I know that he died in 1422.
As Chapter 8 noted, alternative theories of evidence distort the concept in the attempt to make evidence something that we can infallibly identify. Characteristically, they interiorize evidence: it becomes one's present experience, one's present degrees of belief, or the like. Those attempts are quaint relics of Cartesian epistemology. Knowledge of the present contents of one's own mind is neither unproblematic nor prior to knowledge of other things. It is not obvious to me how many shades of blue I am presently experiencing, or to what degree I believe that there was once life on Mars. If one's evidence were restricted to the contents of one's own mind, it could not play the role that it actually does in science. The evidence for the proposition that the sun is larger than the earth is not just my present experiences or degrees of belief. If the evidence is widened to include other people's experiences or degrees of belief, or my past ones, then my identification of it becomes even more obviously fallible. In any case, that does not seem to be the right widening; it is more plausible that the evidence for a scientific theory is the sort of thing which is made public in scientific journals. If evidence is like that, our identification of it is obviously fallible.
9.4 An Argument
Here is a schematic argument for E = K:
All evidence is propositional.
All propositional evidence is knowledge.
All knowledge is evidence.
All and only knowledge is evidence.
The argument is obviously valid, but its premises are contentious. Its aim is simply to divide the contentiousness of the conclusion into manageable portions; sections 9.5, 9.6, and 9.7 respectively defend the three premises. Since 'knowledge' here means propositional knowledge, each premise follows from the conclusion; thus the conclusion is equivalent to the conjunction of the premises.
One's evidence is propositional if and only if it is a set of propositions. Propositions are the objects of propositional attitudes, such as knowledge and belief; they can be true or false; they can be expressed relative to contexts by 'that' clauses. For present purposes, we do not need a developed theory of propositions. If evidence is propositional, we can refer to evidence by using 'that' clauses: my evidence for the conclusion that the house was empty is that it was silent, that no lights were on in the evening, that the telephone went unanswered, . . . .
9.5 Evidence as Propositional
Why should all evidence be propositional? It would not be on a broad interpretation of
'evidence'. In the courts, a bloodied knife is evidence. It is natural to say that my evidence that I am getting a cold includes various sensations. Some philosophers apply the term 'evidence' to nonpropositional perceptual states; Quine restricts it to the stimulation of sensory receptors (1969: 75).
How can 'All evidence is propositional' do more than stipulate a technical use for the word
'evidence'?
Indiscriminate description of the ordinary use of a term and arbitrary stipulation of a new use are not the only options. We can single out theoretical functions central to the ordinary concept evidence, and ask what serves them. That strategy is pursued here. The argument below substantiates the familiar claim that only propositions can be reasons for belief (for example, Unger
1975: 204-6 and Davidson 1986; for opposing views, Moser 1989: 47-125 and Millar 1991). It also suggests a further conclusion: one grasps the propositions that are one's evidence; one can think them.
Consider inference to the best explanation (Harman 1965, Lipton 1991). We often choose between hypotheses by asking which of them best explains our evidence—which of them, if true, would explain the evidence better than any other one would, if true. Fossil evidence enables us to answer questions about terrestrial life in this way. Even if inference to the best explanation is not legitimate in all theoretical contexts, what matters for present purposes is that, where evidence does enable us to answer a question, a central way for it to do so is by inference to its best explanation. Thus evidence is the kind of thing which hypotheses explain. But the kind of thing which hypotheses explain is propositional. Therefore evidence is propositional.
The kind of thing which hypotheses explain is propositional. Inference to the best explanation concerns why-explanations, which can be put in the form '——because . . . ', which is ungrammatical unless declarative sentences, complements for 'that', fill both blanks. We cannot simply explain Albania, for 'Albania because . . . ' is ill-formed. We can sometimes make sense of the injunction 'Explain Albania!', but only when the context allows us to interpret it as an injunction to explain why Albania exists, or has some distinctive feature. What follows 'why' is a declarative sentence, expressing the proposition to be explained—that Albania exists, or that it has the distinctive feature. It makes no significant difference if what is to be explained is one thing as contrasted with another (Lipton 1991: 75-98). For example, we may seek to explain why Kosovo rather than Bosnia was peaceful in 1995. The evidence in question would be the propositions that
Kosovo was peaceful in 1995 and that Bosnia was not. The same goes for events: 'Explain World
War I!' enjoins one to explain why it occurred, or had some distinctive feature. Again, the sensation in my throat is evidence for the conclusion that I am getting a cold in the sense that the hypothesis that I am getting a cold would best explain why I have that sensation in my throat. The evidence to be explained is that I have that sensation in my throat—not just that I have a sensation in my throat.
Even in the courts, the bloodied knife provides evidence because the prosecution and defence offer competing hypotheses as to why it was bloodied or how it came into the accused's possession; the evidential proposition is that it was bloodied or that it came into the accused's possession. The knife is a source of indefinitely many such propositions.
One can use an hypothesis to explain why A only if one grasps the proposition that A. Thus only propositions which one grasps can function as evidence in one's inferences to the best explanation. By this standard, only propositions which one grasps count as part of one's evidence.
Similar points apply to explicitly probabilistic reasoning. If such reasoning can be assimilated to inference to the best explanation, or vice versa, so much the better. The best way of comparing the conditional probabilities of two hypotheses h and h* on evidence e, P(h| e) and P(h*|
e), is often by calculating the inverse probabilities of e on h and h*, P(e| h), and P(e| h*). For example, a bag contains ten red or black balls; we wish to estimate how many of them are red; we are allowed to gain evidence only by sampling one ball at a time, noting its colour and replacing it. A good way to compare the probabilities of hypotheses about the number of red balls is by calculating the probabilities of the actual outcome e of the sampling (say, red fifteen times and black five times) on those hypotheses. One way of using those probabilities is to regard h as more probable than h* given e (P(h| e)>P(h*| e)) if and only if h makes e more probable than h*
does (P(e | h)>P(e | h*)). Bayesians take this method to involve assigning the same prior probability to h and h* (P(h)=P(h*)); they treat as equally legitimate assignments of unequal prior probabilities to the hypotheses—perhaps reflecting differences in explanatory virtues such as simplicity and elegance. To allow for such cases, their general rule weights the probability of e on h by the prior probability of h; thus P(h | e)>P(h*| e) if and only if P(h)P(e| h)>P(h*)P(e | h*), where P(e), P(h), and P(h*) are all non-zero. For present purposes, it does not matter whether Bayesians are right to introduce prior probabilities here. The point is that such probabilistic comparisons of hypotheses on the evidence depend on the probabilities of the evidence on the hypotheses. But what has a probability is a proposition; the probability is the probability that . . . . At least, that is so when
'probability' has to do with the evidential status of beliefs, as now; if we speak in this connection of the probability of an event, we mean the probability that it occurred.7 We might initially suppose that, in P(x| y), only x need be a proposition, but the relation between P(x| y) and P(y| x) means that y must be a proposition too; what gives probability must also receive it. Moreover, these probabilities, as measures of degrees of belief warranted by evidence, are idle unless the subject grasps x and y.
More straightforward uses of evidence also require it to be propositional. In particular, our evidence sometimes rules out some hypotheses by being inconsistent with them. For example, the hypothesis that only males have varicose veins is inconsistent with much medical evidence. But only propositions can be inconsistent in the relevant sense. If evidence e is inconsistent with an hypothesis h in that sense, it must be possible to deduce ~h from e; the premises of a deduction are propositions. Moreover, the subject who deduces ~h from e must grasp e.
Only propositions which we grasp serve the central evidential functions of inference to the best explanation, probabilistic confirmation, and the ruling out of hypotheses. Could non-propositional items count as evidence by serving other central functions of evidence? For example, they might serve as the inputs to a non-inferential process whose outputs were beliefs. But suppose that we are choosing between hypotheses according to which best explains our evidence, or is most probable on our evidence, or is not ruled out by our evidence. The argument so far shows that only propositional evidence would be directly relevant to our choice.
Moreover, in choosing between hypotheses in those ways, we can use only propositions which we grasp. In those respects, any evidence other than propositions which we grasp would be impotent.
Although evidence may well have central functions additional to those considered above, genuine evidence would make a difference to the serving of the functions considered above, whatever else it made a difference to. Certainly, defences of non-propositional evidence have not been based on an appreciation of its impotence in those respects. Since only propositions we grasp make a difference of the requisite kind, only propositions which we grasp are our evidence. A positive case for that conclusion has now been given. Nevertheless, perceptual experience is often regarded as a kind of non-propositional evidence. Do the considerations above somehow fail to do it justice? The remainder of this section will rebut objections to the view that our perceptual evidence consists of propositions which we grasp.
Experiences provide evidence; they do not consist of propositions. So much is obvious. But to provide something is not to consist of it. The question is whether experiences provide evidence just by conferring the status of evidence on propositions. On that view, consistent with E = K, the evidence for an hypothesis h consists of propositions e 1 , . . . , e n , which count as evidence for one only because one is undergoing a perceptual experience ε. As a limiting case, h might be e i . The threatening alternative is that ε can itself be evidence for h, without the mediation of any such e 1 ,
. . . , e n . Both views permit ε to have a non-propositional, non-conceptual content, but only the latter permits that content to function directly as evidence.
If perceptual evidence consists of propositions, which propositions are they? Consider an example. I am trying to identify a mountain by its shape. I can see that it is pointed; that it is pointed may be part of my evidence for believing that it is not Ben Nevis. However, the proposition that it is pointed does not begin to exhaust my present perceptual evidence. No description of the mountain in words seems to capture the richness of my visual experience of its irregular shape. But it does not follow that my evidence is non-propositional. If I want to convey my evidence, I might point and say 'It is that shape'.8 Of course, the mere linguistic meaning of the sentence type 'It is that shape' does not convey my evidence, for it is independent of the reference of 'that shape' in a particular context of utterance. Only by using the sentence in an appropriate context do I express the proposition at issue. My token of 'that shape' still expresses a constituent of that proposition, even if you cannot grasp that constituent without having a complex visual experience with a structure quite different from the constituent structure of the proposition.
The proposition that the mountain is that shape is contingent; it could have been another shape. The proposition is also known a posteriori; I do not know a priori that I am not including the tip of another mountain behind in the profile. But in ordinary circumstances I can know that the mountain is that shape, and a fortiori grasp the proposition that it is, when 'that shape' does not refer to an absolutely specific shape. Of course, I cannot see exactly what shape the mountain is; I can only see roughly what profile it presents to me, and cannot see round the back. That shape must be unspecific enough to give my knowledge that the mountain is that shape an adequate margin for error in the sense of Chapter 5.9 The knowledge that the mountain is that shape is obtainable in other contexts; you can have it too, and we can retain it in memory. Properties other than shape are similar in those respects.
In unfavourable circumstances, one fails to gain perceptual knowledge, perhaps because things are not the way they appear to be. One does not know that things are that way, and E = K
excludes the proposition that they are as evidence. Nevertheless, one still has perceptual evidence, even if the propositions it supports are false. True propositions can make a false proposition probable, as when someone is skilfully framed for a crime of which she is innocent. If perceptual evidence in the case of illusions consists of true propositions, what are they? The obvious answer is: the proposition that things appear to be that way. The mountain appears to be that shape. Of course, unless one has reason to suspect that circumstances are unfavourable, one may not consider the cautious proposition that things appear to be that way; one may consider only the unqualified proposition that they really are that way. But it does not follow that one does not know that things appear to be that way, for one knows many propositions without considering them. When one is walking, one normally knows that one is walking, without considering the proposition. Knowing is a state, not an activity. In that sense, one can know without consideration that things appear to be some way. When I believe falsely that circumstances are favourable, I believe falsely that I am gaining perceptual knowledge about the environment, and therefore that my evidence includes those propositions believed to be known. But our fallibility in identifying our evidence is nothing new, and my actual evidence may justify my false beliefs about my evidence.
In order to grasp the proposition that things appear to be some way, one must grasp the property of appearing, on the assumption that the semantically significant constituents of a sentence express constituents of the proposition expressed by the whole sentence. Although one's grasp of the property of appearing may be inarticulate, one must have some inkling of the distinction between appearance and reality. For instance, one should be willing in appropriate circumstances to give up the belief that things were that way while retaining the belief that they appeared to be that way. In the absence of such dispositions, it is implausible to attribute the qualified belief that things appear to be that way rather than the unqualified belief that they are that way. Perhaps some young children and animals have beliefs and perceptual experiences without even implicitly grasping the property of appearance. Suppose that such a simple creature is given a drug which causes the hallucinatory appearance that there is food ahead; as a result, it comes to believe falsely that there is food ahead. Does it have any evidence for that belief? According to E = K, its evidence cannot be that things appear some way, for it cannot grasp that proposition. Perhaps it knows that the situation is like one in which there is food ahead, where the property of likeness covers both likeness in appearance and other kinds of likeness indifferently, so that grasp of the property of likeness does not require grasp of the property of appearing. If the creature does not even know that the situation is like one in which there is food ahead, then we can plausibly deny that it has perceptual evidence that there is food ahead. It does not recognize the features of its perceptual experience which, if recognized, would provide it with evidence. We can use the proposition that there appears to be food ahead as evidence, but the simple creature cannot. Although the hallucinatory appearance causes a belief, that causal relation is not an evidential one.
Very simple creatures grasp no properties or propositions and have no beliefs or knowledge. It is sometimes even argued—not very plausibly—that any creature which lacks the distinction between appearance and reality is in this predicament. Simple creatures have no evidence, for they have no degrees of belief, and degrees of belief are what evidence justifies.
S can use as evidence only propositions which S grasps. Since S can use S's evidence as evidence, only propositions which S grasps are S's evidence. What has not yet been argued is that those propositions count as evidence by being known.
9.6 Propositional Evidence as Knowledge
Why should all propositional evidence be knowledge? The thesis is that if S's evidence includes a proposition e, then S knows e. If I do not know that the mountain is that shape, then that it is that shape is not part of my evidence. As in the previous section, the argument is from the function of evidence.10 Indeed, the thesis draws support from the role of evidence cited there, in inference to the best explanation, probabilistic reasoning, and the exclusion of hypotheses. When we prefer an hypothesis h to an hypothesis h* because h explains our evidence e better than h*
does, we are standardly assuming e to be known; if we do not know e, why should h's capacity to explain e confirm h for us? It is likewise hard to see why the probability of h on e should regulate our degree of belief in h unless we know e. Again, an incompatibility between h and e does not rule out h unless e is known. But it is prudent to consider the matter more carefully.
Suppose that balls are drawn from a bag, with replacement. In order to avoid issues about the present truth-values of statements about the future, assume that someone else has already made the draws; I watch them on film. For a suitable number n, the following situation can arise. I have seen draws 1 to n; each was red (produced a red ball). I have not yet seen draw n+1. I reason probabilistically, and form a justified belief that draw n+1 was red too. My belief is in fact true. But
I do not know that draw n+1 was red. Consider two false hypotheses: h: Draws 1 to n were red; draw n+1 was black. h: Draws 1 to n were red; draw n+1 was black.
h*: Draw 1 was black; draws 2 to n+1 were red. It is natural to say that h is consistent with my evidence and that h* is not. In particular, it is consistent with my evidence that draw n+1 was black; it is not consistent with my evidence that draw 1 was black. Thus my evidence does not include the proposition that draw n+1 was red. Why not? After all, by hypothesis I have a justified true belief that it was red. The obvious answer is that
I do not know that draw n+1 was red; the unsatisfied necessary condition for evidence is knowledge.
An alternative answer is that I have not observed that draw n+1 was red. That is equally good for the purposes of this section (although not for those of the next), for observing the truth of e includes e in my evidence only by letting me know e. If I observe the truth of e and then forget all about it, my evidence no longer includes e. It is hard to see how evidence could discriminate between hypotheses in the way we want it to if it did not have to be known.
If evidence required only justified true belief, or some other good cognitive status short of knowledge, then a critical mass of evidence could set off a kind of chain reaction. Our known evidence justifies belief in various true hypotheses; they would count as evidence too, so this larger evidence set would justify belief in still more true hypotheses, which would in turn count as further evidence . . . . The result would be very different from our present conception of evidence.
That propositional evidence is knowledge entails that propositional evidence is true. That is intuitively plausible; if one's evidence included falsehoods, it would rule out some truths, by being inconsistent with them. One's evidence may make some truths improbable, but it should not exclude any outright. Although we may treat false propositions as evidence, it does not follow that they are evidence. No true proposition is inconsistent with my evidence, although I may think that it is. If e is evidence for h, then e is true. There is no suggestion, of course, that if e is evidence for h then h is true. For example, that the ground is wet is evidence that it rained last night only if the ground is wet—even if it did not rain last night. If e is not true, then at most a counterfactual holds: if e had been true, e would have been evidence for h.11 If the convincing but lying witness says that the accused was asleep at the time of the murder, then it is part of the evidence for the innocence of the accused that the witness said that he was asleep then. It is not part of the evidence for his innocence that he was asleep, for it is consistent with the evidence that he was not. The rival view, that a false proposition can become evidence through a sufficient appearance of truth, gains most of its appeal from the assumption, disposed of in Chapter 8 and section 9.3, that we must have an infallible way of identifying our evidence.
Once it is granted that all propositional evidence is true—and therefore, by the previous section, that all evidence consists of true propositions—adjusting our beliefs to the evidence has an obvious point. It is a way of adjusting them to the truth. Although true evidence can still support false conclusions, it will tend to support truths. The maxim 'Proportion your belief to your evidence'
requires more than the mere internal coherence of one's belief system; it does so because evidence must be true. Even if an internally coherent belief system cannot be wholly false, a given belief system with a given degree of internal coherence can be better or worse proportioned to the evidence, depending on what the evidence is. But, equally, the evidence is not a wholly external standard, if it is known.
Another consequence of the claim that propositional evidence is knowledge is that propositional evidence is believed—at least, if knowledge entails belief, which is granted here (see section 1.5). The case of perception may seem to suggest that propositional evidence is not always believed. In conformity with the previous section, a piece of perceptual evidence is, for example, a proposition e that things are that way. According to E = K, my evidence includes e because I know that things are that way. But, a critic may suggest, that does not go back far enough; my evidence includes e because it is perceptually apparent to me that things are that way, whether or not I
believe that they are that way. Even if I do believe e, my evidence included e before I came to believe it; according to the critic, I came to believe it because it was perceptually apparent. If 'It is perceptually apparent that A' entails 'A', then the critic's view allows that evidential propositions are always true; what it denies is that they are always believed, and therefore that they are always known.
If my evidence includes a proposition e, then I grasp e, by section 9.5. Thus, if I fail to believe e, my problem is not conceptual incapacity. Perhaps I have simply not had time to form the belief; perhaps I suspect, for good or bad reasons, that I am the victim of an illusion. We can ask the critic whether, for my evidence to include e, I must at least be in a position to know e? If so, then the critic's view does not differ radically from E = K. Given E = K, the evidence in my actual possession consists of the propositions which I know, but there is also the evidence in my potential possession, consisting of the propositions which I am in a position to know. The critic takes my evidence to be the evidence in my potential possession, not just the evidence in my actual possession. To bring out the difference between that view and E = K, suppose that I am in a position to know any one of the propositions p 1 , . . . , p n without being in a position to know all of them; there is a limit to how many things I can attend to at once. Suppose that in fact I know p 1 and do not know p 2 , . . . , p n . According to E = K, my evidence includes only p 1 ; according to the critic, it includes p 1 , . . . , p n . Let q be a proposition which is highly probable given p 1 , . . . , p n together, but highly improbable given any proper subset of them; the rest of my evidence is irrelevant to q. According to E = K, q is highly improbable on my evidence. According to the critic, q is highly probable on my evidence. E = K
gives the more plausible verdict, because the high probability of q depends on an evidence set to which as a whole I have no access.
The contrast with E = K is more radical if the critic allows my evidence to include e even when I am not in a position to know e. For example, it is perceptually apparent to me that it is snowing; I am not hallucinating; but since I know that I have taken a drug which has a 50 per cent chance of causing me to hallucinate, I am not in a position to know that it is snowing. According to the radical critic, my evidence nevertheless includes the proposition that it is snowing, because it is perceptually apparent to me that it is snowing; thus my evidence is inconsistent with the hypothesis that I am hallucinating and it is not snowing, even though, for all I am in a position to know, that hypothesis is true. According to E = K, my evidence includes at best the proposition that it appear to be snowing. Surely, if I proportion my belief to my evidence, I shall not dismiss the hypothesis that I am hallucinating and it is not snowing. E = K gives the better verdict. Perceptual cases do not show that we sometimes fail to believe our evidence.
A truth does not become evidence merely by being believed, or even by being justifiably believed, as the example of the proposition that draw n+1 was red showed above. Nothing short of knowledge will do. But is even knowledge enough?
9.7 Knowledge as Evidence
Any restriction on what counts as evidence should be well-motivated by the function of evidence. By sections 9.5 and 9.6, one's evidence includes only propositions which one knows. If, when assessing an hypothesis, one knows something e which bears on its truth, should not e be part of one's evidence? Would it not violate the total evidence condition to do otherwise? This section examines attempts to justify some further restriction on evidence, and finds them wanting.
One's knowledge is held together by a tangle of evidential interconnections. For example, my knowledge that Henry V died in 1422 is evidentially related to my knowledge that various books say that he died in 1422. Much of one's knowledge is redundant, in the sense that the proposition known is a logical consequence of other known propositions. Perhaps each proposition which I know is redundant in that sense. If all knowledge is evidence, the evidential interconnectedness and redundancy is internal to one's evidence. The redundancy itself is harmless; it does not make the evidence support the wrong hypotheses. The concern is rather that if all one's knowledge is treated as a single body of evidence, its internal evidential interconnections will be obliterated, and therefore that such an account would falsify the nature of our knowledge.
The alternative, presumably, is for evidence to be self-evident, consisting of epistemically self-sufficient nuggets of information. That is an implausibly atomistic picture of evidence, but it constitutes a challenge to explain how there can be evidential interconnections within a single body of evidence. Section 9.2 provides the basis for such an explanation. According to EV, when e is evidence for an hypothesis h for one, one's evidence includes e, and e raises the probability of h, which requires the probability of e on the relevant distribution to be less than 1. Thus EV already permits one proposition in one's evidence to be evidence for another in a non-trivial way. The internal evidential interconnections are not obliterated.
If all knowledge is evidence, then EV in section 9.2 does have the effect of making evidential interconnections within one's knowledge symmetric. For P(p | q)>P(p) if and only if P(p
& q) >P(p)P(q); since the latter condition is symmetric in p and q, P(p | q)>P(p) if and only if P(q |
p) >P(q). Thus, given that S's evidence includes both p and q, p is evidence for q for S if and only if q is evidence for p for S by EV. Consequently, given that one knows p and q and that all knowledge is evidence, EV implies that if p is evidence for q for one then q is evidence for p for one. We could avoid this result by modifying EV. For example, we could stipulate that e is evidence for h for S
only if S's belief in e does not essentially depend on inference from h. But it might be neater to retain EV unmodified and say that e is independent evidence for h for S only if S's belief in e does not essentially depend on inference from h. Since the focus of this discussion is not on the evidencefor relation, we shall not pursue these options further. The claim that all knowledge is evidence faces another sort of objection. Very little (if any)
of what we know is indubitable. Therefore, if all knowledge is evidence, much of our evidence is dubitable. We are uneasy with the idea of uncertain evidence. Is this just the old Cartesian prejudice that only unshakable foundations will do? The worry cannot be so easily dismissed. It takes a particularly sharp form in a Bayesian context. The standard way of accommodating new evidence e is by conditionalizing on it. The new unconditional probability of a proposition is its old probability conditional on e (where the old probability of e was non-zero); P new (h) = P old (h | e). In particular,
P new (e) = P old (e | e) = 1. These probability distributions should be distinguished from P in EV
above, for both P old and P new are supposed to incorporate all of one's evidence at the relevant times; whereas it was observed that P must incorporate only a proper part of one's evidence. Now if the old probability of h was 1, so is its new probability; for if P old (h)= 1 then P old (h & e)=P old (e). Since the new probability of e is 1, it will remain 1 under any series of conditionalizations on further propositions. Thus once a proposition is conditionalized on as evidence, it acquires probability 1, and retains it no matter what further evidence is conditionalized on. But most of our knowledge has no such status. Further evidence could undermine it.12
Here is an example. I put exactly one red ball and one black ball into an empty bag, and will make draws with replacement. Let h be the proposition that I put a black ball into the bag, and e the proposition that the first ten thousand draws are all red. I know h by a standard combination of perception and memory, because I saw that the ball was black as I put it into the bag a moment ago.
Nevertheless, if after ten thousand draws I learn e, I shall have ceased to know h, because the evidence which I shall then have will make it too likely that I was somehow confused about the colours of the balls. Of course, what I know now is true, and so will never be discovered to be false, but it does not follow that there will never be misleading future evidence against it. My present knowledge is consistent with e; on simple assumptions, e has a probability of 1/210,000 on my present evidence. If I subsequently learn e, the probability of h on that future evidence will be less than 1.
But if conditionalization on subsequent evidence will give h a probability less than 1, then the present probability of h is less than 1, so h is not part of my present evidence. The problem is general: if misleading future evidence of positive probability can undermine my knowledge that I
put a black ball into the bag, it can undermine most of my present knowledge. It looks as though h should count as part of my present evidence, and therefore receive probability 1, only if h is bound to be a rational belief for me in the future, come what may. Few propositions will pass that test.
Indeed, not even e passes the test, for later evidence may make it rational for me to believe that I
had misremembered the outcome of the first ten thousand draws; several eyewitnesses may insist that I was misremembering; but since uncertainty about e does not make h certain, it does not rehabilitate h as evidence. By this line of argument, either we know very little, or very little of our knowledge is evidence.
What empirical propositions qualify as evidence by the proposed test that their probability should never subsequently slip below 1? One might suppose that the best candidates would be propositions about the present—traditionally, propositions about the subject's present mental states.
Since the test requires evidence to remain certain as time passes, in order for a proposition about the present to be evidence, it must remain certain long after the time it is about has passed. But even if it is absolutely certain for me today that I seem to see a blue patch, it will not be absolutely certain for me tomorrow that I seemed to see a blue patch today; my memories will not be beyond question.
It would only exacerbate the problem to individuate propositions so that the present tensed sentence
'I seem to see a blue patch' expressed the same proposition at different times, for even if such a proposition is certain and so true now, it will be false and so uncertain in the future. It is hard to see what empirical propositions would qualify as evidence by the proposed test. Thus the very possibility of learning from experience is threatened.
The model assumes that probabilities change only by conditionalization on new evidence.
This is to assume that evidence can be added but not subtracted over time. The assumption is obviously false in practice, because we sometimes forget. But even if the model is applied to elephants, idealized subjects who never forget, the assumption that evidence cannot be lost is implausible. On any reasonable theory of evidence, an empirical proposition which now counts as evidence can subsequently lose its status as evidence without any forgetting, if future evidence casts sufficient doubt on it. Given E = K, this process is the undermining of knowledge. The next chapter develops a more liberal model within a broadly Bayesian framework in which evidence can be lost as well as gained. If today's evidence is not evidence tomorrow, its probability tomorrow can be less than 1. The requirement that the probability of present evidence should never slip below 1 in the future was just an artefact of an overly restrictive model of updating.
One could have a model of the same structure on which only knowledge 13
of the present, or observational knowledge, counts as evidence. But once it is recognized that evidence is not obliged to meet unusual standards of certainty, such restrictions on evidence look ad hoc. Although knowledge of the present or observational knowledge may be easier to obtain than some other kinds of knowledge, that is no reason against counting other kinds of knowledge as evidence, when we obtain them. For example, our evidence for a mathematical conjecture may consist of mathematical knowledge. If we believe that we know p, we shall be disposed to use p in the ways in which we use evidence. If our belief is true, we are right to use p in those ways. It does not matter what kind of proposition p is; as Austin said, 'any kind of statement could state evidence for any other kind, if the circumstances were appropriate' (1962: 116). All knowledge is evidence.
9.8 Non-Pragmatic Justification
The present case for E = K is now complete. If evidence is what justifies belief, then knowledge is what justifies belief. But is all justified belief justified by evidence? Why cannot experience itself, or practical utility, justify belief? Why cannot belief sometimes be justified without being justified by anything at all?
The pragmatic justification of belief need not be by evidence. Without any evidence at all, someone believes that her child somehow survived an air crash, and will one day return to her. The belief is the only thing which keeps her going; without it, she would kill herself. Perhaps it is on balance a good thing that she has the belief, and in that sense the belief is justified. But this is not the sense of 'justified' in which justified belief appeared to have marginalized knowledge within epistemology. Could belief be epistemically justified except by evidence? Epistemic justification aims at truth in a sense—admittedly hard to define—in which pragmatic justification does not. It is far from obvious that any belief is justified in the truth-directed sense without being justified by evidence. It appears otherwise when evidence is conceived too narrowly, for then the evidence looks too scanty to justify all the beliefs which are in fact justified. But if anything we know can be evidence to anchor a chain of justification, as E = K
implies, then evidence plausibly suffices for all truth-directed justification. An epistemically justified belief which falls short of knowledge must be epistemically justified by something; whatever justifies it is evidence. An epistemically justified belief which does not fall short of knowledge is itself evidence, by E = K. If we are aiming at the truth, we should proportion our belief to the evidence.
E = K supports the plausible equation of truth-directed justification with justification by evidence, and therefore with justification by knowledge. On this view, if truth-directed justification is central to epistemology, so too is knowledge.
We can suggest something more radical. Belief does not aim merely at truth; it aims at knowledge. The more it is justified by knowledge, the closer it comes to knowledge itself. If evidence and knowledge are one, then the more a belief is justified by evidence, the closer it comes to its aim. The next two chapters will help to make those suggestions good. 10 Evidential Probability
10.1 Vague Probability
When we give evidence for our theories, the propositions which we cite as evidence are themselves uncertain. Probabilistic theories of evidence have notorious difficulty in accommodating that obvious fact, as section 9.7 noted. This chapter embeds the fact in a probabilistic theory of evidence. The analysis of uncertainty leads naturally to a simple theory of higher-order probabilities. The first step is to focus on the relevant notion of probability.
Given a scientific hypothesis h, we can intelligibly ask: how probable is h on present evidence? We are asking how much the evidence tells for or against the hypothesis. We are not asking what objective physical chance or frequency of truth h has. A proposed law of nature may be quite improbable on present evidence even though its objective chance of truth is 1. That is quite consistent with the obvious point that the evidence bearing on h may include evidence about objective chances or frequencies. Equally, in asking how probable h is on present evidence, we are not asking about anyone's actual degree of belief in h. Present evidence may tell strongly against h, even though everyone is irrationally certain of h. We will refer to degrees of belief as credences; for example, one's prior credence in the proposition that the fair coin will come up heads is normally
1/2; thus credences are not the degrees of outright belief discussed in section 4.4.
Is the probability of h on our evidence the credence which a perfectly rational being with our evidence would give to h? That suggestion comes closer to what is intended, but not close enough.
It fails in the way in which counterfactual analyses usually fail, by ignoring side-effects of the conditional's antecedent on the truth-value of the analysandum (Shope 1978). For example, to say that the hypothesis that there are no perfectly rational beings is very probable on our evidence is not to say that a perfectly rational being with our evidence would be very confident that there were no perfectly rational beings. To make the point more carefully, let p be a logical truth (a proposition expressed by a logically true sentence) such that in this imperfect world it is very probable on our evidence that no one has great credence in p. There are such logical truths, although in the nature of the case we cannot be confident that we have identified an example. For all we know, they include the proposition that Goldbach's Conjecture is a theorem of first-order
Peano Arithmetic (appropriately formalized). Of course, it is not highly probable on our evidence that no one will ever give high credence to the proposition that Goldbach's Conjecture is a theorem of first-order Peano arithmetic; we can eternalize the example, if we like, by imagining good evidence that nuclear war is about to end all intelligent life. Let h be the hypothesis that no one has great credence in p. By assumption, h is very probable on our evidence. On the view in question, a perfectly rational being with our evidence would therefore have great credence in h. Since p is a logical truth, h is logically equivalent to the conjunction p & h; since a perfectly rational being would have the same credence in logically equivalent hypotheses, it would have great credence in p
& h. But that is absurd, for p & h is of the Moore-paradoxical form 'A and no one has great credence in the proposition that A'; to have great credence in p & h would therefore be selfdefeating and irrational. One can have great credence in a true proposition of that form only by irrationally having greater credence in the conjunction than in its first conjunct. Thus the probability of a hypothesis on our evidence does not always coincide with the credence which a perfectly rational being with our evidence would have in it.
Presumably, a perfectly rational being must give great credence to p, be aware of doing so, and therefore give little credence to h and so to p & h; but then its evidence about its own states would be different from ours. If so, the hypothesis of a perfectly rational being with our evidence is impossible. There is no such thing as the credence which a perfectly rational being with our evidence would have in a given proposition. It can be argued that the subjective Bayesian conception of perfect rationality entails perfect accuracy about one's own credences (Milne 1991).
We therefore cannot use decision theory as a guide to evidential probability. Suppose, for example, that anyone whose credences have distribution P is vulnerable to a Dutch Book, a complex bet on which they lose money no matter what the outcome. It may follow that the credences of a perfectly rational being would not have distribution P, if a perfectly rational being would not be vulnerable to a Dutch Book, but it would be fallacious to conclude that probabilities on our evidence do not have distribution P, for those probabilities need not coincide with the hypothetical credences of a perfectly rational being. Perhaps only an imperfectly rational being could have exactly our evidence, which includes our evidence about ourselves. The irrationality of distributing credences according to the probabilities on one's evidence may simply reflect one's limited rationality, as reflected in one's evidence. But it would be foolish to respond by confining evidential probability to evidence sets which could be the total evidence possessed by a perfectly rational creature. That would largely void the notion of interest; we care about probabilities on our evidence.
For all that has been said, any agent with credences which fail to satisfy subjective Bayesian constraints may be eo ipso subject to rational criticism. This would apply in particular to the agent's beliefs about probabilities on its evidence. But it would apply equally to the agent's beliefs about objective physical chances, or anything else. Just as it implies nothing specific about objective physical chances, so it implies nothing specific about probabilities on evidence.
What, then, are probabilities on evidence? We should resist demands for an operational definition; such demands are as damaging in the philosophy of science as they are in science itself.
To require mathematicians to give a precise definition of 'set' would be to abolish set theory.
Sometimes the best policy is to go ahead and theorize with a vague but powerful notion. One's original intuitive understanding becomes refined as a result, although rarely to the point of a definition in precise pretheoretic terms. That policy will be pursued here. The discussion will assume an initial probability distribution P. P does not represent actual or hypothetical credences.
Rather, P measures something like the intrinsic plausibility of hypotheses prior to investigation; this notion of intrinsic plausibility can vary in extension between contexts. P will be assumed to satisfy a standard set of axioms for the probability calculus: P(p) is a non-negative real number for every proposition p; P(p)= 1 whenever p is a logical truth; P(pV q)=P(p)+P(q) whenever p is inconsistent with q. If P(q)> 0, then the conditional probability of p on q, P(p | q), is defined as P(p & q)/P(q).
P(p) is taken to be defined for all propositions; the standard objection that the subject may never have considered p is irrelevant to the non-subjective probability P. But P is not assumed to be syntactically definable. Carnap's programme of inductive logic is moribund. The difference between green and grue is not a formal one.
Consider an analogy. The concept of possibility is vague and cannot be defined syntactically. But that does not show that it is spurious. In fact, it is indispensable. Moreover, we know some sharp structural constraints on it: for example, that a disjunction is possible if and only if at least one of its disjuncts is possible. The present suggestion is that probability is in the same boat as possibility, and not too much the worse for that. On the view to be defended here, the probability of a hypothesis h on total evidence e is P(h
| e). The last chapter gave an account of when a proposition e constitutes one's total evidence. The best that evidence can do for a hypothesis is to entail it (so P(h | e)= 1); the worst that evidence can do is to be inconsistent with it (so P(h | e)= 0). Between those extremes, the initial probability distribution provides a continuum of intermediate cases, in which the evidence comes more or less close to requiring or ruling out the hypothesis.
The axioms entail that logically equivalent propositions have the same probability on given evidence. The reason is not that a perfectly rational being would have the same credence in them, for the irrelevance of such beings to evidential probability has already been noted. The axioms are not idealizations, false in the real world. Rather, they show what kind of thing we are choosing to study. We are using a notion of probability which (like the notion of incompatibility) is insensitive to differences between logically equivalent propositions. We thereby gain mathematical power and simplicity at the loss of some descriptive detail (for example, in the epistemology of mathematics): a familiar bargain.
The characterization of the prior distribution for evidential probability is blatantly vague. If that seems to disadvantage it with respect to subjective Bayesian credences, which can be more precisely defined in terms of consistent betting behaviour, the contrast in precision disappears in epistemological applications. Given a finite body of evidence e, almost any posterior distribution results from a sufficiently eccentric prior distribution by Bayesian updating on e. Theorems on the
'washing out' of differences between priors by updating on evidence apply only 'in the limit'; they tell us nothing about where we are now (Earman 1992: 137-61 has a sophisticated discussion).
Successful Bayesian treatments of specific epistemological problems (for example, Hempel's paradox of the ravens) assume that subjects have 'reasonable' prior distributions. We judge a prior distribution reasonable if it complies with our intuitions about the intrinsic plausibility of hypotheses. This is the same sort of vagueness as infects the present approach, if slightly better hidden.
One strength of Bayesianism is that the mathematical structure of the probability calculus allows it to make illuminating distinctions which other approaches miss and provide a qualitatively fine-grained analysis of epistemological problems, given assumptions about all reasonable prior distributions. That strength is common to subjective and objective Bayesianism, for it depends on the structure of the probability calculus. On the present approach, which can be regarded as a form of objective Bayesianism, the axioms of probability theory embody substantive claims, as the axioms of set theory do. For example, the restriction of probabilities to real numbers limits the number of gradations in probability to the cardinality of the continuum. Just as the axioms of set theory refine our understanding of sets without reducing to implicit definitions of 'set', so the axioms of probability theory refine our understanding of evidential probability without reducing to implicit definitions of 'evidential probability'. The remarks above are not intended to smother all doubts about the initial probability distribution. Their aim is to justify the procedure of tentatively postulating such a distribution, in order to see what use can be made of it in developing a theory of evidential probability. That is the focus of this chapter.1
10.2 Uncertain Evidence
Suppose that evidential probabilities are indeed probabilities conditional on one's evidence.
Then, trivially, the evidence itself has evidential probability 1. P(e| e)= 1 whenever it is defined.
Does this require evidence to be absolutely certain? If so, how can evidential probabilities fit into a non-Cartesian epistemology? Section 9.7 gave the problem a preliminary discussion. Let us now consider it more thoroughly.
Section 9.5 defended the assumption that evidence is propositional. Since the approach in this chapter identifies evidential probabilities with probabilities conditional on the evidence, it is in any case committed to treating evidence as propositional. P(h | e)=P(h & e)/P(e); this equation makes sense only if the evidence e is propositional. We therefore cannot avoid attributing evidential probability 1 to the evidence by denying that evidence is propositional, for then evidential probabilities would be undefined.
We should question the association between evidential probability 1 and absolute certainty.
For subjective Bayesians, probability 1 is the highest possible degree of belief, which presumably is absolute certainty. If one's credence in p is 1, one should be willing to accept a bet on which one gains a penny if p is true and is tortured horribly to death if p is false. Few propositions pass that test. Surely complex logical truths do not, even though the probability axioms assign them probability 1. But since evidential probabilities are not actual or counterfactual credences, why should evidential probability 1 entail absolute certainty?
There is a further link between probability 1 and certainty. Bayesian accounts of learning from experience give a significance to probability 1 which does not depend on any identification of probabilities with actual or counterfactual credences. Suppose that the new evidence gained on some occasion is e. On the standard Bayesian account of this simple case, probabilities should be updated by conditionalization on e. The updated unconditional probability of p is its previous probability conditional on e:
BCOND
Pnew(p) = Pold(p|e) = Pold(p & e)/Pold(e)
(Pold(e) ≠ 0)
We can interpret BCOND as a claim about evidential probabilities. Note that P old is not absolutely prior probability P, but probability on all the evidence gained prior to e. Suppose further, as Bayesians often do, that such conditionalization is the only form of updating which the probabilities undergo. By BCOND, P new (e)= 1. When P new is updated to Pvnew Pnew by conditionalization on still newer evidence f, P vnew (e) = (e | f)=P new (e & f)/P new (f)= 1 whenever conditionalization on f is defined. Thus e will retain probability 1 through all further conditionalizations. Since no other form of updating is contemplated, e will retain probability 1.
Once a proposition has been evidence, its status is as good as evidence ever after; probability 1 is a lifetime's commitment. On this model of updating, when a proposition becomes evidence it acquires an epistemically privileged feature which it cannot subsequently lose. How can that be? Surely any proposition learnt from experience can in principle be epistemically undermined by further experience.
What propositions could attain that unassailable epistemic status? Science treats as evidence propositions such as 'Thirteen of the twenty rats injected with the drug died within twenty-four hours'; one may discover tomorrow that a disaffected laboratory technician had substituted dead rats for living ones. The Cartesian move is to find certainty in propositions about one's own current mental state ('I seem to see a dead rat'; 'My current degree of belief that thirteen of the twenty rats died is 0.97'). Arguably, we are fallible even about our own current mental states (see Chapters 4 and 8). But even if that point is waived, and we are assumed to be infallible about a mental state when we are in it, we do not remain infallible about it later. However certain I am today of the proposition which I now express by the sentence 'I seem to see a dead rat', I may be uncertain tomorrow of the same proposition, then expressed by the sentence 'Yesterday I seemed to see a dead rat'. I can wonder whether I really remember seeming to see a dead rat, or only imagine it. Perhaps 'I seem to see a dead rat' (uttered by me today) and 'Yesterday I seemed to see a dead rat' (uttered by me tomorrow) do not express exactly the same proposition. But if I can think tomorrow the proposition expressed by 'I seem to see a dead rat' (uttered by me today), then that proposition can become uncertain for me. If I cannot even think it tomorrow, then the problem is even worse, because I cannot retain my evidence. We are uncontroversially fallible about our own past mental states. We are likewise fallible about the mental states of others. You can doubt whether I seem to myself to see a dead rat. Even if I tell you that I seem to myself to see one, you may wonder whether I am lying. Yet science relies on intersubjectively available evidence. Even
Bayesian epistemologists assume that evidence is intersubjectively available. Consider, for instance, the arguments that individual differences between prior probability distributions are 'washed out' in the long run by conditionalization on accumulating evidence. They typically assume that different individuals are conditionalizing on the same evidence. If we start with different prior probabilities, and I conditionalize on evidence about my mental state while you conditionalize on evidence about your mental state, then our posterior probabilities need not converge.
In some cases it can be shown that, although our evidence is different, our beliefs will almost certainly converge on each other because they will almost certainly converge on the truth.
For example, if a bag contains ten red or black balls, and we take it in turns to draw a ball with replacement, each observing our own draws and not the other's, and conditionalizing on the results, our posterior probabilities for the number of balls of each colour will almost certainly converge to the same values, even if our prior probabilities are quite different, provided that we both assign nonzero prior probabilities to all eleven possibilities. But even this assumes that our evidence consists of true propositions about the results of the draws, not propositions about our mental states. Where does that assumption come from, on a subjective Bayesian view?
The point generalizes. It is tempting to make a proposition p certain for a subject S at a time t by attributing a special authority to S's belief at t in p. But then belief in p by other subjects or at other times has a special lack of authority, because it is trumped by S's belief at t. For example, to the extent to which eyewitness reports of an event have a special status, non-eyewitness reports are vulnerable to being overturned by them. Thus it is hard to see how any empirical proposition could have the intertemporal and intersubjective certainty which the conditionalization account demands of evidence.
The standard response is to generalize Bayesian conditionalization to Jeffrey conditionalization (probability kinematics). For a proposition p, in Bayesian conditionalization on e (0 <P old (e)< 1):
(i)
Pold(p) = Pold(e) Pold(p|e) + Pold(~e)Pold(p| ~e)
(ii)
Pnew(p) = Pnew(e) Pnew(p|e) + Pnew(~e)Pnew(p| ~e)
For BCOND, the weights P new (e) and P new (~ e) in (ii) are 1 and 0 respectively.
Probabilities conditional on e are unchanged (P new (p| e) = P old (p| e)). What has changed is their weight in determining unconditional probabilities; it has increased from P old (e) to 1. But when experience makes e more probable without making it certain, Jeffrey conditionalization allows us to retain (ii) ((i) is automatic) and make P new (e) larger than P old (e) without making it 1. This increases the weight of probabilities conditional on e at the expense of probabilities conditional on
~e, while giving some weight to both. More generally, experience may cause us to redistribute probability amongst various possibilities, whilst leaving probabilities conditional on those possibilities fixed. Let {e 1 , . . . , e n } be a partition (that is, as a matter of logic, exactly one proposition in the set is true; for mathematical simplicity, infinite partitions are ignored) such that P old (e i )> 0 for each i (1 ≤ i ≤ n). Then P new comes from P old by Jeffrey conditionalization with

respect to {e 1 , . . . , e n } if and only if every proposition p satisfies:
JCOND
Pnew(p) = ∑1≤i≤n Pnew(ei) Pold(p|ei)
Bayesian conditionalization is just the special case where {e 1 ,. . . , e n } = {e,~ e} and P new
(e)= 1.
Jeffrey conditionalization cannot reduce probabilities from 1. If P new (p)= 1 then P new (p)= 1
by JCOND. The idea is rather that no empirical proposition need acquire probability 1 when one learns from experience. On the approach of this chapter, by contrast, evidence must have evidential probability 1, and some empirical propositions must be evidence if evidential probabilities are ever to change. Should the present approach be modified to permit Jeffrey conditionalization?
The updating of evidential probability by Jeffrey conditionalization is hard to integrate with any adequate epistemology, because we have no substantive answer to the question: what should the new weights P new (e i ) be? Indeed, if sufficiently fine partitions are used, any probability distribution P new is the outcome of any probability distribution P old by JCOND, provided only that
P new (p)= 1 whenever P old (p)= 1 and the set of relevant propositions is finite.2 Arguably, the same applies to BCOND.3 But there is a simple schematic answer to the epistemological question 'Which instances of BCOND update evidential probability?': those in which e is one's new evidence.
Although that answer immediately raises the further question 'What is one's evidence?', it still constitutes progress, for it divides the theoretical labour, allowing other work in epistemology and in philosophy of science—such as Chapter 9—to provide Bayesianism with its theory of evidence.
To the parallel question 'Which instances of JCOND update evidential probability?', no such simple answer will do. Jeffrey conditionalization is not conditionalization on evidence-constituting propositions. Moreover, the weights P(e i ) are highly sensitive to background knowledge. When I
see a cloth by candlelight, the new probability that it is green depends on my prior knowledge about its colour, the reliability of my eyesight, and the lighting conditions. Attempts to isolate an evidential input in JCOND have not met with success (see Jeffrey 1975, Field 1978, Garber 1980, and Christensen 1992). Jeffrey conditionalization seems not to admit the kind of articulation which would allow work in other areas of epistemology and of philosophy of science to provide it with a standard of appropriateness for the weights. Without such a standard, an account based on Jeffrey conditionalization promises little epistemological insight. Jeffrey evades the normative question by emphasizing the involuntariness of perceptual beliefs. He denies that sense experience provides reasons for belief: it is a mere cause, and none the worse for that (Jeffrey 1983): 184-5). However, normative questions arise even for involuntary beliefs. When the sight of a black cat causes a superstitious man to believe that disaster is about to strike, it may be improbable on his evidence that disaster is about to strike. Although most perceptual beliefs are involuntary, Jeffrey himself is willing to judge them by norms, for he regards
Bayesianism as a normative theory, not a descriptive one (Jeffrey 1983: 166-7).
Part of the rationale for Jeffrey conditionalization may also depend on an impoverished theory of propositions. Jeffrey's motivating example involves colour vision in poor light; he argues that no proposition 'expressible in the English language' can 'convey the precise quality of the experience' (1983: 165). Surely no context-independent English sentence conveys the precise quality of the experience. It is much less obvious that in the given context no English sentence with perceptual demonstratives (for example, 'It looks like that') can express a proposition which would convey the precise quality of the experience, in the sense that Bayesian conditionalization on it would capture the evidential upshot of the experience (see Christensen 1992, but also section 9.5).
The problem about the certainty of evidence arose from the combination of two claims:
PROPOSITIONALITY The evidential probability of a proposition is its probability conditional on the evidence propositions.
MONOTONICITY Once a proposition has evidential probability 1, it keeps it thereafter. For PROPOSITIONALITY entails that evidence propositions have evidential probability 1, which by MONOTONICITY implies that they have that status ever after, which is epistemologically implausible. Accounts based on Jeffrey conditionalization retain
MONOTONICITY but reject PROPOSITIONALITY; however, they do not yield a nonempty account of evidential probability. A more promising strategy is to retain PROPOSITIONALITY
and reject MONOTONICITY. It will be pursued here. PROPOSITIONALITY will henceforth be assumed.
Both BCOND and JCOND allow propositions to acquire probability 1, but not to lose it.
They are asymmetric between past and future. Thus a model on which all updating is by Jeffrey or
Bayesian conditionalization embodies the empirical assumption that evidence is cumulative, in the sense of MONOTONICITY. In many cases this assumption is false. Bayesians have forgotten forgetting. I toss a coin, see it land heads, put it back in my pocket and fall asleep; once I
wake up I have forgotten how it landed. When I saw it land heads, the proposition e that it landed heads was part of my evidence; e had probability 1 on my evidence. Once I awake, e presumably has probability 1/2 on my evidence. No sequence of Bayesian or Jeffrey conditionalizations produced this change in my evidential probabilities. Yet I have not been irrational. I did my best to memorize the result of the toss, and even tried to write it down, but I could not find a pen, and the drowsiness was overwhelming. Forgetting is not irrational; it is just unfortunate. MONOTONICITY
is sometimes a useful idealization; it is not inherent in the nature of rationality.
Information loss has a decision-theoretic interest. Before I fall asleep, I am certain that when
I wake up I shall have forgotten how the coin landed (I always forget that kind of thing). I am now happy to accept a bet on which I gain £1 if it lands heads and lose £10 otherwise. Tomorrow I shall be happy to accept a bet on which I lose £5 if it lands heads and gain £6 otherwise. If I make both bets, I lose £4 however it lands. I know now that I am vulnerable to such a diachronic Dutch Book, but what can I do? To avoid it by refusing the first bet is just to turn down a certain £1 (compare
Skyrms 1993).4
A proposition can lose the status of evidence for me even when in the usual sense I forget nothing. Recall an example from section 9.7. I see one red and one black ball put into an otherwise empty bag, and am asked the probability that on the first ten thousand draws with replacement a red ball is drawn each time. I reply '1/210,000'. Part of my evidence is the proposition e that a black ball was put into the bag; my calculation relies on it. Now suppose that on the first ten thousand draws a red ball is drawn each time, a contingency which my evidence does not rule out in advance, since its evidential probability is non-zero. But when I have seen it happen, I will rationally come to doubt e;
I will falsely suspect that the ball only looked black by a trick of the light. Thus e will no longer form part of my evidence. The traditionalist claim that the possibility of later doubt shows that e never was part of my evidence presupposes an untenably Cartesian epistemology. On standard Bayesian accounts of updating, the only present trace of past evidence is in present probabilities. No separate record is kept of evidence, off which a proposition can be struck.
But a theory of evidential probability can keep separate track of evidence and still preserve much of the Bayesian framework.5 Let P be the prior probability distribution, e w the conjunction of all old and new evidence for one in a case α, and P α (p) the evidential probability of a proposition p for one in α. The proposal is that P α is the conditionalization of P on e α :
ECOND
Pα(p) = P(p|eα) = P(p & eα)/P(eα)
(P(eα) > 0)
ECOND formalizes PROPOSITIONALITY. It allows MONOTONICITY to fail, for if one forgets something between t and a later time t*, being in cases α and α* at t and t* respectively, then e α* need not entail e α , so possibly P α* (e α )< 1 even though P α (e α )= 1. Thus a proposition can decrease in probability from 1. In that sense, evidence need not be certain.
When no evidence is lost between α and α*, e α* is equivalent to e α & f, where f is the conjunction of the new evidence gained in that interval, and ECOND implies that P α* results from conditionalizing P α on the new evidence f. Formally, for any proposition p: Pα*(p) = P(p & eα & f)/P(eα & f) = (P(p & eα & f)/P(eα))/(P(eα & f)/P(eα)) =
= Pα(p & f)/ Pα(f) = Pα(p|f)
BCOND is the special case of ECOND when evidence is cumulative. Thus Bayesian conditionalization can be recovered when needed.
The distribution P is conceptually rather than temporally prior; it need not coincide with P α
for any case α in which some subject is at some time, for P is not a distribution of credences, and the subject may have non-trivial evidence at every time. An incidental advantage of this approach is that it helps with the problem of old evidence (Glymour 1980: 85-93, Earman 1992: 119-35,
Howson and Urbach 1993: 403-8, and Maher 1996). One would like to say that e confirms h if and only if the conditional probability of h on e is higher than the unconditional probability of h (compare EV in section 9.2). If e is already part of the evidence then its probability is 1, and the conditional probabilities are identical; yet old evidence does sometimes confirm hypotheses. Appeals are sometimes made to probabilities in past or counterfactual circumstances in which the evidence does not include e, but they produce anomalous results, because the evidence in those circumstances may be distorted by irrelevant factors.
Example: a coin is tossed ten times. Let h be the hypothesis that it landed the same way each time. The initial probability of h is 1/29. Witness A says 'I saw the first six tosses; it landed heads each time'. Witness B then says 'I saw the last four tosses; it landed tails each time'; let e be the proposition that B said this. We have no reason to doubt A and B; if they are both telling the truth, then h is false. But B's statement causes A to break down; he admits that he was lying, and has no relevant knowledge. If B had not made his statement, A would not have withdrawn his, and there would have been no reason to suspect that he was lying. Thus, in the nearest past or counterfactual circumstances in which e was not part of our evidence, the conditional evidential probability of h on e is lower than the unconditional evidential probability of h. Nevertheless, in our present situation, e does confirm h, for since we still have no reason to doubt B, the probability of h on our evidence is around 1/26. Once we have the prior probability distribution P, we can say that P(h | e)> P(h). If we like, we can relativize confirmation to background information f by requiring that P(h | e &f)>P(h |
f), but this does not justify subjecting it to the vagaries of the evidence we once or would have had.
Of course, these remarks are schematic, but at least the general form of the solution does not introduce the irrelevant complications consequent on an identification of the probabilities with past or counterfactual credences.
10.3 Evidence and Knowledge
Which propositions are one's evidence? Without a substantive conception of evidence, probabilistic epistemology is empty; in practice, it has taken the existence of such a conception for granted without itself supplying one.
Different conceptions of evidence are compatible with ECOND. Chapter 9 defended the simple, natural proposal that one's evidence is one's body of knowledge. More precisely, one's total evidence e α in a case α is the conjunction of all the propositions which one knows in α (E = K).6 Here 'one' may refer to an individual or a community. Since evidence can lose probability 1, the defeasibility of knowledge by later evidence is no objection to E = K. When I see the black ball put into the bag, the proposition that a black ball was put into the bag becomes part of my evidence because I know that a black ball was put into the bag. When I have seen a red ball drawn each time on the first ten thousand draws, that further evidence undermines my knowledge that a black ball was put into the bag, and the previously known proposition ceases to be part of my evidence. Since only true propositions are known, evidence consists entirely of true propositions, but one true proposition can cast doubt on another.
Subjective Bayesians might identify one's evidence with one's beliefs (understood as propositions of subjective probability 1) rather than with one's knowledge (E = B). Given E = B, one can manufacture evidence for one's favourite theories by manipulating oneself into a state of certainty about appropriate propositions—for example, that one has just seen one's guru perform a miracle. That does not capture the spirit of the injunction to proportion one's belief to one's evidence.
The positive argument for E = K will not be rehearsed here. The rest of the chapter develops the conjunction of E = K with ECOND as a theory of evidential probabilities, in a way which indicates at least their mutual coherence. The concept knowledge is sometimes regarded as a kind of survival from stone-age thinking, to be replaced by probabilistic concepts for the purposes of serious twentieth-century epistemology. That view assumes that the probabilistic concepts do not depend on the concept knowledge. If E = K and ECOND are true, that assumption is false. The concepts knowledge and evidential probability are complementary; neither can replace the other.
Some initially surprising results of the theory stem from the point that we are not always in a position to know whether we know something. By E = K, we are not always in a position to know whether something is part of our evidence. Let us briefly rehearse the context in which this consequence is independently plausible. Whether something is part of our evidence does not depend solely on whether we believe it to be part of our evidence. That p is part of our evidence is a nontrivial condition; arguably, no non-trivial condition is such that whenever it obtains one is in a position to know that it obtains (see Chapters 4 and 8). But if we are not always in a position to know whether something is part of our evidence, how can we use evidence? We shall sometimes not be in a position to know the probability of a proposition on our evidence. How then can we follow the rule 'Proportion your belief in a proposition to its probability on your evidence'?
As noted in earlier chapters, there is a recurrent temptation to suppose that we can follow a rule only if it is always cognitively transparent to us whether we are complying with it. On this view, if we are sometimes not in a position to know whether we are φ-ing when C, then we cannot follow the rule 'φ when C'; at best we can follow the rule 'Do what appears to you to be φ-ing when it appears to you that C'. For instance, we cannot follow the rule 'Add salt when the water boils'
because we are not always in a position to know whether something is really salt, water, or boiling; at best we can follow the rule 'Do what appears to you to be adding salt when what appears to you to be water appears to you to boil'. Can we even follow the modified rule? That something appears to us to be so is itself a non-trivial condition. But we can follow the rule 'Add salt when the water boils', even though we occasionally make mistakes in doing so. It is enough that we often know whether the condition obtains. Compliance with a non-trivial rule is never a perfectly transparent condition. We use rules about evidence for our beliefs because they are often less opaque than rules about the truth of our beliefs; perfect transparency is neither possible nor necessary.
Just as we can follow the rule 'Add salt when the water boils', so we can follow the rule
'Proportion your belief in a proposition to its probability on your evidence'. Although we are sometimes reasonably mistaken or uncertain as to what our evidence is and how probable a proposition is on it, we often enough know enough about both to be able to follow the rule. It is easier to follow than 'Believe a proposition if it is true', but not perfectly easy. And just as adding salt when the water boils is not equivalent to doing one's rational utmost to add salt when the water boils, so proportioning one's belief in a proposition to its probability on one's evidence is not equivalent to doing one's rational utmost to proportion one's belief in a proposition to its probability on one's evidence. The content of a rule cannot be reduced to what it is rational to do in attempting to comply with it. Evidential probabilities are not rational credences.
The next task is to develop a formal framework for the combination of E = K with ECOND, by appropriating some ideas from epistemic logic.7 Within this framework, the failure of cognitive transparency for evidential probabilities will receive a formal analysis. 10.4 Epistemic Accessibility For the sake of familiarity, we may speak of notional worlds rather than cases. In order to facilitate discussion of intersubjective knowledge, we do not conceive a world as centred on a subject and a time. Rather, we implicitly specify the epistemic perspective by our choice of an accessibility relation between worlds (see below). We assume a set of mutually exclusive and jointly exhaustive worlds. In a given application, worlds need be specific only in relevant respects.
We need not assume that all worlds are metaphysically possible, in the sense that they could really have obtained. A set of all worlds is assumed. The relevant propositions are true or false in each world, and closed under truth-functional combinations. We assume that for each set of worlds, some proposition is true in every world in the set and false in every other world.
Let P be a prior probability distribution as in section 10.1. P is assumed to satisfy the axioms of the probability calculus as stated in terms of worlds. Thus P(p)= 1 whenever p is true in every world; P(pV q) = P(p)+P(q) whenever p and q are in no world both true. Consequently, if p and q are true in exactly the same worlds, P(p) = P(q).8 For any set of worlds, some proposition is true at exactly the worlds in the set, and all such propositions are equiprobable; thus the assignment of probabilities to propositions induces a unique assignment of probabilities to set of worlds.
Conversely, an assignment of probabilities to sets of worlds induces a unique assignment of probabilities to propositions.
Propositions are known or not known in worlds; propositions about which propositions one knows are true or false in worlds. The account will not assume any general principle about knowledge, except that a proposition is true in any world in which it is known. In particular, it will not assume logical omniscience; if p and q are true in exactly the same worlds, one may know p and not know q. Relative to a subject S and a time t, a world x is epistemically accessible ('accessible'
for short) from a world w if and only if every proposition which S knows at t in w is true in x. A
world is accessible if, for all one knows, one is in it. Since knowledge implies truth, every world is accessible from itself. A proposition p is consistent with propositions q 1 , . . . , q n if and only if all of p and q 1 , . . . , q n are true in some world; thus, in a world w, p is consistent with what one knows if and only if p is true in some world accessible from w (compare the standard possible worlds semantics for the possibility operator ◊).
Similarly, p follows from q 1 , . . . , q n if and only if p is true in every world in which all of q 1 ,
. . . , q n are true; thus, in a world w, p follows from what one knows if and only if p is true in every world accessible from w (compare the standard possible worlds semantics for the necessity operator
□). Trivially, if one knows a proposition then it follows from what one knows, but the converse may fail, since one need not know that which follows from what one knows.
Now assume ECOND and E = K; in all worlds, evidential probabilities are probabilities conditional on one's evidence and one's evidence is what one knows. Relative to a subject S at a time t, for any world w, e w is the conjunction of S's evidence at t in w. By E = K, e w is true in all and only the worlds accessible from w. P w is the distribution of evidential probabilities for one in w.
ECOND says that P w results from conditionalizing the appropriate prior distribution P on e w .
When the set of worlds is at most countably infinite, a further natural constraint on P is that it be regular, in the sense that P(p)= 0 only if p is true in no world: the probability distribution does not rule out any world in advance. When there are uncountably many worlds, no probability distribution is regular (infinitesimal probabilities are not being considered here). The most natural prior distributions are those for which there is a finite number n of worlds, and P(p)= m/ n whenever p is true in exactly m worlds, but such uniformity in P will not be assumed. Since knowledge entails truth, e w is always true in w. Thus when P is regular, P(e w )> 0 for each w, so probabilities conditional on e w are well defined and ECOND defines evidential probabilities everywhere.
Regularity also entails that the evidential probability of p is 1 only if p follows from one's evidence, for if p is false in some world in which e w is true, then P(~ p & e w )> 0, so P w (p)< 1. Regularity likewise entails that p follows from what one knows if and only if the evidential probability of p is
1, and that p is consistent with what one knows if and only if the evidential probability of p is nonzero. Propositions about evidential probability are themselves true or false in worlds. For example, the proposition that p is more probable than not on the evidence is true in w if and only if
P w (p)> 1/2. Thus propositions about evidential probability themselves have probabilities.9
In the manner of possible worlds semantics, conditions on accessibility correspond to conditions on knowledge, which in turn have implications for evidential probabilities. For example, accessibility is transitive if and only if for every proposition p in every world, if p follows from what one knows then that p follows from what one knows itself follows from what one knows (compare the S4 axiom □ p ⊃ □ □ p in modal logic). The latter condition follows from the notorious 'KK' principle that when one knows p, one knows that one knows p; it is slightly weaker, but not weak enough to be true, even for all rational subjects (see Chapter 5). For a regular probability distribution, transitivity is equivalent to the condition that when p has evidential probability 1, the proposition that p has evidential probability 1 itself has evidential probability 1.
Accessibility is symmetric if and only if for every proposition p in every world, if p is true then that p is consistent with what one knows follows from what one knows (compare the
Brouwersche axiom p ⊃ □ ◊p). For a regular probability distribution, symmetry is equivalent to the condition that when p is true, the proposition that p has non-zero evidential probability itself has evidential probability 1. There is good reason to doubt that accessibility is symmetric. Let x be a world in which one has ordinary perceptual knowledge that the ball taken from the bag is black. In some world w, the ball taken from the bag is red, but freak lighting conditions cause it to look black, and everything which one knows is consistent with the hypothesis that one is in x. Thus x is accessible from w, because every proposition which one knows in w is true in x; but w is not accessible from x, because the proposition that the ball taken from the bag is black, which one knows in x, is false in w. Let p be the proposition that the ball taken from the bag is red. In w, p is true, but that p is consistent with what one knows does not follow from what one knows, for what one knows is consistent with the hypothesis that one knows ~p (see section 8.2 and Humberstone
1988 for related issues). On a regular probability distribution, the evidential probability in w of the proposition that p has non-zero evidential probability falls short of 1 in this case.
Such examples depend on less than Cartesian standards for knowledge and evidence;
Bayesian epistemology must learn to live with such standards. Moreover, failures of symmetry can result from processing constraints, even when false beliefs are not at issue (see also Shin and
Williamson 1994). For a crude example, imagine a creature which knows all the propositions recorded in its memory; we may pretend for simplicity that it is somehow physically impossible for false propositions to be recorded there. Unfortunately, there is no limit to the time taken to deliver propositions from memory to the creature's central processing unit. Now toadstools are in fact poisonous for the creature, but it has no memory of any proposition relevant to this truth. It wonders whether it knows that toadstools are not poisonous. It searches for relevant memories. At any time, it has recovered no relevant memory, but for all it knows that is merely because the delivery procedure is slow, and in a moment the memory that toadstools are not poisonous will be delivered, in which case it will have known all along that they are not poisonous. Everything which it knows in the actual world w is true in a world x in which it knows that toadstools are not poisonous; thus x is accessible from w. But w is not accessible from x, because something which it knows in x (that toadstools are not poisonous) is false in w. Although in w the proposition p that toadstools are poisonous is true, that p is consistent with what it knows does not itself follow from what it knows.
Epistemic logic and probability theory are happily married because the posterior probabilities in w result from conditionalizing on the set of worlds epistemically accessible from w.
This idea has become familiar in standard applications of epistemic logic to the concept of common knowledge in decision theory and game theory (see for example Fudenberg and Tirole 1991: 54172). As usual, the proposition that p is common knowledge is analysed as the infinite conjunction of p, the proposition that everyone knows p, the proposition that everyone knows that everyone knows p, and so on. Thus the analysis of common knowledge requires an account of knowledge.
Something like the framework above is used, with a separate accessibility relation R S for each agent S but a common prior probability distribution; different agents can have different posterior probabilities in the same world because they have different sets of accessible worlds on which to conditionalize. 'S knows p' (K S p) is given the semantics of 'p follows from what one knows' with respect to the accessibility relation R S ; thus knowledge is treated as closed under logical consequence (contrast the present account). Furthermore, in decision theory accessibility is usually required to be an equivalence relation (symmetric and transitive as well as reflexive) for each agent.
On this model, the agent partitions the set of worlds into a set of mutually exclusive and jointly exhaustive sets. In w, the agent knows just those propositions which are true in every world belonging to the same member of the partition as w. Informally, imagine that each world presents a particular appearance to the agent, who knows all about appearances and nothing more; thus one world is epistemically accessible from another if and only if they have exactly the same appearance, which is an equivalence relation. The corresponding propositional logic of knowledge is the modal system S5, with K S in place of □; one can axiomatize it by taking as axioms all truth-functional tautologies and formulas of the forms K S (A ⊃ B) ⊃ (K S A ⊃ K S B), K S A ⊃ A, and ~K S A ⊃ K S ~K S A, and as rules of inference modus ponens and epistemization (if A is a theorem, so is K S A). One of the earliest results to be proved on the basis of assumptions tantamount to these was Aumann's '[no]
agreeing to disagree' theorem: when the posterior probabilities of p for two agents are common knowledge, they are identical (Aumann 1976; the proof relies heavily on the assumption of common prior probabilities).
Earlier examples expose some of the idealizations implicit in the partitional model of knowledge. In particular, the counterexamples to the symmetry of accessibility, and so to the
Brouwersche schema ~A ⊃ K S ~K S A, are equally counterexamples to the S5 schema ~K S A ⊃ K
S ~K S A, given the uncontentious principle that knowledge implies truth (K S A ⊃ A). Some progress has been made in generalizing results such as Aumann's to weaker assumptions about knowledge (Bacharach 1985, Geanakoplos 1989, 1992, 1994, Samet 1990, Shin 1993, Basu 1996).
It can be argued that, even when logical omniscience is assumed, the propositional logic of knowledge is not S5 but the modal system KT (alia s T), which one can axiomatize by dropping the axiom schema ~K S A ⊃ K S ~K S A from the axiomatization above (Williamson 1994b: 270-5).
What KT assumes about knowledge, in addition to logical omniscience, is just that knowledge implies truth. When K S A is read as 'It follows from what one knows that A', rather than as 'One knows that A' (where one is S), logical omniscience becomes unproblematic for K S , whatever S's logical imperfections.
10.5 A Simple Model
We can gain a more intuitive feel for the present account of higher-order probabilities by working through some of its consequences in a toy example. In doing so we can combine it with the account of margins for error in Chapter 5.
According to a straightforward margin for error principle, S knows p in a world w only if p is true in every world sufficiently close to w in the relevant respects (which will depend on the particular case). In the simplest models, that condition is sufficient as well as necessary for knowing p: K p is true in w if and only if p is true in all worlds close to w (for simplicity, we omit the subscript 'S'). Let us introduce an operator B, where B p is to mean that p is highly probable on S's evidence. On the present account of evidence, we can then say that in such a model, B p is true in w if and only if p is true in most worlds close to w. That is only a first approximation, of course, because some worlds close to w may be assigned higher probabilities than others, and 'most' is problematic for infinite sets; but we can build the required probability distribution into our understanding of
'most'. The result is a probabilistic margin for error principle. Whereas any operator defined by the original margin for error principle is automatically factive, because every world is close to itself, B
is not in general factive, because a set which contains most worlds close to w need not contain w itself. A false proposition can be highly probable on one's evidence; some evidence is misleading.
In place of the factiveness principle K p ⊃ p, one can expect only the weaker consistency principle
B p ⊃ ~B~ p; two disjoint sets cannot each contain most worlds close to w. Contradictories cannot both be highly probable on one's evidence.
For definiteness, we can imagine the worlds of our toy model as forming a two-dimensional infinite grid. For convenience, each world may be identified with a 'point', a pair of coordinates < x, y>, where x and y are any integers. Again for convenience, we may identify propositions with sets of points; a proposition is true at a point if and only if the latter belongs to the former. Let us count the points close to < x, y>, the points accessible from it, as just those within one step of it on the grid: < x, y> itself, < x+1, y>, < x-1, y>, < x, y+1> and < x, y-1>. All worlds are treated as equiprobable. Let us count most of these five points as in a set if and only if at least four are. Thus the proposition B p is true in a world < x, y> if and only if {< u, v>: | x-u|+| y-v| ≤ 1} ∩ p has at least four members, whereas K p is true in < x, y> if and only if {< u, v>: | x-u|+| y-v| ≤ 1} ∩ p has five members. We can read B as 'It is at least 80 per cent probable that', understanding 'probable'
evidentially.
As an example, let p be the proposition {<0,1>, <1,0>, <1,2>, <2,1>}. The only point close to at least four members of p is <1,1>, so B p is {<1,1>}. No point is close to at least four members of B p, so BB p is {}. Thus <1,1> is a point at which p is false but at least 80 per cent probable, although it is only 20 per cent probable that p is at least 80 per cent probable. This illustrates the simultaneous breakdown of factiveness and the BB principle that if p is at least 80 per cent probable then it is at least 80 per cent probable that p is at least 80 per cent probable. More generally in the model, B is subject to erosion effects typical of margin for error principles. For example, if p is any finite set, then Bkp (k iterations of B on p) is empty for some natural number k.10 As required, B p entails ~B~ p in the model. Also as we should expect, the closure principle that if p 1 , . . . , p n logically entail q then B p 1 , . . . , B p n logically entail B q holds when n ≤ 1 but not otherwise. For example, if p1 is {<0,1>, <1,0>, <1,2>, <2,1>} and p 2 is {<1,0>, <1,1>, <1,2>,
<2,1>}, then both B p 1 and B p 2 are {<1,1>}, but p 1 & p 2 is the intersection of p 1 and p 2 ,
{<1,0>, <1,2>, <2,1>}; since this has only three members, B(p 1 & p 2 ) is {}. Each of p 1 and p 2 is
80 per cent probable at <1,1>, but their conjunction is only 60 per cent probable. By contrast, K
satisfies the corresponding closure principle in this model for multi-premise inference.
Another contrast between strict and probabilistic margins for error in this model is that K
satisfies the Brouwersche principle p ⊃ K~K~ p because closeness is symmetric, but B does not satisfy the corresponding principle p ⊃ B~B~ p. For example, if p is {<1,1>}, then ~B~ p is {}, so
B~B~ p is {}.
The exposition of the present theory of probabilities on evidence is now complete, and some readers may wish to skip the rest of this chapter. However, deviations from the partitional model sketched at the end of section 10.4 generate a phenomenon which seems to threaten the proposed marriage of knowledge and probability. The aim of the next section is to understand that phenomenon.
10.6 A Puzzling Phenomenon
The paradoxical phenomenon can be illustrated thus. There are just three worlds: w 1 , w 2
and x. As in Figure 3, x is accessible from each world; each of w 1 and w 2 is accessible only from itself. Thus accessibility is reflexive and transitive, but not symmetric. For simplicity, the subject will be treated as logically omniscient; the paradoxical phenomenon does not depend on the failure of knowledge to be deductively closed. Since the only world accessible from x is x itself, if one is in x then one knows that one is in x. Since the worlds accessible from w i are x and w i , if one is in w i then one knows that one is in either w i or x, but one does not know which; for all one knows, one knows that one is in x. In w i , although one is not in x, and therefore does not know that one is in x, one does not know that one does not know that one is in x. This is just
Figure 3
the failure of the Brouwersche and S5 axioms for knowledge in a non-symmetric model.
The prior probability distribution is uniform; each world has a prior probability of 1/3. Let p be the proposition that one is in w 1 or w 2 . The prior probability of p is 2/3. If one is in x, then p is false in all accessible worlds, so its posterior probability is 0. If one is in w i , then p is true in just one of the two accessible worlds, so its posterior probability is 1/2. Thus one knows in advance that the posterior probability of p will be either 0 or 1/2, and so in any case lower than its initial probability.11 But if one knows in advance that, when the evidence comes in, the probability of p on the evidence will drop from 2/3 to at most 1/2, why is that known feature of the future evidence not anticipated by lowering the prior probability of p to at most 1/2? Surely the posterior probabilities are a better guide to the truth than the prior probabilities are, because they are based on more evidence (compare Shin 1989 and 1992 and Geanakoplos 1989, 1992, and 1994).
A money pump argument makes the problem vivid. Consider a ticket which entitles one to
£6 if p is true and to nothing if p is false. The initial probability that the ticket entitles one to £6 is
2/3. Given standard Bayesian decision theory, one should be willing to pay up to 2/3£6 + 1/3£0 =
£4 in advance for the ticket. But the posterior probability that the ticket entitles one to £6 is at most
1/2, so once the evidence is in one should be willing to sell the ticket for any price from 1/2£6 + 1/2£0 = £3 upwards. Indeed, if the evidence shows that one is in x, then one knows that the ticket is worthless. A shark can apparently pump money out of one by selling one many such tickets for £4 before the evidence is in and buying them back afterwards for £3. I remain a money pump even if I require a small profit on each transaction. Moreover, one knows all that in advance. Is there not something irrational in such an assignment of probabilities?
Reasons emerged in section 10.1 to deny that decision-theoretic arguments have a direct bearing on evidential probabilities. Such arguments are especially dubious when (as above) the probabilities do not all belong to the same time (see, for example, Christensen 1991). Nevertheless, the money pump argument provides an intuitive framework for generalizing the problem. For simplicity, let the worlds form a finite set W. It will be convenient to treat the bearers of probability as subsets of W. For w ∈ W, let R(w) be the set of worlds to which w bears the accessibility relation
R. Since e w is true in exactly the worlds in R(w), the posterior probability P w (X) of X in w is
P(X|R(w)) by ECOND (X ⊆ W). The expectation E(P w (X)) of the evidential probability random variable P w (X) is therefore Σ w ∈ W P({w})P(X|R(w)). The identity of prior and expected posterior probabilities comes to this:
EXP P(X) = ∑w∈W P({w})P(X|R(w)) Consider a ticket which entitles one to £ n if one's world is in X and to nothing otherwise.
Suppose that before the evidence is in one buys the ticket at its expected (monetary) value at that time; after the evidence is in one sells the ticket at its expected value at that later time. What is one's expected profit or loss over the two transactions? The buying price is P(X)£ n. The expected selling price is the expected posterior probability of X times £ n. In the example above, the prior probability of p was 2/3; its expected posterior probability was 1/3(0) + 2/3(1/2) = 1/3; the expected profit was 1/3 £6 2/3£6, a loss of £2. Thus, if the left-hand side of EXP is less or greater than its right-hand side, one's expected profit over the two transations is positive or negative respectively.
Since the prior and expected posterior probabilities of W X are one minus the prior and expected posterior probabilities of X respectively, an expected profit on the two transactions with respect to
X implies an expected loss on the corresponding transactions with respect to W X. Thus unless EXP
holds, the transactions make one a money pump with respect to some proposition (see Goldstein
1983, Van Fraassen 1984, and Skyrms 1987 for related discussion).
One response to the strange situation is to deny that it can arise. On this view, the money pump argument shows that no probability distribution P on a set of worlds W with an epistemic accessibility relation R can violate EXP for any X ⊆ W; Figure 3 does not picture a genuine possibility. It can be proved that, given a relation R on a finite set W, EXP
holds for every regular probability distribution P on W and X ⊆ W if and only if R is an equivalence relation on W (Appendix 4, proposition 5). In partitional models of knowledge, expected posterior probabilities always coincide with prior probabilities; any deviation from partitionality makes them diverge on a suitable probability distribution.12
Although the interpretation of R as an accessibility relation for knowledge automatically requires R to be reflexive, one cannot escape the result just by allowing R to be non-reflexive and reinterpreting it as an accessibility relation for (say) rational belief, in the sense that x is accessible from w if and only if whatever the subject rationally believes in w is true in x. The aforementioned result holds provided that each member of W has R to at least one member of W, not necessarily itself: in other words, provided that R is serial. The accessibility relation for rational belief is nonserial only when (if ever) rational beliefs are inconsistent. In that case R(w) is sometimes empty, so the expected posterior probability is not well defined. If R is serial, R(w) is always non-empty; given regularity, the expected posterior probability is then well defined. If the accessibility relation is serial but not reflexive, then expected posterior probabilities diverge from prior probabilities on a suitable probability distribution.
If epistemic accessibility had to be an equivalence relation, EXP would always hold. But the counterexamples to partitionality have not lost their force. Of course, realistic examples involve far more complex epistemic situations than that illustrated above. Nevertheless, we can begin to understand the mechanics underlying non-partitionality by filling out the example above of the worlds w 1 , w 2 , and x in some detail.
A simple creature monitors the ambient temperature by means of two detectors. When it is not cold, the first detector is activated and causes the information that it is not cold to be stored; otherwise the first detector is inactive. When it is not hot, the second detector is activated and causes the information that it is not hot to be stored; otherwise the second detector is inactive. The relevant three (partial) worlds are w 1 (it is hot), w 2 (it is cold), and x (it is neither hot nor cold). In w 1 , only the information that it is not cold is stored. In w 2 , only the information that it is not hot is stored. In x, both the information that it is not hot and the information that it is not cold is stored. Unfortunately, the creature has no capacity to survey what it has stored and detect that a particular piece of information is not stored.
Hence, in w 1 it cannot detect that the information that it is not hot is not stored, and infer that it is hot. Similarly, in w 2 it cannot infer that it is cold. Since it never stores false information, we can reasonably treat it as knowing the stored information and no more. Thus the worlds epistemically accessible from w 1 are w 1 and x; the worlds accessible from w 2 are w 2 and x; the only world accessible from x is x itself. Let the three worlds be equiprobable in advance, and treated as such by the creature. Then the epistemic situation is exactly that depicted in Figure 3. If we like, we can elaborate the story to endow the creature with significant powers of logic and self-reflection (see
Appendix 5 for details).
Is the initial assignment of equal probabilities to the three worlds irrational? Would some other initial assignment do better? Let P be a regular prior probability distribution which coincides with the corresponding distribution of expected posterior probabilities. So, in particular:
P({x}) = ∑y∈W P({y})P({x}|R(y))
By the diagram x ∈ R(y) for all y ∈W, so P({x}|R(y)) = P({x})/P(R(y)). Dividing through by
P({x}) gives:
1 = ∑y∈W P({y})/P(R(y))
But R(x) = {x}, so P({x}/P(R(x)) = 1, so:
0 = P({w1})/P(R(w1)) + P({w2})/P(R(w2))
Thus P({w 1 }) = P({w 2 }) = 0. This contradicts the assumed regularity of P. Only an irregular prior distribution on W can coincide with the corresponding expected posterior distribution. Specifically, the proof shows that either P({x}) = 0, in which case P({x}|R(x)) is undefined, or P({w 1 }) = P({w 2 }) = 0. The creature can align its prior probabilities with its expected posterior probabilities only by ruling out some of the three worlds in advance. But that would be quite irrational; each of them is an epistemically live possibility. The uniform prior distribution was not to blame. One must learn to live with the divergence between prior and expected posterior probabilities: but how?
Consider the money pump argument first. As given above, it assumes that, once the evidence is in, the agent can calculate the relevant expectations, which requires it to know the posterior probabilities. That is just what the structure of the accessibility relation precludes. In the three-world model, it is certain in advance that the posterior probability that it is hot is 1/2 when it is hot and 0 otherwise. Hence if, when it was hot, the creature knew that the posterior probability that it was hot was 1/2, it could deduce that it was hot; but then the posterior probability that it was hot would be 1, not 1/2. For simplicity, sentences about probabilities and actions were omitted from the creature's language; their addition would complicate but not undermine the argument, provided that the creature has no more empirical evidence than before. Thus, when it is hot, the creature cannot know the probability on its evidence that it is hot. It does not know the premises of the decision-theoretic calculation. Even so, the probabilities on its evidence can still play a causal role in its decision-making, for its evidence is physically realized as its stored information. Thus decisions can be made when it is hot that would not have been made if it had not been hot.
Could the creature discover that it is hot by observing its own actions? Once it has acted, it is in a different world; its action may even have changed the temperature. Perhaps it can work out that it was hot, but that would not imply that it could have had the present tense knowledge before it acted. Could it have introspected its intention to act in a certain way before carrying it out?
Sometimes we do not know whether we are going to act in a certain way until we carry out the action; let the creature be like that when it does not know the probabilities on which it will act.
If we assume that prior probabilities should align themselves with expected probabilities posterior to the future acquisition of knowledge, we assign the probability of being known in the future a privileged status in the present. Why should I give the property of being known by me tomorrow a privileged status today? There is one reason: whatever I shall know tomorrow is true.
Thus if I know today that tomorrow I shall know p, I can deduce p today. By contrast, if I rationally believe today that tomorrow I shall rationally believe p, I cannot deduce p today; for all I rationally believe today, tomorrow's rational belief will be based on misleading evidence.13 But this is no reason to give the property of being known by me tomorrow a more privileged status than I give to any other truth-entailing property.
Consider an analogy. A die is about to be cast. Each of the natural numbers from one to six has an equal prior probability (1/6) of being thrown. Exactly five propositions are inscribed on a rock: e 1 A one will not be thrown.
e 2 A two will not be thrown.
e 3 A three will not be thrown.
e 4 A four will not be thrown.
e 5 A five will not be thrown.
The propositions inscribed on the rock are known to have been chosen at random; that a given proposition is inscribed there does not make it any more likely to be true. Say that a proposition is an inscribed truth if and only if it is true and inscribed on the rock; pseudo-posterior probabilities are the results of conditionalizing on the conjunction of all inscribed truths. Let p be the proposition that a six will be thrown. The prior probability of p is 1/6. If a one is thrown, then the inscribed truths are e 2 , e 3 , e 4 , and e 5 , so the pseudo-posterior probability of p is 1/2. By similar reasoning, the pseudo-posterior probability of p is 1/2 if any number between one and five is thrown. If a six is thrown, all the inscribed propositions are inscribed truths, and the pseudoposterior probability of p is 1. Thus the pseudo-posterior probability of p is bound to be much higher than its prior probability. Its expected pseudo-posterior probability is (5/6)1/2 +(1/6)1 =
7/12. Pseudo-posterior probabilities are better informed than prior probabilities, because by definition they result from conditionalizing the latter on true and relevant information. All this is known in advance. Should we therefore revise our prior probabilities to bring them into line with our expected pseudo-posterior probabilities? We have no reason whatsoever to regard a six as any more likely to be thrown than any other number. The inscribed propositions embody a bias towards six. The bias could just as easily have been towards another number, quite independently of the result of the throw.
Moral: it is generally a mistake to try to align one's probabilities with what one knows about the results of conditionalizing them on truths with some given property. One instance of this mistake is to try to align our probabilities with what we know about the results of conditionalizing them on truths which we will know in the future. Although we may be made to suffer for the misalignment, it would not be rational to try to avert the suffering by changing our present beliefs.
From our present perspective, the non-partitional structure of our future knowledge is a source of bias, similar in effect to forgetting although much subtler in its operation. Of course, we shall probably know more tomorrow, and it would be foolish then to disregard the new knowledge. But we cannot take advantage of the new knowledge in advance.
We must cross that bridge when we come to it, and accept the consequences of our unfortunate epistemic situation with what composure we can find. Life is hard. 11 Assertion
11.1 Rules of Assertion
We express and communicate our knowledge by making assertions. That by itself does not constitute a special relationship between knowing and asserting, for by making assertions we still express and communicate our beliefs when they fall short of knowledge. Indeed, assertion is the exterior analogue of judgement, which stands to belief as act to state. Nevertheless, there is a special relationship between knowing and asserting, if the argument of this chapter is correct. By analogy, there is also a special relationship between knowing and judging or believing. The relationship is a normative one.
Assertions are praised as true, informative, relevant, sincere, warranted, well phrased, or polite. They are criticized as false, uninformative, irrelevant, insincere, unwarranted, ill phrased, or rude. Sometimes they deserve such praise or criticism. If any respect in which performances of an act can deserve praise or criticism is a norm for that act, then the speech act of assertion has many norms. So has almost any act. Jumps can deserve praise as long or brave; they can deserve criticism as short or cowardly. But it is natural to suppose that some norms are more intimately connected to the nature of asserting than any norm is to the nature of jumping. One might suppose, for example, that someone who knowingly asserts a falsehood has thereby broken a rule of assertion, much as if he had broken a rule of a game; he has cheated. On this view, the speech act, like a game and unlike the act of jumping, is constituted by rules. Thus not all norms for assertion are on a par. Norms such as relevance, good phrasing, and politeness are just applications of more general cognitive or social norms to the specific act of assertion. Perhaps the norm of informativeness results from a more complex interaction between a general norm of cooperativeness and the nature of assertion as a source of information. But, on this view, not all norms for assertion derive from more general norms, otherwise nothing would differentiate it from other speech acts.
This chapter aims to identify the constitutive rule(s) of assertion, conceived by analogy with the rules of a game. That assertion has such rules is by no means obvious; perhaps assertion is more like a natural phenomenon than it seems. One way to find out is by supposing that it has such rules, in order to see where the hypothesis leads and what it explains. That will be done here. The hypothesis is not perfectly clear, of course, but we have at least a crude conception of constitutive rules, which we may refine as we elaborate the hypothesis. Although no attempt will be made here to define 'rule', some remarks on constitutive rules will focus the discussion.
Constitutive rules are not conventions. If it is a convention that one must φ, then it is contingent that one must φ; conventions are arbitrary and can be replaced by alternative conventions. In contrast, if it is a constitutive rule that one must φ, then it is necessary that one must
φ. More precisely, a rule will count as constitutive of an act only if it is essential to that act: necessarily, the rule governs every performance of the act. This idealizes the case of games, for, in the ordinary sense of 'game', games such as tennis gradually change their rules over time without losing their identity; the constitutive role of the rules is qualified by that of causal continuity.
Similarly, in the ordinary sense of 'language', natural languages such as English gradually change their rules over time without losing their identity. Nevertheless, in a technical sense of 'language'
which the philosophy of language has found fruitful, the semantic, syntactic, and phonetic rules of a language are essential to it (Lewis 1975). The richer ordinary sense of 'language' introduces needless complications. Linguistic conventions and the consequent possibility of linguistic change can then be accommodated at a different point in the theory: a population which at one time has the convention of speaking a language L may later change to a convention of speaking a distinct language L*, constituted by slightly different rules. Likewise, in the present technical sense of
'speech act', the rules of a speech act are essential to it. A population which at one time has the convention of using a certain device to perform a speech act A may later change to a convention of using that device to perform a distinct speech act A*, governed by slightly different rules. 'Game'
can receive a similar sense. Henceforth, 'rule' will mean constitutive rule.
Given a game G, one can ask 'What are the rules of G?'. Given an answer, one can ask the more ambitious question 'What are non-circular necessary and sufficient conditions for a population to play a game with those rules?'. Competent unphilosophical umpires know the answer to the former question but not to the latter. Given a language L, one can ask 'What are the rules of L?'.
Given an answer, one can ask 'What are non-circular necessary and sufficient conditions for a population to speak a language with those rules?'. Given a speech act A, one can ask 'What are the rules of A?'. Given an answer, one can ask 'What are non-circular necessary and sufficient conditions for a population to perform a speech act with those rules?'. This chapter asks the former question about assertion, not the latter. It cannot wholly ignore the latter, for assertion is presented to us in the first instance as a speech act that we perform, whose rules are not obvious; in order to test the hypothesis that a given rule is a rule of assertion, we need some idea of the conditions for a population to perform a speech act with that rule, otherwise we could not tell whether we satisfy those conditions. Fortunately, we need much less than a full answer to the second question for these purposes. Our task is like that of articulating for the first time the rules of a traditional game that we play; that does not require a full philosophy of games.
Constitutive rules do not lay down necessary conditions for performing the constituted act.
When one breaks a rule of a game, one does not thereby cease to be playing that game. When one breaks a rule of a language, one does not thereby cease to be speaking that language; speaking
English ungrammatically is speaking English. Likewise, presumably, for a speech act: when one breaks a rule of assertion, one does not thereby fail to make an assertion. One is subject to criticism precisely because one has performed an act for which the rule is constitutive. Breaches of the rules of a game, language, or speech act may even be common. Nevertheless, some sensitivity to the difference—in both oneself and others—between conforming to the rule and breaking it presumably is a necessary condition of playing the game, speaking the language, or performing the speech act.
The important task of elucidating the nature of this sensitivity will not be undertaken here.
The normativity of a constitutive rule is not moral or teleological. The criticism that one has broken a rule of a speech act is no more a moral criticism than is the criticism that one has broken a rule of a game or language. Although someone who knowingly asserts a falsehood may incur moral criticism, perhaps for having betrayed the hearers or inflicted false beliefs on them, such faults are made possible only by the specific nature of assertion, which is not itself constituted by moral norms. Cheating at a game is likewise not a morally neutral act, but it is made possible only by the non-moral rules which constitute the game. Nor is the criticism that one has broken a constitutive rule of an institution the criticism that one has used it in a way incompatible with its aim, whether the aim is internal or external. Consider a game, which might have the internal aim of scoring more goals than the opposition and the external aim of exercising players or entertaining spectators.
Breaking the rules can serve both internal and external aims. Conversely, lazy play can give away goals to the opposition, bore spectators, and fail to exercise players, without breaking the rules. Within the practice constituted by the rules, their authority does not require the backing of moral or teleological considerations.
What are the rules of assertion? An attractively simple suggestion is this. There is just one rule. Where C is a property of propositions, the rule says:
(The C rule) One must: assert p only if p has C.
In the imperative, assert p only if p has C. As used here, 'must' expresses the kind of obligation characteristic of constitutive rules. The rule is to be parsed as 'One must ((assert p) only if p has C)', with 'only if p has C' inside the scope of 'One must' but outside that of 'assert'. The rule unconditionally forbids this combination: one asserts p when p lacks C. The combination is possible, otherwise it would be pointless to forbid it. The condition that p has C may concern the content of the potential assertion (p), contextual features (for example, speaker and time), or both.
The C rule is constitutive of the speech act: necessarily, assertion is a speech act A whose unique rule is 'One must: perform A with the content p only if p has C'. Furthermore, the envisaged account takes the C rule to be individuating: necessarily, assertion is the unique speech act A whose unique rule is the C rule. In mastering the speech act of assertion, one implicitly grasps the C rule, in whatever sense one implicitly grasps the rules of a game or language in mastering it. As already noted, this requires some sensitivity to the difference in both oneself and others between conforming to the rule and breaking it. All other norms for assertion are the joint outcome of the C
rule and considerations not specific to assertion. If an assertion satisfies the rule, whatever derivative norms it violates, it is correct in a salient sense.1 Call this account the C account, and any account of this form simple.
More complex accounts of assertion are conceivable. Some rules make some assertions obligatory; silence satisfies the C rule. There might be several rules of assertion. There might be none. Assertion might be wholly or partly constituted by a norm or norms whose normativity is not rule-like. Such a norm might be essentially comparative: mastery of the speech act would involve grasping a scale on which assertions could be assessed as better or worse than each other, but not grasping a threshold for an assertion to be 'good enough'—that could be left to the discretion of individual speakers with particular purposes. Alternatively, assertion might be constituted only by non-normative features. Nevertheless, a simple account of assertion would be theoretically satisfying, if it worked. This chapter defends a simple account, shirking the examination of more complex accounts.
One obvious candidate to play the role of the property C is the truth of the content:
(The truth rule) One must: assert p only if p is true.
The truth rule forbids false assertions. It would be often broken, but so are many rules. The truth account—a simple account of assertion based on the truth rule—explains other norms as the joint outcome of the truth rule and considerations not specific to assertion. In particular, it explains epistemic norms as norms of evidence for truth: satisfying these secondary norms consists in having evidence that one satisfies the primary norm. Grice describes the category of Quality in his account of the rules of conversation in this vein: the supermaxim 'Try to make your contribution one that is true' leads to two more specific maxims, 'Do not say what you believe to be false' and 'Do not say that for which you lack adequate evidence' (Grice 1989: 27).
Unlike truth, other candidates to play the role of the property C are sensitive to the epistemic circumstances of the asserter. A speaker who satisfies such a condition will be described as having warrant to assert p, in a schematic sense of 'warrant'. On such views, the rule becomes:
(The warrant rule) One must: assert p only if one has warrant to assert p.
The warrant rule forbids unwarranted assertions. For any reasonable notion of warrant, a true assertion based only on a lucky guess will satisfy the truth rule without satisfying the warrant rule. Even so, versions of the warrant rule can be embedded in radically different simple accounts of assertion. On one kind of account, the content of an assertion consists in the condition for having warrant to make it, or perhaps it consists in that condition and the conditions for having warrant to make other structurally related assertions, for example of the negation of the assertion. This account reduces truth to some abstraction from warrant, and derives the norm of truth from the warrant rule.
Such an account can be called anti-realist, although the term could equally well be applied to accounts of content in which truth plays no role at all.
The warrant rule can also be embedded in a different kind of account, on which having warrant to assert p amounts to knowing p. Then the warrant rule takes this form:
(The knowledge rule) One must: assert p only if one knows p.
The knowledge rule would be broken even more often than the truth rule, but so are many rules. The knowledge account—a simple account of assertion based on the knowledge rule—
explains the norm of truth as a mere corollary of the knowledge rule: satisfying the former is a necessary but not sufficient condition of satisfying the latter. If one knows p then p is true.
Nevertheless, this account in no way limits the transcendence of truth over warrant; still less does it make the former an abstraction from the latter. Knows p is not conceptually prior to p.2 This account can be called realist. Given plausible connections between knowledge, belief, evidence, and truth, the knowledge account explains what is right about Grice's two more specific maxims of quality,
'Do not say what you believe to be false' and 'Do not say that for which you lack adequate evidence', as well as the supermaxim 'Try to make your contribution one that is true'.3
This chapter defends the knowledge account. The account can be roughly summarized in the slogan 'Only knowledge warrants assertion'. 'Warrant' is used here as a term of art, for that evidential property (if any) which plays the role of property C in the correct simple account of assertion. This use need not correspond exactly to that of 'warrant' in everyday English. It is not denied that false assertions are sometimes warranted in the everyday sense that they are sometimes reasonable; the claim is rather that the reasonableness of such assertions is explicable as the joint outcome of the knowledge rule and cognitive considerations not specific to assertion. Still, if the account is correct, ordinary speakers are implicitly sensitive to the knowledge rule, for they must have implicitly grasped it in mastering assertion. It is just that they need not use the word 'warrant'
for that norm. Much of the evidence for the knowledge account comes from the ordinary practice of assertion. 11.2 The Truth Account
It is somehow good to assert the true and bad to assert the false. Is that idea articulated by the truth account, the simple account of assertion based on the truth rule? This section argues that such an account is incorrect, and that its defects recommend the knowledge account.
One doubt about the truth account is that assertion is not the only speech act to aim at truth.
For many speech acts A, normatively different from assertion and from each other, it is somehow good to perform A with a true content and bad to perform A with a false content. By definition, the truth account entails that the truth rule is individuating, in other words that assertion is the unique speech act A whose unique rule is 'Perform A with the content p only if p is true'. In this sense, the truth account claims that assertion is more intimately associated with the aim of truth than with any other speech act. But no basis is discernible for assigning this privilege to assertion in preference to all those other speech acts.
There is, for example, a speech act of conjecturing p, for which the evidential norms are more relaxed than they are for assertion. Although it is somehow good to conjecture the true and bad to conjecture the false, it is quite acceptable to conjecture p, but not to assert p, when p is merely more probable than not on one's evidence. In English, one can perform this speech act by using the words 'I conjecture' parenthetically, as in 'P, I conjecture' (compare Slote 1979: 182-7 on parenthetical uses of 'I believe'). Equally, there is a speech act of swearing to p, for which the evidential norms are more stringent than they are for assertion. Not only is it somehow good to swear to the true and bad to swear to the false, it is acceptable to swear to p only if one has grounds for unusual certainty about p, more than is required to assert p. In English, one can perform this speech act by using the words 'I swear' parenthetically, as in 'P, I swear'. What matters here is not the ordinary use of 'conjecture' and 'swear' but the possibility of speech acts of the kind described.
Indeed, there is a whole range of possible speech acts, differing in their evidential norms but all in some sense aiming at the truth. Attempts to differentiate the speech acts and uphold the truth rule by adding rules about the gravity of breaches of it depart from the structure of a simple account; they also fail to meet an objection below to the truth account. Why should assertion be the only one of them to be a speech act A whose unique rule is 'Perform A with the content p only if p is true', as the truth account requires?
It might be held that, although asserting something is not always swearing to it, swearing to something is always asserting it. Swearing to p would be a solemn way of asserting p. This would not upset the argument. Conjecturing p is no way of asserting p. The evidential standard required for asserting would still be intermediate between those required for conjecturing and swearing-to. The question would remain: is that intermediate standard more intimately connected with the aim of truth than all the other standards are?
Simple accounts of assertion based on evidential rules face no such difficulty. They correspond to simple accounts of conjecturing and swearing-to based on evidential rules which require more and less respectively than does the rule of assertion. The speech acts are thereby differentiated from each other.
Although the preceding doubt about the truth account suggests (without showing) that the rule of assertion is evidential, it fails to indicate an appropriate standard of evidence. A stronger objection to the truth account will now be developed. It does cast light on the appropriate standard of evidence. Assertion obviously has some kind of evidential norm. It is somehow better to make an assertion on the basis of adequate evidence than to make it without such a basis. Now assume the truth account, for an eventual reductio ad absurdum. Then the evidential norm is derivative from the truth rule. One ought to have evidence for one's assertions because they ought to be true.
The proposed derivation is simple. Its core is an inference from the premise that one must assert something only if it is true to the conclusion that one should assert it only if one has evidence that it is true. Since evidence that an assertion is true just is evidence for that assertion, the truth account implies that one should not make an assertion for which one lacks evidence. The underlying principle is quite general; it is not limited to assertion. The principle may be stated as a schema, with parentheses to indicate scope:
(1) If one must (φ only if p is true), then one should (φ only if one has evidence that p is true).
The transition from 'must' to 'should' represents the transition from what a rule forbids to what it provides a reason not to do. For example, if one must not bury people when they are not dead, then one should not bury them when one lacks evidence that they are dead. It is at best negligent to bury someone without evidence that he is dead, even if he is in fact dead. The proposed explanation of the evidential norm substitutes 'assert p' for 'φ' in (1). Clearly, there is much room for variation in the letter of (1) without violation of its spirit.
On a charitable reading of (1), the required weight of evidence for p will vary with the badness of φ-ing when p is false. One should take more care to avoid killing people than to avoid offending them, if the risks are equal in probability. The question is whether (1), so read, can explain the weight of evidence which we require speakers to have for their assertions in terms of the degree of badness which we attribute to making an untrue assertion. Is the former proportionate to the latter?
Consideration of lotteries suggests a negative answer. Suppose that you have bought a ticket in a very large lottery. Only one ticket wins. Although the draw has been held, the result has not yet been announced. In fact, your ticket did not win, but I have no inside information to that effect. On the merely probabilistic grounds that your ticket was only one of very many, I assert to you flat-out
'Your ticket did not win', without telling you my grounds. Intuitively, my grounds are quite inadequate for that outright unqualified assertion, even though one can construct the example to make its probability on my evidence as high as one likes, short of 1, by increasing the number of tickets in the lottery. You will still be entitled to feel some resentment when you later discover the merely probabilistic grounds for my assertion. I was representing myself to you as having a kind of authority to make the flat-out assertion which in reality I lacked. I was cheating.4
There is a special jocular tone in which it is quite acceptable to say '[Come off it—] Your ticket didn't win', but the tone signals that the speaker intends not to make a flat-out assertion. In the imagined example, I do not use that tone.
Can the fault in my assertion be explained by appeal to some version of (1)? The explanation would have to be that it is so bad to make an untrue assertion that one should not run even a minute risk of doing so. Is that plausible? We may well regard both honesty and the pursuit of truth as very serious matters, but it does not follow that we must regard every untrue assertion as a serious crime; the pursuit of truth would not get very far if we did. When we discover that we have inadvertently asserted something false on some casual matter, most of us are racked by no more guilt than we feel when we inadvertently tread on someone's toes. In the present case, let it be common knowledge between us that the result of the lottery will be announced within a few minutes, and that you care little whether your ticket wins. Thus the bad consequences of the falsity of my assertion which I risk inflicting on you—but do not actually inflict, since my assertion is in fact true—amount to briefly having a false belief (if you believe my assertion) on a matter about which you care little. Ordinarily, we should not regard the fact that an action of mine involved a one-in-a-million risk of inflicting consequences of such limited badness on you as much cause for criticism. Yet you are entitled to insist that I was quite wrong to assert 'Your ticket did not win', for I had no authority to do so. That criticism of me does not derive from the kind of consideration embodied in (1). No assessment of the probability or gravity of untruth is even relevant to the criticism. The point is simply that, in making the assertion,
I exceeded my evidential authority. In other cases, where untruth is less improbable or worse in its consequences if it does occur, the speaker is no doubt subject to further criticisms on those grounds, but they should not be allowed to obscure the possibility of criticizing speakers simply for exceeding their evidential authority.
Could a defender of the truth account explain what is wrong with my assertion by appeal to
Gricean rules of conversation? The idea would be that my assertion was misleading because you, to whom I was speaking, were entitled to assume that the grounds on which I made it were not obviously already available to you, so you were entitled to assume that I had inside information about the result of the lottery. For making the assertion on grounds obviously already available to you might be held to violate one of the maxims of Quantity, 'Do not make your contribution more informative than is required' (Grice 1989: 26). However, if that Gricean point were the objection to my assertion, then the objection would extend to case (a), in which I assert 'Your ticket is almost certain not to have won', and the objection would not extend to case (b), in which I assert 'Your ticket did not win' but (unlike the previous cases) it is not obvious that you know how many tickets other than your own have been sold. For in case (a), parallel Gricean reasoning would indicate that you are entitled to assume that the grounds on which I made my assertion were not obviously already available to you, and therefore that you are entitled to assume that I had inside information about the result of the lottery—for example, evidence that it was almost certain to have been rigged in favour of someone else. In case (b), my grounds for the assertion—the number of tickets sold—
are not obviously already available to you, so the assumption to that effect, which the argument supposes you to be entitled to make, is true, and the Gricean objection lapses. In fact, however, the problem behaves in the opposite way to that predicted by the Gricean explanation. It does not extend to case (a), in which the worst to be said of my assertion is that it is banal and unkind. The problem does extend to case (b), in which you are still entitled to feel resentment at the merely probabilistic grounds for my assertion. Probabilistic evidence warrants only an assertion that something is probable.
A further problem for the Gricean explanation is that I should be able to remove the objection to my assertion by explicitly cancelling the supposed conversational implicature. I am not.
I have no more evidential authority to assert 'Your ticket did not win, but I do not mean to imply that I have inside information' than I have to assert the plain 'Your ticket did not win'. The criticisms here are not of Grice's theory of conversational implicature itself but only of an over-enthusiastic application of it.
A different defence of the truth account appeals to the point that, for each ticket, I have a similar basis for asserting that it did not win. If I make all those assertions, I shall have asserted something false. But how does that explain what is wrong with making any one of them, granted the truth rule? Consider an analogy. I am faced with an enormous pile of chocolates. I know that exactly one of them is contaminated and will make me sick; alas, I cannot tell them apart. I have a strong desire to eat a chocolate. I can quite reasonably eat just one, since it is almost certain not to be contaminated, even though, for each chocolate, I have a similar reason for eating it, and if I eat all the chocolates, I shall eat the contaminated one, and my sickness will be overdetermined. No plausible principle of universalizability implies that, in the circumstances, any reason for taking one chocolate is a reason for taking them all; the most to be implied is that, in the circumstances, any reason for taking one chocolate is a reason for taking any other chocolate instead. The truth account does not supply the resources to rule out the possibility that there is adequate evidence for each of the assertions 't did not win' but not for their conjunction. If each conjunct is true then the conjunction is also true, of course, but it does not automatically follow that the same goes for adequate evidence of truth. Although the principle that entitlement to assert each conjunct implies entitlement to assert the conjunction may be independently plausible, the truth account cannot explain it.
It is not even essential to the lottery case that each ticket should have an equal chance of winning. Consider a variant lottery in which each ticket is assigned a publicly known weight proportional to its probability of winning, and your ticket has a somewhat lower weight than the others. I am still not entitled to assert that your ticket will not win, even though my evidence that it will not win is now better than for any other ticket. Alternatively, the lottery might even be one in which there was probably no winning ticket (DeRose 1996). It might finally be protested that if I lacked warrant to assert 'Your ticket did not win', then we lack warrant to make most of our ordinary assertions, because few of them are quite certain. Of course, it follows that I had warrant only given the anti-sceptical premise that we do have warrant to make most of our ordinary assertions. The protest simply assumes that no other account of assertion can discriminate between 'Your ticket did not win' and most of our ordinary assertions. That assumption needs testing; it is rejected in the next section. In any case, for whatever reasons, probabilistic bases are ordinarily taken to be inadequate for assertion.
The truth account does not explain something that it is committed to explaining: the evidential norms for assertion. It should therefore be rejected. A speech act genuinely based on the truth rule would be more like the act of saying; one can say something without asserting it, for example, in guessing the answers to a quiz (Unger 1975: 267 credits the point to Harman).
Assertion itself seems to be governed by a non-derivative evidential rule, which my assertion in the lottery case broke; I was cheating.
One possible explanation is this. The rule of assertion is the knowledge rule; one must not assert p unless one knows p. In the lottery case, it is intuitively clear, given the nature of my evidence, that I did not know that your ticket did not win.5 Thus my assertion violated the rule of assertion. After all, the natural way for you to articulate the criticism that I lacked evidential authority for my assertion is by saying 'But you didn't know that my ticket hadn't won!'. This argument will be developed in the next section.
11.3 The Knowledge Account
One may lack the evidential authority to assert a proposition about a lottery, even though the proposition is very highly probable on one's evidence. It will now be argued that the underlying phenomenon is general to assertions about any subject matter.
Let p be a proposition whose truth value is known to an expert but about which you have no evidence. The expert holds a lottery. There are a million tickets, of which you have one. However, she does not announce the number of the winning ticket; she merely hands each participant a slip of paper. If your ticket won, the true member of the pair {p, ~p} is written on your slip; if your ticket lost, the false member of the pair is written there. There is no doubt that this is the arrangement. You are not in a position to confer with other participants. Suppose that ~p turns out to be written on your slip. On your evidence, there is a probability of one in a million that your ticket won and ~p is true, and a probability of 999,999 in a million that your ticket lost and ~p is false. Thus, if you assert p, the probability on your evidence that your assertion is true is 999,999 in a million. Intuitively, however, you are not entitled to assert p outright. That intuition can be supported. On your evidence, you can certainly assert the biconditional linking p and 'My ticket did not win'; by hypothesis, it is not in doubt. If you assert p, you are therefore surely in a position to detach, and assert 'My ticket did not win'. But you are not entitled to assert that, for your only evidence is that your ticket was one in a million. That ~p rather than p was written on your slip tells you nothing, for you have no independent evidence for or against those propositions. Thus you are not entitled to assert p, even though it has a probability on your evidence of 999,999 in a million. In the preceding example, p could be any assertion about which you happen to have no evidence. Indeed, even if you have probabilistic evidence that tends to support ~p, the number of tickets in the lottery can be made so large that your probabilistic evidence from the lottery for p will overwhelm your other evidence against p. Thus the argument indicates that, for almost any kind of proposition at all, very high probability on one's evidence does not imply assertibility. The propositions not covered by the argument are those for which one is bound to have independent non-probabilistic evidence, for example, 'I exist': but they are not plausible candidates for assertion on a merely probabilistic basis. The obvious moral is that one is never warranted in asserting a proposition by its probability (short of 1) alone. What matters in the original lottery case is not the subject matter of the assertion but the probabilistic basis on which it was made.
To say that no probability short of 1 warrants assertion is not yet to say that only knowledge warrants assertion. Some non-deductive forms of inference might be held sometimes to warrant assertion non-probabilistically without providing knowledge; an example is inference to the best explanation. It is hard to see how inference to the best explanation could ever generate numerical probabilities, but even if it does lead to conclusions of high probability short of 1, it would not warrant assertion in virtue of doing so. The implication is that one might have warrant to assert the conclusion of an inference to the best explanation, even though one lacked warrant to assert an equally probable proposition whose high probability had a different basis; no inference to the best explanation provided the probabilistic evidence that your ticket did not win.
Such a view is consistent, but is it plausible? If one has warrant to assert a proposition of probability less than 1 on one's evidence, then in some lottery case one lacks warrant to assert a proposition—
perhaps the very same proposition—of higher probability on one's evidence.
Assume, plausibly, that if p is less probable than q on one's evidence, and one has warrant to assert p, then one has warrant to assert q. Given our intuitions about lotteries, it follows that one never has warrant to make assertions of probability less than 1 on one's evidence. This conclusion might appear to be a sceptical one, even a reductio ad absurdum. For it is easy to suppose that almost all our ordinary empirical assertions are of probability less than 1 (for example, Edgington
1995: 287). But what kind of probability is in question? If it is objective probability, then the problem affects only assertions about the future, for only they have an objective probability other than 1 or 0. But objective probability is too objective to warrant assertion: of two past tense assertions whose objective probability is 1, I may have excellent evidence for one and none for the other. Equally, subjective probability (degree of belief) is too subjective to warrant assertion: I do not gain warrant to assert that I am Napoleon merely from my baseless conviction that I am
Napoleon, even if my conviction is so dogmatic that the assertion has subjective probability 1. If any probability warrants assertion, it is probability on one's evidence.
What is one's evidence? The simple answer defended in Chapters 9 and 10 is available to the knowledge account: one's evidence is just what one knows. We could additionally argue for it from the knowledge account of assertion, given the not wholly uncontroversial premise that one's evidence consists of just those propositions which the rules of assertion permit one to assert outright. The equation of knowledge with evidence was not assumed in the earlier discussion of evidence for assertions. For present purposes, it would not matter if it were considered to sharpen the prior notion rather than merely elucidating it, for either way the result is a tenable notion of evidence. Without making any substantive assumptions about the conditions for knowledge, this view makes it trivial that if one knows p, then the probability of p on one's evidence is 1. This does not imply that no discovery could shake one's confidence in p, for discoveries can undermine knowledge. Nor does it imply that one would in practice bet one's life against a penny on p; that test defines no useful notion of probability (let p be a moderately complicated tautology). The standard of probability 1 on one's evidence is no more demanding than the standard of knowledge. The denial of knowledge in the lottery case might also be feared to have sceptical implications, on the grounds that virtually all our empirical knowledge has a probabilistic basis. For example, our perceptual processes are subject to random error. However, one must distinguish between causal and evidential senses of the word 'basis'. The causal connection between the environment and our perceptual beliefs about it is no doubt probabilistic, but it does not follow that those beliefs rest on probabilistic evidence. On the view above of evidence, when they constitute knowledge, they are part of our evidence. Moreover, they may constitute knowledge simply because perceiving counts as a way of knowing; that would fit the role of knowledge as evidence (see section 1.4). I certainly did not perceive that your ticket did not win. There is no valid argument from the denial of knowledge in the lottery case to its denial in perceptual and other cases in which we ordinarily take ourselves to know. The knowledge rule provides a better explanation of the inadequacy of probabilistic grounds for assertion than do accounts on which something less than knowledge warrants assertion.
Conversational patterns confirm the knowledge account.6 Consider a standard response to an assertion, the question 'How do you know?'. The question presupposes that it has an answer, that somehow you do know. If not only knowledge warrants assertion, what makes that presupposition legitimate? The question 'Where did you read that?' is not normally appropriate in response to an assertion, because someone who asserts p is not usually committed to having read p somewhere.
But 'How do you know?' is normally appropriate. Of course, it is silly to ask 'How do you know?'
when the questioner obviously knows as well as the asserter how the latter knows, for example, when someone has said 'I want to go home'. And the questioner does not always believe the presupposition of the question, for it is sometimes (not always) intended as a challenge to the assertion. Nevertheless, it is an implicit challenge: the questioner politely grants that the asserter does know p, and merely asks how, perhaps suspecting that there is no answer to the question. If not only knowledge warranted assertion, the absence of an answer would not imply the absence of a warrant; why should the question constitute even an implicit challenge? The hypothesis that only knowledge warrants assertion makes good sense of the phenomenon.
A less standard and more aggressive response to an assertion is the question 'Do you know that?'. Its aggressiveness is easy to understand on the hypothesis that only knowledge warrants assertion, for then what it calls into question is the asserter's warrant for the assertion. On the hypothesis that not only knowledge warrants assertion, the aggressiveness of the question is hard to understand, for the asserter might truthfully answer 'No' and still have warrant for the assertion.
A related argument starts from a version of Moore's paradox, with 'know' in place of
'believe' (Moore 1962: 277; Unger 1975: 256-60; Jones 1991). Something is wrong with any assertion of the form 'A and I do not know that A', even though such assertions would often be true if made. What is wrong can easily be understood on the hypothesis that only knowledge warrants assertion. For then to have warrant to assert the conjunction 'A and I do not know A' is to know that
A and one does not know A. But one cannot know that A and one does not know A. One knows the conjunction only if one knows each conjunct, and therefore knows that A (the first conjunct); yet one knows the conjunction only if it is true, so only if each conjunct is true, so only if one does not know that A (the second conjunct); thus the assumption that one knows the conjunction that A and one does not know that A yields a contradiction. Given that only knowledge warrants assertion, one therefore cannot have warrant to assert 'A and I do not know that A'.7 In contrast, the hypothesis that not only knowledge warrants assertion makes it hard to understand what is wrong with an assertion of that form. One often has good evidence that A whilst knowing for sure that one does not know that A; in such cases one has good evidence short of knowledge for the conjunction that A
and one does not know that A. If good evidence short of knowledge warranted assertion, one would have warrant to assert 'A and I do not know that A': but one has not. For example, I have excellent evidence for the conjunction that your ticket did not win and I do not know that your ticket did not win. If such evidence warranted assertion, I should have warrant to assert 'Your ticket did not win and I do not know that your ticket did not win'.
Given that knowing entails believing, a similar explanation reveals what is wrong with any assertion of the more familiar Moorean form 'A and I do not believe that A', for one knows the first conjunct only if the second conjunct is false (Sorensen 1988: 15-56 has a more general account of
Moorean paradoxes along similar lines).
Naturally, these arguments apply only to utterances of the conjunction within a single context. If the contextual standards for knowledge are raised between the utterance of the first conjunct and that of the second, the assertion might be acceptable. Its unacceptability within a single context must still be explained.
Knowledge is not even a cancellable implication of assertion (Slote 1979: 179). For if the implication could be cancelled, the second conjunct 'I do not know that A' would cancel it, and it would be acceptable to assert the conjunction; but it is not acceptable.
One might fear that such arguments would prove too much. After all, something is wrong even with the assertion 'A and I cannot be certain that A'. Does that not suggest that only something more than knowledge warrants assertion? What seems to be at work here is a reluctance to allow the contextually set standards for knowledge and certainty to diverge. Many people are not very happy to say things like 'She knew that A, but she could not be certain that A'. However, we can to some extent effect such a separation, and then assertibility goes with knowledge, not with the highest possible standards of certainty. For example, one may have warrant to assert 'A and by Descartes's standards I cannot be absolutely certain that A', where the reference to Descartes holds those standards apart from the present context. Again, it would often be inappropriate to respond to the assertion 'A' by asking 'How can you be so certain that A?'. The word 'so' flags the invocation of unusually high standards of certainty. By ordinary standards you may have had warrant to assert that A even if you could not be so certain that A.
The putative connections between knowledge, assertion and certainty contain an obvious sceptical threat (elaborated in Unger 1975). One response is to permit contextual variation in epistemic standards: in effect, 'know' would express different contents in different contexts, as a result of either variation in meaning or an invariant indexical meaning (DeRose 1995 and Lewis
1996 are recent examples). If so, 'assert' will express correspondingly different contents. The contents will nevertheless have enough in common to be appropriately discussed together, as is standard in contextualist epistemology. The present account permits such contextual variation, but, as argued in Chapters 7, 8, and 9, it can resist the concession that sceptical arguments create a context in which sceptical utterances express truths.8
Considerable evidence has emerged that our ordinary linguistic practice acknowledges the knowledge rule. Certain phenomena are nevertheless likely to be adduced as counter-evidence. The next section considers such objections.
11.4 Objections to the Knowledge Account, and Replies
That false beliefs are often reasonable is a commonplace. The account of evidence in
Chapters 9 and 10 allows a false proposition to be very highly probable on one's evidence, even though one's evidence itself is true. Evidence can be misleading. When one reasonably but falsely believes p, is it not reasonable to assert p, even though one does not know p? If so, what becomes of the claim that only knowledge warrants assertion?
On some views, it is sometimes reasonable to believe p, even though one knows that one does not know p. For example, it is reasonable for me to believe that I shall not be run over by a bus tomorrow, even though I know that I do not know that I shall not be run over by a bus tomorrow
(Slote 1979: 180; I am not confined in a bed, lost in a jungle, or the like). Such cases do not threaten the hypothesis that only knowledge warrants assertion, for they are ones in which, intuitively, assertion is not warranted. It would be foolish of me baldly to assert that I shall not be knocked down by a bus tomorrow; it would invite the objection 'You don't know that'. As in the lottery case,
I should assert no more than that it is very unlikely that I shall be knocked down by a bus tomorrow.
Such cases support the hypothesis that only knowledge warrants assertion.
It is plausible, nevertheless, that occurrently believing p stands to asserting p as the inner stands to the outer. If so, the knowledge rule for assertion corresponds to the norm that one should believe p only if one knows p (see also section 1.5). Given that norm, it is not reasonable to believe p when one knows that one does not know p. If one knows that what one knows is only that p is very probable, then what it is reasonable for one to believe is only that p is very probable. For example, I should not believe that my ticket will not win the lottery. Outright belief in this sense requires more than a high subjective probability as determined by betting ratios (see section 4.4). On this analogy between assertion and belief, the knowledge rule for assertion does not correspond to an identification of reasonable belief with knowledge (contrast Wright 1996: 935). The rule makes knowledge the condition for permissible assertion, not for reasonable assertion. One may reasonably do something impermissible because one reasonably but falsely believes it to be permissible. In particular, one may reasonably assert p, even though one does not know p, because it is very probable on one's evidence that one knows p. In the same circumstances, one may reasonably but impermissibly believe p without knowing p. That possibility is consistent with the equation of evidence with knowledge.9
Sometimes one knows that one does not know p, but the urgency of the situation requires one to assert p anyway. I shout 'That is your train', knowing that I do not know that it is, because it probably is and you have only moments to catch it. Such cases do not show that the knowledge rule is not the rule of assertion. They merely show that it can be overriden by other norms not specific to assertion. The other norms do not give me warrant to assert p, for to have such warrant is to satisfy the rule of assertion. Similarly, when I am speaking a foreign language, the urgency of the situation may require me to speak ungrammatically, because it would take me too long to work out the correct grammatical form for what I want to say; it does not follow that my utterance satisfied the rules of grammar in that context.
In other cases, one reasonably but falsely believes p, and is in no position to know that one does not know p (see also section 8.2). One cannot discriminate between one's actual circumstances and circumstances in which one would know p. For example, it is winter, and it looks exactly as it would if there were snow outside, but in fact that white stuff is not snow but foam put there by a film crew of whose existence I have no idea. I do not know that there is snow outside, because there is no snow outside, but it is quite reasonable for me to believe not just that there is snow outside but that I
know that there is; for me, it is to all appearances a banal case of perceptual knowledge. Surely it is then reasonable for me to assert that there is snow outside.
The case is quite consistent with the knowledge account. Indeed, if I am entitled to assume that knowledge warrants assertion, then, since it is reasonable for me to believe that I know that there is snow outside, it is reasonable for me to believe that I have warrant to assert that there is snow outside. If it is reasonable for me to believe that I have warrant to assert that there is snow outside, then, other things being equal, it is reasonable for me to assert that there is snow outside.
Thus the knowledge account can explain the reasonableness of the assertion. However, granted that it is reasonable for me to believe that I have warrant to assert p, it does not follow that I do have warrant to assert p. The term 'warrant' has been reserved for the property C in the rule C of assertion. There may be other evidential norms for assertion, if they can be derived from the knowledge rule and considerations not specific to assertion. The reasonableness of asserting p when one reasonably believes that one knows p has just been derived in exactly that way. One can think of the knowledge rule as giving the condition on which a speaker has the authority to make an assertion. Thus asserting p without knowing p is doing something without having the authority to do it, like giving someone a command without having the authority to do so.
Characteristic standards of authority thus play a constitutive role in the speech act of assertion, as they do in other institutions. The distinction between having warrant to assert p and reasonably believing oneself to have such warrant becomes a special case of the distinction between having the authority to do something and reasonably believing oneself to have that authority. Someone who does not know p lacks the authority to assert p, and therefore cannot pass that authority on to me by asserting p, no matter how plausibly he gives me the impression that he has done so. Although there are special cases in which someone comes to know p by hearing someone who does not know p assert p (Lackey 1999), the normal procedure by which the hearer comes to know p requires the speaker to know p too.
The assimilation of warrant to authority is misleading in one respect. Authority, even intellectual authority, usually extends over an area; it is not confined to a single proposition. In the present sense, testimony can give one the authority to assert p, even if one is pitifully ignorant about neighbouring questions, and no extent of knowledge about neighbouring questions can give one the authority to assert p if one happens to be mistaken on that single point.
We are not always in a position to know whether we know p (Chapters 5 and 8). The knowledge account therefore implies that we are not always in a position to know whether we have warrant to assert p. We are liable to error and ignorance about warrant, just as we are about almost everything else (Chapter 4). This view of warranted assertibility is in sharp contrast with its treatment in anti-realist theories of meaning to which the notion of the assertibility conditions of sentences is crucial. Such theories characteristically assume that one has no difficulty in knowing whether one has warrant to assert p. Independently of the knowledge account, there is reason to doubt that there could be a norm of the kind postulated by anti-realist theories (section 4.8 and
Chapter 8).10
The knowledge account may seem to imply that speakers should always be at great pains to verify a proposition before asserting it. The wide variety of situations in which speakers go to no such pains may therefore seem to threaten the knowledge account: consider a lively seminar discussion, or gossip. To rule that speakers are not making genuine assertions in such situations would be to trivialize the account. In natural languages, the default use of declarative sentences is to make assertions, and the situations at issue are not special enough to cancel the default. Rather, the point is that the knowledge account does not imply that asserting p without knowing p is a terrible crime. We are often quite relaxed about breaches of the rules of a game which we are playing. If the most flagrant and the most serious breaches are penalized, the rest may do little harm. In some sports, it is said that some rules are being breached most of the time. Similarly, many of the utterances in an ordinary conversation are syntactically ill formed even by the standards of the speaker's own idiolect, for example as a result of intentional or unintentional changes of direction in mid-sentence. Breaches of the rules are more serious in writing than in speech; that applies to the rule of assertion, too. When assertions come cheap, it is not because the knowledge rule is no longer in force, but because violations of the rule have ceased to matter so much.
To be relaxed in applying a rule is not to replace it by a different rule. Even in a lively seminar discussion, or gossip, the knowledge rule does not give way to a rule of reasonable belief.
For example, even in gossip, it would be cheating to assert 'Mr Jones won nothing in the lottery again last week' merely on the basis of its high probability. Similarly, if I overhear an expert logician in a room full of people say 'A flaw has just been found in the proof of the main theorem in his last paper' when it is 99 per cent probable that the person whom he is demonstrating is Professor
X, I may form a reasonable belief that a flaw has just been found in the proof of the main theorem of Professor X's last paper, but, even in a lively seminar discussion, it would be cheating for me to answer someone who bases an objection to my views on that theorem by asserting, without qualification, 'A flaw has been found in the proof of that theorem'. Such assertions are unacceptable because the speaker knows that he lacks the requisite knowledge, even though he has a reasonable belief. When we are relaxed in applying the rule, we feel entitled to assert p whenever we are not confident that we do not know p. We still try to obey the knowledge rule, but we do not try very hard.
In debate, we are often willing to assert p when we do not expect to persuade our interlocutors of p. However, knowing p is quite consistent with being unable to persuade other people of p. Knowledge often depends on good judgement, the speaker may have better judgement than the hearer, and most speakers value their own judgement more highly than they know their hearers do.
Some people use the locution 'I assert that . . . ' only when they cannot supply compelling grounds; the implied contrast is with 'I can prove that . . . ' or the like. For the reason just given, they are not conceding that they do not know. The simplest analysis of what one does in uttering the syntactically declarative sentence 'I assert that A' is that one asserts that A by asserting that one asserts that A—just as, in uttering 'I promise to φ', one promises to φ by asserting that one promises to φ (Lemmon 1962; Hedenius 1963; Heal 1974; Lewis 1983: 224, from Lewis 1970; Ginet 1979; for a different but related view, Recanati 1987: 169-75). On that view, one obviously knows that one asserts that A, and therefore is warranted in asserting that one asserts that A. This may help to distract attention from the more problematic question: is one warranted in asserting that A? One dodges that question by focusing one's hearers' attention on the less contentious assertion.
11.5 The BK and RBK Accounts
I may believe on good evidence that your lottery ticket did not win; I am not warranted in asserting that it did not win. I may believe on good evidence that I shall not be knocked down by a bus tomorrow; I am not warranted in asserting that I shall not be knocked down by a bus tomorrow.
Neither belief nor belief on good evidence warrants assertion. Nevertheless, it might still be thought that some false assertions are warranted in the technical sense that they obey the rule of assertion.
One proposal along such lines is that the rule for assertion is this:
(The BK rule) One must: assert p only if one believes that one knows p.
(Thijsse forthcoming, citing similar views from Lenzen 1980). What one believes oneself to know need not be true. Can the BK account explain the phenomena?
The BK account can explain many of the conversational phenomena that were used as evidence for the knowledge account by adapting the latter's explanations to its own use. For example, I can follow the proof which shows that I cannot know the conjunction that A and I do not know that A, and should therefore refrain from believing that I know that A and I do not know that
A. If I do so refrain, then the assertion 'A and I do not know that A' would violate the BK rule.
Similarly, if I am committed to believing that I know by my assertion, then the challenge 'How do you know?' has an obvious relevance.
One problem for the BK account is that my belief that I know p may be as irrational as any other belief. The BK account's analysis of the modified Moorean sentence depends on the assumption that if 'B' is inconsistent then 'I believe that B' is inconsistent, which is invalid for subjects who are logically capable of irrationality. Suppose that I have an irrational belief that I
know that G. E. Moore was a serial killer. On the BK account, my assertion 'G. E. Moore was a serial killer' satisfies the rule of assertion. Neither its falsity nor its irrational basis constitutes a breach of the BK rule. So far, nothing is wrong with the assertion itself. Plenty is wrong with the asserter, for I have a completely irrational belief, but that is another matter. Although I have obeyed the BK rule only by expressing an irrational belief, the BK account lacks the resources to explain why that is a fault in the assertion itself. Defenders of the BK account cannot deny that we distinguish faults in the assertion from faults in the asserter. If I am asked 'Do you really have the belief that G. E. Moore was a serial killer?' (a question about me, not about G.
E. Moore) then, in the circumstances, I ought to answer 'Yes', which is to assert that I have the belief that G. E. Moore was a serial killer; the assertion itself is quite in order, even though its being so depends on my irrational belief that G. E. Moore was a serial killer. The fault there is clearly in the asserter, not in the assertion. Since the BK account cannot explain why we regard the assertion
'G. E. Moore was a serial killer', not just its assertor, as faulty, it should be rejected. In contrast, the knowledge account has no difficulty in explaining what is wrong with the assertion, for it breaks the knowledge rule.
On an obvious revision of the BK account, the rule for assertion is this:
(The RBK rule) One must: assert p only if one rationally believes that one knows p.
The added condition of rationality both improves the analysis of modified Moorean sentences and eliminates the counterintuitive consequences above. Nevertheless, all is not well with the RBK account. One problem concerns conjunctive assertions. Consider a complicated paradox, in which a contradiction is deduced from a very large number of premises p 1 , . . . , p n . For each number i, p i seems intuitively obvious; indeed, it seems intuitively obvious that we know p i . Even on reflection, we are quite unsure which premise to blame for the contradiction. Suppose also that it is unlikely that more than one of the premises is false; each premise seems to have a quite different basis from the others, so that its falsity would be unlikely to infect them. Then we might easily, for each number i, rationally believe ourselves to know p i . For each i, on the RBK account, we therefore have warrant to assert p i . Nevertheless, we know that the conjunction of p 1 , . . . , p n is false, because it entails a contradiction; thus it is not rational to believe ourselves to know the conjunction, so, on the RBK account, we lack warrant to assert it. Warrant to assert would not be closed under conjunction. This consequence of the RBK account is disturbing, but not clearly absurd.11 The RBK account shares a simpler problem with the BK account; the analogue for falsity of the latter's problem about irrationality. Suppose that I rationally believe myself to know that there is snow outside; in fact, there is no snow outside. On the BK and RBK accounts, my assertion 'There is snow outside' satisfies the rule of assertion. Yet something is wrong with my assertion; neither the BK nor the RBK account implies that it is. They can allow that something is wrong with my belief that I know that there is snow outside, for it is false, but that is another matter. The BK and
RBK accounts lack the resources to explain why we regard the false assertion itself, not just the asserter, as faulty.
A further objection to the BK and RBK accounts, an obvious methodological one, is that they are less simple than the account based on the knowledge rule. Their adoption might be reasonable if the latter were refuted, but it has not been. The onus of proof is on the BK and RBK
accounts. After all, when I assert p, why should it matter whether I rationally believe myself to know p if I am not required to know p? Of course, the truth account is even simpler than the knowledge account, so the onus of proof is on the latter against the former; but it has already been discharged.
A final objection to the RBK account is that it makes it too easy for someone who lacks the authority to assert p to confer that authority on someone else. For even if one knows ~p, one might create sufficiently misleading appearances to make others reasonably but falsely believe themselves to know p. Intuitively, such a trick confers only the appearance, not the reality, of the authority to assert p; according to the RBK account, it confers genuine authority. If a truth requirement were added to the RBK rule ('One must: assert p only if one rationally and truly believes that one knows p'), it would require knowledge after all. One should adopt the simpler knowledge account instead.
One possible motivation for belief-based accounts of assertion (hinted at by Thijsse) is the idea that what warrants assertion should be a mental state of the asserter. On a common view, believing and reasonably believing oneself to know p are mental states, while knowing p is not.
However, it was argued in Chapter 1 that knowing pis a mental state, of an externalist kind. Indeed, the combination of that idea with the idea that falsity is a fault in the assertion itself, so that what warrants asserting p entails p, implies that what warrants asserting p is a mental state which entails p. Knowing p is the best candidate for such a state. On a more internalist conception of mental states, this question would become more pressing: why should what warrants assertion be a mental state of the asserter? One bad answer would be that one can always tell whether one is in a given mental state. One cannot. It may be hard to tell whether one's confidence that one knows p is high enough for one to count as believing oneself to know p, and even harder to tell whether it is rational enough for one to count as rationally believing oneself to know p (Chapter 4). There is no good reason to accept a belief-based account of assertion. Indeed, our attitude to false assertions is misrepresented by any simple account on which what warrants assertion does not entail truth.
11.6 Mathematical Assertions
The rule of assertion is easier to identify in more formal situations, of which mathematics provides some of the best examples. Assertibility in mathematics has the additional interest that attempts to construct assertibility-conditional theories of meaning have taken the intuitionistic proof-conditional account of mathematics as a paradigm. Assertion in mathematics will therefore be considered. The mathematical case is, it will be argued, more representative than has often been supposed.
In mathematics, the distinction between warranted and unwarranted assertions is striking.
Count the propositions that are axiomatic for working mathematicians as having one-line proofs.
Then, to a first approximation, in mathematics one has warrant to assert p if and only if one has a proof of p. On the knowledge account, that is so because, to a first approximation, in mathematics one knows p if and only if one has a proof of p. One has a proof of p when one has followed such a proof and retains some memory of it, in particular of its conclusion. Those are just first approximations, but where having warrant to assert p diverges from having a proof of p, so does knowing p. Conversely, where knowing p diverges from having a proof of p, so does having warrant to assert p. Having warrant to assert p and knowing p do not diverge from each other; the knowledge account is confirmed.
The word 'proof' has just been used in the informal sense common in ordinary mathematics, in which only truths have proofs; a working mathematician who says that it has been proved that A
does not leave it open whether A. This notion is not relativized to an arbitrary formal system; if it were, the connection with (unrelativized) assertibility would be lost. The axioms have one-line proofs in virtue of their status in the practice of mathematics, not in virtue of their place in a particular formal system. 'Proof' will be used in this informal sense below.
Consider first putative cases in which one has warrant to make a mathematical assertion, but lacks a proof. In the simplest cases, one knows by testimony that there is a proof of p: but then one knows p by testimony, and thereby satisfies the knowledge rule. In rarer cases, the non-deductive evidence for a mathematical proposition may be strong enough to warrant its assertion (Steiner 1975: 93-108). Nevertheless, this biconditional remains plausible: the evidence is strong enough to warrant asserting p if and only if it is strong enough for one to know p. What the knowledge account will not grant is that one can have warrant to assert p without a proof of p by having grounds for a mistaken belief that one has a proof of p, or for a mistaken belief that there is such a proof. When one has such a belief, on the knowledge account, one at best mistakenly believes that one has warrant to assert p. Even if expert mathematicians play a practical joke and inform you falsely that p has been proved, you do not really acquire warrant to assert p (if you did, the joke would be still less funny).12 You acquire only misleading evidence that you have such warrant. Although your belief that you have it is reasonable, that does not make it true. The reasonableness in question can be explained as derivative from the knowledge rule. You reasonably believe yourself to know p, so you have reason to believe that you have warrant to assert p. This view of the matter is independently defensible.
Testimony is a special source of warrant because one speaker can pass on a warrant to another.
Since the expert mathematicians have no warrant to assert p themselves, they have none to pass on to you.
Now consider putative cases in which one has a proof of a mathematical proposition but lacks warrant to assert the proposition. The possibility of such cases is sometimes denied, on the
Cartesian grounds that genuine proofs are transparent to the subject. That denial does little justice to the complexity of many actual proofs. It can take months of effort by the mathematical community to decide whether a purported proof is genuine. When I have a genuine proof, expert mathematicians may tell me falsely that it contains a fallacy. They may give me a complicated explanation of the supposed fallacy, blinding me with science. I may recall other occasions on which what I believed for broadly similar reasons to be a proof really did turn out to be fallacious.
In such cases, it would be unreasonable for me to assert p, for it is unreasonable for me to believe that I have warrant to assert p. It does not immediately follow that I have no warrant to assert p. One may have the authority to do something even when it is unreasonable for one to believe that one has that authority. What the knowledge account implies is just that I cease to have warrant to assert if and only if I cease to know. That biconditional remains plausible. If I know p, I thereby have warrant to assert p. Conversely, there is no reason to expect my possession of a proof of p to give me warrant to assert p independently of letting me know p. The more plausible of the two ways for the biconditional to hold is for me to lose both knowledge and warrant to assert: the appearance of ignorance undermines knowledge in a way in which the appearance of knowledge does not undermine ignorance. But even if I retain both knowledge and warrant to assert, the knowledge account stands.
The remaining cases are those in which one has a proof of p if and only if one has warrant to assert p. They are still less likely to threaten the proposed equivalence between knowing p and having warrant to assert p.
How untypical are mathematical assertions? Proofs are often supposed to warrant them in a way inapplicable to most or all empirical assertions. Proofs, it is said, are conclusive, whilst empirical warrants are not. However, the nature of the contrast is unclear. No doubt new information cannot make a proof into a non-proof. But the issue is not whether proofs continue to be proofs; it is whether they continue to warrant assertion. Define a way of having warrant to assert p to be defeasible just in case one can have warrant to assert p in that way and then cease to have warrant to assert p merely in virtue of gaining new evidence. A way of having warrant to assert p is indefeasible just in case it is not defeasible. Most ways of having warrant to make empirical assertions are defeasible, but the considerations above about the social character of mathematical knowledge suggest that even grasping a proof of a mathematical proposition is a defeasible way of having warrant to assert it. One can have warrant to assert a mathematical proposition by grasping a proof of it, and then cease to have warrant to assert it merely in virtue of gaining new evidence about expert mathematicians' utterances, without forgetting anything. If so, mathematical propositions do not differ from empirical ones in point of defeasibility.
The notion of indefeasibility should not be confused with that of factiveness. A way of having warrant to assert p is factive just in case a necessary condition of having warrant to assert p in that way is that p is true. Grasping a proof of a mathematical proposition is a factive way of having warrant to assert it: a necessary condition of grasping a proof of p is that p is true.
Factiveness does not entail indefeasibility. Knowing p is always a factive way of having warrant to assert p; it is almost never an indefeasible way. New evidence can almost always undermine old knowledge (perhaps there is an indefeasible way of having warrant to assert that one exists). On the knowledge account, any way of having warrant to assert something is factive. Thus mathematical propositions also fail to differ from empirical ones in point of factiveness.13
By itself, indefeasibility does not entail factiveness. If warrant to assert p consisted merely in good reason to believe p, then the inhabitants of a universe created six thousand years ago with every appearance of having existed for millions of years might have an indefeasible non-factive warrant to assert that they are not inhabitants of a universe created six thousand years ago with every appearance of having existed for millions of years. The account defended in this chapter guarantees factiveness independently of indefeasibility.
On the showing of this section, mathematical practice is consonant with the knowledge account in a way that generalizes smoothly to practice outside mathematics.
11.7 The Point of Assertion
The knowledge rule is a constitutive rule; it is not a convention. The rule might nevertheless be linked to conventions. Suppose that a language £ assigns to each sentence type s in some domain a proposition £(s). Then it might be a convention in a particular community that in normal contexts one should utter s only if one knows £(s). Such a convention of knowledgeableness in £ might even be part of what it is for £ to be the language of that community. This convention in £ is an obvious variant on the convention of truthfulness in £ used by David Lewis to define what it is for £ to be the language of a community: 'To be truthful in £ is to act in a certain way: to try never to utter any sentences of £ that are not true in £. Thus it is to avoid uttering any sentence of £ unless one believes it to be true in £' (1983: 167, from Lewis 1970). Of course, the account of what it is for £ to be the language of a community must somehow take into account the probability that speech acts other than assertion can be performed in £ (Lewis 1983: 172). The shift from conventions of truthfulness to conventions of knowledgeableness also has repercussions in the methodology of interpretation. The appropriate principle of charity will give high marks to interpretations on which speakers tend to assert what they know, rather than to those on which they tend to assert what is true, or even what is reasonable for them to believe.
It is pointless to ask why the knowledge rule is the rule of assertion. It could not have been otherwise. It is, however, pointful to ask why we have such a speech act as assertion in our repertoire. Could we not have done otherwise? No doubt we need a speech act something like assertion, to communicate beliefs, but could we not have done so just as well by using a speech act whose rule demanded less than knowledge? It would have to permit testimony and inference to enable us to utter new instances on the basis of old ones, just as they do for assertion. But the knowledge rule is not the only rule to underwrite that possibility; the truth rule is another.14
One obvious answer is that we need assertion to transmit knowledge.15 In normal circumstances, when the hearer knows that the speaker asserted p, the speaker has no reputation for unreliability, and so on, a speaker who asserts p thereby puts a hearer in a position to know p if (and only if) the speaker knows p (see Lackey 1999 for some qualifications). That answer is probably right, as far as it goes, but leaves at least two points to be explained. First: why could we not transmit knowledge by means of a speech act whose rule required only (for example) truth? The idea might be that, when successful communication occurs, what is transmitted is what is overt in the assertion of p, and what is overt in the assertion is satisfaction of the rule, so what is transmitted is satisfaction of the rule; thus knowledge is transmitted if and only if it is what the rule requires. However, the relevant notion of overtness is hard to pin down. If the overtness of the satisfaction of the rule put the hearer in a position to know that the rule was satisfied, then, if the rule required truth, the hearer would be in a position to know that the assertion was true, and the truth rule would suffice for the transmission of knowledge after all. Second: it will be asked why the transmission of knowledge is what matters, rather than the transmission of true belief, or reasonable belief, or some other cognitive attitude.
A comparison between knowing and doing gives a clue to a further line of thought. One may think of knowing p as standing to believing p as (intentionally) bringing p about stands to desiring p. If one knows p, then p is true; likewise, if one brings p about, then p is true. But even if p was true and one believed p, it does not follow that one knew p; likewise, even if p was true and one desired p, it does not follow that one brought p about. In each case, the fit between content and world is insufficient because it may have been 'accidental'. Both knowing p and bringing p about are ways of ensuring p; what differs is the direction of fit. If one brings p about, one's actions
(characterized in environment-dependent ways) ensure the truth of p; likewise, if one knows p, one's mental states (characterized in environment-dependent ways) ensure the truth of p (see section
1.4).
Obedience to a command, as ordinarily understood, involves bringing something about; what matters is not simply the fit between content and world, but someone's responsibility for that fit. To issue a command with appropriate authority is to confer a responsibility; to obey a command is to discharge that responsibility.16 The point emerges more distinctly for negative commands, where what is commanded is not itself an intentional action. You shout 'Don't move!'; I try to move, but find myself stricken by paralysis. In one sense I did not obey your command. Although its content was fulfilled, I did not ensure that it was; I did not bring it about. The knowledge account extends the analogy between commanding and asserting. To make an assertion is to confer a responsibility (on oneself) for the truth of its content; to satisfy the rule of assertion, by having the requisite knowledge, is to discharge that responsibility, by epistemically ensuring the truth of the content.17 Our possession of such speech acts is no more surprising than the fact that we have a use for relations of responsibility. 12 Structural Unknowability
12.1 Fitch's Argument
The limits of knowledge on which previous chapters concentrated were extrinsic to the propositions unknown. A tree may be at least n inches tall although no one is in a position to know that it is at least n inches tall, but there is nothing intrinsically unknowable about the proposition that the tree is at least n inches tall. If my visual discrimination were better, or I had appropriate measuring instruments, or the tree were taller, then I should be in a position to know that it is at least n inches tall. The emphasis was on the virtual ubiquity of such extrinsic limits. They are the rough texture of our cognitive life. This chapter explores some limits to knowledge which are intrinsic to the propositions unknown, necessary limits embedded throughout our contingent ignorance.
Mathematics and physics reveal unexpected limits to our knowledge which depend on
Gödelian undecidability, complexity considerations, spatio-temporal limits to the portions of the universe with which we can causally interact, and the like. The limits discussed in this chapter are far more prosaic than those. But they are also more thoroughly intrinsic to the propositions unknown, for they do not depend on our contingent computational limitations or the contingent causal structure of space-time. They arise wherever we are ignorant at all.
The argument for such intrinsic limits was first published by Frederic Fitch (1963), although he attributed it to an anonymous referee in 1945 for a paper which he submitted but never published. The argument was reintroduced into public discussion by Bill Hart and Colin McGinn
(1976), whose attention was also drawn to it by an anonymous referee (see also Hart 1979). The nub of the argument is this: if something is an unknown (but perhaps knowable) truth, then that it is an unknown truth is itself an unknowable truth. Every point of contingent ignorance corresponds to a point of necessary ignorance. The core of the argument has already been used at several places in this book without much discussion, for example when section 11.3 deployed Moorean paradoxes in arguing for the knowledge account of assertion.
The argument is sometimes called 'The Paradox of Unknowability', although why it should be regarded as a paradox is quite unclear. The conclusion that there are unknowable truths is an affront to various philosophical theories, but not to common sense. If proponents (and opponents) of those theories long overlooked a simple counterexample, that is an embarrassment, not a paradox. This chapter primarily concerns the positive lessons of Fitch's argument, not its use to refute philosophical theories, although the prospects for such applications will be mooted from time to time.
We must analyse Fitch's argument in more detail. Let strong verificationism be the insanesounding thesis that every truth is known; in symbols:1
SVER ∀p(p ⊃ Kp)
Let weak verificationism be the sane-sounding thesis that every truth is knowable, in the sense that it is possible for it to be known:
WVER ∀p(p ⊃ ◊Kp)
Obviously, since whatever is can be, strong verificationism entails weak verificationism.
Fitch's argument shows, on very weak assumptions, that weak verificationism entails strong verificationism.
In the initial presentation of the argument, we will read the operators ◊ and K as 'it is possible that' and 'it is known that' respectively, without probing their meaning further. Once the argument has been presented, we will ask how we must understand those phrases to make it valid.
To carry through Fitch's argument, we first argue that nothing can be known to be an unknown truth. In brief, if something is known to be an unknown truth then it is known to be a truth; but, equally, if it is known to be an unknown truth then it is an unknown truth and therefore is not known to be a truth. The argument uses two principles about knowledge: that it is necessarily factive and that it necessarily distributes over conjunction. Nothing can be known without being true:
FACT ∀p□ (Kp ⊃ p)
If a conjunction is known, its conjuncts must be known:
DIST ∀p ∀q □ (K(p & q) ⊃ (Kp & Kq)) Substituting ~Kp for p in FACT gives this special case:
(1) ∀p □ (K~Kp ⊃ ~Kp)
Substituting ~Kp for q in DIST gives this special case:
(2) ∀p □ (K(p & ~Kp) ⊃ (Kp & K~Kp))
Since K~Kp ⊃ ~Kp is inconsistent with Kp & K~Kp, and the consequences of necessary truths by reasoning in propositional logic are themselves necessary, (1) and (2) yield:
(3) ∀p □ ~K(p & ~Kp)
Since necessary truths are those that are not possibly false, (3) is equivalent to:
(4) ∀p ~◊K(p & ~Kp)
We now show that (4) makes weak verificationism collapse into strong verificationism. In brief, if, contrary to strong verificationism, something is an unknown truth, then by (4) it is an unknowable truth that it is an unknown truth, contrary to weak verificationism. More precisely, substituting p & ~Kp for p in WVER gives this special case:
(5) ∀p((p & ~Kp) ⊃ ◊K(p & ~Kp))
Given (4), (5) yields:
(6) ∀p ~(p & ~Kp)
But (6) is equivalent to SVER by elementary reasoning. Thus 'weak' verificationism is as strong as 'strong' verificationism.
Strong verificationism is obviously false. Of course, (4) itself implies that we cannot know of any one proposition that it is a counterexample to strong verificationism, for then we should be in a position to know it to be an unknown truth, which by (4) we cannot do. But we can do the next best thing: we can know of two propositions that one or other of them is an unknown truth; we just cannot know which. For example, either my office contains an even number of books at noon on 11
October 1999 (time t) or it does not. I could find out by counting whether it contains an even number of books at t. But I will not count them; nor will anyone else. As a matter of contingent fact, no one will ever know whether my office contains an even number of books at t. Thus either it is an unknown truth that my office contains an even number of books at t or it is an unknown truth that my office contains an odd number of books at t. Either way, there is an unknown truth; strong verificationism is false. Fitch's argument then shows that either it is an unknowable truth that it is an unknown truth that my office contains an even number of books at t or it is an unknowable truth that it is an unknown truth that my office contains an odd number of books at t. Either way, there is an unknowable truth; weak verificationism is false too.
Although strong verificationism is obviously false and weak verificationism is not obviously false, the two theses are equivalent, given our assumptions.
We can construct similar counterexamples to strong verificationism from Gray's stanza:
Full many a gem of purest ray serene,
The dark unfathom'd caves of ocean bear:
Full many a flower is born to blush unseen,
And waste its sweetness on the desert air.
Each of them corresponds to a counterexample to weak verificationism. Quite generally, each counterexample to strong verificationism corresponds to a counterexample to weak verificationism.
How should we understand the operators ◊ and K in Fitch's argument? The weaker the proposition ◊Kp, the weaker the thesis WVER, so the more significant is its refutation. Since the strength of ◊Kp increases monotonically with the strength of Kp, we seek the weakest interpretations of ◊ and K that validate the argument.
For the step from (3) to (4), ◊ should express a kind of possibility that is dual to the kind of necessity expressed by □; ◊ is equivalent to ~□ ~ and to ~◊~. For FACT and DIST, knowledge should be factive and distribute over conjunction with that kind of necessity. Moreover, for the step from (1) and (2) to (3), that kind of necessity should be preserved by deductions in classical propositional logic. These requirements constrain the relevant kind of necessity hardly at all.
Perhaps it is not a purely logical necessity that knowledge is factive and distributes over conjunction, since the notion of knowledge is not a purely logical one. But it might still have those features as a matter of metaphysical necessity: however things had been, knowledge would still have been factive and distributed over conjunction. We will therefore understand ◊ and □ as 'it is metaphysically possible that' and 'it is metaphysically necessary that' respectively.
We can understand K as 'some being at some time [past, present or future] knows that'.
Since those who believe that there actually is an infinite omniscient being will take SVER to be true on that understanding, they should understand 'being' as tacitly qualified by 'finite'. We must not allow the phrase 'at some time' to act as a tense operator on the content clause following 'that'; it merely binds the time variable in 'knows'. Thus K(it is raining) is evaluated as true with respect to a time t if some being knows at some time t* of rain at t; knowledge at t* of rain at t* is neither necessary nor sufficient.
This is in fact a natural reading of the English sentence 'It was, is, or will be known that it is raining'. On the other reading, K(it is raining) would entail 'It was, is, or will be raining' but not 'It is raining' itself; thus FACT would fail.
On these understandings, Fitch's argument concludes that for some truth p, however things had been, no being would ever have known p. We can also substitute other attitudes for knowledge in the interpretation of K. Any necessarily factive attitude that necessarily distributes over conjunction will do, although we must check that SVER is genuinely implausible on the new interpretation.
Consider, for example, T-conception. One T-conceives p if and only if p is true and one conceives (that is, grasps the proposition) p. T-conception is factive by definition. It necessarily distributes over conjunction because both its conjuncts do; a true conjunction has true conjuncts, and in conceiving the conjunction one conceives the conjuncts. Fitch's argument therefore shows that if all truths are T-conceivable, then all truths are T-conceived. But surely not all truths are Tconceived, for not all truths are conceived; some will never be grasped by anyone. Naturally, one cannot conceive a specific example of a truth which no one will ever conceive. One cannot even do what can be done in the case of knowledge, by listing two or more propositions such that one knows that at least one item on the list is an example. For in listing the propositions in the intended sense, one would conceive all of them. Nevertheless, there are examples of never conceived truths, and we can gesture towards areas in which some of them lie. For example, there are conceivable truths which no one will ever conceive about the state of my office at noon on 11 October 1999. We all have better things to think about. By contraposition, the argument shows that there are truths about the state of my office at that time which can be conceived, but can never be both true and conceived.
Can the argument be generalized to non-factive attitudes? It uses FACT only to derive ~Kp from K~Kp, and could therefore make do with that restricted subcase of factiveness. For example, if one reads K as 'it is rational to believe that', one might hold that although it is sometimes rational to believe a false proposition, if it is rational to believe that it is not rational to believe p then it is not rational to believe p. If what it is rational to believe is closed under conjunction, a counterexample to that principle would involve its being rational to believe a Moore-paradoxical conjunction (p and it is not rational to believe p). But such principles are highly sensitive to the interpretation of
'rational to believe'. For instance, an example in section 10.5 shows that even if p is at least 80 per cent probable on one's evidence, it may still be at least 80 per cent probable on one's evidence that p is not at least 80 per cent probable on one's evidence. Perhaps the required inference goes through on other interpretations of 'rational to believe', on which the argument shows that some truths cannot be rationally believed. Since our concern is primarily with knowledge, we can leave that question open.2
Fitch's argument against weak verificationism employs classical logic. Dummett's wellknown arguments for weak verificationism ('anti-realism') commit the weak verificationist to rejecting classical logic in favour of intuitionistic logic, or something like it. Fitch's argument is not intuitionistically valid. In particular, the inference from (6) to SVER involves the intuitionistically invalid move from ~(p & ~Kp) to p ⊃ Kp. Thus Dummett's weak verificationist is not committed to strong verificationism, although the commitment to (6) may reasonably be regarded as already bad enough. At any rate, the use of Fitch's argument against Dummett's weak verificationist is not dialectically straightforward. Fortunately, section 4.8 identified a flaw in Dummett's reasoning
(there are probably others), and Dummettian anti-realism is in any case not the main topic of this book.3 For present purposes, we assume without argument the validity of classical logic. Our aim here is not to outmanœuvre an anti-realist opponent but to explore limits to knowledge from a classical starting point. The next two sections confront objections to Fitch's argument within a classical framework. The final sections discuss modifications of weak verificationism designed to finesse the argument.
12.2 Distribution Over Conjunction
Fitch's argument assumes that knowing the conjuncts is necessary for knowing a conjunction (DIST). Once DIST is dropped, the remaining background assumptions do not permit the reductio ad absurdum of weak verificationism, the derivation of SVER from FACT and WVER. We can clarify the role of DIST in Fitch's argument by giving K an unintended reinterpretation. We introduce a new sentence constant c into the language and consider possible worlds models in which, for every formula A, KA is interpreted as A & (c &
~◊(A & c)). All the other operators are treated as usual. In particular, ◊A is true at a world w if and only if A is true at some world to which w bears the accessibility relation in the model. FACT is trivially true at all worlds in all such models, for KA is interpreted as though it had A as a conjunct.
WVER is also true at all worlds in all such models, provided that ◊A is true at a world whenever A
is, which we can guarantee by making accessibility reflexive. For suppose that p is true at a world w. There are just two cases to consider. If ◊(p & c) is true at w, then p & c is true at some world x accessible from w, so p & (c & ~◊(p & c)) is true at x, so Kp is interpreted as true at x, so ◊Kp is interpreted as true at w. If ◊(p & c) is false at w, then p & (c & ~◊(p & c)) is true at w, so Kp is interpreted as true at w, so ◊Kp is interpreted as true at w, since accessibility is reflexive. Either way, p ⊃ ◊Kp is interpreted as true at w, as WVER requires. But we can easily construct such models in which SVER fails. For example, if p is necessarily true at a world w and c is contingently false at w, then Kp is interpreted as false at w. DIST fails because K(p & ~c) is interpreted as true at w. Any reasonable modal logic for the interpretation of ◊ and □ as metaphysical possibility and necessity respectively has such models. In particular, there are such models of the strong modal logic S5 augmented with propositional quantifiers like those used in the argument (see Fine 1970
and Kaplan 1970). Thus SVER cannot be derived even from the necessitation of WVER and FACT
in propositionally quantified S5, let alone the vastly weaker modal logics that suffice for Fitch's argument. Of course, we can easily point to differences between the deviant interpretation of K and the intended one. The point is simply that FACT by itself provides insufficient information about K
to enable us to make the connection from WVER to SVER.4 Something more is needed, such as
DIST.
Is there any reason to doubt the distribution principle DIST? Many propositional attitudes distribute over conjunction. In conceiving a conjunction, for example, one conceives its conjuncts; in asserting a conjunction, one presumably asserts its conjuncts. But not all attitudes distribute. I
disbelieve the conjunction that Edinburgh is in Scotland and Scotland is in Asia because I
disbelieve the latter conjunct, but I do not disbelieve the former. However, that example leaves open the possibility that all positive propositional attitudes distribute over conjunction, in a sense of 'positive'
that would need to be made precise.5
If a positive propositional attitude is closed under at least some forms of logical consequence beyond logical equivalence, we may expect it to be closed under a very intimate one such as the &-elimination inference from p & q to p and to q. To investigate whether it distributes over conjunction would then be to test the null hypothesis that it satisfies no form of deductive closure at all, or at least none involving inferences between logically inequivalent formulas. The null hypothesis in turn exemplifies a liberal view of the extent to which rationality constrains the attribution of propositional attitudes (of course, it is not suggested that closure under logical consequence is even a rational ideal for negative propositional attitudes, such as disbelief). Our present interest is in a specific positive propositional attitude, knowing.
Robert Stalnaker has shown that there is much more to be said than we might have expected for the claim that both knowledge and belief are closed under logical consequence (1984: 71-99 and
1999: 241-73). If the claim were correct, a fortiori DIST would hold. But if DIST depends on the deductive closure of knowledge, its status is shaky indeed, for Stalnaker's highly qualified considerations do not destroy the plausibility of the original case against closure. Let us retain the common-sense idea that, in logic and mathematics, we may understand a conjecture p without knowing p until we prove p, even though all along it was in fact a logical consequence of what we knew. If we do not know all the logical consequences of what we know, we do not even know all the obvious logical consequences of what we know, for what we know is linked to some of what we do not by chains of propositions each member of which is an obvious logical consequence of its predecessors.6 Thus to deny DIST is not to deny that a conjunction obviously entails its conjuncts.
Our question is whether a conjunction has some more intimate relation to its conjuncts under which knowledge is closed, even though it is not closed under obvious logical consequence.
As usual, we assume that knowledge entails belief. Then two quite different kinds of putative counterexample might be offered against the claim that knowledge distributes over conjunction. Suppose that one knows p & q without knowing p. Then one believes p & q. One either believes p or fails to believe p. If one fails to believe p, that by itself accounts for one's failure to know p. Call such a case irrational. It would also be a counterexample to the principle that belief distributes over conjunction. On the other hand, if one believes p, then one's belief is true, since p & q is true; one's failure to know p would have to be accounted for in some other way. Call such a case rational.
With respect to the relevant propositions it would not violate the distribution of belief over conjunction.
Formally, the distribution of belief over conjunction is neither necessary nor sufficient for the distribution of knowledge over conjunction. It is unnecessary, because belief in the conjunct might somehow follow from knowledge of the conjunction, although not from mere belief in it; perhaps failure to note certain immediate consequences blocks knowledge but not belief. Thus knowledge might distribute while belief failed to do so. Conversely, the distribution of belief is insufficient for the distribution of knowledge, since it rules out irrational counterexamples to the latter principle but not rational ones. Are there rational or irrational counterexamples?
Robert Nozick's analysis of knowledge implies the possibility of rational counterexamples to the distribution of knowledge over conjunction. It does not imply the possibility of counterexamples to the distribution of belief. According to Nozick, knowledge is truth-tracking belief. On the simple version of his analysis, before methods complicate matters, one knows p if and only if (1) p is true;
(2) one believes p; (3) if p were false one would not believe p; (4) if p were true but things were slightly different one would still believe p. On this analysis, belief in a conjunction may track the truth while belief in a conjunct does not because '[w]e can satisfy condition 3 for a conjunction by satisfying it for its most vulnerable conjunct, the one that would be false if the conjunction were false; it does not follow that we satisfy condition 3 for the other conjunct as well' (1981: 228).7
Nozick sometimes knows that he is in Emerson Hall and not floating in an Emerson-Hall-simulator on Alpha Centauri, for if the conjunction had been false it would have been so because he was somewhere mundane other than Emerson Hall, not because he was floating in an Emerson-Hallsimulator on Alpha Centauri, and he would then not have believed the conjunction. However, at those times he does not know that he is not floating in an Emerson-Hall-simulator on Alpha
Centauri, for if that conjunct had been false he would still have believed it. All of this is quite consistent with the distribution of belief over conjunction—although if one believes that one knows p & q, that one does not know p and that one should believe only what one knows, one may try to believe p & q without believing p.
We saw reason in Chapter 7 to reject Nozick's account of knowledge, even when it is complicated by reference to methods. Nevertheless, we can consider a putative counterexample of
Nozick's kind to an instance of DIST of the sort used in Fitch's argument, to decide whether the case has any independent plausibility. A climber reaches the summit of a mountain at 12.03, but does not look at his watch until much later; nobody else is around. Let p be the proposition that he did not reach the summit between 12.01 and 12.02. He is convinced of p on probabilistic grounds, but neither he nor anyone else will ever know p. If p had been false, he would still have believed p on the same probabilistic grounds. Indeed, he knows that no one will ever know p. He truly believes the conjunction p & ~Kp, and his belief tracks the truth, for ~Kp is the more vulnerable conjunct.
He could have looked at his watch more easily than he could have reached the summit earlier. If p & ~Kp had been false, ~Kp would have been false, so Kp would have been true; he would then have believed Kp and would not have believed p & ~Kp; thus condition 3 is satisfied. Moreover, if p & ~Kp had been true while things were slightly different, he would still have believed p & ~Kp; thus condition 4 is satisfied. On Nozick's account, K(p & ~Kp) is true and Kp false. But this is not a convincing example of knowing a conjunction without knowing the conjuncts, for, intuitively, the merely probabilistic grounds on which the climber believes p prevent him from knowing p & ~Kp as well as from knowing p. The intuition is general: in such cases one has inadequate grounds for one's true belief in a conjunction only if one has inadequate grounds for one's true belief in at least one of the conjuncts. The conflict between Nozick's analysis of knowledge and the distribution principle is a problem for Nozick's analysis, not for distribution.
What of irrational counterexamples to distribution? We can easily find cases in which someone would assent to a conjunction if queried but would have dissented from (and not assented to) one conjunct if queried on that alone. For example, someone might answer 'Yes' if asked 'Is it true that a city other than Rome was once the capital of Italy and Turin was the capital of Italy from 1861 to 1864?' although he would have answered 'No' if asked 'Is it true that a city other than Rome was once the capital of Italy?'. He might have forgotten that Turin was the capital of Italy from 1861 to 1864, and need mention of it to jog his memory. If a disposition to heartfelt assent on being asked whether p is true is sufficient for believing p, and a disposition to heart-felt dissent in those circumstances is incompatible with believing p, then our man believes that a city other than Rome was once the capital of Italy and Turin was the capital of Italy from
1861 to 1864 although he does not believe that a city other than Rome was once the capital of Italy.
Moreover, he knows the conjunction, having learnt it at school from a reliable teacher in the usual way. Yet he does not know the conjunct, for he does not believe it. But the case is not terribly convincing, for one's speech dispositions are an inadequate test of belief. Arguably, our man does have a non-occurrent belief that a city other than Rome was once the capital of Italy, which sometimes slips his conscious mind. As for occurrent belief, when he occurrently believes the conjunction, he occurrently believes the conjuncts.
A subtle challenge to distribution arises indirectly from analogies between the semantic paradoxes and some epistemic paradoxes (Kaplan and Montague 1960, Burge 1978 and 1984,
Koons 1992). Here is an example of such a paradox. I say at time t just 'I am not expressing knowledge at t'. If I am expressing knowledge at t, then I am expressing knowledge that I am not expressing knowledge at t; since knowledge is factive, I am therefore not expressing knowledge at t.
Thus, given the circumstances, the supposition that I am expressing knowledge at t is self-defeating.
Therefore, I am not expressing knowledge at t. Since I am aware at t of this reasoning, I know at t that I am not expressing knowledge at t, so in saying 'I am not expressing knowledge at t' at t, I
express knowledge at t after all. That is a contradiction. Such reasoning obviously bears a close resemblance to the Liar Paradox. Many diagnoses of the fallacy have been offered. Suppose that one is sympathetic to a hierarchical solution to the Liar, on which each level i of a hierarchy corresponds to a truth predicate 'true i ', where something is true i only if it contains no occurrence of 'true j ' for any level j not lower than i in the hierarchy, and legitimate occurrences of the unsubscripted 'true' in ordinary language are interpreted as implicitly indexed to a level in the hierarchy. Since such an approach can be shown to block the paradoxical reasoning in the Liar, one might adopt a similar approach to the epistemic paradoxes. Legitimate occurrences of the unsubscripted 'know' in ordinary language would be interpreted as implicitly indexed to a level in the hierarchy. I could then be coherently described as knowing i+1 (but not knowing i ) at t that I am not expressing knowledge i at t. We may assume that for each level i, knowledge i is factive and distributes over conjunction; FACT and DIST hold when K in them is subscripted uniformly. We may also assume that knowledge i entails knowledge j whenever i ≤ j; the hierarchy is cumulative. The weak verificationist principle is read as a schema A ⊃ ◊KA, in any instance of which K is assigned the least subscript higher than any subscript in A. The result in the special case needed for Fitch's argument would be of the form (p & ~K i p) ⊃ ◊K i+1 (p & ~K i p). By FACT and
DIST for K i+1 we can derive (p & ~K i p) ⊃ ◊(K i+1 p & ~K i p), but since K i+1 p & ~K i p is not a contradiction, we cannot proceed to deny p & ~K i p. Thus an instance K(A & B) ⊃ (KA & KB) of the original DIST can fail when we assign each occurrence of K the least subscript higher than any subscript in the sentence to which it is applied, since K will be assigned a lower subscript in KA
than in K(A & B) if there are higher subscripts in B than in A. Exactly that happens when B is
~KA, as in Fitch's argument.
A difficulty emerges for the hierarchical approach when we ask how Ki+1p & ~K i p could be true. The answer would be easy if the subscript i occurred in p, for then K would need a higher subscript than i to be correctly applied to p. But in the crucial cases, no such subscript occurs in p.
For example, p may say that the number of books in my office at noon on 11 October is even. In what sense could that be known at level i+1 but not at level i? Perhaps a claim could be known at level i+1 but not at level i if the route to knowing it involved claims about knowledge i , even though the target claim did not, but it would be bizarre if such contrived cases were crucial to a defence of weak verificationism. They would at any rate not serve a defence based on the
Dummettian meaning-theoretic idea that truth implies the possibility of canonical verification, for one canonically verifies a conjunction by canonically verifying its conjuncts, and canonically verifying that the number of books in my office at noon on 11 October is even would consist in something like counting them, not in verifying the steps of an indirect argument involving claims about knowledge i . Thus K i+1 p & ~K i p is an implausible combination.
The hierarchical objection to Fitch's argument faces another problem. We seem able to grasp the idea that p is totally unknown, in a sense which entails that p is unknown i for each level i, but which does not entail that p is untrue. If so, we can simply adapt Fitch's argument by considering the proposition that p is a totally unknown truth, since that proposition cannot be known i for any level i. Naturally, such quantification over levels must be handled with great care, but we should not allow our precautions to blind us to the ready intelligibility of the supposition that it is a totally unknown truth that the number of books in my office at noon on 11 October 1999 is even.
Although it is far from obvious how to solve the epistemic paradoxes, it is most unlikely that an adequate solution would involve restrictions draconian enough to block every form of Fitch's argument.8
Can we argue that knowledge does distribute over conjunction? It would scarcely be relevant to argue that one will always infer the conjuncts from the conjunction, for, since making an inference takes time, one might still violate distributivity before completing the inference. If knowledge of the conjunction causes knowledge of the conjuncts, and the cause is not simultaneous with the effect, then for an intermediate period one would know the conjunction without knowing the conjuncts; if no one else had the relevant knowledge, that period would be a counterexample to distribution. The members of a rather dim community may take several seconds to notice the entailment from a given conjunction to one of its conjuncts. Moreover, there is no form of inference that one can be relied on to carry out exceptionlessly. Distraction or sudden death is always liable to intervene. The required premise is precisely not that deductive inference is a way of extending knowledge. Rather, what would need to be shown is that knowledge of a conjunction is already knowledge of its conjuncts.
It might be suggested that one can know a conjunction only by inferring it from its conjuncts, and that the output of the inference is knowledge only if the inputs are, so that in order to know a conjunction one must already know its conjuncts. Perhaps inference from the premises p and q is in some sense the canonical way of coming to know the conjunction p & q, since the meaning of & is so closely tied to the validity of the &-elimination rule. Nevertheless, there are other ways of knowing p & q: from testimony to the conjunction, or by inference from the premises
(p & q) & r and ~r, and so on. Even so, &-elimination has a rather special status. It may be brought out by a comparison with the equally canonical V-introduction inference to the disjunction pVq from the disjunct p or from the disjunct q. Although the validity of V-introduction is closely tied to the meaning of V, a perfect logician who knows p may lack the empirical concepts to grasp (understand) the other disjunct q.
Since knowing a proposition involves grasping it, and grasping a complex proposition involves grasping its constituents, such a logician is in no position to grasp pVq, and therefore does not know pVq. In contrast, those who know a conjunction grasp its conjuncts, for they grasp the conjunction.9
Moreover, they grasp the sense of its composition: they grasp the conjuncts as consequences of the conjunction. If they know the conjunction they grasp it, and in doing so grasp its conjuncts as its consequences. There is no obstacle here to the idea that knowing a conjunction constitutes knowing its conjuncts, just as, in mathematics, we may count a proof of a conjunction as a proof of its conjuncts, so that if p & q is proved then p is proved, not just provable.
Someone might know a conjunction but believe one of its conjuncts for independent and bad reasons. The latter belief would not constitute knowledge. Nevertheless, the case is no counterexample to what has just been said. For the person may be considered as having two beliefs in the conjunct, one constituted by the knowledge of (and therefore belief in) the conjunction, the other dependent on the bad reasons. The former counts as knowledge; the latter does not.
We have no well-confirmed analysis of knowledge to use as an effective test of the claim that knowledge distributes over conjunction. Indeed, according to the account developed in Chapter
1, knowledge has no analysis of the traditional kind. That account is consistent with the distribution principle but does not entail it. Although DIST is highly plausible, and no objection to it has proved persuasive, the case for it is not quite as decisive as we might hope. It is therefore prudent to ask whether we can modify Fitch's argument so as to avoid commitment to distribution. Since SVER is not derivable from WVER and FACT without DIST in any reasonable modal logic (such as propositionally quantified S5), we must either strengthen the premises or weaken the conclusion.
Both strategies look promising.
We can strengthen weak verificationism to moderately weak verificationism, defined as the principle that a conjunction is true only if it is possible that both conjuncts are known:
MWVER ∀p ∀q((p & q) ⊃ ◊(Kp & Kq)) Given a true conjunction, weak verificationism entails that both conjuncts are possibly known (◊Kp & ◊Kq); moderately weak verificationism adds the compossibility of those possibilities. It is hard to guess what argument someone might have for weak verificationism that would not also be an argument for moderately weak verificationism. For example, Dummett and others motivate WVER by a theory of meaning in which the key concept is canonical verification in place of truth. Rather than saying that p & q is true if and only if p is true and q is true, the theory will say that p & q is canonically verified if and only if p is canonically verified and q is canonically verified. Such a verificationist will argue for WVER by arguing on meaning-theoretic grounds that truth entails the possibility of canonical verification, conceived as a species of knowledge; but then, since canonical verification distributes over conjunction, the truth of a conjunction entails the possibility of canonically verifying every conjunct together, as in MWVER. Now as a special case of MWVER we have ∀p((p & ~Kp) ⊃ ◊(Kp & K~Kp)); but FACT and the background modal logic yield ∀p ~◊(Kp & K~Kp), so we can derive SVER as before. Thus moderately weak verificationism entails absurdly strong verificationism even in the absence of DIST. Moderately weak verificationism is false. A conjunction may be true even if its conjuncts cannot be known together.
Alternatively, we can weaken strong verificationism to moderately strong verificationism, defined as the principle that a proposition is true only if it is a conjunct of a known conjunction:
MSVER ∀p(p ⊃ ∃qK(p & q)) We can derive moderately strong verificationism from the original weak verificationism even in the absence of DIST. For if p is defined as completely unknown if and only if it is not a conjunct of any known conjunction (p & ~∃qK(p & q)), then WVER entails that p is a completely unknown truth only if it can be known that p is a completely unknown truth. But nothing can be known to be a completely unknown truth (∀p ~◊K(p & ~∃qK(p & q))), for, necessarily, something is known to be a completely unknown truth only if it is not completely unknown. Therefore, given
WVER, no truth is completely unknown, a principle equivalent to MSVER. The formal version of this reasoning uses FACT and a background modal logic but not DIST. Now moderately strong verificationism is almost as absurd as strong verificationism. For example, no one will ever know a conjunction of which it is a conjunct that the number of books in my office at noon on 11 October
1999 is even, and no one will ever know a conjunction of which it is a conjunct that the number of books in my office then is odd. Since one of those propositions about the number of books is true, one of them is a completely unknown truth. Thus we can argue without appeal to DIST that even the original weak verificationism is false.
Dorothy Edgington (personal communication) has pointed out another way of modifying
Fitch's argument to avoid commitment to DIST. His argument still goes through if we weaken DIST
to its consequence ∀p ∀q(◊K(p & q) ⊃ ◊(Kp & Kq)). But what justifies the latter if not DIST? If the idea is that someone who knows the conjunction could have inferred the conjuncts, its natural expression is at most ∀p ∀q □ (K(p & q) ⊃ ◊(Kp & Kq)), which yields ∀p ∀q(◊K(p & q) ⊃ ◊◊(Kp
& Kq)) and its special case ∀p(◊K(p & ~Kp) ⊃ ◊◊(Kp & K~Kp)) given just the weak principles of modal logic used in the original argument: that necessity is closed under logical consequence and that possibility is the dual of necessity. If we slightly strengthen FACT by substituting □ □ for □ we can derive ∀p ~◊◊(Kp & K~Kp) using the same principles of modal logic, and the argument then proceeds as before to collapse WVER into SVER. Although Edgington's weakening of DIST deals plausibly with irrational counterexamples to distribution in which one accidentally fails to notice the consequences of one's knowledge, it scarcely addresses rational counterexamples, in which one has already inferred the conjuncts but fails to know them for some other reason. The earlier modifications of Fitch's argument respond more pertinently to such cases.
Appendix 6 discusses the earlier modifications of Fitch's argument in a more formal context.
For present purposes, the upshot is that rejecting the distribution principle leaves the overall philosophical position unchanged. It is no way out for the verificationist.
12.3 Quantification into Sentence Position
As formulated in section 12.1, Fitch's argument involves quantification into sentence position with the propositional variables p and q. When (1) is derived from FACT and (2) from
DIST, the complex formula ~Kp is substituted for the universally quantified propositional variables within the scope of the modal operator. Such substitutions may appear problematic.
Consider a putative analogy: the inference from 'For every natural number n, it is not necessary that n is the number of the planets' to 'It is not necessary that the number of the planets is the number of the planets', which apparently involves the substitution of the definite description 'the number of the planets' for the universally quantified variable n. Let us assign all the definite descriptions narrow scope, so that the premise is true if and only if for every natural number n, in some possible world there are not exactly n planets. Thus the premise is indeed true, for it is contingent how many planets there are. But the conclusion is false, for in every possible world there are exactly as many planets as there are planets. Consequently, the inference is invalid. A common diagnosis is that the definite description 'the number of the planets' is not a rigid designator; it designates different numbers with respect to different possible worlds. The moral is then drawn that the rule of universal instantiation does not permit the substitution of non-rigid designators for variables within the scope of modal operators. Since variables are interpreted rigidly, whatever is substituted for them must also be interpreted rigidly, if universal instantiation is to be valid.
We might expect a corresponding restriction to apply to the rule of universal instantiation for quantifiers into sentence position. Then ~Kp could be substituted for the propositional variables in Fitch's argument only if ~Kp counted as a rigid designator in whatever sense is appropriate to sentences. No check was made to see that ~Kp satisfied such a restriction. This has been regarded as a crucial flaw in Fitch's argument (Kvanvig 1995).
To make sense of the question whether ~Kp is a rigid designator, we must understand what sentences designate with respect to worlds. A suggestion inspired by Frege is that a sentence designates its truth-value at a world with respect to that world. But then a sentence counts as a rigid designator only if it has the same truth-value with respect to every world, which drastically restricts the class of rigidly designating sentences. It certainly excludes ~Kp in the cases of interest, since it is supposed to be contingent whether p is known; for example, it is contingent whether it is known that the number of books in my office at time t is even. But that interpretation is far too restrictive.
Since the restriction on universal instantiation is needed only if propositional variables are rigid designators, and the objection assumes that the restriction is needed, it presumably counts the formula ∀p(□ p & □~p) as valid. Propositional quantification into modal contexts is not worth having at that price. Moreover, we surely have an understanding of the formula ∀p(□ p & □ ~p) on which it is falsified by contingency.
A more promising suggestion is to treat sentences as designating propositions with respect to worlds. Thus a sentence is a rigid designator if it designates the same proposition with respect to every world, even if that proposition varies in truth-value from world to world. The question is now: why should one doubt that a sentence is rigid? In particular, ~Kp seems to be as rigid as the propositional variable p; with respect to each world it designates the proposition that the proposition p is not known.
The formula ~Kp denies that some being at some time knows p. Someone might think that the designation of the quantifiers 'some being' and 'some time' with respect to a world depends on what beings and times there are in that world; if the designation of the quantifier is a component of the proposition designated by the whole formula, and it is contingent what beings or times there are, then the formula will designate different propositions with respect to different worlds. Kvanvig
(1995) regards such non-rigidity as a kind of indexicality, like the referential context-dependence of
'I', but that is a confusion. In the terminology of Kaplan (1989), indexicality is variation in reference
(designation) with respect to the context in which the expression is uttered, whereas non-rigidity is variation in reference with respect to the circumstance with respect to which it is evaluated. The indexicals 'I' and 'me' are rigid designators; when uttered by a given speaker, they rigidly designate that speaker. For example, although 'James Mill fathered me' was true as uttered by John Stuart
Mill, that is irrelevant to the truth-value of 'James Mill could have fathered me' as uttered by Harriet
Taylor. In evaluating her supposed utterance, we take 'me' rigidly to designate her, and ask whether in any (possible) circumstances James Mill fathered her. We do not consider contexts in which 'me'
designates someone other than Harriet Taylor. Similarly, contextual variation in the reference of
~Kp is irrelevant to present concerns. What matters is whether ~Kp, as uttered in a fixed context, designates different propositions with respect to different circumstances (possible worlds).
The comparison with non-rigid definite descriptions does not help the suggestion that ~Kp is non-rigid in the relevant sense. Intuitively, a sentence like 'The number of the planets is less than fifty', as uttered in this context with the definite description understood non-rigidly, designates the same proposition with respect to all circumstances. The variation in the designation of the definite description does not constitute variation in the proposition expressed by a sentence containing it.
Indeed, the former variation is best explained by the assumption that the description contributes the same property with respect to all circumstances, coupled with the assumption that different items have that property in different circumstances. If we follow the Russellian tradition and analyse the definite description as a quantifier, then what is rigid is a quantifier—precisely the category of constituent that is supposed to be non-rigid on Kvanvig's proposal. On the Russellian view, the rule of universal instantiation does not permit the substitution of definite descriptions for individual variables (as in the problematic argument about the number of the planets) for the simple reason that definite descriptions are not singular terms.
We do not expect variation in the extension of 'dog', as uttered in a fixed context, with respect to different circumstances of evaluation to constitute variation in the proposition expressed by the sentence 'Fido is a dog'; why should it constitute variation in the proposition expressed by the sentence 'Some dogs bark'? Variation in the extensions of constituent terms of a proposition without variation in the proposition itself is just what is needed for the proposition to have its truth-value contingently.
We have no grounds to suppose that a sentence, as uttered in a fixed context, can designate different propositions with respect to different circumstances of evaluation. The idea that it can seems to confuse expression with evaluation. What a sentence expresses is conceptually prior to the procedure of evaluation, and not relative to a circumstance of evaluation at all.
Kvanvig's proposal assumes that it is contingent what beings or times there are, but threatens our ability to express that very proposition. For suppose that the actual Fs are exactly a 1 ,. . . , a n .
If the propositional constituents actually expressed by the F-restricted quantifiers ∃F and ∀F were tied to a 1 ,. . . , a n in the way proposed, then the proposition actually expressed by the sentence
∃Fx1…∃Fxn((x1 = a1 &…& xn = an)) & ∀Fy (y = a1 V…V y = an))
('a 1 , . . . , a n are F and every F is one of them') should be a necessary truth. Consequently, we should expect the proposition actually expressed by its necessitation to be true, and the formula
◊~∃Fx1…∃Fxn((x1 = a1 &…& xn = an)) & ∀Fy (y = a1 V…V y = an))
to express a false proposition. But if it is contingent what Fs there are, then the latter sentence should have a true reading. Another kind of quantification appears to be needed to provide that reading.
Kvanvig allows that we could introduce unrestricted rigid quantification over all possible beings and times, but supposes that this interpretation of K would trivialize Fitch's argument by making 'strong' verificationism self-evidently as weak as weak verificationism. That is, he supposes that SVER, read as 'Every proposition, if true, is known at some possible time by some possible being', says no more than WVER, read as 'Every proposition, if true, could be known at some time by some being'. But that is a mistake. Although 'time' and 'being' occur within the scope of 'possible'
in the reading of SVER, 'known' does not. For SVER to be true in the actual world, every truth in the actual world must be known in the actual world at some possible time by some possible being. Since actual knowing happens at an actual time by an actual subject, the possibilist liberalization of the quantifiers makes no substantive difference to what the actual truth of SVER requires. Thus SVER is still absurd, and Fitch's argument succeeds as a reductio ad absurdum of WVER. Kvanvig's mistake is like that of confusing
'I am eating something that could have been a cake' with 'I could have been eating a cake'; the first but not the second entails that I am eating. Similarly, even read with possibilist quantifiers, SVER
but not WVER entails that every truth is known (not necessarily now).10
The use of universal instantiation into sentence position is harmless in Fitch's argument.
12.4 Unanswerable Questions
Fitch's argument shows that if there are unknown truths then there are unknowable truths.
As Joseph Melia (1991) points out, it does not show that if there are unanswered questions then there are unanswerable questions. More precisely, it does not show that if for some proposition p it is unknown whether p is true then for some proposition p it is unknowable whether p is true. In particular, if p is an unknown truth then it is unknowable that p is an unknown truth, but it does not follow that it is unknowable whether p is an unknown truth. For that it is an unknowable truth that p is an unknown truth does not imply the metaphysical impossibility of a situation in which p is false and even known to be false, and thereby known not to be an unknown truth. Equally, that it is an unknowable truth that p is an unknown truth does not imply the metaphysical impossibility of a situation in which p is known to be true, and even known to be known to be true, and thereby known not to be an unknown truth. In situations of both kinds, it is known whether p is an unknown truth. Indeed, Fitch's argument does not show the impossibility of omniscience: a situation s such that, for every proposition p, it is known in s whether p is true (in s as opposed to actuality). The world might take an especially simple form in s, rendering it easier to know; naturally, the cognitive capacities of beings in s would also have to be far more extensive than in actuality. The possibility of omniscience would entail that, for every proposition p, it can be known whether p is true in this weak sense:
WDEC ∀p◊(Kp V K~ p)
If WDEC is false, the reasons are different from those explored in this chapter.
Although Fitch's argument does not refute WDEC, it does not follow that we have reason to believe WDEC. In particular, the anti-realist arguments advanced by Michael Dummett, Crispin
Wright, and others for the weak verificationist thesis WVER cannot be reinterpreted as arguments merely for the weak decidability thesis WDEC. For the point of those arguments is to identify a difficulty in the supposition that speakers' use of a language sometimes associates a sentence with a truth-condition that can obtain even when they have no disposition to recognize that it obtains. This supposed difficulty is in no way met by the concession that, in some circumstances in which the truth-condition does not obtain, speakers recognize that it does not obtain. For that does not explain why the sentence expresses a truth-condition which does obtain unrecognizably in other circumstances. The anti-realist arguments in question support something like WVER if they support anything at all. If they are not sound arguments for WVER, they are not sound arguments for
WDEC either. This is a recurrent problem for responses on behalf of anti-realism to Fitch's argument which modify WVER: they fail to show that anti-realist arguments for WVER are better reinterpreted as arguments for the modified thesis.
12.5 Trans-World Knowability
We have examined objections to the soundness of Fitch's argument, and found them defective. Henceforth, we will assume that Fitch's argument is sound. There are unknowable truths in the sense of the formula ∀p(p & ~◊Kp). In this final section we examine attempts to formulate a different sense in which all truths are knowable, at least for all Fitch's argument shows, and thereby to mitigate its effect. The upshot will be that the alternative sense is a rather trivial one. But it is not obviously trivial.
The picture naturally associated with the claim that all truths are knowable is that if a truth about some subject matter is unknown, then that epistemic position could be different without any difference in the subject matter itself. Fitch's argument reminds us that we cannot always cleanly separate the unknowing from the unknown in that way, because the epistemic position may be part of the subject matter. Knowing can make a difference to the unknown.
Nevertheless, one might object, a difference in the epistemic position makes no difference to how the subject matter was in the original world in which it was unknown, as opposed to the world in which the epistemic position is different. In particular, if p is true in this actual world, why should it not be known in some non-actual world w that p is true in this actual world, rather than in w? If we read the operator A as 'in this actual world' or 'actually', we can formulate that idea thus:
WAVER ∀p(A p ⊃ ◊KA p)
WAVER is in effect the restriction of WVER to instances with the initial operator A. In compensation for the loss of WVER, WAVER claims to provide for each actual truth p a corresponding knowable actual truth A p. Moreover, one can actually know a priori that p is equivalent to A p; sentences of the form 'P if and only if in this actual world P' (with their present meaning) are guaranteed not to express untrue propositions. Of course, in the hypothetical world in which A p is known, its actual equivalence to p may not be known (a priori or a posteriori), otherwise p could be known too in that world, WAVER would yield WVER and Fitch's argument would apply. The phrase 'in this actual world' as uttered in a counterfactual world with its current meaning refers to that counterfactual world, not to this actual one. Only as uttered in this actual world does the sentence 'In this actual world P' expresses the proposition that in this actual world P.
But when we actually say 'Someone could have known that in this actual world P', we are using 'in this actual' in this actual world to refer to it, not to a counterfactual world.
Dorothy Edgington (1985) and, less clearly, George Schlesinger (1985: 103-6) proposed just such a modification of weak verificationism in response to Fitch's argument. Edgington generalizes
WAVER from the actual world to all possible worlds within a framework of two-dimensional modal logic by prefixing an operator read 'Fixedly', which functions like a necessity operator except that in effect it universally quantifies over worlds of utterance rather than worlds of evaluation.
More recently, Wlodek Rabinowicz and Krister Segerberg (1994) have worked out the technical details involved in interpreting WAVER when the knowledge operator K also has its semantics given in terms of possible worlds.
If we try to apply Fitch's argument to WAVER by making the critical substitution of p &
~Kp for p, FACT and DIST get us as far as A(p & ~Kp) ⊃ ◊(KA p & A~Kp), but there is no obvious absurdity in the consequent, for in some other possible world it may be known that p is true in this actual world, and still be true that in this actual world p is not known. Edgington compares 'actually' to indexicals such as 'I' and 'now'. Other people may know that p is true and I do not know p, although of course they must express their knowledge by saying something like 'p is true and he does not know p', not by saying 'p is true and I do not know p'. Similarly, at future times it may be known that p is true and not known now, although of course one will then have to express that knowledge by saying something like 'p is true and p was not known then', not by saying 'p is true and p is not known now'. Fitch's argument draws no disturbing consequences from WAVER.
WAVER can be strengthened to a biconditional, for its converse is uncontentious. By
FACT, ◊KA p yields ◊A p; the actual truth of ◊A p requires the truth of A p at some possible world; but since the semantic rule for the operator A evaluates A p as true with respect to any world if and only if p is evaluated as true with respect to the actual world, that requires the actual truth of p and of A p. Thus WAVER yields:
WAVER+ ∀p(A p ≡ ◊KA p)
WAVER+ may encourage those verificationists who identify truth with knowability, and who therefore require knowability to be sufficient as well as necessary for truth. WVER, by contrast, resists strengthening to a biconditional. For example, suppose that I toss a coin, it comes up heads, and I know that it did. Nevertheless, it could have come up tails, and if it had, I would have known that it had. Thus it could have been known that the coin came up tails; in that sense, it is knowable that it came up tails—even though it did not come up tails.11 This is a further illustration of the failure in WVER to keep fixed how things are with the subject matter while varying the epistemic position. A verificationist might therefore suspect that the complex operator
◊KA comes closer to the intended sense of 'it is knowable that' than does ◊K alone.
A curious feature of WAVER and WAVER+ is that they concern knowledge only of necessary truths. Just as the semantics of A validates ◊A p ⊃ A p, so it validates A p ⊃ □ A p. How things are in this actual world is not contingent; what is contingent is whether this actual world obtains. Fitch's argument reveals a limit to possible knowledge of contingent truths; we may wonder how far its effect is mitigated by possible knowledge of necessary truths. A deeper point arises. As already noted, counterfactual knowledge of the actual truth of p cannot be counterfactually expressed in words such as 'p is actually true', for counterfactual uses of
'actually' do not refer to the actual world, just as your use of 'I' does not refer to me and past or future uses of 'now' do not refer to now. But then how could knowledge of the actual truth of p be counterfactually expressed? If this actual world had not obtained, how could anyone have referred to it? If counterfactual knowers could not refer to this actual world, they could not think about it; if they could not think about it, how could they know that p is true in it?12
In the case of the first person, if you know that I am sitting, then although you cannot express your knowledge by saying 'I am sitting', you can express it by saying 'You are sitting' to me, or by saying 'He is sitting' or 'Williamson is sitting' to someone else. Perhaps you associate 'you',
'he', and 'Williamson' with modes of presentation of me different from the mode of presentation of me that I associate with 'I', but even without the latter mode of presentation of me you can know that I am sitting. Your reference to me typically depends on a causal connection between you and me, mediated by perception and perhaps testimony. Counterfactual knowers cannot refer like that to this actual world, for they are not causally connected to it. One cannot perceive a possible world other than one's own, or receive testimony from it. Similarly, in the case of tense, if on future days we know that it rained today (31 October 1999), although we cannot express our knowledge by saying 'It rained today', we can express it by saying 'It rained yesterday' tomorrow, or by saying 'It rained then' with a memory of today, or simply by saying 'It rained on 31 October 1999'. Perhaps we shall associate 'yesterday' uttered tomorrow, the memory demonstrative 'then', and '31 October
1999' with modes of presentation of today different from the mode of presentation of it that today we associate with today, but even without the latter mode of presentation we can still know on future days that it rained today. Those ways of referring at one time to another are not analogous to ways of referring in one possible world to another possible world. Future reference to today on the basis of a memory demonstrative depends on remembering today, and therefore on a causal connection with today's events; there is no such connection from one possible world to another.
Reference to today with 'yesterday' tomorrow or '31 October 1999' depends on the temporal order, an ordering of times that is independent of what happens at those times. We have no such ordering of worlds. How is counterfactual reference to this actual world to be achieved?
The obvious means of reference to a possible world w in a world other than w is descriptive: one specifies w by specifying what is true at w. Let c be a long conjunction which can be expressed in a counterfactual world x, and is true at this actual world and at no other world. Then perhaps knowers in x could grasp and know A p by grasping and knowing □ (c ⊃ p). Would that solve the problem for WAVER and WAVER+?
The descriptive solution is in one way too cheap, in another too expensive. It is too cheap, for if p is actually true, then it can be included as a conjunct of the long conjunction c describing the actual world. Thus, in counterfactually knowing A p by having knowledge that one would express as □ (c ⊃ p), one has knowledge no more substantive than knowledge of the trivial truth □ ((p & c)
⊃ p). If that kind of knowledge satisfies WAVER and WAVER+, then they do nothing serious to mitigate the effect of the limits to knowledge which Fitch's argument reveals. In a different respect, the descriptive solution is too expensive, for it requires the counterfactual knower to specify the actual world down to the finest details in the conjunction c, a scarcely imaginable achievement.
This way in which the descriptive solution is too expensive hardly compensates for the way in which it is too cheap. Moreover, it is not plausible that counterfactual knowledge of □ (c ⊃ p)
constitutes knowledge of A p, for actual knowledge of □ (c ⊃ p) hardly constitutes knowledge of A
p, since it does not put one in a position to know p if one is not in a position to know c, and it is unclear why counterfactual knowledge of □ (c ⊃ p) should come any closer than actual knowledge of it to knowledge of A p.
Edgington suggests a different way of specifying counterfactual possibilities: by using counterfactual conditionals. Suppose, for example, that it actually rained last night and no one ever knows that it did. Consider a world w which would have obtained if someone had known that it rained last night. We may also assume that in w some such person knows on reflection that it would still have rained last night even if no one had known that it did, and therefore that if no one had known that it rained last night it would have been an unknown truth that it rained last night
(K(~Kp□ → (p & ~Kp))). But the counterfactual supposition that no one knows that it rained last night seems to take us back from w to the actual world; does that not permit us to count the knowledge in w that if no one had known that it rained last night it would have been an unknown truth that it rained last night as knowledge in w that it is actually an unknown truth that it rained last night? More generally, the proposal would be that if, in a world w, another world x would have obtained if the proposition q had been true, then knowledge in w that if q had been true the proposition r would have been true constitutes knowledge in w that r is true in x.
Knowers in w need not describe x in detail. They describe one difference (q) from their world and let everything else be as close as possible to their world in the manner of counterfactual suppositions; they need not even know what their world is like. In particular, x can be the actual world, q the proposition ~Kp, and r the proposition p & ~Kp.
Unfortunately for the proposal, the descriptive element in the antecedent of the counterfactual suffices to regenerate the trivialization argument. For suppose that, in the world w, the world x would have obtained if q had been true, and that r is true in x. Then, in w, x would have obtained if the conjunction q & r had been true; in the terms of a simple possible worlds semantics for the counterfactual conditional, if r is true in x and x is the closest world to w in which q is true then x is the closest world to w in which q & r is true. The proposal therefore implies that knowledge in w of the counterfactual (q & r) □ → r constitutes knowledge in w that r is true in x.
But since r is a truth-functional consequence of q & r, the counterfactual (q & r)□ → r is a trivial necessary truth. Knowledge of it in w is knowledge of nothing interesting.
It would not help to stipulate that the relevant counterfactual not be a logical truth. For let s state something contingent but utterly outlandish, logically quite independent of both q and r, such that it is obvious in w that there are much closer worlds to w in which q & r is true than any in which s is true. Then, as before, x is the closest world to w in which the disjunction (q & r) & s is true. Thus the counterfactual ((q & r) & s)□ → r is true but not logically true in w, so knowledge of it constitutes knowledge in w that r is true in x even by the modified proposal. But knowledge of the counterfactual ((q & r) & s)□ → r is still trivial by contrast with knowledge of A r, because its basis is just that s is a far more outlandish supposition than q & r. Rabinowicz and Segerberg admit that they are not sure that the trivialization problem can be overcome (1994: 113-14).
The specification of worlds by counterfactual conditionals also faces a problem of specificity, for why should we suppose that there is a unique closest world to w in which q is true?
For example, why should the counterfactual supposition in w that no one ever knows that it rained last night single out the actual world uniquely? David Lewis (1973) rejects the uniqueness assumption in his semantics for counterfactual conditionals. We could make the looser requirement that, in w, x is one of the worlds which might have obtained if q had been true; but if the counterfactual supposition made by the knowers in w does not single out x uniquely, then it is not obviously legitimate to characterize them as knowing something specifically about x—for example, about the actual world.
The problem of specificity is implicit in the formulations WAVER and WAVER+
themselves. For ~A p ≡ A~ p is a theorem of standard logics of the operator A; either p is actually true or ~p is. Consequently, any counterfactual knower who can somehow express the propositional constituent which we express with A is in a position to specify this actual world; it is the world with respect to which the proposition ∀p(p ≡ A p) is true. Thus reference to a complete world is built into the technical conception of actuality to which Edgington appeals. Moreover, we can use 'actual'
to make comparatively unproblematic reference because our ostension takes place in a unique complete world, this world. Incomplete worlds differ from complete ones in not being mutually exclusive. If we try to use 'actual' to refer to an incomplete world, our ostension with 'this world'
takes place in many worlds of varying degrees of incompleteness simultaneously; which of them is being ostended?
These considerations suggest that the 'actually' operator is not best suited to Edgington's purposes. She herself says 'Knowledge of counter-factual situations is never of one specific possible world' (1985: 564). Her preferred formulations are in terms of unspecific possible situations. We can adapt WAVER in this way, generalizing it beyond the actual world:
WSVER ∀p∀s(In(s, p) ⊃ ∃s*In(s*,KIn(s, p)))
This says in effect that for every possible situation s, if p is true in s then in some possible situation s* it is known that p is true in s. Sten Lindström (1997) has worked out the technical details of such a situation-theoretic approach.
A radical version of situation theory forbids situations to involve the whole universe. If so, then it cannot be true in any situation that p is an unknown truth, for 'unknown' abbreviates the unrestricted generalization 'not known by anyone at any time', which on its intended understanding involves the whole universe. That version of the approach scarcely engages with Fitch's argument; it restricts verificationism to statements about limited portions of the universe. If p is an unknown truth in a limited situation s, where the quantifiers implicit in 'unknown' are restricted to s, then an observer outside s may be able to perceive that p is an unknown truth in s, as Lindström points out (1997: 197). It is unclear how semantic arguments for verificationism could be reinterpreted to yield only that limited version of it, unless—very implausibly—they denied the intelligibility of unrestricted quantification over all subjects and all times.
A moderate version of situation theory permits but does not require situations to involve the whole universe. Thus it can be true in some situation s that p is an unknown truth, in a sense from which it follows that if s obtains then p is an unknown truth simpliciter. Then, according to
WSVER, it is known in some possible situation s* that p is an unknown truth in s. It is not immediate that s and s* are not compossible. If they both obtained, might someone in s* know that p is an unrestrictedly unknown truth in s without knowing that p is an unrestrictedly unknown truth, by not realizing that s obtains? Someone who specifies s simply by a perceptual or memory demonstrative or by spatio-temporal coordinates without drawing the consequence that s obtains is still in a position to know that s obtains. We can understand 'unknown' broadly enough to exclude such cases. The knowers in s* must specify s by means which do not require s to obtain. But then they must specify s by something like description or a counterfactual supposition. Given that s is not a complete possible world, the specificity problem is no longer pressing. Perhaps it can be described by a short conjunction; perhaps in s* it is the most specific situation that would obtain if p were not known. However, the trivialization problem is just as serious as before. Knowers in s* can build p as a conjunct into their specification of s, and thereby achieve trivial knowledge that p is true in s; the argument runs just as before. WSVER, even if true, does not seriously mitigate the effect of Fitch's argument. The knowledge that it claims to be possible is achievable in a trivial way if achievable at all.
We may briefly note some further problems for the counterfactual strategy used to defend
WSVER; similar criticisms can be made of WAVER and WAVER+.
(i) Edgington's treatment of the proposition that p is an unknown truth assumes that p itself is knowable in the original sense (◊K) in which it is conceded that not all truths are knowable. But p may not be knowable in that sense. For example, let p be the conjunction of a complete description of all actual neurophysiological events at all times conjoined with the proposition that there are no non-physical thinkers. We may assume that p is unknown. If p were known, it would be true, and therefore known by a physical knower; but then some neurophysiological events in the brain of that knower would be different from all actual neurophysiological events, so p would not be true after all, and so would not be known.
Thus p is arguably unknowable, because the supposition that p is known is self-defeating. But then we could not know that p is an unknown truth in an actual situation s by knowing p in a non-actual situation s* and reflecting that p would still have been true if it had not been known, for p cannot be known in any possible situation.
(ii) Now suppose that p is a knowable but unknown truth in s. The idea is that if s* is the closest situation to s in which p is known, then s is the closest situation to s* in which p is unknown, so subjects in s* can specify s as the situation which would obtain if p were unknown. But the relation between s and s* need not be so symmetrical. For example, let p be the proposition that there is a pebble at spatio-temporal location xyzt, and s be a situation in which p is true but unknown because the conditions for intelligent life emerge only long after t (the time of xyzt). Let s* be a situation as close as possible to s in which p is known. Cosmic history follows vastly divergent paths in s and s*. In the closest possible situations to s* in which p is unknown, it is unknown simply because no one chances to travel near xyzt; such situations are far closer to s* than to s in cosmic history. Thus although someone in s* may know that if p had been unknown it would have been an unknown truth, that cannot be represented as knowledge in s* that p is an unknown truth in s, for, in s*, if p had been unknown s would not have obtained. Knowers in s* may be unable to single out s by any counter-factual supposition. Although the knowledge that WSVER attributes is achievable in trivial ways if achievable at all, it may not be achievable at all.
(iii) Edgington's counterfactual strategy makes another assumption: that if a proposition p is an unknown truth in a situation s, and s* is the closest situation to s in which p is known, then, in s*, if p had not been known it would still have been true. What happens if that assumption breaks down? Edgington argues:
If there are truths which fail to satisfy the principle
(7) p would still have been true, had no one known that p, that I am in pain, for example, then they satisfy the principle,
(8) If p, then someone knows that p and, a fortiori, they satisfy [WAVER]. (1985: 567; numbering added)
There is a lacuna here, for the counterfactual strategy requires (7) to be known, not just true, in s*; the observer-independence of what we observe is not always easy to establish. Because I wonder whether asking myself whether I
am embarrassed causes me to be embarrassed, I may not know that I would still have been embarrassed, had no one known that I was embarrassed (I may know that no one else will ever know that I was embarrassed). Thus even if the falsity of (7) implies the truth of (8), that does not help when (7) is true but unknown, and perhaps even unknowable (in the sense in which Fitch's argument shows that there are unknowable truths).
(iv) But does the falsity of (7) imply the truth of (8) in the relevant situation? The difficulty for the counterfactual strategy arises when (7) is false in s*. If the falsity of (7) implies the truth of
(8), then what follows is that (8) is true in s*. That is no surprise, for the consequent of (8) is true in s*. But since it is consistent with the truth of (8) in s* that p is an unknown truth in s, no way has yet been provided of knowing either in s* or in s that p is an unknown truth in s. Thus WSVER is still under threat. An argument to the truth of (8) in s from the falsity of (7) in s would be unlikely to help, for, by hypothesis, both the antecedent and the consequent of (7) are true in s; (7) is probably true in s. What is really needed is an argument to the truth of (8) in s from the falsity of (7)
in s*. But there is no such connection. Suppose that our best physical theory tells us that one can know what state a?-particle is in only by interacting with it in ways which unpredictably change its state; one knows what state it is in after the change. Suppose also that it is an unknown truth in s that a?-particle z is in a state k (that proposition is p). Then (7) is not true in the corresponding situation s* in which it is known that z is in state k, for if it had not been known that z was in k, the interactions would not have occurred and z might well not have been in k. Nevertheless, (8) is not true in s. Of course, a verificationist might deny that there can be unknown truths in cases of this kind: but such a claim has no plausibility for those not antecedently committed to verificationism.
At any rate, we have no good reason to think that the falsity of (7) in s* entails the truth of (8) in s.
That is another respect in which the counterfactual strategy is insufficiently general.
(v) The counterfactual strategy is inadequate as a defence of WAVER and WSVER, and the knowledge which they ascribe is anyway trivial in the sense explained above. There is also an underlying problem about the motivation for such modified verificationist principles. A
verificationist principle (WVER) was originally motivated by arguments about the nature of meaning. In response to Fitch's argument, the principle was modified. But it was not checked that the meaning-theoretic argument for WVER could plausibly be reconstrued as an argument for WAVER or WSVER. Such a reconstrual looks quite dubious. For the meaning-theoretic argument for WVER proceeds at the level of sentences; roughly, it attempts to demonstrate that the truth-condition of a sentence somehow depends on its assertibility-condition in such a way that if the assertibility-condition is impossible (incapable of obtaining), then so too is the truth-condition. Sentences of the form 'A and it is not known that A' constitute counterexamples to that claim. Given a sentence S with a possible truth-condition and an impossible assertibility-condition, the defence of WAVER or WSVER, if successful, would produce a complex sentence Φ(S) of which S is a constituent, and show that Φ(S)
has a possible assertibility-condition. For example, if S is 'It rained last night without its being known that it rained last night', Φ(S) might be 'If it had not been known that it rained last night, it would have been the case that it rained last night without its being known that it rained last night'.
Presumably, the idea is that the possibility of the assertibility-condition of Φ(S) somehow explains the possibility of the truth-condition of S in a manner consistent with the spirit of a verificationist theory of meaning. Since the truth-condition of S is an aspect of the meaning of S, even on a verificationist account, the meaning of S is in effect being explained in terms of the meaning of
Φ(S). But verificationist theories of meaning of the kind used in the arguments for WVER,
WAVER, and WSVER are compositional; they give the meaning of complex expressions in terms of the meanings of their constituents. Since S is a constituent of Φ(S), the meaning of Φ(S) is explained in terms of the meaning of S. This looks like an explanatory circle. Perhaps the defender of WAVER or WSVER has some way of rendering it harmless, but we should not rush to assume that the defence of those principles can be reconciled with the meaning-theoretic ideas which were supposed to motivate the original weak verificationism. Sometimes we should learn from counterexamples that a philosophical idea was wrong in spirit, not just in letter.13
Point (i) above indicated the presence of unknowable truths similar in spirit but formulated without use of specifically epistemological concepts. The domain of unknowability is probably far wider than that. Once we acknowledge that the domain is non-empty, we can explore more effectively its extent. In order to be able to set a limit to knowledge, we do not have to find both sides of the limit knowable. Although, trivially, we cannot know that which we cannot know, we can know that we cannot know something. In this chapter we saw a route to knowing of various pairs of propositions that since both are unknowable and one or other of them is true, one or other of them is an unknowable truth. What we have not seen is a route to knowing that when the pair consists of a proposition and its negation (see section 12.4). Yet we may plausibly conjecture that, in some sense of 'impossible', we can know of some propositions both that they are true or false and that it is impossible to know them to be true and impossible to know them to be false. We are only beginning to understand the deeper limits of our knowledge. Appendix 1 Correlation Coefficients
Given real-valued random variables X and Y whose arguments are conditions ('events') in a suitable probability space, their correlation coefficient ρ[X,Y] is defined as Cov[X,Y]/(σ[X]σ[Y]); their covariance Cov[X,Y] is in turn defined as E[XY]-E[X]E[Y], where E[X] is the expectation of
X; the standard deviation σ[X] is defined as √ E[(X-E[X])2] (e.g. Parzen 1960: 362). Covariance is not itself an adequate measure of correlation; for example, any random variable is perfectly correlated with itself, but Cov[X,X] = σ[X]2, which varies. One must calibrate Cov[X,Y] by dividing by σ[X]σ[Y].
All these notions can be relativized to a set of background conditions by conditionalizing the underlying probabilities on those conditions.
We must now define correlation coefficients for the conditions on which the probabilities are defined. Denote the probability of a condition C as P[C]. The indicator random variable X(C) is
1 if C obtains and 0 otherwise; thus E[X(C)] = P[C]. For any conditions C and D we define their correlation coefficient ρ[C,D] (with harmless ambiguity in ρ) as ρ[X(C),X(D)]. We will calculate an expression for ρ[C,D] in terms of probabilities, and then derive some elementary facts about it. The conditional probability P[C|D] is P[C & D]/P[D] (0 < P[D]).
We assume that 0<P[C]<1, and similarly for D and E, otherwise the correlation coefficients for these states are not well-defined.
Proposition 1. ρ[C,D] = (P[C & D]-P[C]P[D])/√ (P[C](1-P[C])P[D](1-P[D])).
Proof. Cov[X(C), X(D)
= E[X(C) X(D)] – E[X(C)]E[X(D)]
= E[X(C & D)] – E[X(C)]E[X(D)]
= P[C & D] – P[C]P[D]
Moreover, σ[X(C)] = √E[(X(C) – E[X(C)])2]
= √(E[X(C)2] – (E[X(C)])2) by a standard calculation
= √(E[X(C)] – (E[X(C)])2) because X(C) ∈ {0,1}
= √(P[C](1 – P[C])). ▪
Proposition 2.
(a) If P[C|D] > P[C] then ρ[C,D] > 0.
(b) If P[C|D] = P[C] then ρ[C,D] = 0.
(c) If P[C|D] < P[C] then ρ[C,D] < 0.
Proof. By Proposition 1, ρ[C,D] has the same sign as P[C & D]-P[C]P[D] = (P[C|D]P[C])P[D].▪ Proposition 3.
(a) If ρ[C,D]≥0 and ρ[C,E]≥0 then ρ[C,D]≤ ρ[C,E] iff
(P[C|D] – P[C])(P[C] – P[C|~D]) ≤ (P[C|E] – P[C])(P[C] – P[C|~E])
(b) If ρ[C,D]≤0 and ρ[C,E]≤0 then ρ[C,D]≤ ρ[C,E] iff
(P[C|D] – P[C])(P[C] – P[C|~D]) ≥ (P[C|E] – P[C])(P[C] – P[C|~E])
Proof. (a)

(P[C|D] – P[C]P[D])2 =
= (P[C|D]P[D] – P[C]P[D])(P[C] – P[C & ~D] – P[C]P[D])
= (P[C|D] – P[C])P[D](P[C](1 – P[D]) – P[C|~D]P[~D])
= (P[C|D] – P[C])(P[C] – P[C|~D])P[D](1 – P[D]).

Hence by Proposition 1,
ρ[C,D]2P[C](1 – P[C]) = (P[C|D] – P[C])(P[C] – P[C|~D]).
But if ρ[C,D]≥0 and ρ[C,E]≥0 then
ρ[C,D] ≤ ρ[C,E] ⇔ ρ[C,D]2P[C](1 – P[C]) ≤ ρ[C,E]2P[C](1 – P[C])
⇔ (P[C|D] – P[C])(P[C] – P[C|~D]) ≤ (P[C|E] – P[C])(P[C] – P[C|~E]).
(b) is similar. ▪
Proposition 4. If P[C|D]≤P[C|E] and P[C| ~D]≥P[C| ~E] then ρ[C,D]≤ ρ[C,E].
Proof. Suppose that P[C|D]≤P[C|E] and P[C| ~D]≥P[C| ~E]. Case (i): P[C]≤P[C|D]. Then P[C]≤P[C|E], so by Proposition 2, ρ[C,D]≥0 and ρ[C,E]≥0.
Hence by Proposition 3(a), ρ[C,D]≤ ρ[C,E] iff
(*) (P[C|D] – P[C])(P[C] – P[C|~D]) ≤ (P[C|E] – P[C])(P[C] – P[C|~E]).
But 0 ≤ P[C|D]-P[C] ≤ P[C|E]-P[C]. Moreover, since P[C] = P[D]P[C|D] + (1-P[D])P[C|
~D], 0 ≤ P[C]-P[C| ~D] ≤ P[C]-P[C| ~E]. Hence (*) holds, so ρ[C,D] ≤ ρ[C,E].
Case (ii): P[C|D]<P[C]<P[C|E]. Then ρ[C,D]<0<ρ[C,E] by Proposition 2.
Case (iii): P[C|E]≤P[C]. Similar to case (i), using Proposition 3(b).
Proposition 5.
(a) ρ[C,C] = 1
(b) ρ[C, ~C] = -1
(c) -1 ≤ ρ[C,D] ≤ 1
(d) ρ[C,D] = 1 iff P[C|D] = 1 and P[C| ~D] = 0.
(e) ρ[C,D] = -1 iff P[C|D] = 0 and P[C| ~D] = 1.
Proof. (a) and (b) are simple consequences of Proposition 1.
(c) P[C|D]≤P[C|C] and P[C| ~D] ≥ P[C| ~C], so ρ[C,D]≤ ρ[C,C] = 1 by (a) and Proposition
4. Similarly, ρ[C,D]≥ ρ[C, ~C] = -1.
(d) Suppose that ρ[C,D] = 1. Then ρ[C,C] ≤ ρ[C,D] by (a) and (c), and P[C|D] >P[C] by
Proposition 2. Hence by Proposition 3
(P[C|D] – P[C])(P[C] – P[C|~D]) ≥ (P[C|C] – P[C])(P[C] – P[C|~C]) = (1- P[C])P[C]. But P[C|D]-P[C]≤1-P[C] and P[C]-P[C| ~D]≤P[C], so P[C|D]-P[C] = 1-P[C] and P[C]-P[C|
~D] = P[C], so P[C|D] = 1 and P[C| ~D] = 0. Conversely, if P[C|D] = 1 and P[C| ~D] = 0 then P[D]
= P[C & D] = P[C] and the result follows by Proposition 1.
(e) is similar to (d). ▪ Appendix 2 Counting Iterations of Knowledge
We can treat the propositional modal logic KT (=T) as an idealized logic for knowledge by reading the necessity operator as 'One knows that', here written K. As the axioms of KT we use all truth-functional tautologies and all instances of KA ⊃ A ('knowledge implies truth'). As rules we use modus ponens and the rule RK that if [A 1 & . . . &A n ] ⊃ B is a theorem, so is [KA 1 &. . . &
KA n ] ⊃ KB (n ≥ 0, 'knowledge is closed under logical consequence', with the analogue of the rule of necessitation for n = 0). See Chellas (1980) for further details.
Suppose that the tree is in fact k inches tall. We are interested in how many iterations of knowledge one can have of the propositions that it is not j inches tall, where j< k, and that if it is n inches tall then one does not know that it is not n-1 inches tall, where j< n≤ k. Let us read the propositional variable p i as 'The tree is i inches tall'. For iterations of knowledge we define Kn inductively: K0A = A, Kn+1A = KnKA. For each natural number n from j to k, let i[n] be a natural number. Now consider this formula:

Λ

(*) Ki[j] ~ pj & j < n ≤ k Ki[n](pn ⊃ ~K~pn-1) & pk.
According to *: one has i[j] iterations of knowledge that the tree is not j inches tall; for each n from j to k, i[n] iterations of knowledge that if it is n inches tall then one does not know that it is not n-1 inches tall; the tree is k inches tall. Our question is: for which numbers is * consistent in
KT? The answer turns out to be that it is consistent if and only if i[n]< k-n for some n (j≤ n≤ k).
Thus one can have arbitrarily many iterations of knowledge of all but one of the propositions, provided that one falls below the specified limit for the remaining proposition.
Proposition. For all natural numbers j, k (j≤ k) and i[j], i[j+1], . . . , i[k]:
⊢KT ~* if and only if for all n, if j ≤ n ≤ k then i[n] ≥ k – n.
Proof. First suppose that for all n, if j≤ n≤ k then i[n]≥ k-n. Consider this formula:
(**) Kk - j ~ pj &

Λ

k-n
(pn ⊃ ~K~pn-1) & pk.
j< n ≤ k K Since ⊢KT KA ⊃ A, ⊢KT Ki[j]~ p j ⊃ Kk−j~p j and ⊢KT Ki[n](p n ⊃ ~K~ p n−1 ) ⊃ Kk−n(p n ⊃

~K~ p n−1 ) for all n (j<n≤ k) by supposition. Hence ⊢KT * ⊃ **, so it suffices to show that ⊢KT ~**.
Now ⊢KT (K~ p n−1 & (p n ⊃ ~K~ p n−1 )) ⊃ ~p n (j<n≤ k), so by k−n applications of RK, ⊢KT
(Kk−n+1~ p n−1 & Kk−n(p n ⊃ ~K~ p n−1 )) ⊃ Kk−n~ p n , so ⊢KT ** ⊃ (Kk−n+1~ p n−1 ⊃ Kk−n~ p n ).
Putting all these pieces together for n from j+1 to k, ⊢KT ** ⊃ (Kk−j~ p j ⊃ ~p k ). But ⊢KT ** ⊃

(Kk−j~ p j & p k ), so ⊢KT ~**.
For the converse, suppose that for some h, j≤ h≤ k and i[h]< k-h. We use the well-known fact that any KT theorem is true at any world in any standard possible worlds model with a reflexive accessibility relation to show that not KT ~*, by constructing such a model with a world at which *
is true. The worlds are the natural numbers from h to k inclusive; for any worlds m and n, n is accessible from m if and only if | m-n|≤1. Thus for any formula A and world m, KA is true at m if and only if for every world n, if | m-n|≤1 then A is true at n. Consequently, for any natural number l,
KlA is true at m if and only if for every world n, if | m-n|≤ l then A is true at n. For j≤ m≤ k and h≤
n≤ k, we set p m true at n if and only if m = n. We will show that * is true at k. Certainly p k is true at k. There are two cases to consider.
(i) h = j. Thus for any world n, if | k-n|≤ i[h] then | k-n|< k-h because by hypothesis i[h]< k-h, so h< n, so ~p h is true at n. Consequently, Ki[h]~ p h is true at k. If j< n≤ k, p n -1 is true at n-1, so ~K~p n -1 is true at n; since p n is true only at n, pn ⊃ ~K~ p n -1 is true at every world; thus Ki[n](p n ⊃ ~K~ p n -1 ) is true at k.
(ii) h > j. If j≤ n< h then p n is false at every world, so Ki[j]~ p j and Ki[n](p n ⊃ ~K~ p n -1 ) are true at every world. Ki[h](p h ⊃ ~K~ p h -1 ) is true at k because if | k-n|≤ i[h] then h< n, so p h is false at n. If h< n≤ k then p n ⊃ ~K~ p n -1 is true at every world, so Ki[n](p n ⊃ ~K~
p n -1 ) is true at k. ▪
Evidently, this is just a specimen result. We can generalize it by adding as extra conjuncts to
* any formulas true at world k in the models specified in the second half of the proof. For example, since Ki~ p n is true at k whenever | k-n|> i, we can add any such formula. Similarly, one can add
Ki~ (p m & p n ) for any i, m and n where m ≠ n. One can also add worlds k+1, k+2, . . . , subject to the same truth definitions. What is crucial is omitting j as a world when enough iterations of knowledge of ~p j are needed.
The accessibility relation just used is symmetric as well as reflexive. The model therefore validates the Brouwersche schema A ⊃ K~K~A, the addition of which to KT gives the system
KTB. KTB is exactly the logic for knowledge determined by the simplest version of the margin for error considerations. The only logical features essential to the binary similarity relation are reflexivity and symmetry, accessibility in the model plays the role of similarity, and KTB is the logic determined by the constraints of reflexivity and symmetry on accessibility. Section 5.3 also describes more sophisticated versions of the margin for error considerations on which the width of the margin varies from point to point, which makes the accessibility relation non-symmetric.
A feature of both KT and KTB is that, for any formula A, A ⊃ KA is a theorem if and only if either ~A is a theorem or A is (Williamson 1992a). This is a formal analogue of the hypothesis in
Chapter 4 that only trivial conditions are luminous. Appendix 3 A Formal Model of Slight Insensitivity Almost Everywhere
We will use a formal model to study how the slightest systematic inaccuracy can make one almost totally insensitive in the counterfactual sense: for every contingent proposition p, if p were false one might still believe p.
For simplicity, we evaluate counterfactual propositions according to Lewis's semantics, and imagine possible worlds as varying along a single dimension. We treat propositions as sets of worlds. We represent the worlds by the real numbers, and measure the distance between worlds w and x in the natural way, by | w-x|. Thus q□ → r is true at w if and only if either q is true at no world or q is true at some world x such that for every world y, if | w-y|≤| w-x| and q is true at y then r is true at y. The same negative results about sensitivity will follow from the weaker assumption that
Lewis's condition is necessary for the truth of the counterfactual. For any proposition p, B p is the proposition that one believes p. One believes p sensitively at w if and only if B p & (~ p□ → ~B p)
is true at w.
Let one's process of belief formation embody a very slight bias towards one world, which may as well be 0. More precisely, given a small quantity ε>0, define a mapping f from worlds to worlds: f(w) = w + ε if w < -ε
f(w) = 0
if –ε ≤ w ≤ ε
f(w) = w – ε if ε < w
Thus f is a shift of at most ε in the direction of 0. To formalize the bias, suppose that for every proposition p and world w, B p is true at w if and only if p is true at f(w). At 0, one in effect believes one to be in 0 (f(0)= 0). Elsewhere, the world in which one believes oneself to be is very slightly closer than the world in which one is to 0. For example, if a is a real number, let p(a) be the proposition true at exactly the worlds w such that -a< w< a. Then, for a>ε, B p(a) is true at w if and only if -a-ε< w< a+ε, so one believes p(a) falsely at w if and only if -a-ε< w≤-a or a≤ w< a+ε. Since one believes p(a) at any world at which it is true, the worlds at which one believes p(a) falsely form a tiny proportion of the worlds at which one believes p(a), if ε is small compared to a. The model makes one's beliefs consistent (for p and ~p are not both true at f(w)), complete (for either p is true at f(w) or ~p is)) and deductively closed (for if q logically follows from p 1 , . . . , p n , and p 1 , . . . , p n are true at f(w), then so is q) at every world w. These highly idealized properties ensure that any cognitive problems one has in the model are not the result of logical incapacity. At 0, one believes p if and only if p is true. But one's beliefs are insensitive. For example, ~p(a)□ → p(a+ε) is true at 0 because if one's world were not within a distance a of 0 it would be within a+ε of 0; but B p(a) is true at exactly the same worlds as p(a+ε), so ~p(a)□ → B p(a) is true at 0 whenever ε>0. If p(a) were false one would still believe it. Thus one believes p(a) insensitively at 0, in virtue of the tiny belt of worlds at which one believes it falsely between the broad core of worlds at which one believes it truly and the infinitely broad remainder of worlds in which it is false and one disbelieves it.
The point generalizes: one believes no contingent proposition sensitively at any world within a distance ε/2 of 0. Proof: Suppose that B p & (~ p□ → ~B p) is true at w, where | w|≤ ε/2
and p is contingent. Without loss of generality we may assume that 0≤ w≤ ε/2. Since p is contingent, the truth of the counterfactual at w requires a world x at which ~p is true and for every world y, if |
w-y|≤| w-x| then ~p ⊃ ~B p is true at y. Let f 0(x)= x and f n+1(x)= f(fn(x)). We show by induction on n that p is false at fn(x) and | w-fn(x)|≤| w-x| for all n. Basis: Trivial. Induction step: By the induction hypothesis, ~p ⊃ ~B p is true and p false at fn(x), so B p is false at fn(x), so p is false at fn+1(x). We must show that | w-fn+1(x)| ≤ | w-x|. If fn(x)≤0 then fn(x)≤ fn+1(x)≤0≤ w, so | w-fn+1(x)|≤| w-fn(x)| ≤
| w-x| by the induction hypothesis. If 3ε/2≤ fn(x) then w≤ ε/2≤ fn+1(x)≤ fn(x), so again | w-fn+1(x)|≤|
w-fn(x)|≤| w-x|. If 0< fn(x)<3ε/2 then 0≤ fn+1(x)<ε/2, so | w-fn+1(x)|≤ ε/2; since B p is true at w, p is true at f(w)=0; but B p is false at x, so p is false at f(x), so f(x)≠0, so ε<| x|, so ε/2≤| w-x|, so | wfn+1(x)|≤| w-x|. This completes the induction. By definition of f, fn(x)=0 for some n. Hence p is false at 0, which yields a contradiction. Thus no contingent proposition is believed sensitively at w if |
w|≤ ε/2. ▪
Contingent propositions are believed sensitively at worlds more distant from 0. If ε/2< w<ε, a proposition false at (2w-ε)/3 and 2(w+ε)/3 and true elsewhere is believed sensitively at w. If ε ≤ w, a proposition false at w-2ε/3 and w+ε/3 and true elsewhere is believed sensitively at w.
One's only sensitive beliefs at worlds near 0 are beliefs in necessary propositions, which are vacuously sensitive. Given that necessary propositions entail only necessary propositions, (4) in section 7.5 implies that at these worlds one has no knowledge of contingencies if there is any such bias at all, no matter how small. As soon as ε = 0, all beliefs are sensitive and may count as knowledge. Is a notion of sensitivity on which the slightest bias can produce total insensitivity an adequate basis for an account of knowledge attribution? Intuitively, we might expect a slight bias to rule out knowing p close to the boundary of worlds at which p is true; on a sensitivity-based account, it can do so arbitrarily far from the boundary.
We can modify the model to give it more desirable features. For example, as it stands it assigns one some Moore-paradoxical beliefs at some worlds (although not at 0). Since p(ε) is true at
0 and false at ε and f(ε)= 0, ~p(ε) & B p(ε) and ~p(ε) & ~B~p(ε) are true at ε; since f(2ε)= ε, B(~
p(ε) ~B p(ε)) and B(~ p(ε) & ~B~ p(ε)) are true at 2ε. Thus at 2ε one has presumably irrational beliefs tantamount to 'p(ε) is false but I believe p(ε)' and '~ p(ε) is true but I don't believe ~p(ε)'. There are several ways around this point. Most simply, we can make B p true at w if and only if p is true at both f(w) and 0. One believes oneself to be in f (w) or 0 and is not sure which. Since one still believes all and only truths at 0, neither ~p & B p nor p & ~B p is ever true at 0, so neither B(~ p &
B p) nor B(p & ~B p) is ever true at w. Under this modification, one's beliefs are still consistent and deductively closed at every world but complete only at 0. W can show almost as before that one believes no contingent proposition sensitively at w if | w|≤ ε/2.
We could also 'fill in' the worlds between f(w) and 0 by making B p true at w if and only if p is true at every world x such that f(w)≤ x≤0 or 0≤ x≤ f(w). One believes oneself to be in some world between f(w) and 0 inclusive and is not sure which. Under this modification too, one's beliefs are consistent and deductively closed at every world but complete only at 0. Moorean paradoxes are avoided and we can show in a similar way that one believes no contingent proposition sensitively at w if | w|≤ ε/2.
The last model differs from the first two in having a transitive accessibility relation and therefore validating all instances of the 'positive introspection' (S4) principle B p ⊃ BB p; if one believes something then one believes that one believes it. In the previous two models, by contrast, since p(2ε) ⊃ p(ε) is true at 2ε and 0 but not at ε, B(p(2ε) ⊃ p(ε)) is true at 3ε but not at 2ε, so
BB(p(2ε) ⊃ p(ε)) is false at 3ε, so positive introspection fails at 3ε. If positive introspection holds everywhere in a model in which one's beliefs are everywhere consistent, wherever B p is true so is
BB p, so ~B~ B p is true by consistency, so B p□ → ~B~B p is true everywhere: one cannot believe insensitively that one does not believe p. This is consistent with one's failure to believe contingent propositions sensitively, for in both the second and third models one believes ~B p at some world only if one believes it at every world; if B~B p is true at w then ~B p is true at 0, so p is false at 0, so ~B p is true at every world; belief in it is vacuously sensitive.
None of the three models validates all instances of the 'negative introspection' (S5) principle that if one does not believe something then one believes that one does not believe it. For example, since p(ε) is false at ε, B p(ε) is false at 2ε; since p(ε) is true at 0, B p(ε) is true at ε, so B~B p(ε) is false at 2ε; thus ~B p(ε) ⊃ B~ B p(ε) is false at 2ε. If negative introspection holds everywhere in a model in which one's beliefs are everywhere consistent, then wherever ~B p is true so is B~B p, so
~BB p is true by consistency, so ~B p□ → ~BB p holds everywhere: one cannot believe insensitively that one believes p. In the models above, one can falsely believe that one believes p;
~B p(ε) & BB p(ε) is true at 2ε.
That the models are not realistic is obvious. Nevertheless, they enable us to see how sensitivity works, and the startling demands it can impose. They further undermine (4) in section
7.5, by showing how it can make the slightest bias destroy all knowledge of contingencies whatsoever. The same pathology can be expected in models of more realistic complexity, although of course harder to establish there. Intuitively, what goes wrong is that the counterfactual supposition ~p can take one to worlds at which one believes p on too different a basis from that on which one actually believes p. The obvious remedy is to relativize sensitivity to finely individuated methods, perhaps as (3) does in section 7.4. Appendix 4 Iterated Probabilities in Epistemic Logic (Proofs)
First some standard definitions. A frame is a pair <W,R>, where R is a binary relation on the set W. For w∈W, R(w)={x∈W: wR x}. R is serial on W just in case for every w∈W there is an x∈W such that wR x. <W,R> is serial (reflexive, symmetric, transitive) just in case R is serial
(reflexive, symmetric, transitive) on W. A frame is partitional just in case it is reflexive, symmetric, and transitive. A probability distribution on W is a mapping P from all subsets of W to nonnegative real numbers such that P(W) = 1 and P(X ∪Y) = P(X) + P(Y) whenever X and Y are disjoint subsets of W. If P(Y) > 0, P(X|Y) = P(X∩ Y)/P(Y); if P(Y) = 0, P(X|Y) is undefined. A probability distribution P on W is regular just in case P(X) > 0 whenever X is a non-empty subset of W. A
frame <W,R> is bland just in case it is serial and P(X) = w∈W P({w})P(X|R(w)) for every X ⊆ W
and regular probability distribution P on W. R(w) is always non-empty when <W,R> is serial, so
P(R(w)) > 0 if P is regular, so P(X|R(w)) is defined; if <W,R> is not serial, R(w) is empty for some w∈W and P(X|R(w)) is undefined.
Proposition 1. Every bland finite frame is reflexive.
Proof. Let <W,R> be a bland finite frame and x∈W. Suppose that not xR x. Since <W,R> is serial, xR y for some y≠ x. Thus W has n+2 members for some n≥0. There is a (unique) regular probability distribution P on W such that:
P({x}) = 2/3
P({w}) = 1/3(n + 1) for w ∈ W – {x}.
Now
∑w∈W P({w})P(W – {x}|R(w)) ≥ P({x})P(W – {x}|R(x)).
Since not xR x, R(x) ⊆ W-{x}, so P(W-{x}|R(x)) = 1. Thus
∑w∈W P({w})P(W – {x}|R(w)) ≥ P({x}) = 2/3 > 1/3 = P(W – {x}).
This contradicts the blandness of <W,R>. Thus xR x. ▪
Proposition 2. Every bland finite frame is symmetric.
Proof. Let <W,R> be a bland finite frame, and x, y∈W. Suppose that xR y but not yR x.
Hence x≠ y, so W has n+2 members for some n≥0. There is a (unique) regular probability distribution P on W such that: P({x}) = ½
P({y}) = (n + 2)/4(n + 1)
P({w}) = 1/4(n + 1) for w ∈ W – {x,y}.
Now
∑w∈W P({w})P({y}|R(w))
≥ P({x})P({y}|R(x)) + P({y})P({y}|R(y))
= P({y}|R(x))/2 + (n + 2)P({y}|R(y))/4(n + 1)
> P({y}|R(x))/2 + P({y}|R(y))/4.
Since xR y, {y} ⊆ R(x), so
P({y}|R(x)) = P({y})/P(R(x)) ≥ P({y}).
But not yR x, so R(y) ⊆ W-{x}, so
P(R(y)) ≤ P(W – {x}) = 1 – P({x}) = ½.
Now yR y because R is reflexive by Proposition 1, so {y} ⊆ R(y), so
P({y}|R(y)) = P({y})/P(R(y)) ≥ 2P({y}).
Thus
∑w∈W P({w})P({y}|R(w) > P({y})/2 + 2P({y})/4 = P({y}).
This contradicts the blandness of <W,R>. Thus if xR y then yR x. ▪
Proposition 3. Every bland finite frame is transitive. Proof. Let <W,R> be a bland finite frame, and x, y, z∈W. Suppose that xR y and yR z but not xR z. Hence x≠ y and y≠ z. By Proposition 1, xR x, so x≠ z. Thus W has n+3 members for some n≥0. There is a (unique) regular probability distribution P on W such that:
P({x}) = P({z}) = 1/3
P({w}) = 1/3(n + 1) for w ∈ W – {x, z}.
Now
∑w∈W P({w})P({y}|R(w))
≥ P({x})P({y}|R(x)) + P({y})P({y}|R(y)) + P({z})P({y}|R(z))
= P({y}|R(x))/3 + P({y}|R(y))/3(n + 1) + P({y}|R(z))/3.
Since xR y, {y} ⊆ R(x), so
P({y}|R(x)) = P({y})/P(R(x)).
Moreover, yR z and R is symmetric by Proposition 2, so zR y, so {y} ⊆ R(z), so
P({y}|R(z)) = P({y}/P(R(z)).
Finally, yR y since R is reflexive, so {y} ⊆ R(y), so
P({y}|R(y)) = P({y})/P(R(y)). Thus
∑w∈W P({w})P({y}|R(w)) ≥ P({y})/3P(R(x)) + P({y})/3(n + 1)P(R(y)) + P({y})/3P(R(z))
> 1/3P({y})(1/P(R(x)) + 1/P(R(z))).
Since not xR z, R(x) ⊆ W-{z}, so
P(R(x)) ≤ P(W – {z}) = 1 – P({z}) = 2/3.
Similarly, not zR x because R is symmetric, so
P(R(z)) ≤ 2/3.
Hence
1/3P({y})(1/P(R(x)) + 1/P(R(z))) ≥ 1/3P({y})(3/2 + 3/2) = P({y}).
Thus
∑w∈W P({w})P({y}|R(w)) > P({y}).
This contradicts the blandness of <W,R>, so if xR y and yR z then xR z. ▪
Proposition 4. Every finite partitional frame is bland.
Proof. Let <W,R> be a finite partitional frame and P a regular probability distribution on W.
Since R is reflexive on W, <W,R> is serial. Let w, x∈W. If not w∈R(x) then not x∈R(w) because R
is symmetric, so {x}∩ R(w) = {}, so
P({x}|R(w)) = 0.
If w∈R(x) then R(x) = R(w) and {x} ⊆ R(w), since <W,R> is partitional, so
P({x}|R(w)) = P({x})/P(R(w)) = P({x})/P(R(x)).
Hence
∑w∈W P({w})P({y}|R(w))
= ∑w∈R(x) P({w})P({x}|R(w))
= ∑w∈R(x) P({w})P({x})/P(R(x))
= (P({x)/P(R(x))) ∑w∈R(x) P({w})
= (P({x})/P(R(x)))/P(R(x))
= P({x}).
Hence, for any X ⊆ W, w∈W P({w})P(X|R(w)) = P(X). ▪
Proposition 5. A finite frame is bland if and only if it is partitional.
Proof. From Propositions 1-4. ▪
Remark. The proofs of Propositions 1-3 and 5 use non-uniform distributions: P({x}) ≠
P({y}) for some x, y∈W (for finite frames, uniformity entails regularity). This is essential, in the sense that if 'bland' had been defined with 'uniform' in place of 'regular' then the analogues of
Propositions 1-3 would have been false. A non-partitional frame <W,R> can satisfy the equation P(X) = w∈W P({w})P(X|R(w)) for every X ⊆ W when P is the uniform distribution on W. To see this, let W = {0, 1, 2} and R =
{<0,1>, <1,2>, <2,0>}. Thus R(0)={1}, R(1)={2}, R(2)={0}, and R is serial but neither reflexive, symmetric, nor transitive on W. Let P be the uniform distribution on W; P({0}) = P({1}) = P({2}) =
1/3. Nevertheless,
∑w∈W P({w})P({y}|R(w)) = ∑w∈W P(X|R(w))/3
= P(X ∩ {1})/3P({1}) + P(X ∩ {2})/3P({2}) + P(X ∩ {0})/3P({0})
= P(X ∩ {1}) + P(X ∩ {2}) + P(X ∩ {0})
= P(X).
Of course, the examples in the main text show that not every finite serial frame is bland even in this weakened sense.
Now say that a frame <W,R> is banal just in case it is serial and P(X|{w∈W:P(X|R(w))=c})
= c for every real number c, subset X of W and regular probability distribution P on W such that the conditional probability is defined (i.e. P(X|R(w))=c for some w∈W). Banality is a form of Miller's
Principle or the Principal Principle.
Proposition 6. A finite frame is banal if and only if it is partitional.
Proof. Suppose that <W,R> is a finite partitional frame, X ⊆ W and P is a regular probability distribution on W. If wR x then R(w)=R(x) since R is an equivalence relation, so
P(X|R(x))=c if P(X|R(w))=c. Thus, if the conditional probability is defined,
{w∈W: P(X|R(w)) = c} = R(w1) ∪…∪ R(wn)
where the R(w i ) are pairwise disjoint and P(X|R(w i ))=c for 1≤ i≤ n. Thus
P(X ∩ R(wi)) = cP(R(wi))
for 1≤ i≤ n. Hence
P(X ∩ {w∈W: P(X|R(w)) = c}) = P(X ∩ (R(w1) ∪…∪ R(wn))
= ∑1 ≤ i ≤ n P(X ∩ R(wi))
= c∑1 ≤ i ≤ n P(R(wi))
= cP(R(w1) ∪…∪ R(wn))
= cP({w∈W: P(X|R(w)) = c}).
Thus P(X|{w∈W:P(X|R(w))=c}) = c.
Conversely, suppose that <W,R> is a finite banal frame. Let W = {w 0 ,. . . , w m }. There is a regular probability distribution P on W such that:
P({wi}) = 2i/(2m + 1 – 1)
(1 ≤ i ≤ m)
Thus for all X,Y ⊆ W, P(X) = P(Y) only if X = Y. Suppose that xR y. Let c = P({y}|R(x)).
Since y∈R(x), c>0 and P({y}) = cP(R(x)). Now suppose that P({y}|R(w)) = c. Since c>0, y∈R(w), so P({y}) = cP(R(w)). Hence cP(R(w)) = cP(R(x)); since c>0, P(R(w)) = P(R(x)), so R(w)) = R(x). Conversely, if R(w) = R(x) then
P({y}|R(w)) = P({y}|R(x)) = c. Thus:
{w: P({y}|R(w)) = c} = {w: R(w) = R(x)}
Hence:
P({y}|{w: R(w) = R(x)} = P({y}|{w: P({y}|R(w)) = c}) = c = P({y}|R(x))
because <W,R> is banal. By reasoning as above, {w:R(w)=R(x)} = R(x). Since <W,R> is serial (because banal), this conclusion holds for all x∈W. Thus wR x if and only if R(w)=R(x); since the latter equation defines an equivalence relation, <W,R> is partitional. ▪ Appendix 5 A Non-Symmetric Epistemic Model
A creature stores information in sentential form. Its language L has two atomic sentences H
('It is hot') and C ('It is cold'), the logical constants ~ and & with their usual interpretations, and the unary sentence functor K ('I know that . . . '). Let <A> be the proposition expressed by the sentence
A on this interpretation, and W = {w 1 , w 2 , x}. In order to specify which sentences are stored in which worlds, recursively define an auxiliary function φ from L to W:
φH
= {w1}
φC
= {w2}
φ~A = W – φA φ(A & B) = φA ∩ φB
φKA = φA if x ∈ φA
= {} otherwise.
Let the creature be so connected to its environment that for all y∈W and A∈L:
# It is disposed in y to store A if and only if y ∈ φKA.
For example, since φ~ C = {w 1 , x}, φK~ C = {w 1 , x}, so it is disposed to store ~C in w 1
and x but not in w 2 . Since φKC = {}, it is not disposed to store C in any world. Thus # agrees with the example in section 10.6 on the storage of information about whether it is cold; likewise for information about whether it is hot.
We can argue plausibly that φA is the set of worlds in which <A> is true. The argument is by induction on the complexity of A. The only non-routine case is the induction step for K. The induction hypothesis is that φA is the set of worlds in which <A> is true. Since the clause for φKA
implies that φKA φA, # implies that A is stored only in worlds in φA. Thus, by the induction hypothesis, the creature is disposed to store A only when <A> is true. We can therefore reasonably suppose that if the creature is disposed to store A then it knows <A>. Conversely, if it is not disposed to store A, then it does not know <A>. But <KA> is true if and only if it knows <A>. Thus
<KA> is true if and only if the creature is disposed to store A. It follows by # that φKA is the set of worlds in which <KA> is true. This completes the induction step. ▪
Given that φA is the set of worlds in which <A> is true, the definition of φ recursively specifies the truth-conditions of sentences of L. One can easily check that its results coincide with those of a semantics in possible worlds style, using the accessibility relation in the diagram in section 10.6. Since the accessibility relation is reflexive and transitive, every theorem of the modal system S4 is true in every world, when □ is replaced by K and propositional variables by arbitrary sentences of L. Consequently, the creature knows every logical consequence of what it knows; moreover, whenever it knows p, it knows that it knows p. But sometimes, when it does not know p, it does not know that it does not know p. That is because it cannot survey the totality of its knowledge. It is a failure of self-knowledge, not of rationality in any ordinary sense. Appendix 6 Distribution Over Conjunction
There are two obvious ways of trying to approximate an operator O which lacks a feature F
by an operator with F. One is to seek the weakest operator O+ stronger than O which has F; the other is to seek the strongest operator O- weaker than O which has F. Of course, there is no general guarantee that either O+ or O- exists. However, when F is the feature of distributing over conjunction, we can define both O+ and O- in terms of O by quantifying into sentence position.
Formally, we use a binary sentence operator Con, where Con(p, q) is true if and only if p is semantically a conjunct of q. We understand this in such a way that all of the following are true:
∀p∀q □Con(p, p & q)
∀p∀q □Con(q, p & q)
∀p∀q □(Con(p, q) ⊃ (q ⊃ p))
∀p □Con(p, p)
∀p∀q∀r □((Con(p, q) & Con(q, r)) ⊃ Con(p, r))
The operator O distributes over conjunction if and only if ∀p ∀q □ (Con(p, q) ⊃ (O q ⊃ O p)) is true. O is factive if and only if ∀p □ (O p ⊃ p) is true. The operator O 1 entails the operator O 2 if and only if ∀p □ (O 1 p ⊃ O 2 p) is true. We assume that ∀p commutes with □, i.e. that the Barcan formula and its converse hold; this is in effect to assume that it is not contingent what propositions there are.
We define the operators O+ and O- thus: O+p = def ∀q(Con(q, p) ⊃ Oq) O-p = def ∃q(Con(p, q) & Oq)
We first show that O+ is the weakest operator at least as strong as O to distribute over conjunction. More precisely, we show: O+ entails O; O+ distributes over conjunction; if an operator O* entails O and distributes over conjunction then O* entails O+. O+ entails O because Con is reflexive. O+ distributes over conjunction because, given O+ p and Con(q, p), we can derive O+ q since Con is transitive. Now suppose that O* entails O and distributes over conjunction. We show that O* entails O+. Assume O* p. Given Con(q, p) we have O* q because O* distributes over conjunction, so we have O q because O* entails O. Hence +
+
* entails O , as required. We also note that, since O+ entails O, O is factive if O is. ▪
Given that K is factive, we can construct a Fitch-style argument from ∀p(p ⊃ ◊K+ p) to ∀p(p ⊃ K+ p). Since K+ entails K, that yields an argument from ∀p(p ⊃ ◊K+ p) to ∀p(p ⊃ K p).
Since ∀p(p ⊃ K p) is absurd, we must deny ∀p(p ⊃ ◊K+ p): a proposition can be true even if it is impossible to know all its conjuncts.
We now show that O- is the strongest operator at least as weak as O to distribute over conjunction. More precisely, we show: O entails O-; O- distributes over conjunction; if O entails an operator O* that distributes over conjunction then O- entails O*. O entails O- because Con is reflexive. O- distributes over conjunction because, given O- p and Con(q, p), we can derive O- q since Con is transitive. Now suppose that O entails O* and O* distributes over conjunction. We show that O- entails O*. Assume O- p. Hence we can assume Con(p, q) and O q for some q. We have O* q because O entails O*, so we have O* p since O* distributes over conjunction.
Consequently, O- entails O*, as required. We also note that since conjunctions entail their conjuncts, O- is factive if O is. ▪
Given that K is factive, we can construct a Fitch-style argument from ∀p(p ⊃ ◊K- p) to ∀p(p
⊃ K p). Since K entails K-, that yields an argument from ∀p(p ⊃ ◊K p) to ∀p(p ⊃ K- p). The conclusion says that every truth is a conjunct of a known truth. Since that is false, we must deny ∀p(p ⊃ ◊K p).
Are K+ and K- well-defined? More specifically, does the quantification into sentence position create some kind of impredicativity, circularity, or paradox? We may suppose that a formula is interpreted by being assigned a subset of a set I as its semantic value. We can think of I as a set of possible worlds, indices, or the like, and the set assigned to a formula as the set of such items at which it is true. If a is an assignment of subsets of I to formulas, then a(∀pΦ(p)) is the intersection of a*(Φ(p)) for all such assignments a* differing from a on sentence letters at most over p. Similarly, a(∃pΦ(p)) is the union of a*(Φ(p)) for all such assignments a* differing from a on sentence letters at most over p. Such a semantics is formally unproblematic. The only danger is that it may yield a rather coarse-grained interpretation of Con and K. For example, we might say that a(Con(A, B)) is I if a(A) is the intersection of a(B) and some subset of I; otherwise a(Con(A, B)) is {}. But then a(Con(A, B)) is I if and only if a(A) is a subset of a(B); in effect, all consequences are treated as conjuncts. Thus to deny ∀p(p ⊃ ◊K+ p) is in effect to say that a proposition can be true even if it is impossible to know all its consequences. The falsity of ∀p(p ⊃ K- p) is in effect the existence of a truth that is a consequence of no known truth. A finer-grained semantics might be desirable, but might raise problems for the semantics of the quantifiers.
Nevertheless, the results under the coarse-grained semantics are already highly unfavourable to the verificationist conception.

Preface
Although the occasion for this book was recent, it came as a welcome opportunity to explain and explore the confluence of two lines of thought about philosophical methodology on which I had been brooding separately for much longer. They correspond to the two words conjoined in the title, 'overfitting' and 'heuristics'.
In April 2020 I received an email from Larry Temkin with an invitation to give the Rutgers Lectures in Philosophy once COVID-19 permitted. I was delighted to accept, and finally gave the three lectures at Rutgers in September 2022. They grew into the first three chapters of this book.
The two earlier lines of thought developed thus:
Overfitting. As an undergraduate at Oxford in the mid-1970s, studying mathematics and philosophy, I remember feeling disgust at the ugly, messy, ad hoc complications of the analyses many contemporary philosophers seemed content with. They contrasted sharply with the elegant, powerful, well-motivated definitions central to logic and mathematics. I knew how unlikely one was to make significant progress if one started from bad definitions. In a space of abstract structures, a sense of form functions as a compass; without it one wanders, lost. My paradigm of a philosopher guided by a strong aesthetic sensibility has always been Plato; in his own metaphor, he understood the need to cut at the joints.
I wrote my DPhil thesis on approximation to the truth (1976–
80), inspired by Karl Popper's failed conception of verisimilitude.
Of my philosophical contemporaries at Oxford, I was closest to the late Peter Lipton, whose DPhil thesis on inference to the best explanation later became a classic book on the topic (Lipton 1991).
Loveliness (his preferred term) as a criterion for a good explanation was a familiar theme in our conversations. Already then, what is now called a broadly abductive methodology struck me as the only viable approach to philosophical theorizing, despite the opposition of my final supervisor, Michael Dummett. In my book on vagueness (Williamson 1994), the case for an epistemicist theory is fundamentally abductive. Alternatives to classical logic and bivalent semantics are not dismissed as ultimately nonsensical; they are just inferior theories, judged by normal scientific standards. In Knowledge and Its Limits (Williamson 2000), I treat attempts to analyse knowledge, causation, meaning, and so on in more basic terms like Ptolemaic astronomy, to which new epicycles must continually be added to fix up anomalies. To invoke Imre Lakatos's useful category, many philosophers seemed unable to recognize a degenerating research programme when they saw one.
Oddly, the first edition of The Philosophy of Philosophy (Williamson 2007) mentions abductive methods only in passing. The reason was not any temporary loss of confidence in them but simply that my main concern was to correct more basic misconceptions about philosophical questions and evidence in philosophy. Once the book was published and I had to answer frequently asked questions about my positive view of philosophical methodology, I found myself giving centre stage to abduction and soon wished I had discussed it properly in the book, rather than leaving it to do its work offstage. I later started to fill the gap with articles on abductive theory comparison in philosophy (Williamson 2016c, reprinted in the second edition of The Philosophy of Philosophy) and in logic (Williamson 2017b).
In particular, classical logic is unrivalled in its combination of simplicity, strength, and fit with evidence.
Around that time, inspired by a seminal paper by Malcolm Forster and Elliott Sober (1994), I started connecting over-complication as an abductive vice in philosophical theories with overfitting as a recognized pathology in the natural and social sciences, where it prototypically manifests as profligacy with degrees of freedom in fitting quantitative data: at each stage, an equation with many parameters closely fits the data so far but makes bad predictions about new data, and so is replaced by a new equation with even more parameters that closely fits the old and new data so far, and so on. Of course, the data in philosophy are rarely quantitative, so the specific mathematical results that Forster and Sober use to justify tight limits on degrees of freedom are not relevant to philosophy. Nevertheless, one can recognize a similar pattern in philosophical programmes of analysis, with accepted verdicts on real or hypothetical cases as the data and proposed analyses of the target term in place of equations. At each stage, a complicated analysis fits the accepted verdicts on the cases so far, but makes bad predictions about new cases, and so is replaced by a new, even more complicated analysis that fits the accepted verdicts on the old and new cases so far, and so on.
As a reality check, I have taken to asking scientists whom I find myself sitting next to at a meal whether overfitting is a problem in their research area. In my experience, they are all familiar with overfitting, both the word and the pathology, and can get quite worked up denouncing the practice. Their understanding of it is informal, not narrowly mathematical: they see overfitting as a lazy-minded way of describing a data set without gaining theoretical insight into what is really going on. Of course, on an informal understanding of overfitting, one cannot expect an algorithm for determining what counts and what does not. It takes experience and good judgment to determine in a particular case how many degrees of freedom are too many, how much complication is too much. So understood, overfitting in philosophy is possible, and indeed actual. It is therefore cause for concern how many philosophers have never even heard of overfitting and how few are on the alert for it as a danger in philosophical theorizing. One aim of this book is to do some consciousness-raising. There is a gap in the story so far. The main reason why overfitting in natural and social science leads to bad predictions is that it is too respectful of occasional erroneous data points, which are almost certain to arise in large data sets, if only through random noise.
Such errors are then built into an overfitted equation. To complete the analogy with overfitting in natural and social science, we need to understand how errors can arise in philosophers' accepted case judgments. Such judgments are sometimes even assigned a quasi-definitional status. In The Philosophy of Philosophy, my focus was on showing that accepted verdicts on hypothetical cases in philosophy are in effect just ordinary judgments of counterfactual conditionals and can be known in the same ordinary ways: appeals to conceptual truth, philosophical intuition and so on are obscurantist and miss the point. Although such an anti-exceptionalist account supports the generic expectation that accepted case judgments in philosophy will be subject in principle to ordinary human error, it does not supply details. Will the errors be just occasional random noise, or are they more systematic? How big is the problem?
The most high-profile attempt to show that accepted case judgments in philosophy are unreliable has been the 'negative program' of experimental philosophy, which tried to show that judgments on given cases vary with factors irrelevant to their truth, such as ethnicity, gender, and the order of the questions, using the methods of social psychology. However, in recent years, the negative program—though not experimental philosophy itself—has largely run out of steam. Many of its signature results turned out not to be repeatable, once the experiments were done with proper controls. In other cases, experiments were poorly designed because subjects were asked questions involving words used as technical terms in philosophy. Indeed, there is increasing evidence that many of the crucial case judgments are more like human universals.
Meanwhile, general epistemological arguments for the negative program implicitly supported more general forms of scepticism inimical to science, contrary to their proponents' intentions. This book does not discuss the negative program in detail; the first edition of The Philosophy of Philosophy contains an initial critique of it, the 2021 edition supplies more specific and extensive objections, and I prefer not to repeat myself.
However, the negative program is not the only threat to the reliability of accepted case judgments. The second line of thought leading to this book concerns a potential source of error in case judgments even when they are humanly universal.
Heuristics. In The Philosophy of Philosophy, another role for our ordinary capacity to know counterfactual conditionals is in explaining our knowledge of metaphysical modality—necessity, contingency, possibility, impossibility. In a standard combined logic for counterfactual conditionals and modal operators, something is necessary if and only if its negation counterfactually implies a contradiction, and similar equivalences hold for the other modal operators. Thus, if your cognitive system has the power to handle counterfactual conditionals, it also has the power to handle modal operators. This does not require it to define the latter in terms of the former; it just needs to handle them alike.
The equivalences are validated by standard semantic accounts of modal operators and counterfactual conditionals in a framework of possible worlds. They can also be derived by standard modal logic from two plausible and more general linking principles: first, whatever is necessarily implied is counterfactually implied; second, no possibility counterfactually implies an impossibility. So far, everything fits nicely together. Integral to this picture is the vacuous truth of counterpossibles: any counterfactual conditional with an impossible antecedent is true. That follows from the first linking principle by standard modal logic, for an impossibility necessarily implies anything. Semantically, no world is a counter-instance to a counterfactual conditional whose antecedent is false at every world.
Around 2004, in the run-up to The Philosophy of Philosophy,
I started presenting this material in talks on the epistemology of modality. One feature of the reactions slightly took me aback: the vehemence with which many able philosophers rejected the vacuous truth of counterpossibles, on the basis of what they took to be decisive counterexamples, obviously false counterpossibles. The alleged counterexamples themselves did not surprise me. Of course, pre-reflectively, some counterpossibles—such as 'If there were a largest prime, it would make no difference to mathematics'—struck me (and still strike me) as repugnant. What I found naïve or frivolous was the confidence with which carefully developed, elegant and powerful logical and semantic theories were thrown out on the basis of such uncritically accepted first impressions. It only got worse when cumbersome, feeble, and unexplanatory alternatives such as semantic frameworks of impossible worlds were invoked as substitutes to vindicate whatever the first impressions happened to be. In teaching logic to clever students, one spends much of one's time explaining how plausible-sounding objections to standard theorems are subtly mistaken. In present terminology, I regard
'counterexamples' to the vacuous truth of counterpossibles as clear cases of overfitting.
Still, an explanatory task remains. Why do the 'counterexamples' seem so compelling? It is surely not just a brute psychological fact. I noticed two features of typical alleged examples of false counterpossibles. First, they are rejected on the basis of what seems to be very shallow cognitive processing: the judgment is immediate, and the antecedent's impossibility plays no apparent role.
After all, they are presented as obvious counterexamples. Second, the opposite counterpossible is found obviously true, where opposite counterfactuals have the same antecedent and mutually contradictory consequents, as in 'If p were true, q would be true' and 'If p were true, q would be false'. For example, we accept the counterpossible 'If there were a largest prime, it would make a difference to mathematics' without needing to consider whether its antecedent is impossible or just contingently false. We just think how much actual mathematics involves the infinity of primes. This suggests the hypothesis that we treat opposite counterfactuals as mutually inconsistent, so, having accepted one, we immediately reject the other.
Opponents of the vacuous truth of counterpossibles might respond that we treat opposite counterfactuals as mutually inconsistent because they are mutually inconsistent; so two opposite counterpossibles cannot both be true. However, the principle does not fit our practice in full generality. For, on the equally obvious-seeming principle that a conjunction counterfactually implies its conjuncts, we accept both 'If the Russell set were a member of itself and not a member of itself, it would be a member of itself ' and 'If the Russell set were a member of itself and not a member of itself, it would be not a member of itself ', which are opposite counterfactuals. The mutual inconsistency of opposite counterfactuals is also hard to reconcile with their natural use to articulate arguments by reductio ad absurdum, when we refute the hypothesis h by proving (for some q) both 'If h were true, q would be true' and 'If h were true, q would be false'.
I therefore proposed treating the mutual inconsistency of opposite counterfactuals as a heuristic in the psychologists' sense: a cognitive shortcut, reliable in most but not all cases. I generalized it to the mutual inconsistency of counterfactuals with the same antecedent and contrary consequents, which need not be contradictory, such as 'If Maria were in Europe, she would be in Italy' and 'If Maria were in Europe, she would be in Spain'. We often rely on heuristics without realizing that we are doing so, for example, when they are built into our unconscious perceptual processing.
I argued that apparent examples of false counterpossibles are artefacts of our unconscious reliance on the heuristic for mutual inconsistency of counterfactuals. It fails only for counterpossibles; since few counterfactuals are counterpossibles, it is quite reliable. Those who take themselves to be refuting the vacuous truth of counterpossibles have been suckered by their own heuristics (Williamson 2017c, 2018b). However, postulating one heuristic for handling the special case of counterfactuals with the same antecedent and contrary consequents left me in an unstable position. The heuristic leads you, having accepted one counterfactual, to reject other counterfactuals related to it in the special way, but it does not lead you to accept any counterfactual in the first place. It is useful only if you already have some other way of cognitively assessing counterfactuals and accepting or rejecting them. But if you have that other way, why do you need the heuristic for the special case?
Fortunately, the special heuristic hinted towards a much broader generalization. For simplicity, take the analogous case for plain conditionals, without 'would'. Compare 'If A, C' and 'If A, C*', where C and C* are contraries. Suppose A. On that supposition, we have C and C*, an inconsistency. By the analogous special heuristic for plain conditionals, we project that inconsistency conditional on A onto an unconditional inconsistency between the corresponding conditionals with antecedent A. The general rule is to project an assessment of C1, . . . , Cn on the supposition A onto the same assessment outright of the conditionals 'If A, C1', . . . , 'If A, Cn'. In particular, for n =1, 'If A, C' is assessed outright as C is assessed on the supposition A. Thus, we accept 'If A, C' outright when we accept C on the supposition A, and we reject 'If A, C' outright when we reject C on the supposition A.
A similar pattern applies to counterfactual conditionals, with a slightly different style of assessment appropriate to counterfactual suppositions, which are more 'distanced' from reality. From this general heuristic, one can then recover the original principle that opposite counterfactuals are mutually inconsistent as a special case.
This large step of generalization is not meant as a compelling argument. It just explains how natural it was for me to reach the hypothesis of a simple, general, supposition-based heuristic for assessing conditionals. The hard work was then to show in detail how postulating such a heuristic explains our assessment of conditionals.
I did that work in my book Suppose and Tell: The Semantics and Heuristics of Conditionals (Williamson 2020a). Once I had the central idea, I wrote the book quickly, because everything fell into place much more smoothly and neatly than I had anticipated.
The suppositional heuristic was by no means a completely new idea. It is closely related to a seminal suggestion by Frank Ramsey about how we assess conditionals, known as the 'Ramsey test'. It is also reminiscent of the attractive, much-discussed, but problematic idea that the probability of a conditional should be the conditional probability of its consequent on its antecedent. More generally, it explains the central role of imagination in our assessment of conditionals, because the natural human way to develop the consequences of a supposition is by a reality-constrained exercise of the imagination. Indeed, that is arguably the main cognitive function of the imagination (Williamson 2016e). In turn, much of the cognitive value of using conditional words like 'if ' is that they enable us to extract, articulate, and communicate information embedded in our experientially informed ways of developing suppositions, which are 'offline' analogues of our capacities for updating our expectations about the future 'online'.
Attempts to build such ideas about conditionals directly into their semantics had led to disaster, as shown by various impossibility theorems proved by David Lewis and others. In brief, the unqualified suppositional test is inconsistent in various ways, both in itself and with uncontentious background knowledge. From my perspective, those results showed, not that the ideas should be abandoned but that their plausibility comes from their match to the heuristics, not to the semantics, of conditionals. An inconsistent test can give correct results most of the time, but it cannot be valid.
Since the basic cognitive role of the imaginative assessment of conditionals makes it likely to be a human universal, it constitutes a potential source of error in our case judgments of conditionals which the usual methods of experimental philosophy would not pick up. In postulating a general heuristic for conditionals, I have encountered far more resistance from semanticists in both philosophy and linguistics than I have from psychologists and psychologically informed philosophers. The latter groups' reaction seems to be: 'Of course we rely on heuristics in assessing conditionals, just as we do in other cognitive tasks—how else would we do it? The question is which heuristics we use.' By contrast, semanticists are more likely to question the need for an intermediate level of heuristics between the semantics and our assessments of particular conditionals in particular contexts. It is as if the semantic evaluation of the conditional in the context is transparent to competent speakers and hearers, cognitively effortless; they can read off its semantic status directly.
Although it would be uncharitable to accuse semanticists of really believing that, I often find them reluctant to admit that the cognitive task might be hard enough to require heuristics. They seem understandably afraid that admitting the role of heuristics risks losing them their data, since common native speaker assessments of sample sentences will no longer be reliable. But such fears are over-pessimistic. The natural sciences have operated for centuries with less than fully reliable data and have found ways to manage the risks.
Aversion to overfitting is one of those ways. Significantly, contemporary semantics shows increasing signs of overfitting, with very complicated semantic clauses for common words (such as 'if '), and little sense that adding new parameters of semantic evaluation might have a cost in degrees of freedom. I have even seen simplicity as a criterion of theory choice incredulously rejected as quite alien to semantics. In Suppose and Tell, I argue that the 'paradoxes' of material implication and even more apparently decisive counterexamples to the simplest semantics for 'if ', as a material conditional, are just artefacts of the suppositional heuristic, and that the material interpretation makes the best overall sense of our total practice of using conditionals, for example, to store and communicate information.
When writing the conditionals book, I naturally wondered what role heuristics might be playing in other philosophical problems. Unsurprisingly, my thoughts turned to the problem of vagueness.
I saw how the tolerance principles for vague terms which serve as major premises in sorites paradoxes can be understood as artefacts of a labour-saving heuristic. That some philosophers classify them as 'analytic' or 'conceptual connections' just indicates the poverty of the received list of options for general principles. It needs to be expanded with 'heuristic' as another option. To emphasize its generality, I added a few pages on tolerance principles as heuristics to
Suppose and Tell. I even showed how to estimate their reliability in some cases: although tolerance principles generate paradoxes, in almost all instances they are truth-preserving. Subsequently, I realized that tolerance principles are just special cases of a much more general heuristic which is neither specific to vague terms nor merely labour-saving, but is instead practically unavoidable, as I explain below (chapter 1.3).
Other candidates for philosophically significant heuristics are also mentioned in the conditionals book, such as disquotational principles for truth and falsity: in continual use but responsible for the Liar and other semantic paradoxes.
Around the 1970s, the default front cover design for books of analytic philosophy showed a paradoxical image by the artist M. C. Escher. Philosophical paradoxes were analogized to visual illusions.
Fallible heuristics built into our visual systems generate visual illusions; fallible heuristics built into our more general cognitive systems generate philosophical paradoxes. This book expands the project of tracing the role of heuristics in producing both genuine and illusory knowledge.
In deciding what to lecture on at Rutgers, I also had in mind a specific application of the general ideas about overfitting and heuristics:
Hyperintensionality. Studying philosophy at Oxford in the 1970s, I grew up in an environment where familiarity was assumed with the modal-metaphysical theorizing of Saul Kripke, David Lewis, and many others, even though such theorizing was regarded as suspect by still-influential figures of an older generation such as Michael Dummett and Donald Davidson. Of all these thinkers, Kripke impressed me most. He was unquestionably the best logician, and also, despite his day-to-day unworldliness, the philosopher most in touch with common sense realism. Even for those of my generation with different philosophical loyalties, 'Naming and Necessity' (at first the article version, Kripke 1972) was a central text in metaphysics, philosophical logic, the philosophy of language, and to some extent the philosophy of mind.
Older critiques of the Kripkean modal approach usually accused it of manufacturing illusory metaphysical distinctions, for instance, between the necessary and the a priori, or the essential and the accidental: in short, of making reality too subtle. By contrast, newer critiques of the approach increasingly accused it of neglecting more fine-grained metaphysical distinctions: in short, of making reality not subtle enough. For example, the possible worlds apparatus was well suited to defining relations of supervenience between families of properties, so one could claim that mental properties supervened on physical properties. By the 1980s, a commonly heard complaint in discussions of the mind-body problem was that the modal nature of supervenience made it unsuitable for capturing the sense in which, it was alleged, physical properties determine mental properties whereas mental properties do not determine physical properties; the challenge was to clarify the nature of such asymmetric determination. We were also uneasily aware of Elliott Sober's causal argument that some necessarily co-extensive properties are distinct (Sober 1982). Those were straws in a wind blowing towards what is now called hyperintensional metaphysics.
I first became aware of hyperintensional metaphysics as a systematic trend in 1992, when Kit Fine presented an early version of his seminal paper 'Essence and Modality' (Fine 1994) to a discussion group in Oxford, arguing for a non-modal conception of essence which distinguished between the necessarily co-extensive properties of being Socrates and being a member of the singleton set {Socrates}. I felt the power of Fine's examples. As his work developed, I also felt suspicious of the proliferating distinctions. They were not exactly unmotivated, but their motivation felt rather flimsy. In present terms, there was a whiff of overfitting. However, since I was working on other topics, mainly in epistemology, I could take a wait-and-see attitude, content to judge hyperintensional metaphysics by its explanatory fruits. A new research programme, ably pursued, deserves time and space to demonstrate its potential.
As the years passed, and hyperintensional metaphysics spread more widely, my scepticism increased. Instead of deriving many phenomena from a few simple laws, it seemed to derive a few phenomena from many complex laws. Still I did not engage with it, though in Modal Logic as Metaphysics (Williamson 2013a) I said, rather peremptorily, that only representational matters are hyperintensional. Finally, once my thoughts on overfitting and heuristics were sufficiently developed, I felt in a position to give a proper methodological critique of hyperintensional metaphysics.
I could propose a psychologically plausible heuristic to explain data points of the kind typically presented as decisive counterexamples to merely intensional metaphysics, and why the heuristic is unreliable in such cases. I could also point to many signs of overfitting in the semantic frameworks used to make sense of hyperintensional theorizing.
Admittedly, I had previously assumed a hyperintensional treatment of representational phenomena, such as ascriptions of propositional attitudes. I had long rejected the Fregean distinction between sense and reference, because it is so ill-suited to the needs of natural language semantics, and, even in an individualistic setting, interposing a level of sense between the level of expressions and the level of reference does not pay its way in explanatory rewards. For many years, I envisaged a framework of Russellian structured propositions—complexes of the objects, properties, and relations they are about—as a reasonable compromise, with an unspecified fix for Russell-Myhill paradoxes. Robert Stalnaker's austerely intensionalist treatment of propositional attitudes as relations to sets of possible worlds seemed hopelessly coarse-grained, and his metalinguistic strategy for handling non-contingent discourse broke down. However, I realized that my preferred strategy for tracking cognitive significance in Frege cases of unrecognized co-reference—by relativizing attitudes to guises of propositions—in principle works just as well for intensional propositions as for structured ones. I gradually came to the conclusion that the huge extra complexity of a framework for structured propositions is not adequately compensated by the opportunity to do without guises in some but not all Frege cases. A better bargain is the simplicity of intensional content—which shares a common framework with both probabilistic approaches and epistemic and doxastic logic—combined with a willingness to relativize to guises (to which we are independently committed anyway) whenever we need to distinguish between different forms in which the same content can recur.
A rough analogy: sometimes we can just make calculations about point masses; sometimes we must acknowledge that planets are more complicated than that.
This book is organized into five chapters:
Chapter 1, 'Heuristics', grew out of the first Rutgers lecture. It first discusses the nature of heuristics. It then describes several general heuristics and explains both why they are useful and how their limitations generate philosophical paradoxes. It concludes by assessing the implications for philosophical methodology of our unreflective reliance on such heuristics, arguing that they require a more sophisticated attitude to our data but do not justify scepticism. After all, fallible heuristics are built into our sensory systems and sometimes generate perceptual illusions, but that does not mean that scientists should stop using sense perception. Chapter 2, 'Overfitting and Degrees of Freedom', grew out of the second Rutgers lecture. It first discusses the nature of overfitting, why it is a pathology, and why natural and social scientists emphasize the need for limiting degrees of freedom. It then describes apparent cases of overfitting in philosophy, especially in semantics, logic, philosophical analysis, and philosophical model-building, and discusses why philosophers may have stayed unaware of the danger. It emphasizes the need for philosophers' practice to be better informed by reflective awareness of abductive methodological constraints.
Chapter 3, 'Case Study: Hyperintensionalism', grew out of the third Rutgers lecture. It first discusses the nature of the distinctions between extensionalism, intensionalism, and hyperintensionalism, and how they map onto developments in the history of analytic philosophy. It then considers three frameworks for hyperintensional semantics, involving impossible worlds, truthmakers, and Russellian structured propositions, respectively, explaining their problems and in particular the extent to which they exhibit overfitting. Finally, a natural new heuristic is postulated to explain the case judgments underpinning typical 'counterexamples' to intensionalism. The heuristic is shown to generate errors in cases closely related to the alleged counterexamples, which are therefore not probative.
The final section adapts and develops some material from my lecture to celebrate the 25th anniversary of the journal Disputatio, delivered online to an audience in Lisbon in October 2021 and published as 'Degrees of freedom: is good philosophy bad science?',
Disputatio, 13, 61 (2021): 73–94.
Chapter 4, 'Frege Puzzles', does not correspond to any of the Rutgers lectures but is included because it fills out my account of apparent hyperintensionality by discussing propositional attitude ascriptions. In particular, it shows how Kripke's article 'A Puzzle about Belief ' (Kripke 1979) can be read against his intentions as pointing towards a fallible heuristic for ascribing belief and its absence. This leads to a discussion of heuristics for ascribing other attitudes and shows how Frege puzzles can be understood as manifesting the fallibility of those heuristics.
Much of the chapter uses material from my previously published article 'Epistemological consequences of Frege puzzles',
Philosophical Topics, 49 (2021): 287–319, though with elimination of overlaps and significant revision. I have also added a section on heuristics for knowledge ascription, based on a section of my chapter 'Where did it come from? Where will it go?' in Arturs Logins and Jacques Vollet (eds.), Putting Knowledge to Work: New Directions for Knowledge-First Epistemology (Oxford: Oxford University Press, forthcoming), and modified the conclusions accordingly. Parts of section 4.10 and all of sections 4.11–12 are new.
Chapter 5, 'Intensional Metametaphysics', also does not correspond to any of the Rutgers lectures but is included because it fills out my account of apparent hyperintensionality in inquiries into non-contingent matters, mainly metaphysics, but logic and mathematics too. It argues that attempts to reinterpret such inquiries because they do not admit of non-trivial, substantive truths rest on a misdiagnosis of the problem and an underestimation of its generality. The underlying issue is not necessary truth but necessary equivalence, irrespective of the modal status of the equivalent propositions. It is just another manifestation of the coarse-grained consequences of intensionalism, and must be handled in the usual way. Metalinguistic reinterpretations of the relevant sentences do not work, but relativization to linguistic guises does. One should not conclude anything special about metaphysics, logic, or mathematics.
Most of the chapter uses material from my previous published article 'Metametaphysics and semantics', Metaphilosophy, 53: 2-3 (2022): 162–175, though with elimination of overlaps and significant revision. Acknowledgments
First of all, I thank the Department of Philosophy at Rutgers, for the invitation, and all the hospitality and stimulus provided over the week of my enjoyable stay in New Brunswick. Those most involved in setting up, organizing, and running the events were Larry Temkin, Karen Bennett, and Dean Zimmerman. Unsurprisingly, the book has gained much from all the valuable constructive questions and comments from numerous members of the audiences at the lectures and participants in other discussions at Rutgers, formal and informal.
I thank Peter Ohlin of Oxford University Press (New York) for being such a supportive and efficient editor, a pleasure to deal with.
My wife Ana Mladenović Williamson kept the show on the road as always throughout the writing of this book.
In the period from writing rough drafts of the Rutgers lectures in August 2022 to submitting the final version of the book to Oxford University Press in October 2023, I have presented parts of the material at numerous events. Two of the most extensive presentations, in several sessions, both in the first half of 2023, were to a class at Yale University and a class at the University of Oxford. I also gave talks on parts of the material at a conference in Glasgow of the British Society for the Theory of Knowledge, a workshop at Bochum University on 'Experimental Philosophy and the Method of Cases', and a meeting of the student philosophy society at the University of Italian Switzerland, Lugano (all in 2022), a session of the American Philosophical Association Pacific Division Meeting in San Francisco on 'Modality, Essence, and Ground', three separate events at the London School of Economics (a symposium on Anna Mahtani's fine book Objects of Credence, a workshop, and a meeting of the student philosophy society), a conference at University of St Andrews on 'Analysis: History and Metaphilosophy', a LOGOS Anniversary Conference at the University of Barcelona, and a workshop on 'Higher-Order Metaphysics' at the University of Oxford (all in 2023). I thank participants in all those events who helped improve the book in one way or another—disentangling the causal chains would be an impossible task.
I have also been extremely lucky in the philosophers who have read versions of all or part of the material and given me excellent feedback on it. The three referees for Oxford University Press provided comments of exactly the kind that are most really helpful at a comparatively late stage of the writing process; having agreed to waive their anonymity, they are Cian Dorr, John Hawthorne, and Brian Weatherson. At earlier stages, Jennifer Nagel, Mariona Miyata-Sturm, Daniel Kodsi, Alexander Roberts, and Benjamin Brast-McKie volunteered exceptionally detailed and perceptive written comments on the material in the first three chapters. In being given reactions of this quality from so many people, I feel that
I am experiencing the philosophical community at its best.
Chapters 4 and 5 also inherit earlier acknowledgements from their article ancestors, which can be found in the footnotes to them.
In early October 2023, shortly before submitting the finalized manuscript to Oxford University Press, I gave it a last try-out in a week-long pre-read seminar with faculty and graduate students at the University of Costa Rica in San José, organized by Lorenzo Boccafogli. We did a chapter a day, with several hours of lively, focused discussion on each. The sessions led me to add several passages of further clarification and argument. I write these words in Playa Chiquita, Costa Rica, to an accompaniment of Caribbean forest sounds.
1
Heuristics
1.1 Counterexamples
Counterexamples keep theorists honest. It is easy to regard counterexamples as the epistemological gold standard, as in Karl Popper's falsificationism. But just as there is fool's gold as well as genuine gold, so there are fool's counterexamples as well as genuine counterexamples. And just as all of us can be fooled if we trust our first impressions of apparent gold, so all of us can be fooled if we trust our first impressions of apparent counterexamples.
To check whether something is genuine gold, you can ask to have it tested at your nearest assay office. To check whether something is a genuine counterexample to a philosophical generalization, you can ask to have it tested at your nearest philosophy department, though somehow that sounds less reassuring. You may be disappointed to find that the philosophers' tests hardly go deeper than their first impressions.
Of course, if your local philosophy department is slightly old-fashioned, it may claim to possess a philosopher's stone, which turns base metals into pure gold. The likely mechanism is to reclassify the proffered counterexample as an analytic or conceptual truth, built into the use of the relevant terms. But that will be unsatisfying if the source of the case judgment in question is also the source of other case judgments inconsistent with it. They cannot all be pure gold.
In this book, I will argue that many alleged examples and counterexamples in philosophy are the products of heuristics, which can produce mutually inconsistent case judgments, so we are indeed in the envisaged predicament. The philosophical questions are not usually about the heuristics, and we needn't use the heuristics in asking the questions. But we do rely on the heuristics to generate the data on whose basis we answer the questions. The trouble is that we tend to rely on those outputs uncritically, treating them as data that our theories must fit. When some of the outputs are false, we are liable to dismiss true theories erroneously, as falsified by those counterexamples. The apparent counterexamples may be all too convincing.
The situation is not all bad. If a heuristic produces mutually inconsistent outputs, no theory will be consistent with all of them together. False theories as well as true ones will appear falsified.
Moreover, we may be able to identify what heuristics produced the outputs, and consequently to understand their strengths and weaknesses. That may enable us to handle our data in a more sophisticated and critical way, as other sciences have learnt to do. The occurrence of heuristic-induced errors is not a generic justification for scepticism. Our capacities for knowledge are hard to extricate from our propensities to error. The same cognitive systems enable us, in good cases, to learn how things are, yet, in bad cases, make us misjudge how they are: no risk, no gain. This interdependence of strength and weakness is crucial to the operation of the heuristics integral to so much cognition—human, animal, and artificial.
1.2 What are heuristics?
Roughly speaking, a heuristic is a rule of thumb for solving problems of some type. The application of the rule may be automatic or deliberate; it may be conscious, unconscious, or somewhere in between. Even if it involves conscious activity, one may or may not know what rule one is applying, and one may or may not think of it as a heuristic. Even on reflection, it may not be obvious to us when we are using a heuristic, still less what heuristic it is. The function of a heuristic is to provide a way of solving problems of a given type that is fast, easy, efficient, and reliable enough to be useful. The way must be feasible in real time. It can be reliable enough without being perfectly reliable. Reliability here is equated with the probability that the way provides a correct solution, where the standard of correctness is built into the specification of the problem. For example, sniffing food to check whether it smells bad is a heuristic for determining whether it is still good to eat. Since food can go bad without smelling bad, it is not a fully reliable test, but it is quicker, more convenient, and less expensive than having the food tested in a laboratory. It is more reliable for some foods than for others.
Heuristics are often described as shortcuts. That is roughly right, but we should not assume that there is also a long way round, slower but safer. Sometimes such an alternative is available; sometimes there is none.
Psychologists have studied many heuristics intensively.
Sometimes they characterize heuristics negatively, as 'cheap and dirty', in the tradition of Daniel Kahneman (Kahneman, Slovic, and Tversky 1982), sometimes more positively, as 'fast and frugal', in the tradition of Gerd Gigerenzer (Gigerenzer, Hertwig, and Pachur 2011). At worst, heuristic-based cognition is regarded as a form of irrationality, at best, as a form of bounded rationality. Presumably, some heuristics are better than others, at least for a given purpose under given conditions. We might be better off avoiding some heuristics, but the nature of human cognition—perhaps of finite cognition in general—precludes our avoiding them all.
Heuristics, as understood here, can be culturally acquired, or even idiosyncratic. For example, medical experts—communally or individually—develop heuristics for interpreting X-rays. But many important heuristics are virtually universal to humans.
For example, visual illusions are probably by-products of such heuristics built into the visual systems of humans and other animals (Fleming 2012, Gigerenzer 2021). The heuristics responsible for such illusions are topics for psychological investigation. When heuristics are virtually universal, they may be innately hardwired, or at least the natural outcome of innate domain-general principles and learning mechanisms. Either way, evolutionary adaptiveness will often play a large role in explaining how we have come to use such heuristics. Still, in principle, checking on Google could become a culturally transmitted virtually universal heuristic, whether or not it is evolutionarily adaptive.
One heuristic that often involves conscious thought is take-the-best (Gigerenzer and Goldstein 1996). It is a way to choose between two alternatives for some purpose, given various epistemic cues ranked by 'validity' (how well they indicate optimality for that purpose). Take-the-best tells you simply to follow the highest-ranked cue that discriminates between the alternatives—as opposed, for instance, to somehow constructing and comparing weighted averages over all the cues. Thus, one might simply decide to shop at the nearest supermarket, without having taken into account price, range, or quality of goods. Of course, even when one consciously applies the heuristic, one rarely thinks of oneself explicitly as applying take-the-best.
Often, there is a slower but more accurate alternative to using a given heuristic. For instance, our visual systems routinely treat colour contours as a guide to the shapes of three-dimensional material things. Camouflage succeeds in misleading observers about those shapes by exploiting their reliance on that heuristic. In principle, we can correct such mistakes, for example, by using our sense of touch, though that alternative may be unfeasible in the circumstances, as in time of war. Still, heuristics are in principle, and often in practice, defeasible.
Sometimes no more reliable alternative is available. With take-the-best, one might expect to do better when time permits by consciously 'weighing up all the pros and cons'. But that may be over-optimistic. One may have only the faintest idea how to individuate the relevant considerations, what relative weights to assign them, and how to measure performance on one dimension against performance on another. When I try to take a decision by weighing up all the pros and cons, the result is only to make me vividly aware how open the process is to manipulation in favour of whichever alternative I independently prefer. Indeed, experimental studies suggest that take-the-best is surprisingly reliable, compared to more elaborate methods available to the subjects at the time, where the correct answer is known to the experimenter by some method unavailable to the subjects at the time (Gigerenzer and Goldstein 1996). When many complex ramifications of different kinds really must be taken into account in making a difficult decision, my preferred method is to procrastinate until one morning I wake up knowing what I'm going to do. Conscious reflection passes the buck to unconscious processes, which may do a better job of integrating information from many sources (on the limits of reflection, see Kornblith 2012). In retrospect, that method has served me fairly well. Many other people seem to do likewise.
When we rely on a heuristic without thinking of it as such, and with no conception of a more reliable way of solving the problem, we may mistakenly regard the heuristic's output as indefeasible. For lack of an alternative category to put it in, a philosopher may even call it an 'intuition', an 'analytic truth', a 'conceptual connection', or whatever. That illustrates the poverty of the philosophically current taxonomy and is all the more reason to make room for the category of heuristics in philosophers' working vocabulary. According to Daniel Rothschild, 'heuristics in the psychology literature (such as those posited by Kahnemann and Tversky, including the famous conjunction fallacy) can be overruled by slower, more careful reasoning' (2023: 214). This is of course true in principle. However, take-the-best is a heuristic in the psychology literature that may be hard to overrule, because it is far from obvious to agents that the slower, more careful reasoning involved in reflectively weighing up the pros and cons or the like is more reliable than take-the-best itself.
In discussing heuristics, I have not specified whether being a heuristic entails being less than perfectly reliable, or being above some moderate level of reliability, or whatever. More generally, I will not stipulate a precise definition for the word 'heuristic'. No such definition is needed for present purposes, and at this early stage of inquiry, picking one might even be harmful, by cutting across, instead of along, a cognitive joint. We have a range of more or less paradigm cases of heuristics, as already indicated, and by classifying something as a heuristic we draw attention to its similarities to such cases. For present purposes, that is what matters. Heuristics are typically moderately reliable, but perhaps some perfectly reliable or hopelessly unreliable methods play a very similar psychological role in our lives to paradigm heuristics.
Just as heuristics built into the human visual system produce visual illusions in special circumstances, so heuristics built into the human cognitive system may more generally have the capacity to produce philosophical paradoxes, which can be properly diagnosed only once we identify the heuristics at work. Such heuristics may be very general, but even much more specific heuristics may play a role in generating philosophical paradoxes: for example, heuristics for attributing beliefs to people on the basis of what they say, and heuristics for individuating physical objects on the basis of visual perception.
Naturally, postulating a new heuristic does not come free. For the postulate to be initially plausible, the candidate heuristic should be simple, quick, efficient, and useful. In particular, the problem it solves should crop up often enough to make a solution dedicated to that problem worth our storing it up for future use. Postulating a heuristic is especially plausible when it would be strange if we didn't use something like that heuristic.
Philosophers may be tempted to postulate that what we really use is not the first-proposed crude heuristic but some complex refinement of it, constructed by adding exception-clauses, restrictions, and qualifications, to rule out counter-instances and so enhance its reliability. One should resist that temptation, for the 'refined' heuristic is likely to be psychologically unrealistic, since it increases computational times and costs of application, typically for a comparatively small gain in reliability, and perhaps even a loss in generality. Those increases will be drastic if they require conscious reflection, which is very slow by neural standards, and liable to create a bottleneck in processing. In the midst of action, a prompt, moderately reliable answer usually does better than a very reliable answer when it is too late, or than no answer at all. When over-reflective creatures pause to reflect, they risk being eaten, or at least beaten to scarce resources, by their less reflective predators or competitors. Even in modern life, indecision can lead to disaster.
Of course, philosophers may use the refined heuristic themselves in their consciously controlled theorizing, but they should not attribute it to ordinary pre-reflective human cognition.
In general, what heuristic we use, if any, under given circumstances is a psychological question, open to experimental test. Evolution does not guarantee that our actual heuristics will be the optimally efficient ones. In this chapter, however, the concern will not be with such experimental work, though the need for it in the long run is obvious. The aim here is to clarify our initial theoretical understanding of the potential relevance of specific heuristics to philosophy, rather than to engage 'blind' with the psychological literature. We need to develop theoretical hypotheses properly before we test them, to know what we are looking for.
In the next four sections, I will explain and discuss some plausible candidates for heuristics on which we may be relying, knowingly or unknowingly, when we wrestle with some philosophical problems.
In such cases, we risk getting suckered by our own heuristics.
1.3 The persistence heuristic
Here is a short vignette:
Mary was in London when a man wolf-whistled at her. She took a step towards the man, then slapped him. To check whether a subject has properly understood the vignette, a psychologist might ask this comprehension question:
Where was Mary when she slapped the man?
A natural answer, which the psychologist would presumably accept, is:
She was in London when she slapped him.
However, the vignette only specifies that Mary was in London when he wolf-whistled at her. It adds that she took a step towards him before slapping him. Thus, the natural answer in effect assumes that if someone is in London, and takes a step, then they are still in London. But that assumption is not universally correct, for people occasionally walk out of London. In comprehending the vignette, one automatically updates the initial information 'Mary was in London' to the slightly later time when she slapped him, because the change involved in taking a step forward is treated as 'too small to matter'. That treatment is the default, but it is defeasible: if you had previously been told that Mary lived right on the edge of London, or that she had seven-league boots, you might have been wary about updating her supposed location in that way.
The example illustrates a very general cognitive tendency. For instance: you learn today from a trustworthy source that Emomali Rahmon is the president of Tajikistan. Tomorrow, someone asks you 'Who is the president of Tajikistan?' It would be natural for you to answer (complacently): 'Emomali Rahmon'. To answer 'Well, Emomali Rahmon was the president yesterday' would be unnatural and pedantic, even though you know that presidents can die or resign in a day; no president is forever. One day is treated as too small a change to matter.
Of course, we have some sense of such information having a use-by date; if you are asked twenty years from now 'Who is the president of Tajikistan?', having heard nothing about Tajik politics in the meanwhile, you may answer 'It used to be Emomali Rahmon'. To stamp each piece of present-tense information with an expiry date for its validity as it goes into memory would involve significant expenditure of time and energy, for questionable benefits—
inefficient, and probably infeasible. Naturally, most memories fade away, at different rates, but that does not mean that the timetable for their doing so has to be written into their content.
What we treat as too small to matter is sensitive to our vague, general sense of realistic timescales for different states and activities: 'He is thin' or 'He is asleep', 'She is writing a novel' or 'She is writing an email'. How all this works is a topic for detailed psychological investigation. For present purposes, what counts is the general form of the phenomenon, not the specifics of its implementation.
When we update information in present-tense form, we often do so by retaining the present tense, even though such present-tense updating involves going beyond our original information. Much of what we describe as factual 'memory' is the result of present-tense updating ('Do you remember who is the president of Tajikistan?').
By contrast, past-tense updating sticks closer to the original content rather than the original form of the information, by putting it in past-tense form, with reference to the time when it was strictly expressed in present-tense form ('Emomali Rahmon was president of Tajikistan on 15th October 2022' or 'The last I heard, Emomali
Rahmon was president of Tajikistan'), as we might do when we regard change as plausibly imminent. Past-tense updating is more appropriate for episodic memory of particular events. If one cannot date the event, one may simply use a memory demonstrative such as 'then' or 'that time we were in Barcelona' or 'when I was pick-pocketed'.
Although present-tense updating is not always truth-preserving, it is usually truth-preserving. Almost every step that starts in London ends in London; almost every president of a country yesterday is its president today, and so on. Moreover, there is no feasible alternative to present-tense updating, however much sceptics may complain about its fallibility. No one can be constantly rechecking everything. Indeed, even computer data bases use present-tense updating perforce. Once someone's address has been entered into a data base, it cannot be checked every day, let alone every second, to test whether it is still their current address.
Predictive processing models of perception may also rely on present-tense updating. For example, Andy Clark writes about the perception of a moving object against a stable background: 'most of the background information for the present frame can be assumed to be the same as the previous frame' (2016: 26). Without such assumptions, the task of prediction could easily become intractably complex.
Present-tense updating does not reflect some peculiarity of the human brain, but instead far more general features of the problem of information-gathering and retention. Artificial intelligence will have to do present-tense updating, just as natural intelligence does.
For example, much of the data on which an AI system was trained up will sooner or later go out of date.
One advantage of present-tense updating over past-tense updating is that the questions to which the former gives direct answers tend to be of more practical significance than the questions to which the latter gives direct answers. For instance, if you want to get food and drink, it is usually more helpful to know where food and drink are now than to know where they were yesterday.
Creatures without episodic memory, as some non-human animals are alleged to be, may well be unable to do past-tense updating; for many of their purposes, present-tense updating will suffice. Even for humans, although we can sometimes make inferences from the outputs of past-tense updating to the information we need for decision-making—from where food and drink were yesterday to where they are now—conscious inference is psychologically costly.
In the heat of action, it is more useful to have the required information already available directly—at one's fingertips—than to spend time and attention inferring it. That consideration favours present-tense updating. The underlying heuristic is more general than the phrase 'present-tense updating' may suggest. The heuristic provides much of our understanding of physical things as persisting through change over time. Seeing a tree, I think 'This tree is here', using 'this tree' and 'there' as perceptual demonstratives. The next day, somewhere else, I remember the tree as so located, thinking 'That tree is there'—not just 'That tree was there'—using 'that tree' and 'there' as memory demonstratives anaphorically linked respectively to the original perception, even if I am sure that it lost some leaves over the intervening windy day. I unreflectively treat such changes as too small to matter to the tree's identity. The same underlying principle applies modally as well as temporally, to variation across counterfactual possibilities as well as to variation across times: just as we allow that this ship will soon have another plank in place of this rotten one, we allow that it could have been originally made with another plank instead of this one with which it was originally made: a difference of one plank is too small to matter.
The underlying heuristic can be summed up in the generic slogan 'Small changes don't matter'. We may call it the persistence heuristic.
It plays a major if largely passive role in solving the problem of adapting what we know or believe to new situations as efficiently as possible.
In the slogan 'Small changes don't matter', 'changes' should be understood loosely, even metaphorically. In particular, for present purposes, zero change counts as the smallest change. By the heuristic, things persist when they remain unchanged. Furthermore, the difference from one possibility to a counterfactual alternative, or from one object to a similar object, also counts as a change for these purposes, as will be illustrated below.
Examples of the persistence heuristic and its inhibitors are easily multiplied. Normally, one need not keep rechecking someone's scalp to retain knowledge that they are not bald, even though they lose a few hairs every day. But if you tell me that John, though not yet bald, is rapidly going bald, I may keep glancing at his scalp. If you have borrowed a book, you need not keep asking yourself whether you still have that book every time you dislodge a few molecules off a page with your fingers. But if the book is a priceless, crumbling medieval manuscript, you may worry more about its survival. 'I
wish this table had been made slightly longer' is much less likely than 'I wish this table had been made ten times longer' to prompt the default-breaking thought 'Would that still have been this table?'
The persistence heuristic explains such patterns, obviating the need to postulate more elaborate forms of proto-metaphysical thinking.
Of course, experience and testimony can modify our sense of what counts as a small change for a specific kind of object, and so raise or lower the threshold for inhibiting the persistence heuristic.
But tweaks in how we implement the heuristic do not replace it by something else.
We also use the persistence heuristic to transfer information about one thing to another. I pick an apple from a tree and bite it.
The apple tastes sour. I expect it to taste sour at the next bite too, and I expect another similar-looking apple from the same tree to taste sour also. With respect to taste, the difference between the two apples is treated as too small to matter. That is a primitive form of induction.
We use the persistence heuristic offline as well as online. We use it online when we update on new evidence, perhaps received from sense perception or from testimony. We use the heuristic offline when we adapt what we know or believe to a hypothetical supposition. For example, in deciding whether to eat that other similar-looking apple, I suppose 'I eat that apple', and develop its consequences in imagination; as a result, I may decide not to eat that apple. You may have been carrying out such offline processing, using your imagination, when reading this chapter, as you considered the various hypothetical cases presented above.
Naturally, what counts as a small change depends on what we are talking about—the table, the house, the city, the country, the planet.
A noticeable difference in taste between two bites of the same apple may surprise us more than between two bites of different apples from the same tree. Differential standards for smallness surely have to be calibrated by experience. But most of this happens offstage, without troubling consciousness.
The persistence heuristic is a crucial labour-saving device.
Without it, cognition would be continually restarting from scratch.
That would be hopelessly inefficient. The heuristic's utility is manifest. As already emphasized, it is defeasible. Persistence is only the default, and we can often identify its failures. When a large change is in the offing, or we know or strongly suspect that a boundary is nearby, the operation of the heuristic is inhibited. But normally we need not actively exclude such defeating conditions, for that would undermine the heuristic's utility, which is exactly to avoid such testing. We rely on persistence unless something sets off a mental alarm.
One corollary of the persistence heuristic's inhibiting conditions is that the heuristic is more easily inhibited for precise terms than for vague ones. For a precise term, we are more clearly aware of its boundaries and where they lie. Our awareness of their proximity sounds an alarm; the heuristic's operation is inhibited. By contrast, for a vague term, we have no such clear awareness of its boundaries, and usually no alarm is sounded; the heuristic's operation is not inhibited—though we may feel growing unease as we slide down a slippery slope. But the heuristic itself is applicable equally to precise and vague terms. For example, in the vignette about Mary and the wolf-whistler, the heuristic delivers the verdict that she is still in London after taking a step, irrespective of whether one envisages the boundaries associated with the name 'London' as vaguely or precisely defined. When one reads the vignette, that question does not naturally arise. Checking whether the terms in play are vague or precise is no part of the persistence heuristic: such checking would use up valuable time and energy for no commensurate benefit. The heuristic itself applies equally in vague and precise cases, but is more liable to be psychologically defeated in the latter than in the former because the boundary is psychologically salient. In cases of vagueness, the shortage of defeaters for the persistence heuristic makes it prone to sorites paradoxes, since it can be applied iteratively—which rarely happens under normal conditions. Many small differences add up to a large difference. Correspondingly, the heuristic validates tolerance principles such as 'If n grains make a heap, n–1 grains make a heap' for arbitrary 'n' or 'If x looks red and y is visually indiscriminable from x then y looks red too'. One assesses the principle by supposing the antecedent 'n grains make a heap' or
'x looks red and y is visually indiscriminable from x' and applying the heuristic under that supposition to verify the consequent 'n–1 grains make a heap' or 'y looks red'. Informally, one imagines a heap, imagines one grain being removed, or something looking red, and something else where one can see no difference in colour, and uses the heuristic offline in the imagination to confirm that what remains is still a heap or that the second thing looks red too. There is no psychologically salient boundary for 'heap' or 'looks red' to inhibit the heuristic's operation. We have experienced no relevant analogue of taking a second bite of an apple and suddenly tasting something rotten to make us cautious. By default, the tolerance principle is accepted. Notoriously, it suffices to generate the sorites paradox, which drives one from an obviously true starting-point such as 'Ten thousand grains make a heap' to an obviously false conclusion such as 'One grain makes a heap', or from 'This looks red' said of a prototype of red to 'This looks red' said of a prototype of yellow. The tolerance principle only needs to fail at one step out of many in the sorites series for the sorites argument to be unsound. Our instinctive reliance on the highly but not perfectly reliable persistence heuristic helps explain why we are cognitively vulnerable to paradoxes of this form, why we find them so hard to resist.2
2 The phrase 'tolerance principle' goes back to Wright 1976. Williamson 2020: 63–7 treats tolerance principles as heuristics, though not with the generality of the persistence heuristic, in relation to sorites paradoxes, and provides numerical estimates of their reliability in some cases. Williamson 2023b (a review essay on Dorr, Hawthorne, and Yli-Vakkuri 2021) makes the generalization to the persistence heuristic. The latter Some philosophers have got the impression that tolerance principles for vague expressions are somehow 'analytic' or 'semantic', or that they are 'conceptual connections' built into the corresponding concepts, thereby rendering those concepts defective.3 That is a misunderstanding of the principles' status, perhaps resulting from the absence of 'heuristic' from the traditional philosopher's impoverished menu of options. Tolerance principles for vague expressions are no more 'analytic' than are the analogous tolerance principles for precise expressions; they are all applications of the same heuristic. The difference is just that some of them are psychologically more easily inhibited than others. Since our susceptibility to sorites paradoxes simply results from our reliance on the persistence heuristic in epistemically non-ideal conditions, it motivates no revision of classical logic or bivalent semantics. Much of the literature on vagueness exhibits one of the harms done by the 'linguistic turn': the tendency to seek linguistic solutions for epistemic problems.
exchange contributes to a debate about whether the S4 axiom (that what is possibly possible is possible) holds for metaphysical possibility, despite apparent examples of series of cases where each case entails the possibility of the next, but the first case does not entail the possibility of the last because the difference between neighbouring cases (for instance, in the original constitution of a given artefact) is 'small enough' but the difference between the first case and the last is 'too large'. Salmón 1989 argues that the cases are genuine counterexamples to S4, Williamson 1990 that the underlying motivation for his premises is soritical and so unsound, and Salmón 1993 that the motivation is not soritical. Dorr, Hawthorne, and Yli-Vakkuri 2021 argue for a metasemantic approach on which a tolerance principle for constitution as uttered in a given possible world expresses a true proposition, but which proposition it expresses is contingent, while the corresponding necessitated tolerance principle expresses a false proposition. They defend the unnecessitated tolerance principle by non-soritical, epistemological considerations. Williamson 2023b responds that the pre-theoretic appeal of the tolerance appeal extends to the necessitated tolerance principle, because it does not depend on thinking of the cases as actual, and is best explained as deriving from the persistence heuristic. Similarly, the appeal of the crucial premises in Salmón's anti-S4 reasoning is easily explained as deriving from the persistence heuristic. When an independently attested heuristic validates an assumption, explaining the latter's pre-theoretic appeal in some other way is typically ill-motivated.
Incidentally, although the persistence heuristic does not figure in the case for an epistemicist account of vagueness in Williamson 1994, our reliance on it supports my approach there.
3 See Eklund 2002 for an account of how principles can be 'analytic' without being true. 1.4 The suppositional heuristic for conditionals
The persistence heuristic is general-purpose. For contrast, we now consider a heuristic primarily for the assessment of conditionals, expressed by sentences of forms such as 'If A,
C', although it can also be applied to the assessment of generic generalizations, as explained below (see Williamson 2020, henceforth 'S&T', for a book-length discussion of the heuristic).
Arguably, it is humans' primary way of assessing conditionals, though not our only one. It is not a new discovery: for example, it is closely related to the Ramsey Test, originally described by
Frank Ramsey, which uses a form of hypothetical updating. But its role has been misunderstood, because its heuristic status went unrecognized.
Here is Ramsey's concise description, in a footnote (1929: 143, with change of lettering):
If two people are arguing 'If A will C?' and are both in doubt as to
A, they are adding A hypothetically to their stock of knowledge and arguing on that basis about C.
A simple, schematic version of the suppositional heuristic is this:
Assess 'If A, C' outright as you assess 'C' on the supposition 'A'.
We can see how this works with some examples. Mary has bought a ticket in a lottery. The prize is a million pounds. Here are three conditionals about it:
(1)
If Mary's ticket wins, she will get lots of money.
(2)
If Mary's ticket wins, it will lose.
(3)
If Mary's ticket wins, she will buy a new house.
To assess (1)-(3), we first suppose their shared antecedent, 'Mary's ticket wins', and then assess their consequents on that supposition. Since the prize is lots of money, we accept (1)'s consequent 'She will get lots of money' on the supposition of (1)'s antecedent 'Mary's ticket wins'. Using the suppositional heuristic, we therefore accept
(1) outright.
Since Mary's ticket winning is inconsistent with its losing, we reject (2)'s consequent 'It will lose' on the supposition of (2)'s antecedent 'Mary's ticket wins'. Using the suppositional heuristic, we therefore reject (2) outright.
Since we have no idea of Mary's priorities, we suspend judgment on (3)'s consequent 'She will buy a new house' on the supposition of
(3)'s antecedent 'Mary's ticket wins'. Using the suppositional heuristic, we therefore suspend outright judgment on (3).
These predictions fit natural reactions to (1)-(3). Similarly, as we learn more about Mary's priorities, her buying a new house will look more or less likely conditional on her ticket's winning, and (3) will come to seem correspondingly more or less likely outright. There is extensive evidence that speakers' assessments tend to conform to the suppositional heuristic (Evans and Over 2004, Douven 2016, S&T).
Often, we need to assess conditionals not outright but on a further set of background suppositions, Γ. Strictly speaking, that was already happening with our assessments of (1)-(3), since 'Mary has bought a ticket in a lottery' and 'The prize is a million pounds' really played the role of background suppositions; we did not believe them outright. For these purposes, we need a more general version of the suppositional heuristic:
Assess 'If A, C' on the suppositions Γ as you assess 'C' on the suppositions Γ∪{'A'}.
The original, simpler version corresponds to the special case where
Γ is the empty set. In more complex reasoning, we often find ourselves making suppositions within suppositions. For example, when we are devising a strategy with multiple choice-points as we confront different contingencies at different stages, we need to consider a tree of branching possibilities. In constructing or following a tricky mathematical proof, one typically has to make hypotheses in the scope of hypotheses already made. Without the generalized suppositional hypothesis, one would be stymied in one's natural attempts to assess conditionals in such situations, but that does not happen. In effect, in the outright version of the heuristic, the final verdict on the conditional itself is online, whereas the generalized version extends the heuristic to offline cases too.
How does such hypothetical thinking help us? Many of our dispositions to form expectations have been calibrated by experience, our own or our ancestors', and so encode information about the world so experienced. We may need to apply such information to a prospective new situation, in advance of encountering it. Is it a danger to be avoided or an opportunity to be sought? How can we prepare ourselves to encounter it? We imaginatively suppose that the situation obtains, and use our expectation-forming dispositions
'offline' to assess what it may be like and what it may lead to. We can then store such information in the convenient form of a declarative sentence, as a conditional: 'If the situation obtains, such-and-such will happen'. Such reality-oriented cognitive uses of the imagination are plausibly central to its evolutionary function (Williamson
2016e). In short, the suppositional heuristic enables us to use connections implicit in our cognitive system to make them explicit in a conditional.
One advantage of suppositional thinking is that it is often feasible when truth-functional thinking is not, because we cannot assess the antecedent or consequent separately. I may know that if
John drops the vase, it will smash, even though I have no idea how likely he is to drop the vase, and so no idea how likely it is to survive. This is an epistemological point, not a semantic one. It does not show that 'if ' is not truth-functional. After all, we may verify the truth-functional disjunction 'Either he will not drop the vase or it will smash' or falsify the truth-functional conjunction 'He will drop the vase and it will not smash' by supposing 'He drops the vase' and on that basis verifying 'It will smash'. Just as we can verify a disjunction without verifying either disjunct, and we can falsify a conjunction without falsifying either conjunct, we can verify a conditional without either falsifying its antecedent or verifying its consequent. But conditionals invite hypothetical thinking in a way that disjunctions and conjunctions do not; conditionals as it were ask to be so assessed. To put it another way, hypothetical thinking feels like a direct way of assessing a conditional, but an indirect way of assessing a conjunction or disjunction. That difference manifests the suppositional heuristic's naturalness for conditionals.
The suppositional heuristic can also be applied to generic generalizations, such as 'Tigers are striped', which we do not treat as refuted by an occasional albino tiger. For 'Ns are F' can be paraphrased as 'If it's an N, it's F' ('If it's a tiger, it's striped'), where 'it' is treated as if it referred to an arbitrarily chosen item. One assesses 'It's striped' on the supposition 'It's a tiger', which gives the appropriate result. Even when the generic is not expressed in conditional form, the suppositional heuristic is still applicable (S&T: 142–6). Much of humans'
general knowledge is most naturally expressed in such generics.
Of course, many of our general biases and prejudices are also most naturally expressed in generics. But that is not the suppositional heuristic's fault, for it prompts one to accept 'Ns are F' only if one already has the bias or prejudice, disposing one to accept 'It's
F' on the supposition 'It's an N'. What the heuristic does is to enable one to make one's implicit bias or prejudice explicit in a conditional or a generic generalization. The heuristic can hardly be expected to do better than the underlying cognitive dispositions—its role is to use them, not to filter the good ones from the bad. Although well-intentioned proposals have occasionally been made to ban the utterance of generics, the likely effect of such a ban would be to force the biases and prejudices underground, while doing the same to most of ordinary humans' general knowledge of the natural and social world, very little of which consists in exceptionless universal generalizations. Despite all its virtues and benefits, the suppositional heuristic is inconsistent, both in itself and with uncontroversial background knowledge. This can be shown in various ways.
One route to inconsistency goes via graded attitudes. Let Prob(X | Y)
be the probability (in any relevant sense) of X conditional on Y, and
A * C formalize 'If A, C'. Applying the simple version of the suppositional heuristic gives the equation Prob(A * C) =Prob(C | A), the identification of the probability of the conditional with the corresponding conditional probability, as proposed by various authors
(Jeffrey 1964, Ellis 1969, Stalnaker 1970). For Prob(A * C) is the probabilistic assessment of 'If A, C', while the conditional probability Prob(C | A) is the probabilistic assessment of C on the supposition A, that is, with all but the A-possibilities excluded. The same connection holds for the generalized version of the suppositional heuristic. Let B be the conjunction of the background suppositions.
Then applying the generalized heuristic to assignments of probability results in the equation Prob(A * C | B) =Prob(C | A ∧ B), which is in effect the previous equation conditionalized on B. This is the generalized version of the identification of the probability of a conditional with the corresponding conditional probability. For
Prob(A * C | B) is the probabilistic assessment of 'If A, C' on the supposition B, while Prob(C | A ∧ B) is the probabilistic assessment of C on the suppositions A and B. The generalized equation feels very natural, thanks to the suppositional heuristic, but a version of an argument originally devised by David Lewis shows the equation to imply that no three mutually exclusive possibilities have nonzero probability (Lewis 1976, S&T: 42–3). That is an absurdly restrictive constraint: when a die is thrown, there are six mutually exclusive outcomes, each with probability 1/6. Attempts to find a loophole in Lewis's argument all founder when applied to the corresponding argument for the generalized suppositional heuristic; it is simply a mathematical result.
Much ingenuity has been spent on finding subtle restrictions or complications of the equation to get around Lewis's result. For a heuristic, that is exactly the wrong reaction. The heuristic's utility depends on its unrestricted simplicity. No subtle restrictions or complications are baked in. Of course, philosophers can seek consistent semantic approximations to the generalized probabilistic identity, but the identity is just one manifestation of a more general heuristic, which has non-probabilistic manifestations too. Treating the probabilistic case in isolation is arbitrary.
Another proof of the heuristic's inconsistency does not even require the assumption of three mutually exclusive possibilities. It is worth sketching to give an idea of what is going on (S&T: 37–42
presents the proof in more detail).
First, we apply the generalized heuristic to assessments of deductive entailment. This is like the special case of the probabilistic equation for probability 1, the principle that Prob(A * C | B) =1
if and only if Prob(C | B ∧ A) =1, but without the mathematical complications that arise for probabilities conditional on a hypothesis whose probability is 0 (when the standard ratio definition of the conditional probability, Prob(X | Y) as Prob(X)/Prob(X ∧ Y), involves division by 0). The result can be formalized as the equivalence of Γ  A * C with Γ∪{A}  C, where  is interpreted as deductive entailment. That equivalence amounts to the combined rules for a standard conditional in a standard system of natural deduction: the implication from Γ  A * C to Γ∪{A}  C is in effect modus ponens (the conditional elimination rule), while the implication from Γ∪{A}  C to Γ  A * C is just conditional proof (the conditional introduction rule). These rules can be shown to make *
equivalent to the material (truth-functional) conditional. So far so good, at least for friends of the material reading of 'if '.
The trouble is that we can also apply the generalized heuristic to assessments of deductive incompatibility. This is like the special case of the probabilistic equation for probability 0, the principle that Prob(A * C | B) =0 if and only if Prob(C | A ∧ B) =0, but again without the complications arising for probabilities conditional on a hypothesis of probability 0. The result can be formalized as the equivalence of Γ ¬ A * C with Γ∪{A} ¬ C, where ¬ is interpreted as deductive incompatibility. Since being deductively incompatible with something is equivalent to deductively entailing its negation, in effect Γ  ¬(A * C) is equivalent to Γ∪{A}  ¬C. That can be shown to make ¬(A * C) equivalent to the negated conjunction
¬(A ∧ C), which in turn makes * equivalent to conjunction. But *
cannot be simultaneously equivalent to both the material conditional and conjunction, since any material conditional with a false antecedent is true, whereas any conjunction with a false conjunct is false. In brief, two legitimate special cases of the heuristic force mutually incompatible readings on natural language conditionals.
Human reliance on the inconsistent suppositional heuristic in assessing conditionals helps explain why their semantics has puzzled logicians for over two millennia, on and off. The issue was so controversial in Alexandria during the third century bce that the poet Callimachus wrote, 'Even the crows on the roof-tops are cawing about which conditionals are true' (Mates 1949: 234).
Although some applications of the heuristic require the material reading, using the heuristic we reject (2) above ('If Mary's ticket wins, it will lose'), even though it is almost certainly true on the material reading, since its antecedent is almost certainly false. More generally, when A is highly improbable or C highly probable, and therefore the material conditional A → C is also highly probable, C
can still be highly improbable conditional on A, so by applying the suppositional heuristic one judges 'If A, C' highly improbable. In effect, the suppositional heuristic is responsible for the 'paradoxes'
of material implication. Since the heuristic is inconsistent, it will generate apparent counterexamples to any proposed interpretation of a natural language conditional.
How can the suppositional heuristic be useful, given its inconsistency? How has it survived the pressures of evolution? The answer is much less straightforward than for the persistence heuristic.
An illuminating case to start with is the practice of mathematical proof. Mathematicians write their proofs in a framework of natural language, afforced with lots of mathematical notation and diagrams, not in some purely formal language—as one can see by glancing at the pages of mathematical journals. In particular, mathematicians reason with natural language conditionals such as 'if '; they receive no special training in how to use them mathematically, no special explanations or warnings. Nevertheless, to a good approximation, their reasoning with 'if ' fits standard natural deduction rules for the material conditional—modus ponens and conditional proof—just as in the special case of the heuristic for deductive entailment above. That is why, as often noted, 'if ' can be seamlessly read in mathematical texts as a material conditional.
Still, since mathematics seems to press our deductive capacity to the utmost, why does the inconsistency between applying the heuristic to deductive entailment and applying it to deductive incompatibility never surface in mathematics? For example, let A be an implicitly inconsistent mathematical hypothesis. Since A deductively entails any mathematical conclusion C, one can use the heuristic to establish 'If A, C' outright. Since C is also deductively incompatible with A, one can also use the heuristic to refute 'If A,
C' outright. That would make mathematics itself inconsistent.
Obviously, no such paradox arises in mathematical practice. The reason is that refutability is simply identified with provability of the negation, rather than being treated as an independent form of assessment. In effect, mathematical proofs work with acceptance as the only operative mode of assessment. Near enough the only way an unembedded sentence occurs in a mathematical proof is as proved from—deductively entailed by—the set of relevant suppositions. In limit cases, that set is either empty or just the singleton of the sentence itself (in the speech act of supposing it). To that extent, the standard logical framework of mathematical proof is just like that of a natural deduction system. In such a setting, a material reading of
'if ' is the only one to validate the suppositional heuristic.
The primacy of acceptance over rejection in mathematical practice may be rooted in a more general pattern of human thought: to register rejection of 'A' by accepting 'Not A', replacing a negative attitude to a positive sentence by a positive attitude to its negation. 'Not A' may then in turn be fleshed out in more positive terms (on the psychology of negation, see Kaup, Zwaan, and Lüdtke 2007). If the default attitude to a sentence occurring in inner speech is acceptance, this would tend to avoid mental clutter, by reducing the need for special attitude-markers. Such a cognitive tendency would be efficient for both outright attitudes and attitudes under suppositions. It would set one up to apply the suppositional heuristic to acceptance, for which it gives good results. That would help explain why the heuristic's inconsistency causes so little trouble in practice, in mathematics or elsewhere, without any special training. Although it would not strictly resolve the inconsistencies lurking in the heuristic, especially as applied to probabilistic assessments, it would help limit the damage.
The effect of the suppositional heuristic is also modified by the generic practice of accepting conditionals preserved by memory or communicated by testimony, without reapplying the suppositional test in the new epistemic context. For example, when I assess the opposite conditionals 'If A, C' and 'If A, not C' by the suppositional heuristic, I do not accept both, because I do not accept both the contradictories 'C' and 'Not C' on the supposition 'A' (when 'A' is consistent). But sometimes I may rationally accept 'If A, C' from one trustworthy source while also accepting 'If A, not C' from another trustworthy source; I then conclude 'Not A'. Perhaps each trustworthy source has direct access to information to which neither I nor the other trustworthy source has direct access, and both trustworthy sources used the suppositional heuristic.4
4 S&T: 89–102 discusses such cases in detail. Incidentally, the centrepiece of Daniel
Rothschild's critique of S&T is a lengthy argument against that account of conditional testimony (Rothschild 2023: 221–6). At the decisive point, he plausibly claims that 'direct expressions of conditional probabilities might behave as strangely as assertions of conditionals', and concludes 'these cases do not provide a good reason to pull apart conditionals from expressions of conditional probabilities' (Rothschild 2023: 226). But one obvious reason why direct expressions of conditional probabilities might behave as strangely as assertions of conditionals in the relevant cases (where they are made by Once one takes into account the overall practice of using conditionals to encode and transfer information, one can argue that the information stably associated with a conditional is simply that of the material reading, outside mathematics as well as inside.
The point is not obvious, for the suppositional heuristic often grossly underestimates the probability of a conditional on its material reading. For example, the heuristic assigns probability zero to the conditional (1) above, 'If Mary's ticket wins, it will lose', since the consequent is inconsistent with the antecedent and so has probability zero conditional on the latter. That fits the strong unreflective impression that the conditional is idiotic, and the strong unreflective inclination, when asked 'What is the chance that if Mary's ticket wins, it will lose?', to answer 'None'. But the material reading makes the conditional almost certainly true, since its antecedent is almost certainly false, and a material conditional with a false antecedent is true. In isolation, such cases look like decisive counterexamples to the material reading of 'if '. But that attitude is no longer adequate once one realizes that the unreflective judgments are the outputs of an inconsistent heuristic. In those circumstances, we cannot rely on the standard methodology of requiring a semantics for the conditional to vindicate all normal patterns of speakers' unreflective judgments.
a trusted expert) is that, confronted with the authoritative but forbiddingly technical-sounding claim 'My conditional probability for C on A is very high', a natural way to extract something useful from it about the relation of A to C is to think something like
'That's just his way of communicating that if A then C'. How we should directly update our conditional probabilities on information about two experts' conditional probabilities is quite unobvious, even to probabilistic epistemologists. Pre-theoretically, we are much more used to working with conditionals than with explicit conditional probabilities.
Similarly, when an expert meteorologist says 'The probability on my current evidence that it will rain is very high', we may cut to the chase and treat him as having said (with professional caution) that it will rain, though we are under no illusion that the literal truth-conditions are the same. Comparisons with explicit statements about probabilities pose no threat to the argument of S&T. Significantly, Rothschild rejects my appeal to heuristics without providing any alternative account to explain how language users ascertain whether sentences' truth-conditions obtain in specific hypothetical cases. This follows a more general practice in semantics of treating the application of semantics to hypothetical cases as in effect epistemically transparent to language users. We may have to be content with a less direct connection between semantics and heuristics. For example, when we treat the conditional probability Prob(C | A) as an estimate of the probability of the conditional on its material reading, Prob(A → C), it is often too low, but never too high: in that sense, the heuristic may make us trust too little, but will not make us trust too much. More demanding truth-conditions for the conditional lose that advantage, by sometimes making the heuristic overestimate its probability; less demanding truth-conditions make the conditional unnecessarily uninformative, given the heuristic. Thus the material truth-conditions make conditionals as informative as they can be, compatibly with preventing the heuristic from overestimating their probability. Such a useful connection between the heuristic and the truth-conditions provides further confirmation of the overall picture (S&T: 103–10).
Being too cautious with conditionals may be less costly than not being cautious enough. After all, on the present view, the point of conditionals is not to provide access to a special kind of information but rather to provide a special kind of access to information. For example, on the material reading, 'If Mary's ticket wins, it will lose' has the same truth-condition as 'Mary's ticket will either lose or not win'; although we cannot access the high probability of that condition's obtaining via the suppositional heuristic, we can access it via the known high probability of Mary's ticket losing. As already noted, suppositional thinking comes into its own with conditionals like 'If the vase is dropped, it will break'. Even though it has the same truth condition as 'The vase will either break or not be dropped', we may be unable to access the high probability of the condition's obtaining via the separate probabilities of the disjuncts, because we have no idea how to estimate the latter probabilities. Instead, we can apply the suppositional heuristic, since we can access the high probability of the vase's breaking conditional on its being dropped, through an imaginative exercise constrained by our background knowledge. The suppositional heuristic's limitations are a small price to pay for its distinctive benefits.5
1.5 Disquotation and heuristics for belief ascription
Here is an elementary speech exchange between two children:
John: I'm taller than you.
Janet: That's not true! I'm taller than you.
We might articulate Janet's underlying thought process as an inner monologue like this:
Janet:	 John said 'I'm taller than you'. He said that he's taller than me. But I'm taller than him, so he's not taller than me. So what he said is not true.
5 Care is needed in applying the suppositional heuristic to conditionals involving descriptions of cognitive status. For example, 'If Elvis lives, it is surprising that he lives'
has a true reading, whereas 'It is surprising that if Elvis lives, he lives' has no true reading.
This may look like a case where we are unwilling to apply the heuristic. But that is a confusion. The heuristic tells us to assess 'If A, C' as surprising just when we assess C as surprising on the supposition A: in particular, to assess 'If Elvis lives, he lives' as surprising just when we assess 'He lives' as surprising on the supposition 'Elvis lives'. Naturally, we assess 'If Elvis lives, he lives' as unsurprising, and 'He lives' as unsurprising on the supposition 'Elvis lives'. As usual, the latter involves an ex post assessment of 'He lives', already informed by the supposition, not an ex ante uninformed assessment. We can record our assessment by saying truly 'If Elvis lives, it is not surprising that he lives', with 'surprising'
read ex post, in a context already informed by the antecedent. That the same sentence can also read as false with 'surprising' understood ex ante is irrelevant. The point comes out clearly when one uses the parenthetical 'surprisingly' in place of the sentential operator 'it is surprising that': there is little difference between 'If Elvis lives, surprisingly he lives' and 'Surprisingly, if Elvis lives, he lives'; in both, the primary propositional content is trivially true, while the secondary parenthetical comment on its cognitive status is obviously false. Of course, we accept 'If Elvis lives, it is surprising that he lives' read ex ante, but that just corresponds to accepting 'It is surprising that he lives' read ex ante on the supposition 'Elvis lives', again in line with the suppositional heuristic. Similar points apply to explicitly probabilistic operators such as 'the probability is less than 1% that', where one must be careful to distinguish between prior and posterior probabilities. In passing from the internal direct speech report 'John said “I'm taller than you” ' to the internal indirect speech report 'He said that he's taller than me', Janet unreflectively replaces John's pronouns 'I'
(first-person) and 'you' (second-person) by her 'he' (third-person)
and 'me' (first-person); she also replaces the name 'John' by 'he'.
In passing from the thought 'I'm taller than him' to the speech addressed to John, 'I'm taller than you', she unreflectively replaces the third-person pronoun 'him' by the second-person pronoun 'you'.
All these effortless replacements are to preserve reference and conversational appropriateness—though Janet's use in inner speech of the third-person rather than the second-person in referring to John suggests that she is keeping her psychological distance from him.
By contrast, the words 'taller than' are preserved verbatim from the direct speech report to the indirect speech report, as is the present tense of the verb from 'I'm' (='I am') to 'he's' (='he is') rather than
'he was', in effect a case of the persistence heuristic, since the speech reports themselves are past tense ('said', not 'says').
In arriving at the indirect speech report, Janet's default is to repeat
John's words (homophonic disquotation), while fluently adjusting to the context-sensitivity of pronouns. Reasonably enough, she does not even consider the possibility that John means something different by
'taller' from what she means. Counterfactually, if John had a notorious habit of using words as if they meant the opposite of what they in fact do, her knowledge of his bad habit might have inhibited the default's operation, and she might have reacted differently. Homophonic disquotation is the standard heuristic for indirect speech reports, both in speech and in verbalized thought, but it is modified more or less automatically in familiar cases of context-sensitivity, and it can also be modified more reflectively in light of special circumstances.
Homophonic disquotation, suitably modified, can also be extended to refusals to say: for example, someone who refuses to say 'Abortion is wrong' may be reported as refusing to say that abortion is wrong.
We often need the indirect speech report in order to assess others' statements. For instance, Janet obviously cannot just assess the sentence type 'I'm taller than you', since she addresses that very sentence back to John in rejecting his use of it. Rather, she assesses what John said. In doing so, her implicit reasoning is something like this:
(1)
John said that he's taller than me
(2)
What John said =that he's taller than me
(3)
He's not taller than me
(4)
That he's taller than me is true if and only if he's taller than me
(5)
What John said is true if and only if he's taller than me
(6)
What John said is not true
Here (1) is just the indirect speech report, which (2) reworks in a context where nothing else John said is relevant. Line (3) states something Janet knows or believes about John's height compared to hers. Line (4) is just an instance of a standard logical schema for propositional truth, which does not involve disquotation, since
'that' is not a device for quotation:
(T)
That P is true if and only if P
Principles not unlike (T) can already be found in Plato's Sophist and Aristotle's Metaphysics. Line (5) follows from (2) and (4) by the logic of identity (Leibniz's law), since (2) licenses substituting
'what John said' for 'that he's taller than me' in (4). The conclusion
(6) follows from (3) and (5) by modus tollens for the biconditional
(using its left-to-right direction), a standard principle of propositional logic.
Plato and Aristotle pair their principles about truth with corresponding principles about falsity not unlike (F):
(F) Overfitting and heuristics in philosophy
The instance of (F) corresponding to (4) is (4*):
(4*)
That he's taller than me is false if and only if he's not taller than me
Just as Janet can derive (5) from (2) and (4), she can derive (5*)
from (2) and (4*):
(5*)
What John said is false if and only if he's not taller than me
The conclusion (6*) follows from (3) and (5*) by modus ponens for the biconditional (using its right-to-left direction), another standard principle of propositional logic:
(6*)
What John said is false
Unless Janet suspects that John is insincere, she may well conclude that what he thinks, as well as what he said, is false, and not true. She may go straight from the indirect speech report 'He said that he's taller than me' to the belief ascription 'He thinks that he's taller than me' ('think' is the usual term in ordinary English where philosophers say 'believe'; they are near-synonyms in this context).
In effect, Janet uses what someone says as a heuristic for what they believe. The default assumption is sincerity: if someone says that P, they believe that P. Call that the sincerity heuristic.
What about the converse principle, a default assumption of non-reticence, that if someone believes that P, they say that P (when the question arises)? If they say that not-P, by the default assumption of sincerity, they believe that not-P, and so do not also believe that
P, unless they are inconsistent. But if they say neither that P nor that not-P, can we assume by default that they have no belief either way? Obviously not, when the question whether P did not even arise in the conversation. But if they positively refuse to say that P, when the question does arise, a reasonable default assumption is that they lack the belief that P. As usual, the default can be inhibited: for instance, when the matter is confidential, or the speaker did not understand the question, or was unable to speak. Call that the non-reticence heuristic.
One can get from a direct speech report to a belief ascription by first applying the (suitably modified) homophonic disquotation heuristic and then applying the sincerity heuristic to the result.
This can lead to Frege puzzles about co-referential terms such as
'Hesperus' and 'Phosphorus'.
For example, imagine this speech:
NN: Some people confuse Mike Brearley, the former captain of the England cricket team, with J. M. Brearley, the former lecturer at Newcastle University. They are not the same person.
J. M. Brearley was once a professional philosopher. Mike
Brearley was never a professional philosopher.
NN is mistaken. Mike Brearley, the former captain of the England cricket team, is J. M. Brearley, the former lecturer in philosophy at
Newcastle University.
Imagine Brearley overhearing NN's speech.
When NN says 'J. M. Brearley was once a professional philosopher', Brearley can use the homophonic disquotational heuristic to make the indirect speech report 'NN said that J. M. Brearley was once a professional philosopher', but normal conversational standards for the use of pronouns also allow him to report 'NN said that I was once a professional philosopher'. Since NN's sincerity is not in question, Brearley then applies the sincerity heuristic to infer
'NN believes that I was once a professional philosopher'.
When NN says 'Mike Brearley was never a professional philosopher', Brearley can use the same heuristic to report 'NN said that
Mike Brearley was never a professional philosopher', but normal conversational standards for the use of pronouns also allow him to report 'NN said that I was never a professional philosopher'. By the sincerity heuristic again, Brearley infers 'NN believes that I was never a professional philosopher'.
Putting the pieces together, Brearley ends up concluding 'NN
believes both that I was never a professional philosopher and that
I was once a professional philosopher', thereby accusing NN of having mutually contradictory beliefs. Yet NN may be a leading classical logician, with a militant aversion to inconsistency.
In that respect, the threatened contradiction is in NN's beliefs.
But contradiction also threatens Brearley's own beliefs, by the non-reticence heuristic. For NN is far from reticent, and he clearly refuses to say 'Mike Brearley was once a professional philosopher'.
Thus, by the homophonic disquotational heuristic, Brearley can report 'NN refuses to say that Mike Brearley was once a professional philosopher', but normal conversational standards for the use of pronouns also allow him to report 'NN refuses to say that I was once a professional philosopher'. Brearley then applies the non-reticence heuristic to conclude 'NN does not believe that I was once a professional philosopher'. But, as seen above, Brearley has already concluded 'NN believes that I was once a professional philosopher'. The threatened contradiction is now in Brearley's own beliefs
(about NN's beliefs), not just in NN's beliefs.
Of course, there is a long history of trying all sorts of ingenious strategies to resolve the inconsistencies, from Frege's distinction between sense and reference to contemporary contextualist accounts of the implicit constraints on the guises or modes of presentation of the relevant objects under which the subject must conceive them in taking the putative attitude, for the attitude ascription to count as true. But when Janet complains to a friend 'John thinks that he's taller than me', she does not seem to be implying that, in so doing, John thinks of her in some way relevantly similar to the way in which she thinks of herself, or anything of the kind; the issue of the guise under which John thinks of her seems not to arise at all. Naturally, one can imagine deviant cases where John thinks of her in some surprisingly convoluted way, but most things we say can be true in surprising ways. Rather than assume that some elaborate semantic apparatus is needed to explain the puzzle cases, we should explore the hypothesis that they are just predictable outcomes of our fallible heuristics for attitude ascriptions, as the Brearley example illustrates. That may be the right moral to draw from Saul Kripke's article 'A Puzzle about Belief ' (1979), even though it is probably not the one he intended—what he seems to treat as an incoherence in the very concept of belief may be better understood as manifesting the inevitable limits of some of our ordinary, useful heuristics for ascribing belief (see chapter 4 for more discussion).
The sincerity and non-reticence heuristics are obviously specific to belief and do not generalize in any straightforward way to other propositional attitudes, such as hope, fear, and intention.
One would expect the human capacity for what psychologists call 'mindreading' to comprise heuristics for many different such attitudes. Furthermore, the sincerity and non-reticence heuristics are specifically based on speech behaviour. Yet we also apply our mindreading capacity to ascribe propositional attitudes, including beliefs, to pre-linguistic and non-linguistic creatures, such as very young children and non-human animals, often thereby explaining their behaviour much better than we could if we refrained from ascribing such attitudes to them. We may therefore need other mindreading heuristics to operate on non-linguistic behaviour.
How far can all these mindreading heuristics be unified? After all, linguistic and non-linguistic behaviour are not totally independent of each other, and propositional attitudes are interrelated in various ways: hopes and fears are connected to beliefs about the probabilities of good and bad outcomes, and intentions to beliefs about what one will do. To what extent different mindreading heuristics can all be understood as applications of one more general mindreading heuristic is an open question. One should not assume that the default is always not to ascribe an attitude, in the absence of positive behavioural evidence—such as speech—for ascribing it. In particular, for the central attitude of knowledge, the default may be the other way round, to ascribe knowledge of truths unless there is some specific reason not to.
For the most efficient cognitive policy may be to treat the world as by default open to view for all potential knowers, and then track specific obstacles to cognitive access. Metaphorically, if each of us carries around a mental map of the world in our head, I don't want to carry around mental maps of everyone else's mental maps, and so on ad infinitum. It would be easier just to carry around one mental map, mark on it where others are, and make further requisite adjustments on that basis in more or less systematic ways, or at worst ad hoc, rather than treating other minds as by default blank slates. With such an open-world heuristic, we will ascribe plenty of knowledge to creatures who exhibit no speech-like behaviour at all (Williamson forthcoming-b, section 8). Given that knowledge is treated as entailing belief, we will ascribe plenty of beliefs to them too—at least when the occasion arises, since there is most point in attributing belief when we are not willing to attribute knowledge.
Thus several more or less independent heuristics or sub-heuristics can combine, or even compete, in ascribing the presence or absence of the same attitude to the same subject at the same time. The result is not 'conceptual incoherence' but just what one might expect when several methods or sources of evidence are available for answering the same question.
We have seen how homophonic disquotational principles for the ascription of belief generate paradoxes of belief. Notoriously, and for related reasons, homophonic disquotational principles for the ascription of truth and falsity generate Liar-like semantic paradoxes. From the present perspective, such paradoxes are evidence that an underlying heuristic is at work. Although (T) and
(F) are not strictly disquotational themselves, they are still associated with versions of the Liar paradox. For example, I say 'What I'm saying is not true'. The corresponding first-person present-tense indirect speech report is (7) (which I can think rather than say):
(7)
I'm saying that what I'm saying is not true
In a context where nothing else I say is relevant, I can rework (7) as (8), just as Janet could rework her indirect speech report (1) as (2) above:
(8)
What I'm saying =that what I'm saying is not true
The relevant instance of (T) is (9):
(9)
That what I'm saying is not true is true if and only if what
I'm saying is not true
Just as Janet could derive (5) from (2) and (4) above by the logic of identity, so I can derive (10) from (8) and (9), substituting 'what I'm saying' for 'that what I'm saying is not true' in (9):
(10)
What I'm saying is true if and only if what I'm saying is not true
But (10) is a contradiction, since it is of the form 'P if and only if not-P', and so cannot be true, given classical logic.
In the analogous paradox for (F), I say 'What I'm saying is false'.
The relevant indirect speech report is (7*):
(7*)
I'm saying that what I'm saying is false
In a context where nothing else I say is relevant, I can rework (7*)
as (8*):
(8*) Overfitting and heuristics in philosophy
The relevant instance of (F) is (9*):
(9*)
That what I'm saying is false is false if and only if what I'm saying is not false
In the same way as before, I can derive (10*) from (8*) and (9*), substituting 'what I'm saying' for 'that what I'm saying is false' in (9*):
(10*)
What I'm saying is false if and only if what I'm saying is not false
But (10*) is another contradiction, since it too is of the form 'P if and only if not-P'.
These paradoxes have been taken to warrant revision of classical logic, in particular by accepting some instances of 'P if and only if not-P'. From the present perspective, such drastic reactions look methodologically perverse. There is a far more obvious suspect: the homophonic disquotational heuristic for speech reports.
We already know that it is only a heuristic, as the elementary case of pronouns and other indexicals makes clear. With the indirect speech reports (7) and (7*), the problem is not with the personal pronoun 'I'. Rather, the natural explanation is that in uttering the sentence 'What I'm saying is not true' or 'What I'm saying is false' in the envisaged contexts, I fail altogether to say that something is the case. No positive indirect speech report at all is appropriate. Such failures may be initially surprising, but they violate no law of logic.
Since (7) and (7*) are to be rejected, the paradoxical arguments do not even get started.
A natural objection is that the underlying problem does not really depend on indirect speech reports, because it still manifests in direct speech reports such as (7D) and (7*D):
(7D)
I'm uttering 'What I'm uttering is not true'
(7*D) I'm uttering 'What I'm uttering is false' Here 'utter' is used in place of 'say' to indicate that a relation to sentences rather than to propositions is in play. What is uttered is a sentence. So understood, (7D) and (7*D) are much harder to deny than (7) and (7*). Where no other utterances are relevant, we then have the required equations:
(8D)
What I'm uttering ='What I'm uttering is not true'
(8*D)
What I'm uttering ='What I'm uttering is false'
Since the problem now concerns the truth or falsity of sentences, it requires appropriately modified analogues of (T) and (F). The closest analogues are these familiar disquotational schemata:
(TD)
'P' is true if and only if P
(FD)
'P' is false if and only if not-P
The paradoxical arguments can then proceed much as before, with quotation marks in place of 'that' and 'utter' in place of 'say'.
However, a reason for restricting homophonic disquotational indirect speech is also a reason for restricting (TD) and (FD). To put it schematically, when in uttering 'P' you fail to say that P, you cannot be expected to have said something that is true if and only if P, or false if and only if not-P. For instance, when you utter the sentence 'I'm hungry', you do not say that I'm hungry, so I do not expect the sentence as uttered by you to be true if and only if I'm hungry, or false if and only if I'm not hungry. More generally, (TD)
and (FD) should be restricted to contexts where the homophonic disquotational schema (D) also holds:
(D)
In uttering 'P', one says that P. Overfitting and heuristics in philosophy without really saying that anything is the case. For purposes of disquotation, we can understand 'say' more liberally than that. Such non-assertive utterances will form another case where the sincerity heuristic for belief ascription is inhibited.
Of course, when you utter 'I'm hungry', you say something that is true if and only if you are hungry, and false if and only if you are not hungry, for you say that you are hungry. Thus, the proper generalizations are something like these non-homophonic principles (where s is a sentence):
(TG)
In contexts where, in uttering s, one says that P, s is true if and only if P
(FG)
In contexts where, in uttering s, one says that P, s is false if and only if not-P.
From (TG) and (FG), one can recover the homophonic principles (TD) and (FD) respectively for contexts where (D) holds. The paradoxes are resolved because one cannot recover the relevant instances of (TD) and (FD) in the relevant contexts, since (D) fails there (see Williamson 1998 and Andjelković and Williamson 2000
for some relevant discussion). For the sentential as well as the propositional versions of the paradoxes, the culprit is the homophonic disquotational heuristic for indirect reported speech. A similar diagnosis applies to versions of the paradoxes for thought rather than speech.
Although the specific problems for disquotation differ between
Frege puzzles and semantic paradoxes, they both manifest its rough-and-ready character. Naturally, much remains to be explored about exactly where and why homophonic disquotational speech breaks down. In particular, we need to understand better the mechanisms of its failure in semantic paradoxes, which may also help explain its failures elsewhere. Since we already have decisive independent evidence that homophonic disquotation has merely heuristic status, postulating failures in unrelated principles—such as those of elementary propositional logic—is gratuitous and methodologically wrong-headed.
1.6 The weighing heuristic for reasons
Talk of 'reasons' is central to much contemporary debate in metaethics and, more generally, metanormativity. It promises to unify the practical with the theoretical: there are both reasons for action and reasons for belief. The term 'reasons' is assumed to be intellectually perspicuous enough to serve in the most abstract reasoning, yet also securely enough rooted in pre-philosophical normative thought and talk to ground what we say in concrete cases.
There is even a research programme with the slogan 'Reasons first', which proclaims that the category of reasons is explanatorily fundamental (Schroeder 2021).
The use of the word 'reasons' in the plural is a reminder that we need some way of thinking and talking about combining reasons, on pain of being left at a loss when more than one reason bears on our decision. For example, in a group debate on whether or not to take a certain course of action, each side may present various considerations for and against taking that course, and the group faces the challenge of combining those considerations and resolving them into a decision one way or the other. As a single individual, one may carry out a similar process in one's own head.
We do indeed have such a way of combining reasons, for we often speak of 'weighing reasons', 'adding up' or 'balancing' the 'pros and cons', the 'reasons for' and the 'reasons against', and of reasons that
'outweigh' other reasons. The metaphor is of a pair of scales, with reasons-for going into one pan, reasons-against into the other, and the decision for or against depending on which pan goes down, which up. The metaphor is not inert. It structures our thinking about what to do or what is the case, when we think about more than one reason. Without this organizing metaphor, our thought about reasons would be in danger of impotence.
The metaphor of weighing reasons is in effect an additive model.
If you put two lumps of metal into a pan, the added weight is the sum of the weight of one lump and the weight of the other. Likewise, two reasons-for add up to a weightier case-for than either reason-for by itself.
Such an additive model has costs as well as benefits. For sometimes it gives the wrong result. Here is a simple case. A number labelled
'N' has been chosen from the set {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}, by a random draw. You have to guess whether 'N is even' or 'N
is odd'; if you are right, you win $100, if you are wrong, you lose
$100. A perfectly trusted and trustworthy informant, X, tells you just 'N is in the set {2, 4, 6, 7}'. X's testimony is a good reason for guessing 'N is even', since its probability on X's testimony is 75%.
Another perfectly trusted and trustworthy informant, Y, tells you just 'N is in the set {7, 8, 10, 12}'. By parity of reasoning, Y's testimony is another good reason for guessing 'N is even', since its probability on Y's testimony is again 75%. But X's testimony and Y's testimony together amount to a decisive reason against guessing 'N is even', since the conjunction of what you learn from
X's testimony and what you learn from Y's testimony entails that
N is 7. Thus, two good reasons for doing something can together make a decisive reason against doing it, contrary to the additive model of weighing reasons (see Titelbaum 2019 for more extensive discussion of such cases, Nair 2021 for more examples and non-additive ways of combining reasons, Schroeder 2008: 32–4, 125–6
on adding up reasons, and more generally Kagan 1988 and Lord and Maguire 2016).
Friends of the additive model tend to object to such examples along the following lines. When you have just one of the two testimonies, it is a reason for guessing 'N is even'. But once you have both testimonies, each of them is a reason against guessing
'N is even', given what else you know. The trouble with such replies is that they effectively abandon the weighing metaphor as a useful way of structuring our thinking about how to combine reasons. If putting a second lump of metal into one pan of the scales may cause both lumps to jump into the other pan, all bets are off. Less metaphorically, such replies on behalf of the weighing model presuppose that we already have some other way of thinking about how to combine reasons, so that we can determine the new strength and valence of each reason once it is combined with the other reasons.
Of course, in examples with a simple probabilistic structure like that above, we do have such an alternative structure, because we can work with conditional probabilities, as the discussion implicitly illustrated. The real work of combining the two testimonies was done in the framework of probability theory, not in the framework of reasons theory (if there is such a thing). A serious defence of the reasons framework must show how to combine reasons within that framework, not by abandoning it. Rendering the additive model harmless by rendering it impotent does not constitute such a serious defence.
Friends of the reasons framework can do better by treating the weighing metaphor as a convenient heuristic for combining reasons. It assesses the weight of each reason, and which pan it goes into, separately, and then combines the results additively. As a result, it will sometimes give the wrong answer, as in the example above. Nevertheless, its friends can plausibly claim, such examples tend to be rather artificial: the additive model may typically give the right answer in realistic cases. In many such cases, any assignment of numerical probabilities would be highly artificial, while the reasons framework is in much less danger of imposing a false precision, and may be psychologically more realistic as a model of human thinking.
In fact, there is no exceptionless rule for calculating how much a conjunction supports a conclusion in terms of how much its conjuncts do, since the latter underdetermines the former. To see this, consider a variant case in which X still tells you 'N is in the set {2, 4, 6, 7}' but Y tells you 'N is in the set {2, 4, 6, 9}'. As before, the probability of 'N is even' is 75% on X's testimony and 75% on
Y's testimony, but now its probability on the combined testimony is 100%, not 0%. In that sense, the original problem is insoluble.
A heuristic is the best we can do.
Failures of the additive model are not just intellectual curiosities.
They can have practical consequences. The contested term
'intersectionality' may sometimes be used to get at such practically important failures of the additive model. For example, in an assessment of reasons for compensating someone for discrimination, if the weight of their being a black woman is equated with the sum of the weight of their being black and the weight of their being a woman, then in some circumstances a serious injustice will be done
(compare Crenshaw 1989, the seminal text on intersectionality).
Whether the category of reasons is really as useful or as fundamental as proponents of the 'Reasons first' programme like to claim is not a question to be conclusively settled here. Still, one may wonder how fundamental the ideology of weighing reasons really is. After all, the metaphor makes sense only in a society familiar with the mechanism of a balanced scale. Although the technology for weighing and balancing is modest, there may not have been much need of it under evolutionary conditions. In any case, the reasons framework seems much better adapted to the regulation of debate than to tracking perception and memory—
the acquisition and retention of the knowledge that should inform the debate. It is a strange child who acquires the category of reasons before they acquire the category of knowledge. Indeed, having a reason is arguably a matter of knowing the relevant fact, so that the ideology of reasons has to be explained in terms of knowledge, not the other way round (Hawthorne and Magidor
2018). But even if the category of reasons does not go very deep in the human cognitive system, we still cannot use it properly without heuristics to help us determine the results of combining reasons. 1.7 Implications for philosophical methodology
The last four sections presented various ways in which reliance on unacknowledged heuristics may have distorted our philosophical understanding—in particular, of vagueness, conditionals, belief, truth and falsity, and reasons. Specifically, what look like clear counterexamples to philosophical and logical theories may be the misleading artefacts of fallible heuristics.
This concern should not be confused with the 'negative program' characteristic of the early stages of 'experimental philosophy', which tried to demonstrate by surveys that philosophers' verdicts on hypothetical cases were too sensitive to subjects' ethnicity or gender to be reliable.6 By contrast, many heuristics like those above are so general and so useful that they may well turn out to be more or less universal features of the human cognitive system and not susceptible to significant variation with ethnicity, gender, social class, or other such factors. Of course, in the long run, the presence or absence of those heuristics in cognition over various human populations can and should be tested experimentally. However, since none of the heuristics at issue is specifically philosophical—
each of them is targeted on a general class of cognitive challenges that frequently arise in ordinary life—they will be best investigated in the broader setting of cognitive psychology. They do not call for a special experimental branch of philosophy, though naturally frequent two-way interaction between philosophically informed
6 The seminal paper for the negative program was Weinberg, Nichols and Stich 2001, of which Nagel 2012 is an effective critique. For further criticism of the negative program, see Williamson 2011a and 2016d. Many early results of experimental philosophy have turned out not to be repeatable under more rigorous conditions. For instance, after more extensive experimentation, early claims that the Gettier 'intuition' (that the subject of a classic Gettier case lacks knowledge) depends on ethnicity and gender have been replaced by the hypothesis that the Gettier 'intuition' is part of a humanly universal folk epistemology (Machery, Stich, Rose, Chatterjee, Karasawa, Struchiner, Sirker, Usui, and
Hashimoto 2017). Most contemporary experimental philosophy is not involved in the negative program. Sytsma and Buckwalter 2016 is a wide-ranging recent survey of experimental philosophy. psychologists and psychologically informed philosophers is likely to benefit both sides.
How should we react to the discovery that we have been relying on fallible heuristics? Don't panic! After all, sense perception has long been known to rely on heuristics whose limitations result in perceptual illusions, but it would be melodramatic to conclude that we have no perceptual knowledge. Generic sceptical arguments from the occurrence of heuristic-induced errors are no better than generic sceptical arguments from the occurrence of errors of other kinds. Whatever kind of reliability or safety from error knowledge requires, it is local, not global.
We cannot understand all this by treating the heuristic as the major premise of a deductive argument, an unrestricted universal generalization that will inevitably be false and so no basis for knowledge, just as we cannot understand perceptual knowledge by treating it as based on deductions whose major premise is that perception is perfectly reliable. No such premise is in play; it is neither assumed nor needed. Most cognition is not deductive. Like other biological processes, it often functions properly even though it is capable of functioning improperly.
If a heuristic is humanly universal, or nearly so, it is likely to have survived because it is adaptive; in the most straightforward case, a heuristic is adaptive because it tends to give correct results in normal cases. In particular, we should be wary of drawing pessimistic methodological conclusions for philosophy from our reliance on fallible heuristics. The heuristics are not themselves specific to philosophy; they underpin much of our thinking in general.
Since our reliance on them does not warrant generic scepticism, assuming it to warrant philosophy-specific scepticism would be arbitrary.
Still, such general reflections do not warrant complacency. We should at least ask what improvements on our current philosophical methodology might make it less vulnerable to heuristic-induced illusions. That is work for the following chapters. It is not easy, for if we are heuristic-using creatures, we are probably creatures who need to use heuristics. We can sometimes correct their outputs, but in correcting them we may well rely on other heuristics, or even on other applications of the same heuristic. Nevertheless, methodological improvements are feasible, and they will call into question some currently fashionable ideas.
The role of sense perception in natural science is a helpful precedent here too. Without sense perception, natural science is simply impossible. Although scientists use artificial aids such as microscopes and telescopes, measuring instruments and computers, at some point or other they must be able to see or hear or touch at least some of the results. To put it crudely: if you are hallucinating, you are in no fit state to do science. Yet human sensory systems are riddled with fallible heuristics. In effect, scientists have learnt how to control their reliance on sense perception in ways that minimize the risks and costs of misperception. Incidentally, they have not done it as many epistemological internalists do, by treating subjective perceptual appearances as foundational: such appearances are quite unsuitable to play the role of scientific evidence, since they are not open to inter-subjective checking. Rather, they have applied whatever external controls were needed to resolve specific problems of misperception as they were identified.
Something analogous may be possible, and necessary, to control the risk of errors induced by the more abstract heuristics prevalent in philosophy, such as those above.
Before we turn to ways of controlling the risk, its general nature could do with some further clarification. In discussing the reliability or unreliability of heuristics, one typically presupposes that their outputs are judgments, classifiable as true or false. The heuristic's degree of reliability may then be identified with the objective probability of true outputs conditional on true inputs.
In practice, reliability is often a more complex matter. If the heuristic is inferential, with premise-like inputs, then what counts is truth-preservation from inputs to output, rather than just the truth of the output, and the degree of reliability may be identified with the relative frequency of true outputs given true inputs. If the heuristic's output is an estimate rather than a judgment, it may be assessed on a graded scale of accuracy, rather than on the binary distinction between truth and falsity. One may in turn relativize all such standards of reliability to specified conditions under which the heuristic was applied. And so on. Yet, irrespective of all these complications, reliability is still defined in terms of a standard of truth or accuracy given quite independently of the heuristic itself.
More specifically, the heuristic has been assigned no role in determining the content of the judgments or estimates which it outputs.
That may look like a bad picture when the heuristic is central to our practice of making judgments or estimates with those contents. For example, one might take the disquotational heuristics for ascribing belief and truth and falsity to be at least partially constitutive of the meanings of the words 'believe', 'true', and 'false'.
At the opposite extreme, a heuristic—probably not so-described—
may be treated as an 'analytic' or 'conceptual' connection, quasi-definitional of the terms at issue. That may induce a philosophical crisis when the heuristic turns out to be inconsistent, at least given uncontroversial background knowledge, as with those above: however important to our lives the practices which involve those terms, they suddenly look 'incoherent'. But, as also emerged in those case studies, once the heuristics are properly identified, they are rarely promising candidates for 'analytic' or 'conceptual' status. Not only are the heuristics inconsistent, given our background knowledge: they fail in straightforward, unpuzzling cases—especially once we strip out the ad hoc apparatus of qualifications added as afterthoughts to disqualify exceptions, with no 'analytic' or 'conceptual'
guarantee that no further qualifications will need to be added as further exceptions turn up.
On a better, intermediate alternative, heuristics lack 'analytic' or
'conceptual' status, but still play a role in determining the meanings of the relevant terms. This is at the level of metasemantics, the study of the factors on which the semantics of a language as used by a given community supervenes, or at least constitutively depends.
At that level, something like a principle of charity operates, to favour interpretations that maximize the attribution of true beliefs or (as I prefer) knowledge to the community, given whatever other constraints on interpretation are operative (Williamson
2007/2021a, chapter 8). The heuristics used by the community or its members belong to the putative supervenience base for the metasemantics. They form a significant part of what has to be interpreted charitably.
Of course, no community or individual is omniscient, or error-free, and something is very wrong with any metasemantic theory that implies otherwise. Inconsistent heuristics merely increase how much ignorance or error must be ascribed. Charitable interpretations still do what they can for a much-used heuristic, making it more rather than less reliable, though not perfectly reliable. For instance, we saw how the material interpretation of 'if '
might do that for the suppositional heuristic for assessing conditionals. Despite the persistence heuristic's sorites-susceptibility, it can still exert pressure towards assigning a predicate a convex region of the relevant similarity space for its extension. Informally, the convex closure of a shape is the result of filling in all its holes and hollows, and a convex shape is one that is already its own convex closure. More formally, a region is convex just in case any point directly between two points in the region is itself in the region. Violations of convexity tend to multiply counter-instances to persistence without necessity, so persistence militates in favour of convexity. Of course, the convexity constraint falls far short of uniquely determining predicate extensions; typically, the similarity space can be partitioned into convex regions in many different ways. Some of those may be eliminated because they violate other natural constraints (see Gärdenfors 2000 and Douven and
Gärdenfors 2020 for more discussion). Still, we have no grounds to expect natural constraints to achieve uniqueness: a residual element of happenstance is likely to remain in the determination of reference.
One general strategy for charitable interpretation is contextualist: by varying the assignment of reference to a term with the context in which it is used, the strategy grants itself the flexibility to count more utterances as knowledgeable, or at least true.
Contextualist strategies have been applied to all the kinds of case in which heuristics like those above are used: vagueness, conditionals, ascriptions of belief, truth and falsity, and reasons. However, since the heuristics are applicable even within a single context—which contributes to their power and usefulness—contextualism still cannot make them come out perfectly reliable.
Contextualist strategies have their own drawbacks, often overlooked. They do poorly when information in verbal form is transmitted across contexts through memory and testimony, unless agents keep track of the relevant features of all those contexts
(Williamson 2005). For example, on some contextualist theories of belief ascriptions, the truth-condition of the sentence 'John believed that Cicero was a Roman orator' varies with which guises
John has to have believed the proposition that Cicero was a Roman orator under for the sentence to be true. Believing the proposition under the guise of the sentence 'Tully was a Roman orator' may count in some contexts but not in others (chapter 4 discusses such theories in more detail). Thus, if John loses track of the original set of contextually relevant guises, he in effect loses track of the belief ascription's original truth-conditions, and so is ill-placed to use the stored sentence in a new context, for instance, to pass on information to someone else. Thus, contextualist strategies open up myriads of new error-possibilities for speakers who do not carefully store lots of information about the contexts in which they originally acquired linguistically encoded information. Speakers unaware of such contextualist features of the semantics of their language will be especially liable not to do the hard work of storing all that information. If we store that information about linguistic contexts in linguistic form, an infinite regress threatens. Even if we do not store the information in linguistic form, we are still in danger of having to back up all semantic memory with episodic memory of contexts, which is psychologically quite implausible.
Of course, obviously context-sensitive terms such as pronouns and demonstratives already do impose burdens of adjustment to changing contexts, which speakers and hearers usually manage to handle, often automatically, but contextualist strategies tend to multiply those burdens drastically, with no serious check on whether the benefits really outweigh the costs. That going contextualist conduces to more charitable interpretation is much less clear than it is normally taken to be. In particular, one should not be too optimistic about the prospects of making heuristics like those above come out much more reliable on a contextualist semantics.
For their inconsistency was established with respect to the underlying level of content, whereas contextualism is just a doctrine about the mapping of form to content. For example, in any given context, tolerance principles are false, and the suppositional heuristic is inconsistent. Although contextualists may hope to limit how far the inconsistency is manifested in actual speech situations, that is likely to involve ad hoc complications. If the contextualist can easily model whatever data come in, scientists would tend to regard that as a warning sign of bad science, for reasons explained in the next chapter.
A possible compromise is to have a default standard for applying a term, while permitting contextual inhibition of the default. For example, the default comparison class for 'tall' would presumably be all humans, not all basketball players. In the absence of indicators to the contrary, occurrences of the term in testimony or memory would be evaluated according to the default. That would ease the practical difficulties in using a context-sensitive term. By contrast, pronouns and demonstratives have no such default referent. Proposals for a context-sensitive interpretation need to be explicit on whether they are postulating such a default. If they are, the relevant heuristics may still be less than fully reliable on the default reading.
To sum up, the heuristics on which we often rely in philosophy may be very rough indeed. The next chapter will consider some methodological consequences of that conclusion.
For the present, we may console ourselves with one reflection.
Although the role of heuristics in our pre-theoretical assessments of examples makes our lives harder methodologically, because our data are less reliable than we thought, it also holds out the prospect that true answers to our theoretical questions may often be much simpler than we thought, because true, simple answers have already been wrongly dismissed on the basis of what are really heuristic-generated fool's counterexamples.
2
Overfitting and Degrees of Freedom
2.1 Error-fragility
On the most naïve reading of Karl Popper's philosophy of science, scientific theories are falsifiable but not verifiable. A scientific theory can be falsified, for it is a universal generalization, to which a particular negative instance, a counterexample, can be observed.
But the theory cannot be verified, for however many particular positive instances are observed, they are all jointly consistent with a particular negative instance, which can be observed in the future, so they are all jointly consistent with the theory's negation.
Few contemporary philosophers of science accept that crude picture. By normal scientific standards, the theory of the circulation of blood has been verified. Of course, it has not been verified in the sense of having been conclusively proved by the highest conceivable standard, but then no scientific theory has ever been falsified either in the corresponding sense of having been conclusively refuted by the highest conceivable standard. After all, mistakes in observation are possible, and sometimes actual—through misperception and misinterpretation, incompetence and deceit, and so on. Scientific observation requires skill; things can go wrong. That is why scientists want important experiments to be repeated several times, preferably by different scientists in different laboratories. The reputation of the scientific team performing the experiment matters too—but not all reputations are deserved.
Imagine a scientific community proceeding as if naïve falsificationism were correct. As soon as someone reports an observation inconsistent with a scientific theory, the theory is trashed
Overfitting and Heuristics in Philosophy. Timothy Williamson, Oxford University Press.
© Oxford University Press 2024. DOI: 10.1093/oso/9780197779217.003.0002 as refuted for all time, and the community never returns to it. If such a community ever entertains a correct theory, it is in serious danger of sooner or later throwing it out on the basis of a mistaken observation, and never returning to it. In the terminology of Joshua Alexander and Jonathan Weinberg (2014), such a methodology is error-fragile. A single error is liable to have catastrophic repercussions.
Even if the community raises its standard for accepting an observation report by demanding repeatability, that does not fully solve the problem of error-fragility. For when an experimental result is repeatable, something could still be wrong: the experimental design itself may be flawed; a crucial systematically interfering factor may have been overlooked, may even be unknown to the whole scientific community, so scientists are not measuring correctly what they think they are measuring. Deriving testable predictions from a scientific theory typically depends on auxiliary hypotheses, too–for instance, about how the experimental apparatus works—so a false prediction may result from falsity in an auxiliary hypothesis rather than falsity in the theory under test, as Pierre Duhem pointed out long ago.
Naïve falsificationism is inadequate in practice, not just in theory. It is a bad methodology, and it is not what scientists do.
They rarely treat one observation report as refuting a theory.
Even when no specific error has been identified, an apparent counterexample to an accepted theory may be treated as a mere anomaly, in something like Thomas Kuhn's sense, in the expectation or hope of resolving it eventually, unless an alternative theory nicely accommodates both the apparent counterexample and the other data (Kuhn 1962).
Of course, mathematics is one area of science where a single counterexample does indeed constitute a decisive refutation—
once it has been proved by normal mathematical standards to be a counterexample. Even then, the validity of the proof can be contested, and time may be needed for the mathematical community to reach a consensus. In natural science, the methodological situation is often much messier.
Many contemporary philosophers follow a methodology uncomfortably close to naïve falsificationism. They use thought experiments rather than real-life experiments, but that does not solve the problem of error-fragility. A philosophical theory is put forward, in the form of a necessitated universal generalization.
The theory—say, an account of knowledge as justified true belief—
implies something about a specific possible case—say, that a Gettier case of a justified true belief deduced from a justified false belief would be a case of knowledge. Pre-theoretically, we judge ('observe') that it would not be a case of knowledge. The case is then treated as a counterexample to the theory, which is therefore treated as refuted. In principle, treating our pre-theoretic capacity to judge what would obtain in thought experiments as a source of knowledge is not inherently problematic, just as treating our capacity to observe what obtains in real-life experiments as a source of knowledge is not inherently problematic.1 But, equally, our pre-theoretic capacity to judge what would obtain in thought experiments is not infallible, just as our capacity to observe what obtains in real-life experiments is not infallible. In both natural science and philosophy, our fallibility in classifying examples suffices to make the naïve falsificationist methodology problematic, because it offers no proper means for identifying our errors and correcting them.
The standard methodology for employing thought experiments in philosophy is not maximally naïve, for it does not treat a lone philosopher's verdict on a thought experiment as refuting a philosophical theory. Idiosyncratic errors pose little threat to standard
1 Chapter 6 of Williamson 2007 explains the legitimate role of thought experiments in philosophy as verifying counterfactual conditionals for use as premises in philosophical arguments. Williamson 2021a extends the defence of that account. Chapter 14
of Williamson 2020 streamlines and strengthens the account by replacing the Lewis-Stalnaker semantics for counterfactual conditionals with a simpler semantics on which they express contextually restricted strict conditionals. philosophical methodology, because the intellectual community will usually not adopt them—unless they are made by a charismatic or powerful figure in an intellectual sub-community with a very deferential culture. Normally, a verdict on a thought experiment will be generally accepted in philosophy only if most of those whose work it affects find it independently persuasive, without collusion. This means that thought experiments in philosophy are in effect required to be repeatable.
One could in principle worry about selection effects, where acceptance into a philosophical sub-community depends on sharing the received verdicts on some key thought experiments. That may indeed happen sometimes. But the overall trend in experimental philosophy over recent years has been to find that professional philosophers' verdicts on most thought experiments match the verdicts of lay people fairly well, once proper controls are in place by the standards of current experimental psychology—for example, to check subjects' comprehension of the hypothetical scenario (Mortensen and Nagel 2016, Knobe 2021). In crude terms, there is increasing evidence that the received verdicts in philosophy on thought experiments are mostly the natural human verdicts, irrespective of ethnicity and gender. Nevertheless, the natural human verdict on a thought experiment is still a human judgment; it is not guaranteed to be true.
Chapter 1 explained a potent source of repeatable errors in verdicts on thought experiments: humanly universal heuristics.
Such heuristics have limitations and may even be implicitly inconsistent, so no interpretation makes all their deliverances true.
The persistence heuristic lures us into false verdicts on sorites series. The suppositional heuristic generates false verdicts on conditionals. Disquotational heuristics do likewise in semantic paradoxes and Frege puzzles. If we take those verdicts at face value, following a naïve falsificationist methodology, we may as a result dismiss as refuted true theories of vagueness, conditionals, truth and falsity, and propositional attitudes. Merely scrutinizing the alleged counterexamples very hard will not solve the problem, especially if the scrutiny itself employs the very heuristic in question.
The problem of erroneous data from thought experiments is not just potential; it is actual. Some natural human verdicts on thought experiments are false.
The problem is not confined to philosophy. Semantics as a branch of linguistics employs a similar methodology. Much of its evidence comes from natural human verdicts on sample sentences, envisaged as uttered in hypothetical circumstances.
Those verdicts may be mediated by fallible heuristics rather than issuing directly from semantic facts somehow directly available to the speaker. Linguists as well as philosophers are interested in the semantics of vagueness, conditionals, and propositional attitude ascriptions. They face many of the same methodological challenges.
The method of hypothetical cases, applied in a naïve falsificationist spirit, faces the problem of error-fragility in practice, as well as in theory, when verdicts on thought experiments result from humanly universal heuristics of limited reliability. The scientific analogy is not to a poorly executed experiment giving a single false negative, but rather to a repeatable experiment whose design ignores a hidden source of systematic error.
The scientific analogy does not support any proposal to abandon the method of hypothetical cases in philosophy. On the contrary, errors in data from thought experiments should no more motivate philosophers to give up using thought experiments than errors in data from real-life experiments motivate natural scientists to give up using real-life experiments. Instead, what the scientific analogy supports is the search for controls to mitigate the problem by reducing error-fragility. We cannot realistically hope to prevent errors in the data from ever occurring. What we can realistically hope for are methods that will enable us both to prevent such errors from doing too much damage and eventually to identify and correct the errors. In seeking such methods, we should at least consider how the problem of erroneous data is treated in natural science.
To be scrupulous, we should note a terminological subtlety. The analogy between erroneous data from real-life experiments and erroneous data from thought experiments presupposes that verdicts on the latter count as 'data' in the scientific sense. A verdict is like an attempted measurement of the truth-value of a proposition about the hypothetical scenario, somewhat as quantitative data are like attempted measurements of the value of some physical quantity.
The term 'data' in this scientific sense is by no means precise. 'Data'
are sometimes defined as 'facts', yet the occurrence of errors in data is acknowledged, even though there are no false facts.2 As I will use the term 'data', some data are indeed false, so data are not facts.
Hence data need not be evidence, given that nothing true is inconsistent with the evidence (Williamson 2000: 200-202). For present purposes, we can think of the data as prima facie evidence.
Of course, thought experiments are by no means our only source of evidence in philosophy. On my view, anything we know is part of our total available evidence, in philosophy as elsewhere. But for present purposes, we can focus on thought experiments as the relevant source of evidence, in developing the analogy between data in natural science and data in philosophy. In any case, the best test of an analogy is to try it out.
2.2 Data fitting
In considering the error-fragility of a naïve falsificationist methodology, it is natural to focus on the case of a given data point as an apparent counterexample to a given theory. The question is whether one can rely on that data point. One may treat error as conceivable,
2 For quantitative data, 'correct' should be qualified by 'within the specified margin for error'. though unlikely. But that narrow focus makes the problem look less urgent than it really is. For the overall situation is typically that we have a large body of data, which we are trying to design a theory to fit. Even if each single data point is probably correct, it is often almost certain that the whole data set contains at least one incorrect data point. In natural science, a given data set may include millions of data points. In philosophy, the numbers are obviously much smaller, but a branch such as epistemology has still accumulated scores of thought experiments, any of which may be used to test a given theory. It also has real-life examples, such as chicken-sexers, who can unreflectively but reliably classify chickens on sight as male or female. For simplicity, I will focus on thought experiments.
In effect, philosophers are often trying to design a theory to fit such a body of data. Even if one is legitimately optimistic about the reliability of standard verdicts in philosophical thought experiments, it would be very rash to assume that none of the standard verdicts is incorrect, either through a heuristic's inherent limitations or for some other reason. In philosophy as well as natural science, a reasonable assumption is that we are trying to design a theory to fit a set of data points not all of which are correct.
We cannot solve the problem simply by resolving to be more careful in coming to our verdicts on thought experiments. Careless errors in thought experiments are usually picked up quite quickly.
Many standard thought experiments have been mulled over by the philosophical community for decades. A resolution to take more care would probably make little difference. In any case, if our verdicts are the products of fallible heuristics, taking more care might simply involve applying the heuristic more carefully, when the problem is with the heuristic itself. We cannot realistically expect to make ourselves into error-free thought experimentalists, any more than natural scientists can realistically expect to make themselves into error-free real-life experimentalists.
Instead, we need an error-robust methodology, which enables us to identify and correct our errors after we have made them rather than vainly trying to ensure that we never make them in the first place. More than that, we need to learn from our mistakes, by understanding what went wrong and becoming less likely to make such mistakes in the future. We can make progress by considering how curve-fitting works in natural science.
To keep things simple, imagine that we are studying a physical variable y as a function of another physical variable x. The values of x and y in given units are real numbers. We measure the value of y for many different values of x, and graph the results. The aim is to define a mathematical equation (a curve) for y in terms of x that goes as close as possible to the points on the graph. As it turns out, that can be done perfectly. Although the number of points to fit may be large, it is still finite, say n. Then one can always find a polynomial equation of degree n –1 that goes exactly through all the data points:3
y = a1 x n −1 + a2 x n − 2 + … + an −1 x + an
Here the coefficients a1, a2, . . ., an–1, an are real numbers, parameters selected to fit the data. Since the equation is defined by these n independent parameters, the equation (or model) is said to have n degrees of freedom—n moving parts, as it were. By hypothesis, some of the data points are incorrect—something went wrong in the process of measurement. Even if there are no systematic errors in the data, there is still random noise. The curve goes through all the data points, irrespective of whether they are correct or incorrect.
What happens when new data points are obtained? Now we have a larger total number of data points, but it is still finite, say n + k.
Almost certainly, the old curve does not go exactly through the new data points; in other words, the new data falsify the old theory's
3 For simplicity, I assume that the value of y has been measured at most once for any given exact value of x. I also assume that the number of parameters required to fit a polynomial exactly to noisy, partially incorrect data will be the same as the number of data points. These assumptions are typically correct. predictions. After all, we already know that the equation is incorrect, because it goes exactly through an incorrect data point, and so gives an incorrect value of y for that value of x. If the old curve went exactly through the new data points, that would be amazingly good luck, unless the errors are very systematic, since the new data points would have to fit in exactly with the old errors. But one can still find a polynomial equation of degree n + k –1 that goes exactly through all the old data points and all the new ones. It will have n + k independent parameters, b1, b2, . . . , bn+k–1, bn+k, so the new model will have n + k degrees of freedom. Usually, the new polynomial will behave quite differently from the old one, especially for extreme values of x, where the old polynomial's behaviour will be dominated by that of its largest term, a1xn–1, while the new polynomial's behaviour will be dominated by that of its largest term, b1xn + k–1, which will be quite different. The new curve is also very likely to have more humps and dips than the old one. Although the new curve will coincide with the old one at the n original data points, the old curve will typically not be a good approximation to the new one elsewhere.
This process is repeated every time new data come in. The overall result will not be gradual convergence to the correct equation, since the degree of the polynomial always increases. Instead, there may be increasingly wild oscillation. All this involves large failures of prediction at each stage.
The pathology just described is not merely hypothetical.
Something like it, in a milder form, is a familiar kind of bad science.
Scientists call it 'overfitting' (Forster and Sober 1994). Textbooks of model selection warn against it (see, for example, Burnham and
Anderson 2010). Overfitting is well known to result in unstable theorizing and predictive failures.
To some philosophers, the term 'overfitting' may sound like a contradiction in terms. Fitting the data is a good thing; how can one have too much of a good thing? Even granting that one's data set probably contains errors, one might still feel that since it is the best one has to go on, one can do no better than to fit one's theory to it as closely as one can. But bitter scientific experience shows how unlikely that approach is to end well.
For scientists, a key symptom of overfitting is an increase in degrees of freedom. A common platitude is 'With enough degrees of freedom, you can model anything'. To a philosopher, that may sound like welcome flexibility, but it is not intended in that spirit.
Rather, the point is that if one has given oneself so much flexibility that one can model anything, then one can smoothly accommodate any errors in one's data, so no difficulty will occur to warn one of a potential error, and one will receive no warning that something is amiss. Not even the most grossly erroneous data point will stick out as anomalous. No data point will be a suspicious outlier, because one's curve will go through them all. A standard form of scientific criticism is that a model has too many degrees of freedom. If increasing the number of degrees of freedom is treated as cost-free, the likely result is unstable theorizing under the influx of new data.
Too much flexibility, too much freedom, is a bad thing.
Scientific consensus strongly favours parsimony in degrees of freedom, even at the cost of a looser fit with the data. A large part of the rationale is that allowing oneself less flexibility to fit the data will tend to make incorrect data points show up as outliers, and so let underlying patterns emerge more clearly; the distorting effect of errors in the data is reduced. For example, when scientists use a polynomial, they like its degree to be as low as reasonably possible
(linear is best), without totally flattening the data, to minimize the number of coefficients. This is a far more realistic and error-robust strategy than the hopeless aim of trying to be so careful that there are no incorrect data points in need of identification. It is a better strategy for achieving a reasonable level of predictive success.
As Malcolm Forster and Elliott Sober (1994) have argued, the problem of overfitting helps explain and justify scientists' preference for simple theories over complicated ones, for the number of degrees of freedom roughly measures the complexity of a model. By restricting themselves to comparatively simple theories, they make the data harder to fit, and so reduce the threat of overfitting.
Some philosophers have argued that simplicity is a virtue only in theories at the most fundamental level in physics and metaphysics
(Sider 2016, to which Williamson 2016b replies). But that squares neither with scientific practice nor with its theoretical rationale.
The threat of overfitting is just as serious in non-fundamental sciences such as geology, biology, and economics, and in non-fundamental branches of physics, as it is in fundamental physics, and biologists, economists, and non-fundamental physicists are just as keen to keep the number of degrees of freedom low. Even detectives prefer simple explanations of the evidence. One of the problems with conspiracy theories is that their complexity rapidly increases as more and more people with varying motives have to be notionally recruited into the conspiracy to explain how it managed to remain secret.
In the latter examples, measuring complexity by the number of degrees of freedom is admittedly a stretch. In truth, the standard definition of degrees of freedom in terms of independent parameters is less rigorous than it may sound. It is right in spirit, and often works in scientific practice, but it is not fully general or precise. After all,
Georg Cantor showed that there is a one-one correspondence between the real numbers and the n-tuples of real numbers for any given positive natural number n. Consequently, one can encode any ordered n-tuple of real numbers in a single real number, and thereby encode a model with n real-valued parameters (n degrees of freedom) in a model with just one real-valued parameter (one degree of freedom).
Even if one sticks to functions standardly used in natural science, one can fit all sorts of data with a wave-like sine function specified by just three parameters, for its amplitude, frequency, and phase, by making the frequency high and so the waves close enough together. The match may be perfect even though the data show no overt sign of wave-like behaviour and also perfectly match a simple cubic equation. Absent any background theoretical reason for expecting wave-like behaviour, preferring the sine function would seem scientifically bizarre. Yet cubic equations have four degrees of freedom, which is more than the sine function's three. Thus, the simple criterion of the number of independent parameters in the model is too crude to capture scientific practice exactly. Rather, it is a useful scientific heuristic, an imperfectly reliable sign of something subtler.
The vaguer but deeper lesson is that if we make fitting the data too easy, by helping ourselves to such a wide range of options that any supposed data will find a match, we also make ourselves easy victims of the data, because the process will not alert us to any defects or outliers in them. Flexibility has costs as well as benefits.
We can still talk of 'too many degrees of freedom', understanding the phrase in that less formal way. Knowing how to recognize when there are too many may be a local matter of enculturation and experience in a given sub-discipline, depending on what is needed to achieve a reasonable level of predictive success in that area.
The informal understanding of 'degrees of freedom' also facilitates generalizations to philosophical methodology, since in philosophy we rarely deal with numerical equations, or fitting quantitative data, or data sets large enough for statistical significance. In most cases, we cannot expect literally to count the degrees of freedom in a philosophical theory, since deciding what to count as its 'independent parameters' would involve too many semi-arbitrary choices, though we can come close in more formal areas of philosophy.4
4 Recent successes of AI at tasks such as face recognition and text prediction have been taken to mandate a re-evaluation of accepted wisdom about overfitting, since they have been achieved by using almost unlimited numbers of degrees of freedom
(Bartlett, Long, Lugosi, and Tsigler 2020, Dar, Muthukumar, and Baraniuk 2021). The programmes are typically trained on vast sets of typically accurate data, and their success is measured by predictive accuracy rather than theoretical understanding. One cannot plausibly argue from such cases that natural scientists have been misguided in their strategy of limiting degrees of freedom. Since philosophical inquiry is much more similar in its aims and methods to scientific inquiry than to face recognition or 2.3 Overfitting in philosophical analysis
Comfort with a succession of increasingly complex theories is easily observed in the still-continuing twentieth-century tradition of providing would-be 'conceptual analyses', or just 'analyses', for philosophically significant terms of ordinary language such as
'know', 'cause', 'mean', and 'free', or for the concepts they are supposed to express. For example, in the case of 'know', one can see the complexity proliferate over a decade by leafing through the pages of
Shope (1983); similarly, for the programme of analysing causation in counterfactual terms, following David Hume and David Lewis, see Paul and Hall (2013), and for the programme of analysing meaning in psychological terms, following Paul Grice, see Davis
(2002). The adjective in the term 'analytic philosophy' has been closely associated with that tradition of analysis.
Proposed analyses were tested against potential counterexamples, mostly drawn from hypothetical cases. Thus, the relevant data were taken to be about hypothetical cases, articulated in roughly the same terms as the analysans (on the right-hand side of the analysis)
or the analysandum (on the left-hand side). Overfitting and heuristics in philosophy
Since the analysans was supposed to be necessary and sufficient for the analysandum, counterexamples could be to either the alleged necessity or the alleged sufficiency. Notoriously, alternating spirals grew of ever more complex analyses and ever more complex hypothetical counterexamples, each analysis provoking counterexamples and each counterexample inspiring revised analyses. If the counterexample was to the necessity of the analysans for the analysandum, showing the analysans to be too strong, one could weaken it by adding an extra disjunct. If the counterexample was instead to the sufficiency of the analysans, showing it to be too weak, one could strengthen it by adding an extra conjunct. But making the analysans weaker in one place often made it too weak somewhere else, and making it stronger somewhere often made it too strong somewhere else. Conjunctions of disjunctions and disjunctions of conjunctions started to emerge. The whole process was reminiscent of the tradition in Ptolemaic astronomy of adding epicycles whenever a new discrepancy with observation was found.
In retrospect, it is striking how little resistance there was for so long to the ramifying complications. From inside the tradition, it just felt like discovering more and more hidden complexity in ordinary concepts. The analogy with degenerating research programmes in natural science (in the sense of Lakatos 1970) may have been occluded from practitioners by their understanding of themselves as engaged in the a priori conceptual work of analysis, sharply contrasted with the a posteriori empirical work of science.
From outside the tradition, it looks like a classic case of overfitting, with the typical symptom of adding ever more terms—here in the form of conjunctions or disjunctions—and the resulting theoretical instability and predictive failures in new cases.
A distinctive aspect of the case was that the postulated complexity was attributed not to the world at large but specifically to the cognitive resources of ordinary people, whose concepts or meanings were supposedly being analysed into more basic terms.
As the conceptual structure became ever more complex, to regard it, even metaphorically, as if it were written into lexical entries for the target words in an ordinary person's head became ever less plausible. Yet the complex structure had to be implicit in the ordinary use of the term, and somehow available to a priori reflection, even though normal speakers of the language, presented with the proposed analysis, would typically have great difficulty in so much as comprehending the analysans, and even more in guessing whether or not it corresponded to their use of the analysandum.
Unease about the intended cognitive status of analyses found early articulation in the 'paradox of analysis' (Langford 1942): if the analysis is correct, the analysans expresses the same concept as the analysandum, so they differ only verbally, so the analysis is trivial; thus, no analysis is non-trivially correct. The paradox continued to niggle, with no agreed solution, but also without doing much to slow the growth of the analysis industry.
If the complex structure of the analysans is supposed to play some cognitive role in the process of real-time thinking with the analysandum, questions of computational feasibility arise, which were never properly addressed. From an evolutionary perspective, it is hard to understand how the near-ubiquitous use of concepts such as 'know' and 'cause' (or 'make') in ordinary thought could fail to be counter-adaptive if they really had the apparently ad hoc complex structures the analyses attributed to them. Anyone who has tried working out whether such a philosophical analysans applies to a given hypothetical example will have experienced what a tricky and time-consuming task it is, comparable to a lawyer's job of applying a complicated piece of legislation to a given case.
The easy fluency with which ordinary folk apply words like 'know'
and 'make' in real time would be near-miraculous. On the other hand, if the complex structure of the analysans is not supposed to play some cognitive role in the process of real-time thinking with the analysandum, the intended status of the analysis becomes still more mysterious, given that it is supposed to be an analysis of a concept with which we think. Why should philosophers even expect philosophically interesting concepts to have analyses? Analysis is not supposed to be infinite; it is supposed to bottom out somewhere—why not straight away, at least for philosophically interesting concepts, and perhaps for most or all concepts (Fodor 1998)? In early analytic philosophy, the programme of analysis was motivated by much more general assumptions. For example, Bertrand Russell proposed the Principle of Acquaintance: 'Every proposition which we can understand must be composed wholly of constituents with which we are acquainted'; he called it 'the fundamental epistemological principle in the analysis of propositions containing descriptions' (Russell 1910–11, his italics). Given Russell's extreme empiricist conception of acquaintance, on which we are not acquainted with ordinary material objects, the analysis of almost any proposition is forced to go far below the surface to reach a level of constituents with all of which we can be acquainted. But later analytic philosophers pursued programmes of analysis whose prospects of success were not supported by any such wider vision.
In recent decades, the ideology of 'concepts' and 'conceptual analysis' has come under increasing pressure. Our firmest grip on concepts comes from the words supposed to express them, but then we need an answer to the question: when does a word W used in a context c express the same concept as a word W* used in a context c*? No really helpful answer is available. Identity in reference is presumably insufficient, since most theorists of concepts agree that 'water' and 'H2O' can refer to the same stuff without expressing the same concept. One may be told that W in c expresses the same concept as W* in c* if and only if the condition for understanding
W in c is the same as the condition for understanding W* in c*, but that is unhelpful because the conditions for linguistic understanding are so loose and vague. Alternatively, one may be told that
W in c expresses the same concept as W* in c* if and only if W in c is governed by the same rules as W* in c*, but that will turn out to be circular because the rules themselves are individuated in terms of their constituent concepts. And so on. Without a workable theory of identity conditions for the concepts words are supposed to express, we lose methodological control of inquiry into the concept expressed by a given word W in a given context c, since we cannot tell which uses of W are irrelevant because they express a different concept. For purposes of this book, we need go no deeper into the disarray of concept theory: not even a theory of concepts in good working order would make the methodological issues of overfitting and heuristics go away.5
As enthusiasm for conceptual analysis has waned, and metaphysics has revived in analytic philosophy, many of the philosophers who still seek analyses understand their project as a metaphysical rather than conceptual quest. They seek to analyse causation itself, rather than the concept of causation, or freedom itself, rather than the concept of freedom. Correspondingly, the standard of success for an analysis is just for the analysans to be metaphysically necessary and sufficient for the analysandum, rather than conceptually necessary and sufficient, and perhaps also for the analysans to be metaphysically prior to the analysandum in some sense, rather than conceptually prior. The focus has switched from how we are thinking to what we are thinking about.
In practice, the change has been less radical than it sounds.
Objections to a given conceptual analysis were usually cases where the analysans held without the analysandum, or vice versa; since they usually look metaphysically as well as conceptually possible, they also serve as objections to the corresponding metaphysical analysis. Similarly, objections to a given metaphysical analysis are usually cases where one holds without the other; since they usually
5 The status of conceptual analysis is of course closely related to that of the analytic-synthetic distinction, famously attacked by Quine 1951. My critique of analyticity or conceptual truth is developed in Williamson 2007, extended with many replies to objections in Williamson 2021a; it differs from Quine's strategy by not depending on scepticism about semantics. For a nice contrast between extreme optimism and extreme pessimism about the prospects for conceptual analysis, see Jackson 1998 and
Fodor 1998. look conceptually as well as metaphysically possible, they would also serve as objections to the corresponding conceptual analysis.
Again, objections to conceptual priority can often be recycled as objections to metaphysical priority, and objections to metaphysical priority can often be recycled as objections to conceptual priority.
For such reasons, switching the operative standard from conceptual analysis to metaphysical analysis does little to improve the track record of analysis. The series of analyses do not look convergent; rather, they exhibit the kind of theoretical instability and predictive failures associated with overfitting.
Even if we grant for the sake of argument that everything is somehow metaphysically reducible to an absolutely fundamental level, it does not follow that the reduction of the target phenomena—
causation, freedom, knowledge, meaning, whatever—to the fundamental level will be mediated by an initial reduction of them to other phenomena at the highly non-fundamental level characteristic of a philosophical analysans—for instance, for typical analyses of knowledge, at the level of belief, truth, justification, causation, counterfactuals, and the like. The theoretical instability and predictive failures in the programme's track record is evidence that there is no such mediation.
At this point, a friend of philosophical analysis might try to recruit the considerations about heuristics and overfitting to its aid, by arguing that some original, simple analyses may have been right all along, with the apparent counterexamples being mere artefacts of fallible heuristics.
In the case of the original justified true belief analysis of knowledge (JTB), for example, the suggestion would be that knowledge really is simply justified true belief, while the standard negative verdicts in Gettier cases reflect a limitation of a universal human heuristic for ascribing knowledge. Brian Weatherson (2003) makes the related suggestion that the distinction between justified true belief and its absence might cut at a natural joint, thereby making justified true belief a 'reference magnet' that attracts the reference of the word 'know' as we use it, and globally fitting our use well enough despite local failures of fit such as Gettier cases. Such ideas should not be dismissed out of hand.
To be properly developed, rather than remaining just another application of a generic sceptical argument, a heuristic-based defence of JTB would need, first, to specify what the guilty heuristic is; second, to provide independent evidence that we really use such a heuristic; third, to show how the proposed heuristic delivers a negative verdict on Gettier cases; and fourth, to explain why a charitable interpretation of our practice of using 'know' and similar words nevertheless picks out as its referent justified true belief, thereby falsifying our verdicts on Gettier cases, rather than a relation more directly related to the heuristic and absent from Gettier cases, thereby verifying our verdicts. I am not aware of any promising attempt to meet any of those challenges.
The case is worth dwelling on, to see why JTB is not an example of a natural, elegant, explanatory hypothesis prematurely dismissed as a result of a glitch in a heuristic. Instead, JTB already shows signs of overfitting; it is an early precedent for the post-Gettier tradition of ad hoc analysis-building.
A defence of the original JTB analysis must employ the original understanding of 'justified', on which justified false belief is possible, as Gettier (1963) emphasizes. After all, if only true beliefs can be justified, the truth conjunct in the analysans is redundant, which no defender of JTB intends. Similarly, to understand justification in terms of knowledge would be contrary to the spirit of JTB. Thus, although justified true belief may be necessary and sufficient for knowledge on a more demanding normative understanding of justification, that does not amount to a defence of JTB (for such a more demanding normative conception of justification, see Williamson forthcoming-a).
A different way to assess the plausibility of JTB is by noting that knowledge is a central focus for our ordinary thought and talk about cognitive matters (Williamson 2000, Nagel 2014): is justified true belief a good candidate to play that role? To take one case, our best ordinary understanding of the actions of non-human animals and young children often involves attributing knowledge to them—for example, they need to know where other agents and other relevant things are—but normative questions of justification in the sense of JTB seem out of place and digressive as applied to non-human animals and young children, who are not responsible agents (see also Kornblith 2002). The distinction between knowing and not knowing is much more primitive than the distinction between having and lacking justification for a belief. To see what happens when one starts from the latter distinction rather than the former, we can look at the work of numerous contemporary epistemologists of an internalist bent, who do indeed regard the distinction between having and lacking internal justification for a belief as the right starting-point for epistemology, and such justification as the central epistemic norm. The category of knowledge is typically marginalized in their work, as is the category of justified true belief, which from their perspective looks like an odd hybrid of ill-assorted factors. For they concede that knowledge requires truth, a blatantly external factor.
One might also argue on naturalistic grounds against taking justified belief rather than knowledge as basic, because the usual motivation for that preference treats the standpoint of consciousness as privileged, whereas most of the cognitive action is pre-conscious.
Since perceptual knowledge depends on some level of perceptual reliability, as even most internalists concede, we can easily check that no internalist standard of justification will make JTB equivalent to knowledge. For internalists typically insist that the external reliability of perception can vary independently of internal phenomenology and justification. On such assumptions, one can easily construct a pair of good and bad cases, identical internally in one's phenomenology, justification, and belief, and externally in the truth-value of a proposition p about the environment, although one's perception is reliable only in the good case, so that one knows p in the good case but not in the bad case. In such a set-up, JTB automatically fails, for since one knows p in the good case, by JTB one has a justified belief in p in the good case. Hence, by the internal identity of the two cases, in the bad case too one has a justified belief in p, and by hypothesis p is still true, so one has a justified true belief in p, but one does not know p. Thus, JTB fails in the bad case.
In other words, the very epistemological outlook that vindicates
JTB's order of analysis, by treating justification and belief as more fundamental than knowledge, undermines JTB for other reasons.
Consequently, JTB is an ill-motivated theory.
We can also test JTB in a more abstract structural way, by seeing how it plays out in simple models within the formal framework of doxastic logic. The upshot is that although JTB is not a disjunctive analysis in the usual sense, for its analysans is a conjunction, not a disjunction, it has a subtler disjunctive effect. In such a model of JTB, the propositions (modelled as sets of worlds) known at a world w are just the disjunctions (unions) of propositions justifiably believed at w with the singleton set {w}: the disjunction inherits the property of being justifiably believed from the first disjunct and the property of being true from the second disjunct
(Williamson 2013b, 2015).6 The known propositions are just the justifiably believed propositions with one extra pimple; they hardly form a natural class. Although some of the assumptions built into the models may be unrealistic, such as the closure of justifiable belief under single-premise entailment (if p entails q and p is justifiably believed then q is justifiably believed), an analysis that behaves so awkwardly under simplifying assumptions is not likely to behave much better when more complications are permitted. Thus, JTB
6 Conjunctive definitions often have such disjunctive effects on what satisfy them.
For example, Kripke's examples of the contingent a priori and the necessary a posteriori
(Kripke 1980) might prompt a philosopher to think that what really matters is the property of being both necessary and a priori. But the propositions which are both are just equivalent to disjunctions of any necessary proposition with any a priori proposition; the disjunction inherits necessity from the first disjunct and a priority from the second disjunct. makes knowledge into a rather artificial, gerrymandered category, not at all a natural candidate for reference, and so unlikely to be meant by the word 'know', since its fit with the use of the word is also poor, as Gettier cases show. JTB is not an elegant analysis; it just provides a list of three poorly related bullet points, of the kind which undergraduates like to write down in their notes.
The point of invoking formal models and naturalistic considerations here is not to make thought experiments redundant, but rather to make the rejection of JTB more robust, by basing it on a consilience of different methodologies—traditional, formal, and naturalistic—each pointing to the same conclusion. We have multiple reasons for regarding JTB as a bad theory.
The objections to JTB do not mechanically generalize to other proposed philosophical analyses, but they are suggestive. For example, the formal modelling illustrates how the apparently unifying effect of conjunctive analyses can be more apparent than real, when the conjuncts are not fruitfully related to each other. A conjunction of miscellaneous factors is also a clue to overfitting, since it suggests too many degrees of freedom.
The method of checking theories by calculating how they play out in simplified formal models is capable of being applied far more widely than it currently is in philosophy. It often provides valuable structural information, not least because it displays a theory's consequences over a whole space of propositions, not just one proposition at a time. Most basically, it is a test of the theory's consistency, both in itself and with elementary background constraints.
Where such tests are possible, they should be applied. They can save much time and energy wasted on hopeless theories that fail the test.
The programme of philosophical analysis is now most associated with the long-running quest for necessary and sufficient conditions in more basic terms for philosophically central yet non-logical words like 'know', 'mean', 'cause', and 'free'. Overfitting became rife, for philosophers were not taught to minimize degrees of freedom.
But, I conjecture, it has not led to the rejection of correct analyses on the basis of misjudged examples, because in these cases there are no correct analyses of the kind sought.
2.4 Overfitting in semantics
The formal semantics of natural languages is pursued in both departments of linguistics and departments of philosophy, with similar methodologies. It makes a fruitful test case for issues about overfitting and degrees of freedom, for several reasons.
First, the formal framework lends itself to counting degrees of freedom. Typically, the semantics is implemented in formal models. Typically, a model assigns semantic values to expressions of the natural language under study relative to various parameters.
For simplicity, we can treat the function mapping each sequence of values of those parameters to the semantic value of the expression relative to that sequence as the meaning of that expression in the model. The theorist chooses a set of parameters so as to enable the semantics to be compositional, in the sense that, in any model, the meaning of a complex expression is determined as a function of the meanings of its simpler constituent expressions and how they are put together. That helps explain how users of the language can understand newly encountered sentences composed of previously encountered words.
As a first approximation, we can equate the number of parameters in the formal framework with the number of degrees of freedom of a model. Really, the situation is more complicated, because a model must assign a meaning separately to each atomic expression of the language—roughly speaking, to each word—so each atomic expression adds another degree of freedom to the model. However, since rival formal frameworks tend to agree that each atomic expression must be assigned its own meaning, and on which expressions are atomic, we can assume that all these degrees of freedom cancel each other out when formal frameworks are compared, leaving only differences between the parameter sets themselves, that is, between the sets of all meanings available in a given framework.7
The formal semantics of natural languages lends itself to discussion of overfitting in another respect too: it is strongly data-driven. A typical driver for theory change is that someone identifies examples in some natural language which the old framework seems unable to handle (a background methodological assumption is operative: that the formal framework should be universal: suitable for all human natural languages). The examples are typically in the form of sample sentences, often with native speaker judgments as to whether they could be correctly uttered in given hypothetical circumstances. In effect, the data are verdicts on elementary thought experiments. One or two data points of that kind may be taken to motivate a revision of the formal framework.
The formal semantics of natural languages also provides a good test case for accounts of overfitting because, historically, some highly successful revisions of a formal semantic framework have indeed taken the form of adding a new parameter, increasing the number of degrees of freedom. For instance, Saul Kripke revolutionized the semantics of modal logic in the period 1959–63
by enhancing models with a new parameter for a 'possible world', in what is sometimes described as the start of the 'intensional revolution'. This development is worth describing in some detail.
Before Kripke's innovation, there were extensional models for non-modal predicate logic. Each non-modal model provides a set of individuals to be the domain of quantification, an extension
7 Some semantic theories posit complex logical forms for syntactically simple expressions, such as 'cause to die' for 'kill', but the choice of logical form for a given such expression itself constitutes at least one degree of freedom. A further complication is that a formal framework may treat some atomic expressions (such as 'is', 'not', 'or', 'and', 'if ',
'some', and 'all') as 'logical constants' with a fixed interpretation, so models need not assign them meanings separately. Formal frameworks can differ from each other in which atomic expressions they treat as logical constants. However, most atomic expressions of a natural language are not plausibly treated as logical. In practice, the whole situation is often much messier than indicated in the text—which is typical of model-building.
I have aimed to provide a reasonable first approximation. over the domain for each atomic predicate of the formal object-language, and a referent in the domain for each individual constant. The truth-value of each formula of the object-language in the model is then defined compositionally relative to each assignment of values to all variables, in the usual way. For simplicity, I will henceforth leave this relativity to assignments tacit; it only makes a difference to the final truth-value for formulas with free variables.
One can define a conclusion to be a logical consequence of a set of premises if and only if the conclusion is true in every model in which every premise is true. Similarly, a formula is a logical truth if and only if it is true in every model. Famously, there are formal proof-systems for first-order non-modal logic which can be proved sound and complete, in the sense that if a conclusion is provable in the system from some premises then it is a logical consequence of the premises (soundness), and conversely, if the conclusion is a logical consequence of the premises then it is provable in the system from those premises (completeness).
The non-modal object-language can be expanded to a modal object-language by the addition of modal sentence operators such as ◊ (informally read as 'possibly') and ◻ (informally read as 'necessarily'). Modal operators do not fit into the standard extensional framework because the extension of a formula in such a model is simply its truth-value, and modal operators are not truth-functional: the truth-value of the output is not a function of the truth-value of the input. For example, if a formula α is false in a model, ◊α may be either true or false in the model, and if α is true,
◻α may be either true or false. An increasingly urgent question in the 1940s and 1950s was how to adapt models for non-modal logic to modal logic, preferably so as to enable analogous soundness and completeness theorems to be established for appropriate formal proof-systems for first-order modal logic.
A simple, natural, and economical strategy is to treat the modal operators as generalizing over the extensional models themselves.
More specifically, for any formula α, ◊α is true in a model if and only if α is true in some model, and ◻α is true in a model if and only if α is true in every model. Thus, possibility is understood as truth in some model, and necessity as truth in every model. If we regard extensional models as demystified possible worlds, then possibility is equated with truth in some possible world, and necessity with truth in every possible world. Rudolf Carnap (1947) pursued a strategy along these lines, using syntactic 'state-descriptions' rather than extensional models, but to very similar effect. He even compared his state-descriptions to Leibniz's possible worlds (which were ideas in the mind of God). The consequent reduction of modality to syntax was attractive from the perspective of Carnap's logical positivism.
However, for various technical reasons, the Carnapian approach worked poorly (Williamson 2013a: 75–80). In particular, no formal proof-system is sound and complete for the logical consequence relation it generates. Although many logicians in the 1950s contributed to the search for an alternative approach to the model theory of modal logic, it was Kripke who took the decisive step, in effect by sharply separating the role of possible worlds from that of models. He defined a new kind of model. Such 'Kripke models'
are intensional models. A Kripke model is equipped with a set W, required only to be non-empty, whose members can informally be thought of as possible worlds, although that plays no role in the development of the model theory proper, which involves only mathematical and syntactic reasoning. In a model, the members of W
are in effect the available values of the world parameter. The model assigns each 'world' (each member of W) a set of individuals to be its domain of quantification. The model also assigns each atomic predicate an intension, a function mapping each 'world' to the predicate's extension at that world, defined over the appropriate domain. Formulas are assigned truth-values compositionally relative to each 'world' (they are also relative as before to an assignment of values to variables, which we can ignore for present purposes). For any formula α, ◊α is true at a 'world' w if and only if α is true at some
'world' in W, so possibility is understood as truth in some world, and ◻α is true at w if and only if α is true at every 'world' in W, so necessity is understood as truth in every world (in the simplest version of the semantics). The model also singles out one member of
W, which is informally understood as the actual world. A formula is evaluated as true in the model, without relativization to a 'world', if and only if it is true at the 'actual world' of the model, but the
'non-actual worlds' are still needed to determine whether modal formulas are true at the 'actual world' of the model, since the modal operators are interpreted as quantifiers over worlds.
The simple structures just described are quite restrictive, because they all validate the strong modal logic S5, on which nothing is contingently possible or contingently necessary. The formulas ◊p → ◻◊p,
◊◊p → ◊p, and p → ◊p are all theorems of S5, but fail on many interpretations of the modal operators. For example, when ◊ is interpreted in terms of easy possibility (and ◻ as ¬◊¬), ◊◊p → ◊p is invalid, because even when one can get from A to B by an easy step, and one can get from B to C by an easy step, it does not follow that one can get from A to C by an easy step. When ◊ is interpreted in terms of permissibility, or compatibility with what one believes, or the past or future, p → ◊p is invalid, for when something happens, it does not follow that its happening is permissible, or compatible with what one believes, or past, or future. Kripke therefore equipped his models with an accessibility relation R between 'worlds'. Formally,
R can be any binary relation over W. The generality over 'worlds'
is then restricted by accessibility, in the sense that ◊α is true at w if and only if α is true at some world to which w has R (possibility is truth in some accessible world) and ◻α is true at w if and only if α
is true at every world to which w has R (necessity is truth in every accessible world). To invalidate ◊◊p → ◊p, one allows R to be non-transitive; to invalidate p → ◊p, one allows R to be non-reflexive.
The accessibility relation makes the formal framework much more flexible—and in doing so adds another degree of freedom.
Kripke's work had a profound influence on philosophy. The apparatus of possible worlds soon became a standard part of an analytic philosopher's toolkit, a convenient framework for use in thinking and talking about all sorts of topics. Philosophical theses were increasingly formalized in modal rather than non-modal terms.
Quine's arguments had put modal language under a cloud of suspicion, with dark threats of incoherence, especially when the possibility or impossibility at issue concerned individuals themselves, irrespective of how they were designated, and so resisted paraphrase in terms of the consistency or inconsistency of sentences.
Although Kripke's formal semantics by itself gives little specific information on which such de re modal claims are true, it does call the bluff of those threats of incoherence, and demonstrates very clearly that there is no purely logical obstacle to the meaningfulness of de re modal claims. Natural versions of his semantics also validate some significant structural principles with a metaphysical edge, such as the non-contingency of identity and distinctness. The result was in effect to give the green light to substantive theorizing about modal metaphysics, in which Kripke himself played a leading role.
On the technical side, the perspicuous formal structure of Kripke models lends itself to mathematical investigation, and the model theory of modal logic became a flourishing branch of mathematical logic. It also found numerous applications in other disciplines, often using models equipped with whole families of accessibility relations, each associated with its own modal operators. For example, in computer science, modal logic is applied to the study of indeterministic computing, where the members of W are interpreted as the possible states of the computer, and each programme is associated with an accessibility relation which one state has to another if and only if running the programme can take the computer from the former state to the latter (Pratt 1976 is a seminal paper on dynamic logic, Troquard and Balbiani 2022 a recent survey). Kripke models are also standard in epistemic and doxastic logic, where the knowledge and belief operators are indexed to agents, and one state has a given agent's accessibility relation to another if and only if, when the agent is in the former world, for all they know (or believe) they are in the latter world. Such models are used in theoretical economics and computer science as well as in formal epistemology
(Fagin, Halpern, Moses, and Vardi 1995).
Here, our interest is in the contribution of Kripke models to the formal semantics of natural languages. Although the object-language for his model theory was a formal language, its operators
◊ and ◻ were generally understood to be formal representations of modal operators such as 'possibly' and 'necessarily' in natural languages. Discussions of modal metaphysics often moved seamlessly in and out of languages for quantified modal logic and natural languages. From a linguistic perspective, the most common modal terms are auxiliaries such as 'must', 'can', 'could', 'may', 'might',
'would', 'should', 'ought', and so on. They are commonly used to make highly contingent claims, for which Kripke models are far more natural than a Carnapian framework: the accessibility relation can be as local as desired. Linguists soon applied a world parameter to the semantics of modal auxiliaries in natural languages
(Kratzer 1977 was especially influential). More generally, the use of an intensional framework with a world parameter for the formal semantics of natural languages became standard.
In short, introducing a world parameter to semantic models proved immensely fruitful in logic, philosophy, linguistics, and beyond. It was clearly a progressive move. Adding a degree of freedom is not always bad.
The treatment of context-dependence offers another case of the fruitful addition of new parameters to a formal semantic framework. The occurrence of terms whose reference varies with context is not in doubt: obvious examples include demonstratives like this', 'that', 'then', 'there', and 'they', and other indexicals like 'I' and
'now'. Such context-dependence is not ambiguity: that the word 'I'
refers to me when uttered by me and to you when uttered by you is explained by the same linguistic rule; we use the word with the same linguistic meaning. Although it is controversial how far such context-dependence extends beyond the obvious cases, the need for a proper semantic treatment of it is clear. Such a treatment will require contextual parameters, in order to formulate general linguistic rules such as the rule of reference for 'I'.
The seminal recent account of the semantics of context-dependence is by David Kaplan (1989). One might hope that the parameters needed to handle intensional operators could also be used to track context-dependence: for example, that Kripke's world parameter for modal operators and an analogous time parameter for temporal operators would in effect track shifts in the world and time of the context. But Kaplan showed that it is not so. Take the word 'tomorrow'. As uttered on a given day D, it refers to the day after D, D +1. Imagine someone saying on D 'When it's tomorrow,
I'll feel better'. To handle the phrase 'when it's tomorrow', which applies 'when' to the sentence 'it's tomorrow', the compositional semantics must evaluate 'it's tomorrow' with respect to different times, to determine which of them it is true at. But that is quite different from determining when one can truly say 'it's tomorrow', for the answer is: never (trick cases aside). To get the right result, the semantics must evaluate 'it's tomorrow' as uttered on day D with respect to other days: as uttered on day D, 'it's tomorrow' is true with respect to day D +1. In Kaplan's terminology, one must distinguish the context of utterance (on day D) from the circumstance of evaluation (on day D +1). The reference of 'tomorrow' is fixed in the context of utterance, and then carried over to the circumstance of evaluation. Since the circumstance of evaluation varies independently of the context of utterance, separate time parameters are required for each, and likewise for world parameters. That is how 'tomorrow' manages to be a rigid designator, even though its designation varies over time: if the context of utterance is held fixed, its designation remains the same while the circumstance of evaluation is varied. By contrast, context-dependence is variation in reference (or designation) when the circumstance of evaluation is held fixed while the context of utterance is varied; that is why 'tomorrow' is context-dependent. Kaplan uses the distinction between context of utterance and circumstance of evaluation to implement his general theory of content and character, where the content of an expression in a given context is what it contributes to the propositions expressed by sentences containing it as uttered in that context, while its character is the function mapping each context to the expression's content in that context. The content of 'I' in a given context is normally the speaker of that context. The character of 'I' is what remains constant across contexts, a good candidate for its linguistic meaning.
In short, a proper semantic treatment of context-dependence would hardly be possible without something like the distinction between context of utterance and circumstance of evaluation, and the consequent multiplication of parameters.
Both Kripke's work and Kaplan's were, and still are, paradigms of successful innovation in formal semantics. That may well have given semanticists the impression that this is just what progress in semantics looks like: introducing one or more new parameters into the formal semantic framework to explain linguistic data that could not be explained otherwise. That is just what one would expect from a Kuhnian perspective on semantics: scientists recognize solutions to new problems by their similarity to paradigmatic solutions of old problems. The trouble in this case is that if one keeps introducing new parameters into the semantic framework, thereby increasing degrees of freedom, one will sooner or later sink into overfitting.
We cannot reasonably expect a universal formula for when to stop adding parameters, much though some philosophers might demand one. As so often in science, it requires experience and good judgment. But one must at least recognize the problem, and not regard the introduction of a new parameter as cost-free. Each new parameter makes overfitting more likely.
A semanticist might object that if a new parameter is needed to explain the data, it would be a dereliction of duty not to introduce one. But that is a generic reply, which can always be offered in defence of overfitting. We must ask whether the data really are all correct, and whether the new parameter really is needed to explain them. If introducing a new parameter is regarded as a paradigmatic form of progress in semantics, or at least as methodologically low-cost, then there is little incentive to probe the data for errors, or to keep seeking an alternative explanation for the data within the current framework.
For example, relativism as a view in contemporary semantics involves adding a parameter to the circumstance of evaluation for something like a standard of assessment, in order to explain data about predicates of personal taste and other phenomena (Lasersohn
2005, MacFarlane 2014). That the linguistic phenomena have been correctly described, and can be explained only by adding an assessment parameter to the circumstance of evaluation, is by no means obvious (Cappelen and Hawthorne 2009). For instance, I say to Ana
'Rhubarb is disgusting'; Ana says to me 'Rhubarb is delicious'. In a sense, we disagree; in a sense, we are both right. But if I spoke in a context where the relevant reference class comprised just me, while she spoke in a context where the relevant reference class was just her, then we both spoke truly, and the apparent disagreement was merely verbal, as if I had said 'I like rhubarb' and she had replied
'I don't'. By contrast, if we both spoke in a joint context where the relevant reference class comprised both me and her, then the disagreement was real, but we both spoke tendentiously and falsely.
Once such confusions as to the operative context have been cleared up, the invocation of a new parameter in the circumstance of evaluation may have nothing left to explain.
As in the case of philosophical analyses, adding too many parameters is not the only form of over-complication in semantics. One can also overfit by overusing the standard contextual parameters, for example, to gerrymander a complicated contextualist semantics on which content varies with context in ad hoc ways, or by diagnosing context-dependence more widely than necessary.
Not all semanticists accept that simplicity is a theoretical virtue in the semantics of natural languages. Perhaps the concern is that meaning in natural languages may just be very complicated. But that too is just an instance of a generic form of scepticism about simplicity as a theoretical virtue. A scientist in any branch of science, accused of overfitting, can respond that what they are investigating may just be very complicated. Indeed, in semantics, apart from the usual need to avoid overfitting, there is the additional concern that an over-complicated semantic framework may impose infeasible computational burdens on ordinary speakers. In contemporary semantics, one often sees very complex semantic accounts presented with no apparent sense that their complexity might be a theoretical cost.
A current test case is the research programme of dynamic semantics (not to be confused with Pratt's dynamic logic). In slogan form, the central idea is that 'meaning is context change potential'.
Dynamic semantics is motivated by phenomena such as cross-sentential anaphor. For example, I can say 'Samuel kicked a stone'
and later add 'It rolled into a ditch'. Together, my two statements are equivalent to 'Samuel kicked a stone, which rolled into a ditch', but it is broken into two. In a standard formalization of my original statement, the phrase 'a stone' would introduce an existential quantifier, with no implication of uniqueness; he may have kicked several stones. My use of the pronoun 'it' in my second statement is anaphoric on 'a stone', so one wants to formalize it with a variable bound by the existential quantifier, but that does not work because the quantifier's scope is confined to my original statement.
Although this is not a straightforward counterexample to a non-dynamic framework, it is unclear how to handle it within such a framework. By contrast, dynamic semantics in effect extends the scope of 'a stone' over the whole subsequent discourse. Dynamic semantics is a generalization of standard truth-conditional semantics, in the sense that the latter can be recovered as a special case of the former, but dynamic semantics is significantly more complex and flexible than standard truth-conditional semantics. As another example, 'A and B' is not in general equivalent to 'B and A' in dynamic semantics, since the second conjunct is processed with respect to a context updated on the first. A recent introductory survey of dynamic semantic emphasizes its flexibility as a framework (Nouwen, Brasoveanu, van Eijck, and Visser 2022), but, as we have seen, the obverse of flexibility is overfitting. The jury is still out on whether any linguistic phenomena are explicable only by dynamic semantics. The risk is that dynamic semantics turns out to be another manifestation of overfitting.
A more specific case is the semantics of conditionals. In their attempts to do justice to the complex ways we use conditionals in natural language, semanticists have offered a wide variety of complex semantic and pragmatic accounts of those conditionals.
Elsewhere, I have argued in detail that humans' primary heuristic for assessing such conditionals is the suppositional heuristic described in chapter 1, and that it is implicitly inconsistent
(Williamson 2020). No semantics will validate all aspects of our use of 'if '. Consequently, the search for a semantics that does validate all those aspects is condemned to overfitting. Instead, we do better to accept that our use of 'if ' is flawed, the data cannot all be taken at face value, and the semantics of 'if ' must be related to our use of it less directly. That opens the way to rehabilitating the simplest of all semantics for 'if ', the material, truth-functional interpretation.
How far that approach can be generalized to other problem cases for the semantics of natural languages, I leave to the reader as an open question.
2.5 Overfitting in logic
On a popular stereotype of logic, it is not in the business of fitting data and so cannot be guilty of overfitting. Instead, logic is imagined as laying down ground-rules without which our language could not function, let alone express our hypotheses and the data we test them on. But such preconceptions about logic find no support in the actual practice of disputes between proponents of rival logics in the same natural language.
Most famously, Hilary Putnam once argued that data from 'two-slit' experiments in quantum mechanics can best be explained on the hypothesis of a failure in the distributive principle of classical logic, that P and (Q or R) entails that (P and Q) or (P and R) (Putnam
1969). Putnam later withdrew his conjecture, and the programme of 'quantum logic' is generally regarded as a failure, at least in its attempt to explain the puzzling data (Putnam 2012). However, even if Putnam's reasons for making the proposal were confused, there was never a transcendental proof that any such proposal must be confused—unless one counts an argument that relies on the classical logical principles in question. Imagine that tomorrow a team of leading experts in logic and quantum mechanics announces that they have found a better way to explain the data from experiments in quantum mechanics on the hypothesis of a failure in some generally accepted principle of classical logic. A philosopher who tells them that they must be confused, because their proposal violates the rules of the language, would not have much credibility. One might be sceptical of their proposal on inductive grounds, because so many similar proposals have turned out badly in the past, but such scepticism is itself data-driven.
Whether a given allegedly logical principle has the status of a rule of some natural language is a question about that language, to be settled on the basis of evidence by the normal standards of linguistics. Such evidence might include data on what speakers of the language are or are not willing to say in various speech situations.
The evidence would need to discriminate between linguistic rules and regular theoretical principles to which speakers are deeply committed. Strikingly, philosophers who ascribe the status of a linguistic rule to a logical principle tend to provide little or no linguistic evidence to support their claims (for a deeper and more systematic critique of closely related ideas about 'analyticity', see
Williamson 2007, 2021a). In any case, ascriptions of exceptional linguistic status to logical principles are of scant dialectical use in defending a generalization against alternative logicians who deny that it is a logical principle.
After all, if the generalization is not a logical principle, all kinds of data may be used against it. If someone asserts that Newton's laws of motion are laws of logic, a physicist may appropriately respond by providing experimental evidence against Newton's laws. If an alleged law of logic is false, it is not a law of logic. Thus, when critics of classical logic bring all kinds of data against it, the response that logic is not in the business of fitting data would be question-begging. For instance, linguistic data involving epistemic modals such as 'may', 'might', and 'must' have recently been used as a basis for objections to numerous principles of classical logic (Holliday and Mandelkern 2023). If friends of classical logic decide to take such a critique seriously, they have to get their hands dirty by engaging with the alleged counter-evidence and showing what in particular is wrong with it.
Very schematically, if the criteria for theory comparison are divided into simplicity, strength (informativeness), and fit with data, then proponents of alternative non-classical logics typically have no choice but to make their case on grounds of fit with data. For their alternatives are clearly neither simpler nor stronger than classical logic.
In practice, all kinds of phenomena have been wheeled out against classical logic. For instance, the law of excluded middle has been alleged to fail for the open future, the forgotten past, potential infinity, vagueness, semantic paradoxes, quantum physics, and so on. In each case, the critics willingly give examples where they take the law of excluded middle to have unacceptable consequences. If they often leave it unclear exactly what evidence they are relying on in those cases, it is not for want of trying. But if friends of classical logic manage to show that it can accommodate such challenging phenomena, they have thereby enhanced the case for classical logic. Beyond that, both sides aim at more than mere accommodation: they want to treat the phenomena at issue in their preferred logic smoothly and elegantly, without resort to ad hoc devices.
More positively, proposed laws of logic gain support by identifying a common structural pattern in a mass of examples with diverse subject matters, unifying them by bringing them all under one illuminating generalization. For instance, the gradual identification of modus ponens as a logical principle in ancient
Greece was a very significant intellectual achievement; as a general principle, it was not obvious all along (Bobzien 2002). Again, for many readings of modal operators, which principles of modal logic are sound remains unclear—especially for principles where modal operators occur embedded in the scope of further modal operators.
Settling such questions is at least in part a matter of data-fitting (see also Ripley 2016). In a non-causal sense of 'explanation', we aim at an inference to the best explanation of the data.
Since logic is involved in data-fitting, it faces the issue of overfitting. Indeed, the issue takes some of the same forms for logic as we saw it take for semantics, for logical consequence is standardly defined by a generalization over semantic models.
Standardly, a conclusion is defined to be a logical consequence of some premises if and only if every model of the premises is a model of the conclusion—in other words, the conclusion is true in every model in which every premise is true. Some variations on that theme are played for some non-classical logics, but they all involve generalizations over semantic models. Thus, changing the class of models by adding new parameters can change the logical consequence relation, at least for those connectives whose semantics is sensitive to the change.
For instance, Kripke's semantics for non-modal intuitionistic logic involves adding a new parameter with an associated reflexive, transitive accessibility relation. Informally, the picture is that the parameter's values are states of information, and one state is accessible from another when the latter extends the former. The semantics is designed to make every formula behave monotonically: if a state of information verifies it, so does every extension of that state. Monotonicity requires a tweak to the semantic clause for negation (¬): instead of the classical clause that a state verifies ¬α if and only if it does not verify α, Kripke's semantics requires a state to verify ¬α if and only if no extension of that state verifies α, in order to ensure that whenever a state verifies ¬α, so does every extension of that state. As a result, the semantics invalidates the principle of double negation elimination: in some cases, a state verifies ¬¬α
without verifying α. For example, in a model with just two states, s and s+, where s+ extends s, and only s+verifies an atomic sentence p, neither state verifies ¬p, so both states verify ¬¬p, so s verifies
¬¬p but not p.
Without adding new parameters, one can also increase flexibility by extending the range of values available for an old parameter, by adding or subdividing values. Standard semantic models are bivalent: at a given point in the model, each sentence is either true or false, and not both. In three-valued logic, the available values are typically truth, falsity, and 'neither'. In four-valued logic, they may be 'just true', 'just false', 'neither true nor false', and 'both true and false' [sic]. Such flexibility is used to deal with semantic paradoxes such as the Liar. In response to paradoxes of vagueness, the values may spread out into a continuum, represented by the real numbers from 0 (perfect falsity) to 1 (perfect truth), allowing the truth-value of the vague sentence 'It's dark' to rise continuously at dusk and fall continuously at dawn. A multi-dimensional space of truth-values may be invoked to track the multi-dimensionally vague sentence
'It's a religion' in truth-value. As truth-values proliferate, so do the different possibilities for defining logical consequence in terms of them. In some three-valued logics, preservation of non-falsity determines a different consequence relation from preservation of truth. In some other many-valued logics, a conclusion is a logical consequence of some premises if and only if no model makes the conclusion worse in truth-value than every premise, and so on. Conversational virtues may also be built into the definition of logical consequence, by adding new parameters to models. In relevance logic, validity requires the conclusion to be in some sense relevant to the premises, and models are complicated accordingly (see
Anderson and Belnap 1975 and Mares 2004; see Burgess 1981 for a critique of the idea of 'fallacies of relevance'). Perhaps someone will propose politeness logic, whose models have a politeness parameter taking values in a totally ordered set, informally understood as a scale from the rudest to the politest. A model assigns each atomic sentence a rudeness-value. The rudeness-value of a complex sentence is the maximum (worst) of the rudeness-values of its atomic constituents. An argument is valid only if it is politeness-preserving, in the sense that no model makes the conclusion ruder than every premise (other conditions may also be necessary for validity). In politeness logic, the rule of disjunction introduction is invalid, for if a model makes the atomic sentence r ruder than the atomic sentence p, then it also makes the disjunction p ∨ r ruder than p, so p ∨ r is not a logical consequence of p.
The semantics for a logic can be complicated in other ways too.
Most obviously, the semantic clauses for logical connectives can be gerrymandered to invalidate disliked principles. The possibilities are endless.
Revisions of classical logic are often presented as making for more flexibility. Usually, classical logic can still be recaptured from the proposed alternative as a special case. For example, restricting
Kripke models for intuitionistic logic to those with only one state in effect collapses it back to classical logic. Restricting models for many-valued logic to those which assign each atomic sentence one of the two 'classical' truth-values has a similar effect. Thus, the non-classical model theory can be interpreted as recognizing all the possibilities recognized by classical model theory, and more besides. The non-classical logic is strictly weaker than classical logic, since some arguments in the object-language validated by all classical models are invalidated by some models in the non-classical semantics, whereas every argument validated by all models in the non-classical semantics is also validated by all classical models.
Another rhetorically ingenious way of marketing weakness in a logic as a virtue is by saying that a weaker logic makes more distinctions than a stronger logic. Specifically, given two formulas α
and β, α ↔ β may be a theorem of a logic L but not of a weaker logic
L–, though α ↔ α and β ↔ β are theorems of both. Then friends of
L–may say that it distinguishes between α and β, whereas L does not.
Of course, the distinctness of the sentences α and β is not in dispute.
The question is whether α ↔ β is true on all relevant interpretations.
If it is, what is the virtue in being unable to prove it? Analogously, imagine a theory of arithmetic so weak that it lacks '2 +2 =4' as a theorem. It might be advertised as having the advantage of allowing us to distinguish between 2 +2 and 4. Of course, the distinctness of the terms '2 +2' and '4' is not in dispute. The question is whether
2 +2 and 4 are the same number. If they are, what is the virtue in being unable to prove it?
Proponents of non-classical logic face the challenge of explaining the success of classical logic as the standard implicit background logic for proofs in mathematics for two and a half thousand years, by far the most severe test of any logic in human history. A popular strategy is to claim that the language of pure mathematics satisfies the special conditions for the recapture of classical logic from the preferred non-classical alternative. For example, those who reject excluded middle for languages with vague or meta-semantic vocabulary (such as 'true' and 'false') often accept it for the language of pure mathematics, which they take to lack such vocabulary. However, applications of mathematics in the natural and social sciences do involve vague or meta-semantic vocabulary, so the classical-recapture strategy arguably fails to explain the success of classical mathematics in scientific applications (for details see Williamson 2018a). Such alternative logicians cannot escape as easily as they imagine from the daunting challenge of reconstructing mathematics for scientific applications from the starting-point of their weak non-classical logic.
On one view of logic, it is needed to play the role of a neutral arbiter of more substantive disputes in science or metaphysics.
That view favours weak logics, because they are neutral on more questions. Strength in a logic tends to compromise its neutrality.
But what counts as 'substantive' is never made clear. In any case, the view is hopeless because any proposed principle of logic can be attacked on scientific or metaphysical grounds, however mistaken they may be, and so is not neutral on those scientific or metaphysical issues. We have already seen examples of that, and they can be multiplied. Perhaps under the influence of Hegel, some metaphysician claims that all change involves a contradiction (Priest 1985).
Even the anodyne structural principle that logical consequence is reflexive, so α is always a logical consequence of α, may be denied by a follower of Heraclitus, on the grounds that one can never grasp the same proposition twice. If a correct logic comprises only principles incapable of being challenged on scientific or metaphysical grounds, then the correct logic is empty.8
For present purposes, a key feature of weak logics is how unhelpful they are when we need to identify bad data. For a crude case, take dialetheist logic, which permits true contradictions. When a witness contradicts himself, the dialetheist is not best placed to see the problem. We might also be suspicious of a witness who states
'Not everyone present was invited' but refuses to accept 'Someone present was not invited', a consistent combination of attitudes in intuitionistic logic. Of course, alternative logicians may offer more
8 For a more detailed critique of the idea of logic as a neutral arbiter see Williamson
2014a. For more on strength as an abductive virtue in logic see Williamson 2017b. For how confusion between logic and metalogic has led to scepticism about strength as an abductive virtue in logic see Williamson forthcoming-d. Much of the literature on disagreement in logic is vitiated by similar confusions, for example between disagreement in logic on whether ∀P (P ∨ ¬P) (the law of excluded middle) and disagreement in metalogic on whether '∀P (P ∨ ¬P)' is a logical truth. For a sympathetic treatment of logical nihilism see Russell 2018. roundabout reasons for doubting such testimony. More crudely, they may just say that since classical logic is incorrect, we should not be relying on it in our attempts to identify bad data.9
Such responses on behalf of alternative logics push the question further back. Were concerns about overfitting given enough weight, or indeed any, when the case for revising classical logic was made? Increases in flexibility make data, including bad data, easier to accommodate, and so incur a significant methodological cost.
Sensitivity to this cost is hard to detect in arguments against classical logic. Instead, one finds remarkable levels of implicit trust in unclear data—for example, when the failure of classical logic for vague languages is simply taken for granted. The problem becomes even more acute when the data can be explained as products of imperfectly reliable heuristics, as chapter 1 explained they often can.
One reason the analogy between alternative logics and prototypical cases of overfitting may have been missed is that there are also striking differences. Most notably, in curve-fitting, the old and new curves represent equally specific hypotheses. By contrast, alternative logics are usually less specific—weaker—than classical logic. They withdraw from some consequences of the old hypothesis, without adding new ones to compensate. That is quite different from what happens in the natural sciences. The analogue would be at best a kind of curve-fitting where one specifies upper and lower curves, the hypothesis being that the correct values lie in the band between the two curves. The analogue of weakening the logic would be pushing the two curves further apart, widening the band to include data-points outside the old band, thereby weakening the hypothesis. For some cases, the analogue would
9 Naïve empiricist attitudes to data may lead to errors in logic as they seem to have done elsewhere in philosophical theorizing. According to Ernst Cassirer, in Renaissance
Italy 'empiricism leads not to the refutation but to codification of magic' and to 'empirical magic', through its respect for miscellaneous empirical reports of magic (1963: 151-2), whereas rationalists swept such reports aside in their quest for a uniform mathematical theory of nature. In present terms, the empiricists were guilty of overfitting. be even worse: just crossing out the old curve without proposing a replacement. With such a methodology, the result of erroneous data-points is not a more erroneous hypothesis but just a less informative one. Consequently, one will not get the kind of erratic instability and falsified predictions characteristic of classic overfitting, but just a loss of informativeness.
A logic's predictions can be regarded as its deductive consequences for particular cases. When overfitting produces a weak logic, its predictive failures consist in uninformativeness rather than falsity.
At a more general theoretical level, weakening a logic is analogous to revising a theory in physics by abandoning some of its general principles without replacing them by any alternatives of similar generality. Such a move in physics would look defeatist rather than progressive. Not only would it result in a less informative theory; it would fail to stress-test the crucial data by not trying to explain them on an alternative equally strong theory. That would have in common with overfitting an insufficiently critical attitude towards the data. Proposals for weakening classical logic implicitly treat the relevant data in a similarly uncritical way.
In abductive terms, weakening a logic implies loss of strength rather than loss of simplicity, whereas overfitting in the natural and social sciences typically involves loss of simplicity without loss of strength. In both cases there is a loss of abductive virtue, incurred by an insufficiently critical attitude to the data, but the virtue lost is different. In practice, however, weakening a logic usually involves some loss of simplicity too. In the model theory that almost always happens, since new structure is added to the models to make classical principles fail. It often happens in the proof theory too, since classical rules of inference or axioms are qualified or replaced by more complicated substitutes rather than simply dropped. For example, relevance logics exhibit both loss of strength and loss of simplicity, in both model theory and proof theory. Thus, alternative logics typically enjoy the worst of both worlds, and so do even worse than ordinary overfitting in the natural and social sciences.
2.6 Overfitting in philosophical model-building
When scientists speak of degrees of freedom in a model, the models they have in mind are rarely semantic models such as those in the previous two sections, which assign semantic values to expressions of a language. Although semantic models are a special case of models in the general scientific sense, the scientists are unlikely to have semantic models in mind. Most models of natural or social phenomena imply nothing specific about the semantic values of linguistic expressions—though general methodological morals about models in science are indeed applicable and relevant to semantic models. In the predominant scientific sense, a model of a phenomenon is an intermediary object, which is intended in relevant ways to be easier to study than the target phenomenon itself, but structurally similar enough to it for insights about the model to reveal something about the target phenomenon (for a general treatment of modelling in science see Weisberg 2013). For the model to have well-defined parameters, it must be formally specified, typically in mathematical terms—for example, by differential equations whose coefficients are parameters of the model. Informally, the equations may be conceived as characterizing the development of a closed system over time. By solving the equations analytically, or by approximating their effect for given initial conditions on a computer, scientists can often work out how the model develops, identify patterns, and tentatively transfer them to the target phenomenon. Models of pandemics and of global warming are of this general kind.
Almost always, the model is much simpler than the target phenomenon. For example, it may model a planet as a point mass.
Without such massive simplifications, the model would be mathematically and computationally intractable, and so unfit for purpose. Unless the target phenomenon is the whole universe, just modelling it as a closed system—ignoring the possibility of interference from outside the system—is already a massive simplification: in practice, there is always some outside interference (for example, by gravity). Restricting degrees of freedom in models to avoid overfitting is another source of deliberate simplification. In a deterministic model, the implicit assumption that the parameters' values at one time jointly determine their values at any later time is also a simplification. For example, a biological model of predator-prey interaction may treat the sizes of the two populations at any time as jointly determining their sizes at any later time, ignoring obviously relevant factors such as age profile, interactions with a third species, the changing state of the environment, and so on.
Although models in natural and social science tend to be diachronic, that is inessential to the model-building methodology.
Probability spaces in the mathematical sense are used to model various kinds of uncertainty, but are synchronic: they specify one probability distribution, not an evolving sequence of distributions.
Many models of language in linguistics are synchronic. So is an electoral model of the relation between parties' share of the votes and their share of the seats in an assembly. One can learn about synchronic dependencies between the variables by varying the values of the variables, thereby comparing different models with the same overall structure.
Much progress in the natural and social sciences consists in building better models of natural and social phenomena. The new model may capture all the features of the target phenomenon captured by the old model, and more besides, without becoming mathematically or computationally intractable. That is quite different from the older paradigm of scientific progress as the discovery of new scientific laws. Most macroscopic systems and many microscopic ones are too messy and complicated to satisfy any distinctive universal generalizations, let alone laws, formulated in terms of such systems.
Philosophers sometimes try to hold onto a law-based conception of science and absorb such complications by invoking a category of 'ceteris paribus laws', but it cannot do the required work.
Ceteris paribus—other things being equal—planets are not point-masses, and the number of animals in a population does not vary continuously over time as a differential equation requires—it is discrete. We can determine by rigorous mathematics or computer simulation what holds in a model; by contrast, the assumption that a law holds ceteris paribus is far too vague for us to determine its consequences in any such way. Instead, the appropriate way to study those messy and complicated phenomena is often by building formal models rather than by seeking exceptionless or ceteris paribus laws. One may be able to conclude with some rough but robust generalizations drawn from the model, formulated with 'ceteris paribus' qualifications (Weisberg 2013: 158–9, 167–8), but at the heart of the rigorous scientific action is the model, not a ceteris paribus law. The principles that define the model which explains the ceteris paribus law do not themselves hold ceteris paribus.
Of course, model-building in the natural and social sciences is informed by data. The curves in curve-fitting are more or less simple models. A complication at this point is that the target phenomenon is hardly ever a particular one-off event token, such as the Big Bang or global warming on Earth. Typically, the target phenomenon is a general type of event or process, such as the working of some kind of cell or bodily organ, or some kind of interaction between two species. Scientists aim to produce a model of the type, that is, a model generically of a token of the type, without there being any particular token of which it is a model—just as a diagram can be of a human heart without there being any particular human heart of which it is a diagram. Typically, the model will be based on data from many different tokens of the relevant type. Even if there are no errors in the data, there may still be outlying data, for instance from an abnormal heart. Such outlying data can distort the model, making it a worse model of a normal heart (similar issues would arise in semantics also if it were done in a similarly model-building spirit). Precautions against overfitting can help avoid such distortions too.
Not all model-building concerns quantitative issues. For example, biologists want to understand the predominance of sexual reproduction, since asexual reproduction is also possible and actually occurs in some cases. For such theoretical purposes, biologists use a model-building methodology. In particular, they build models to explore the hypothesis that sexual reproduction makes a population better able to adapt to changes in the environment.
Such a model may schematically represent competition between a sexually reproducing population and an asexually reproducing population, with an initial distribution of genotypes, under intense selection from a rapidly changing environment. The hypothesis to be tested is that sexual reproduction is more conducive than asexual reproduction to variance in genotype, and so makes for more adaptability to environmental change (Weisberg 2013: 115-117, Crow 1992). The dynamics of such a model are encoded in simple mathematical rules, whose consequences over time can be computed. The rules are not intended to be a realistic description of actual events, but just to capture general qualitative features of competition between the two forms of reproduction. The rules are best kept as simple as possible, not merely for ease of computation, but because any unnecessary complication or ad hoc feature would risk rigging the model in favour of a desired conclusion. The aim is not data-fitting or quantitative prediction but general theoretical explanation. Still, the model is ultimately constrained by data: for instance, the dynamical rules for how the sexually reproducing population evolves should not diverge too much from known features of the genetics of sexual reproduction.
In brief, simple formal models are used in the natural and social sciences to gain qualitative understanding of very general phenomena, especially phenomena whose instances are too messy and complicated to be governed by informative exceptionless laws at the relevant level. That is evidence that the model-building methodology would be of value to philosophy too. An example was already noted in section 2.3: the use of simple formal models to test the behaviour of the JTB analysis of knowledge. We should expect the model-building methodology to be much more widely applicable in philosophy than that. After all, the human world is fantastically messy and complicated ('Out of the crooked timber of humanity no straight thing was ever made'), and much of human philosophy concerns the human world: human minds and bodies, human knowledge and action, human thought and language, human art and science, human morality and politics, human identity through change and counterfactual variation. Many of those philosophical issues generalize to the wider world of non-human animals and perhaps even of artificial intelligence, but that wider world is fantastically messy and complicated too. Thus, philosophy spends much of its time and energy engaging with phenomena of just the kind better suited to model-building than to the quest for exceptionless laws.
The model-building methodology is already widely used in some areas of philosophy (Williamson 2017a). It predominates in formal epistemology, including Bayesian probabilistic models, models of epistemic and doxastic logic, and more, for both individual and social epistemology. Formal models from decision theory, game theory, deontic logic, voting theory, and evolutionary theory are sometimes used in moral and political philosophy. In metaphysics, the mereology of gunk—the theory of parts and wholes where everything has a proper part—is hard to think about accurately without a mathematical model. When semanticists of natural language state a formal semantic theory, it is usually for a toy model language.
Despite these examples, only a small proportion of contemporary philosophy uses a model-building methodology. One possible explanation is that only a small proportion of contemporary philosophy studies topics for which a model-building methodology would be useful. However, in my experience, there is also widespread ignorance and incomprehension of the model-building methodology amongst philosophers. Many take the falsity of its simplifying assumptions as sufficient reason to reject a model. Most graduate students in philosophy are neither encouraged to build or use models nor trained in how to do so. Consequently, the methodology has not so much been tried and found wanting as not tried.
Almost certainly, it could usefully be applied more widely in philosophy than it has been so far, as some examples below suggest.
Unfamiliarity with the model-building methodology helps explain the marginalization of epistemic and doxastic logic in twentieth-century mainstream epistemology, despite the pioneering work of Jaakko Hintikka (1962). For decades, new developments in epistemic and doxastic logic came more from computer scientists and theoretical economists than from philosophers. Notoriously, standard models of epistemic logic validate a strong form of logical omniscience for knowledge: automatically, if one knows the premises of a deductively valid argument, then one knows the conclusion too (with no qualifications about knowing the entailment or having competently carried out the deduction). Similarly, standard models of doxastic logic validate the correspondingly strong form of logical omniscience for belief: automatically, if one believes the premises of a deductively valid argument, then one believes the conclusion too (again, with no qualifications). The obvious computational and reflective limitations of actual humans seem to provide innumerable counterexamples to logical omniscience for both knowledge and belief, which were taken to discredit epistemic and doxastic logic: whatever epistemic and doxastic logicians were studying, it was not what interested epistemologists, they thought. Significant opportunities for epistemology were lost. Logical omniscience could have been treated as a legitimate simplification for modelling purposes in order to apply the formal framework of epistemic and doxastic logic to the rigorous exploration of other structural issues in epistemology. But such an outlook on model-building seems not to have been available in epistemology at the time. The required formal skills were also in short supply.
Later work in epistemic and doxastic logic showed how to avoid logical omniscience, and model agents' limited rationality, for example by allowing possible worlds epistemic or doxastic access to
'impossible worlds' where any set of sentences whatsoever can be the set of truths (Rantala 1982). Such models carry a cost, because they drastically increase degrees of freedom. The effect is that the model-builder has to put the agent's knowledge and beliefs into the model 'by hand', so stipulation largely replaces exploration, and many of the potential gains from model-building are lost. Instead of learning from the model, one is just taking out of it what one had explicitly put in.
Some functionalists in the philosophy of mind have argued that, on a proper understanding of knowledge and belief, the failures of logical omniscience are illusory (Stalnaker 1984, 1999). The following chapters will discuss issues about logical omniscience and the individuation of the objects of knowledge and belief more deeply. In any case, technical work on blocking logical omniscience was scarcely noticed in mainstream epistemology, and did not in practice constitute a bridge between mainstream epistemology and epistemic and doxastic logic. Encouragingly, more recent years have seen more interaction between formal epistemology and mainstream epistemology, and consequently more use of the model-building methodology in epistemology by philosophers.
When the model-building methodology is applied in philosophy, issues of overfitting and degrees of freedom arise. We need to be on the alert for complication and ad hoc features as warning-signs of error or distortion. If an example convinces philosophers that a phenomenon can occur, but modelling it requires something reminiscent of gerrymandering, then the example may have been misinterpreted. Even if a phenomenon is genuinely possible, it may be such an outlier that complicating the model to allow for it makes the model less useful for many other purposes.
Often, the dialectic is more intricate. Here is a case from my own experience. I have been interested in using epistemic models to illustrate extreme failures of the 'KK' or 'positive introspection' principle that if one knows that P, one knows that one knows that P, and of watered-down versions of that principle—for instance, that if one knows that P, one is in a position to know that one knows that P. In models of epistemic logic, positive introspection provably corresponds to the transitivity of the accessibility relation for knowledge. I have used an example where one is looking from a distance at an unmarked clockface with a single hand, wondering what time it shows. By looking, one learns something, but not everything, about where the hand is pointing. In the simplest epistemic models of that situation, one can easily show, positive introspection fails drastically (Williamson 2014b). However, friends of positive introspection can approximate those models by slightly more complicated models where positive introspection holds, by arbitrarily selecting a coarse-grained partition of epistemic possibilities to determine the accessibility relation in the model. Similar tricks can be played with less grossly simplified models where positive introspection fails.
However, one can show that any model of the situation which validates positive introspection does so at the cost of a sort of symmetry-breaking (Williamson 2021d). The basic set-up, including all potential positions of the hand, has a symmetry induced by the underlying rotational symmetry of the clockface about its centre. But one can show that if an epistemic model respects that symmetry, in the sense that the underlying epistemic structure remains invariant under 'rotations' of the model, and the model meets basic epistemic constraints such as avoiding both scepticism and omniscience about where the hand is pointing, then the model violates positive introspection. Symmetry-breaking is not just inelegant; it is a symptom of an ad hoc intrusion. In effect, it means that the model postulates differences in associated epistemological structure between one point on the circumference of the clockface and another, even though the basic set-up does not require any such differences. Of course, in real life, the situation is doubtless not perfectly symmetric: our visual system may well embody a slight bias on one side or another. But for an epistemological theory to insist in advance that there must be such a bias or asymmetry in a situation whose basic structure does not impose one looks like gerrymandering. In particular, specifying which way the bias goes would require an extra degree of freedom. Thus, the methodology of model-building tells against symmetry-breaking, and so against positive introspection. In brief, to save positive introspection in this case, you must overfit.
None of this means that all epistemic models must invalidate positive introspection. On the contrary: there is often good reason to use epistemic models that validate both positive introspection and the much less plausible principle of negative introspection: if one does not know that P, one knows that one does not know that
P, which corresponds to the accessibility relation being Euclidean, in the sense that all worlds accessible from a given world are accessible from each other. Negative introspection fails in very ordinary cases of confident error, where it is false that P, but one thinks that one knows that P: as a result, one does not know that P, but one also does not know that one does not know that P (in Donald
Rumsfeld's phrase, an unknown unknown). Despite such clear counterexamples, it often makes good methodological sense to build negative introspection as well as positive introspection into a model. For many epistemic models are designed for exploring interpersonal effects, such as those which depend on the presence or absence of common knowledge (where everyone knows that
P, everyone knows that everyone knows that P, everyone knows that everyone knows that everyone knows that P, and so on). Each agent in the envisaged situation has their own knowledge operator with its own epistemic accessibility relation. The best way to isolate the interpersonal obstacles to common knowledge is by minimizing the intrapersonal obstacles to knowledge about one's own knowledge states, to avoid interference. That requires assuming that each agent satisfies both positive and negative introspection separately. Unfortunately, epistemic logicians have tended to treat positive and negative introspection not just as convenient simplifying modelling assumptions but as all-purpose epistemological dogmas, brushing aside all the epistemological objections to them. When the focus shifts to intrapersonal epistemology, background assumptions of interpersonal epistemology should be called into question. Which simplifying assumptions are legitimate depends on what questions one is using the model to think about.
2.7 Summing up
As we have seen, the methodological issues around overfitting and degrees of freedom are themselves messy and complicated, both in general and in particular in their application to philosophy. But that is no good reason to ignore them. Overfitting is a trap into which too many philosophers have fallen, or jumped. Although it can be hard to know whether one is overfitting, we need to be alert to the danger. To that end, we should put somewhat more weight on simplicity and strength as theoretical virtues in philosophy, as elsewhere, and be somewhat less trusting than heretofore of data that tempt us to complicate and weaken our theories.
Obviously, that does not mean that we should rush to the opposite extreme: having neglected simplicity and strength, we should not switch to neglecting fit with data. We need to be keenly aware that there is a balance to be struck, and that we have not been striking it right. Nothing about the nature of philosophy exempts us from the methodological exigencies that other theorists are used to working under. Clearly, once we have a plausible explanation of potential errors in those data the theory fails to fit, the lack of fit becomes less serious. As we have seen, in philosophy and elsewhere, our reliance on a fallible heuristic may be central to that explanation.
In abductive methodology, theoretical virtues are often roughly summarized as simplicity, strength, and fit with data. Giving too much weight to any one or two of them at the expense of the remainder distorts our view of comparisons between theories, and is liable to end in error or triviality. By focusing on the more specific theoretical vice of overfitting, we can clarify our sense of what would be involved in properly implementing an abductive methodology in philosophy.10 3
Case Study: Hyperintensionalism
3.1 Two revolutions?
According to a fashionable triumphalist narrative, philosophy is in the midst of a revolution. The cartoon version goes like this.
Early analytic philosophy—from Frege to Quine—worked in a coarse-grained extensional framework. Around 1960, through the work of Saul Kripke and others, that framework was overthrown in favour of a more flexible, more fine-grained intensional framework, implemented in terms of possible worlds. Analytic philosophers started working in the intensional framework instead. That was the intensional revolution Much more recently, through the work of Kit Fine and others, the intensional framework has in its turn been overthrown in favour of a still more flexible, still more fine-grained hyperintensional framework, implemented in terms of grounding or some such metaphysical relation. Many analytic philosophers have started working in such a framework instead.
That is the hyperintensional revolution. It began in metaphysics but is spreading to other branches of philosophy. It is where we are now.1
Although the most eye-catching features of the three approaches are metaphysical, the underlying structural differences between the frameworks are more abstract. They concern the
1 Nolan 2014 tells such a story, though I am not attributing the cartoon version to him. It is part of current folklore. Of course, plenty of philosophy—including plenty of analytic philosophy—is not usefully classifiable as working within either an extensional, intensional, or hyperintensional framework, because it does not engage with the relevant issues. That may apply to much ordinary language philosophy.
Overfitting and Heuristics in Philosophy. Timothy Williamson, Oxford University Press.
© Oxford University Press 2024. DOI: 10.1093/oso/9780197779217.003.0003 quasi-logical operations available within each framework, hinted at by the contrast between 'coarse-grained' and 'fine-grained'. The differences emerge most clearly when one compares the forms of semantic theory suited to each approach. The intensional revolution corresponded to the transition to possible worlds semantics, discussed in section 2.4 of chapter 2. The hyperintensional revolution is sometimes implemented by impossible worlds semantics, sometimes by truthmaker semantics. In brief: extensional semantics operates on extensions; a sentence's extension is its truth-value, an n-place predicate's extension comprises the ordered n-tuples that satisfy it. Intensional semantics operates on intensions; a sentence or predicate's intension assigns it its extension at each world.
Hyperintensional semantics operates on . . . something else.
The case for hyperintensionalism is usually made in terms of examples, presented as decisive counterexamples to intensionalism.
Perhaps the most famous is due to Kit Fine, in his seminal paper
'Essence and Modality' (Fine 1994). It is directed against attempts by Kripke and others to develop essentialist metaphysics within an intensional framework, by giving a modal account of essence
(Kripke 1972, 1980; for Fine's view of Kripke's understanding of essence, see Fine 2022). Such a modal account equates 'It is essential to S that X is F' with 'Necessarily S is F', or with 'Necessarily if S
exists then S is F', where 'S' designates S rigidly, the pronoun 'X' is anaphoric on 'S', and the necessity is metaphysical. But consider the contrast between (1A) and (1B):
(1A)
It is essential to Socrates that he is Socrates.
(1B)
It is essential to Socrates that he is a member of {Socrates}.
If one is willing to think in essentialist terms at all, one is liable to be struck by (1A) as true and by (1B) as false, at least until conscious theoretical commitments intervene: (1A) sounds like a truism, (1B) like the introduction of something extraneous to Socrates himself, his singleton set. Nevertheless, on standard views of the modal metaphysics of sets, being Socrates is necessarily equivalent to being a member of {Socrates}. Thus, 'Necessarily Socrates is Socrates' is equivalent to 'Necessarily Socrates is a member of {Socrates}', and
'Necessarily if Socrates exists then Socrates is Socrates' is equivalent to 'Necessarily if Socrates exists then Socrates is a member of {Socrates}'. Consequently, given that (1A) is true and (1B) false, those modal accounts of essence fail. Other modal accounts will do no better. For the predicates 'is Socrates' and 'is a member of
{Socrates}' have the same intension. Since a standard intensional semantic framework operates compositionally on intensions, substituting one predicate for another with the same intension in a sentence makes no difference to its intension, so no difference to its truth-value, since the intension of a sentence determines its truth-value at a given circumstance of evaluation. Thus, whatever semantics is attributed to the sentence operator 'It is essential to S
that . . .' in the intensional framework, it will perforce assign the same truth-value to (1A) and (1B). Since any properly developed modal account of essence will correspond to some semantics of the operator in the intensional framework, any such account will assign (1A) and (1B) the same truth-value. Consequently, if (1A) and
(1B) differ in truth-value, no modal account of essence is correct, and the standard intensional framework cannot handle the operator 'It is essential to S that . . .'; it is hyperintensional.
Another well-known case goes back to Aristotle (Metaphysics, book Θ 10: 1051b6–9, cited against intensionalism by Schnieder
2011: 445–6). For any true declarative sentence in place of the schematic letter 'A', consider:
(2A)
The proposition that A is true because A.
(2B) Overfitting and heuristics in philosophy
The natural verdicts are that (2A) is true and (2B) false. The former seems to get the order of explanation right, the latter to get it wrong.
Nevertheless, on standard views of truth for propositions, necessarily, the proposition that A is true if and only A. Thus 'the proposition that A is true' and 'A' have the same intension, so, in a standard intensional semantic framework, interchanging them in a sentence makes no difference to its intension, so no difference to its truth-value; the hyperintensionalist argument in terms of (2A) and (2B)
goes much like the one in terms of (1A) and (1B). Consequently, if
(2A) and (2B) differ in truth-value, the standard intensional framework cannot handle the sentence operator '. . . because ---'; it is hyperintensional.
A third example was used by Elliott Sober to argue that logically equivalent predicates may pick out different properties (Sober
1982). It involves the terms 'triangle', meaning closed straight-sided figure having three angles, and 'trilateral', meaning closed straight-sided figure having three sides. On the intended readings, being a triangle is necessary and sufficient for being a trilateral, so 'triangle' and 'trilateral' have the same intension (Sober's assumption that the equivalence is logical may be too strong, but that does not matter for present purposes). Sober imagines a machine with two components linked in series. The first component is a closed straight-sided figure detector: given a piece of wire as input, the machine outputs it if and only if it is a closed straight-sided figure. The second component is a three-angle detector: given any number of straight pieces of wire, it outputs them if and only if they have three angles. The second component is not a three-side detector because it will output an open four-sided but three-angled figure if given as input. Now one inputs a wire triangle to the machine, which then outputs it. Why? Sober argues that, given how the machine works, the cause was the object's being a triangle, not the object's being a trilateral. The machine outputted the piece of wire because it was a closed straight-sided figure having three angles, not because it was a closed straight-sided figure having three sides. He takes this to show that the property of being a triangle is distinct from the property of being a trilateral. Thus (3A) is true and (3B) false:
(3A)
Being a triangle =being a triangle
(3B)
Being a triangle =being a trilateral
But 'triangle' and 'trilateral' have the same intension, so, in a standard intensional semantic framework, substituting one of them for the other in a sentence makes no difference to its intension, so no difference to its truth-value. Consequently, if (3A)
and (3B) differ in truth-value, and 'being a triangle' and 'being a trilateral' differ in reference, the standard intensional framework cannot handle the construction 'being a . . .', which forms terms for properties; it is hyperintensional.
Examples such as (1A/B), (2A/B), and (3A/B) can be very persuasive. However, they also hint at an asymmetry between the intensional and hyperintensional 'revolutions'. One can of course give similar pairs for the intensional revolution, involving modal operators, for example:
(4A)
It is contingent that Scotland is part of the United Kingdom.
(4B)
It is contingent that 5 +7 =12.
Since (4A) is true and (4B) false, but 'Scotland is part of the United
Kingdom' and '5 +7 =12' have the same truth-value, so the same extension, the example shows that the standard extensional semantic framework cannot handle the sentence operator 'it is contingent that . . .'; it is intensional.
Such examples can easily be multiplied for any of the usual modal operators. But whereas examples like (1A/B), (2A/B), and (3A/B)
are what motivate the hyperintensional revolution, examples like
(4A/B) were not what motivated the intensional revolution. In 1959, Kripke did not have to show that modal operators lack truth-tables; that had been obvious for decades. What initiated the intensional revolution was a more theoretical development: the discovery of a technically powerful and philosophically fruitful framework for the semantics of modal languages. By contrast, when examples like (1A/B), (2A/B), and (3A/B) are used to motivate hyperintensionalism, they are typically presented as counterexamples to intensionalism just as they stand, with no hyperintensional semantic framework to back them up. Although some hyperintensional semantic frameworks have subsequently been developed—involving truthmakers, or impossible worlds, or whatever—their putative merits are not what proponents of the hyperintensional revolution present as its driving-force. In that role, they cast the putative counterexamples themselves. Indeed, hyperintensionalists do not agree on any one semantic approach: semantics with impossible worlds differs radically from truthmaker semantics.
As explanatory successes of a hyperintensional framework, its proponents also claim its capacity to make systematic sense of independently attractive metaphysical claims, such as 'the mental is something over and above the physical despite supervening on it' or
'the whole is prior to the parts despite each necessitating the other'.
But for those who do not find such claims independently attractive, that is a dubious benefit, just as, for classical logicians, allowing one to get away with contradicting oneself is a dubious benefit of paraconsistent logic. Moreover, the intensional revolution bore much more fruit much more quickly than the hyperintensional revolution outside metaphysics (see the next section). For serious dialectical traction, the hyperintensional revolution still has to rely mainly on apparent counterexamples to intensionalism.
The terminology of 'extensional', 'intensional', and 'hyperintensional' is already a clue to the difference between the two
'revolutions'. Extensional semantics operates compositionally on extensions. Intensional semantics operates compositionally on intensions. Does hyperintensional semantics operate compositionally on hyperintensions, whatever they are? It does something beyond intensional semantics, but its name does not specify what. Indeed, some versions of hyperintensional semantics fall below the minimum standard of compositionality, an issue discussed later in this chapter.
On the standard use of the terms 'extensional', 'intensional', and
'hyperintensional', there is an asymmetry between the extensional-intensional distinction and the intensional-hyperintensional distinction. If an operator is extensional, it is also intensional, because an operation on extensions induces a corresponding operation on intensions. By contrast, if an operator is intensional, it is not also hyperintensional; an operation on intensions may not induce a corresponding operation on 'hyperintensions', whatever they are. I will use the terminology in this standard way.
One might describe hyperintensionalism as a more data-driven approach than either extensionalism or intensionalism. From a methodological perspective, that already raises concerns about overfitting: the data on which subsequent theorizing relies are typically derived from off-the-cuff judgments on examples. Concerns about overfitting intensify when the theoretical frameworks inspired by the data turn out to help themselves to many extra degrees of freedom, as hyperintensional semantic theories do. Still worse, one can give a specific non-hyperintensionalist alternative explanation of the data, in terms of a heuristic of limited reliability.
This chapter will treat the hyperintensionalist programme as a case study in overfitting.
Before we get into the methodological details, some more general reflections on the taxonomy of extensional, intensional, and hyperintensional are worth noting.
3.2 Extensional, intensional, hyperintensional
The hyperintensional is defined as what is beyond the intensional, so the boundary of the hyperintensional is no clearer than the boundary of the intensional. The use of impossible worlds in semantics illustrates the unclarity in the boundary. It is usually thought to entail hyperintensionality. But the general structure of intensional semantics does not exclude worlds in which Socrates was a donkey, for example, even if those worlds are metaphysically impossible. Another aspect of vagueness in the term 'intensional'
concerns the structure of the semantics. Strictly speaking, if models have a parameter for times as well as the one for worlds, they go beyond the original Kripke models, but the addition is usually understood to be well within the spirit of intensional semantics.
The boundary between the non-extensional but intensional and the extensional is also much less clear than it may first sound. For example, David Lewis is usually regarded as a leader of the intensional revolution, having made possible worlds more central to his theorizing than did any other major philosopher, including
Leibniz. Lewis also wrote one of the most systematic early accounts of the semantics of natural languages in the framework of intensional semantics (Lewis 1970). But he designed his modal metaphysics to facilitate his semantic reduction of the intensional language of quantified modal logic to the extensional language of counterpart theory (Lewis 1968). He thereby provided a way of making intensional languages respectable by the extensionalist standards of his old PhD supervisor Quine, though not to Quine's satisfaction. Lewis himself argued that the distinction between extensional and intensional languages is elusive and unimportant
(Lewis 1974). Admittedly, Lewis's counterpart theory and modal realism about concrete possible worlds are minority views in metaphysics. But when one applies intensional semantics to a modal object-language, one standardly does so in an extensional metalanguage, quantifying over worlds rather than using modal operators.
More specifically, work on the model theory of modal logic and formal modal semantics is normally done in the non-modal language of mathematics, with some extra vocabulary to describe the syntax of the object-language. However, when one characterizes the intended model(s) for given readings of the modal operators, one may need to use those operators with those readings to pick them out (Williamson 2013a). It's complicated.
Defining 'extensional', 'intensional', and 'hyperintensional'
precisely may be more trouble than it is worth. We have clear paradigms of extensional semantics, clear paradigms of intensional semantics, and clear paradigms of hyperintensional semantics. Given a clearly specified formal semantics, we can identify its similarities to, and differences from, those paradigms. We know that any standard intensional semantics assigns the sentences in any one of the pairs (1A/B), (2A/B), and (3A/B) the same truth-value, and that some paradigmatically hyperintensional semantics assigns them different truth-values. That is enough to be getting on with. If someone later claims to have a non-standard intensional semantics that assigns different truth-values to the sentences in such a pair, one should look at the details before passing judgment.
Typically, in a perspicuous formal semantic framework, one can define natural formal criteria for an operator to be extensional, intensional, or hyperintensional, but the specific details may vary.
Some philosophers might argue that hyperintensional semantics is nothing new, because Frege's semantics was hyperintensional once he introduced his distinction between sense and reference. For instance, although '2 +2 =4' and 'Peano arithmetic is incomplete'
are necessarily equivalent, they differ in cognitive significance, and so have distinct Fregean senses. That allows Frege to evaluate 'The children believe that 2 +2 =4' as true but 'The children believe that
Peano arithmetic is incomplete' as false. The issue is not straightforward, because Frege implemented the compositional aspect of his semantics primarily at the level of reference rather than of sense, so in a way his semantics is extensional. His trick is that when a declarative sentence occurs in the scope of a propositional attitude operator such as 'The children believe that', the embedded sentence refers to its customary sense, not to its customary referent (the true, for '2 +2 =4' and 'Peano arithmetic is incomplete'). Thus, rather awkwardly, Frege achieves a hyperintensional effect in a nominally extensional setting. That is yet another hard case for the taxonomy of extensional, intensional, and hyperintensional.
Even at the height of the 'intensional revolution', most philosophers of language and mind in effect treated propositional attitude operators as hyperintensional, in accord with ordinary assessments of propositional attitude ascriptions in natural language. That is exactly why they rejected the standard intensional treatments of operators for knowledge and belief in models of epistemic and doxastic logic, on the grounds that they entailed logical omniscience (see chapter 2.6). In that respect, the 'hyperintensional revolution' was not revolutionary at all.
What was more revolutionary in the 'hyperintensional revolution' was the hyperintensional treatment of constructions characteristic of general metaphysics: for instance, 'It is essential to . . . that ---' in (1A/B), '. . . because ---' in (2A/B), and 'being a . . .' in (3A/B). For hyperintensional distinctions had been widely assumed to make a difference only in cognitive or representational matters: the picture was that there is no hyperintensionality out there in the world as it is independently of how it is conceived.
The role of senses in Fregean semantics poses no threat to that picture, because Fregean senses are individuated in terms of cognitive significance.
A further complication is that the talk of 'the world as it is independently of how it is conceived' presupposes a broadly realist approach to metaphysics. A metaphysical idealist who identifies the real with the rational may take cognitive hyperintensionality to be fully worldly hyperintensionality. Henceforth, I will follow most advocates of hyperintensionalism in metaphysics by ignoring metaphysical idealism.
Minimally, to draw non-trivial hyperintensionalist morals from examples like (1A/B), (2A/B), and (3A/B), the constructions in them should be free of metalinguistic elements, as should our assessments of their truth-values, beyond the bare minimum required to understand them. For metalinguistic hyperintensionalism comes very cheap indeed, as in (5A/B):
(5A)
'2 +2 =4' contains '4'.
(5B)
'Peano arithmetic is incomplete' contains '4'.
Obviously, (5A) is true and (5B) false, even though they differ only in the substitution of necessarily equivalent sentences; quotations of meaningful expressions are typically hyperintensional. That shows nothing interesting about hyperintensionality in metaphysics.
Within analytic metaphysics itself, arguments for genuine worldly hyperintensionality went back further than is often recognized, well before the 1990s. For example, the article in which Sober made his case for the hyperintensional individuation of properties was published in 1982. It treats properties as causally potent in mind-independent ways, not as mere projections of predicates or concepts.
Another case concerned the use of a supervenience relation to characterize relations between different 'levels'—
for instance, mental properties or events and physical properties or events (as in Davidson 1970). Supervenience was standardly defined in modal terms: there is no possible difference at the supervening level without a corresponding difference at the base level. That rough statement can be made precise in various non-equivalent ways, yielding various different supervenience relations, but all within an intensional framework. A much-discussed worry was that a modally defined supervenience relation might not capture the full sense in which the base level metaphysically determines the supervening level (Kim 1984). For a start, supervenience as modally defined is a reflexive and not anti-symmetric relation: each level supervenes on itself, and two levels can supervene on each other. Although such cases can be excluded by focusing on one-way supervenience, where one level supervenes on another in the original sense but not conversely, not even that gives one what one wants. For instance, the family of two properties {red, not-red} supervenes one-way on the family of four properties {red and round, red and not-round, not-red and round, not-red and not-round}, but the four-property family does not seem metaphysically to determine the two-family property in the right way; it does not seem 'more basic'. I remember a widespread sense in philosophical discussions around 1980
that modal relations were too coarse-grained to capture what was wanted. In current terminology, the complaint was that modal relations are insufficient to ground the supervening level in the supervenience base.
Other resources for metaphysical hyperintensionality were also available in that period. In particular, since propositions were normally treated as the objects of propositional attitudes, and few were willing to treat propositional attitudes intensionally, hyperintensional theories of propositions were needed. Thus, the sentences '2 +2 =4' and 'Peano arithmetic is incomplete' were usually taken to express distinct propositions, despite their necessary equivalence. Philosophers of language tended to accept a theory of direct reference for various expressions, on which sentences do not express Fregean senses, so propositions were not identified with Fregean thoughts. Instead, a sentence was often taken to express a Russellian proposition, a complex of the objects, properties, and relations the sentence was about, with a structure somewhat similar to the syntactic structure of the sentence. For example,
Nathan Salmón used such an apparatus to give an anti-Fregean treatment of Frege puzzles (Salmón 1986; for more discussion of
Frege puzzles see chapter 4). Russellian propositions are worldly entities; they are not individuated by cognitive significance. Nor are they individuated by necessary equivalence. Consider these two sentences:
(6A)
Mont Blanc has snowfields and Mont Blanc does not have snowfields.
Case study: hyperintensionalism
(6B) Let [6A] and [6B] be the propositions expressed by (6A) and (6B), respectively. On the Russellian picture of propositions, Mont Blanc is a constituent of [6A] but not of [6B], while Mount Everest is a constituent of [6B] but not of [6A], so [6A] and [6B] are distinct propositions, despite being necessarily equivalent, since they are both impossible. That conception should allow one to define a propositional operator O which has nothing to do with cognitive significance but is sensitive to the constituents of the input proposition, so that the proposition O([6A]) is true while the proposition
O([6B]) is false. For example, given any proposition P, we could define O(P) as the proposition that Mont Blanc is a constituent of
P. Then O is a hyperintensional operator at the purely metaphysical level of Russellian propositions.
As this background suggests, the 'hyperintensional revolution'
was not the result of any major new philosophical or technical breakthrough—by contrast with the intensional revolution. Fine's
1994 paper hit intensionalism where it hurt, by casting serious doubt on (many would say 'refuting') one of its supposed successes,
Kripke's modal account of essence, but the damage was limited.
Still, the paper was eye-catching; perhaps it brought interest in hyperintensional theorizing up to a critical mass.
The hyperintensionalist programme tends to be seen as a comparative newcomer on the philosophical scene, which has to be given time to prove itself. But key hyperintensionalist ideas have been around for forty years or more, so one might be forgiven for starting to feel impatient. By contrast, the intensional revolution had achieved a far broader and deeper transformation of philosophical thinking by the mid-1970s, in the work of Kripke, Lewis,
Stalnaker, Kaplan, Barcan Marcus, Plantinga, Fine himself, and many others. Outside philosophy, the breakthrough in modal logic soon had effects in mathematical logic, linguistics, computer science, and theoretical economics. Traces of the 'hyperintensional revolution' are rarer outside philosophy (Fine 2017a: 574–5 lists some examples). Of course, anyone interested in computational phenomena must make syntactic distinction amongst logically equivalent formulas, but such distinctions do not depend on semantic hyperintensionality. Still, the main impact of what is called
'the hyperintensional revolution' has been in pure analytic metaphysics itself.
Hyperintensionalist metaphysical theorizing manifests the self-confidence which analytic metaphysics developed through the work of Kripke, Lewis, and others, and so at least in part through the intensional revolution (see Williamson 2014c for discussion). The suspicions of metaphysics associated with the 'Linguistic Turn', in both its logical positivist and its ordinary language manifestations, have been banished. But there is a concomitant danger of over-confidence. The less one doubts that one's judgments are directly responsive to relations out there in the non-linguistic world, with no linguistic bias or projection, the more vulnerable one is to exactly such linguistic biases and projection, because one is not screening for them. That problem will surface in the final section of this chapter.
Before that, we will scrutinize some versions of hyperintensional semantics to see how resistant they are to overfitting—for overfitting is a typical effect of over-confidence in one's data.
3.3 Hyperintensional semantics: impossible worlds
The role of 'impossible worlds' in semantics goes back long before the 'hyperintensional revolution'. They were used early on in models of epistemic and doxastic logic to block logical omniscience, in what could be presented as a natural generalization of intensional semantics (Hintikka 1975, Rantala 1982; for more recent developments see Berto and Jago 2019). Even earlier, Kripke had used models with 'nonnormal' worlds at which every formula of the form ◊α is true to handle the non-normal modal systems
S2 and S3, though that was a far more restricted use of impossible worlds than was later made of them (Kripke 1965).2
If there is a problem with 'impossible worlds' in semantics, it is not that they could not exist. They do exist. A model contains a set W, whose members are the values of the 'world' parameter with respect to which formulas of the object-language are evaluated as true; W
can be any non-empty set. In models for the semantics, the 'impossible worlds' form a proper subset of W; the semantics imposes no constraints on which formulas of the language are true at an impossible world. Consequently, in some cases, the formulas true at a given impossible world in a given model are not jointly compatible; they may be formally inconsistent or (on their intended interpretations)
metaphysically incompossible. The designated actual world of a model is not allowed to be one of the impossible worlds.3
To see the attraction of using 'impossible worlds' in the semantics to handle apparent metaphysical hyperintensionality, we will consider counterpossibles. A counterpossible is a counterfactual conditional with an impossible antecedent, such as 'If there were true contradictions, Graham Priest would be vindicated'. In semantics, the default reading of counterfactuals is standardly taken to be non-epistemic, though epistemic readings are sometimes available
(see Edgington 2008, Vetter 2016, and Williamson 2020: 251–3 for discussion). For example, whether the counterfactual 'If you had pressed the red button, there would have been an explosion', is true
2 A standard Kripke model can have impossible worlds in the less extreme sense that some members of W are inaccessible from the actual world of the model. This can happen even for the intended model structure on a metaphysical reading of the modal operators if metaphysical modality violates the S4 axiom ◊◊p → ◊p; some worlds will be possibly possible but not possible (Salmón 1984). Unlike the models with 'impossible worlds' discussed in the main text, such cases involve no relaxation of the standard semantic constraints on the semantic evaluation of formulas at worlds.
3 The 'impossible worlds' here are impossible only in belonging to a subset of W
exempted from the usual semantic evaluation clauses for the connectives. At some such worlds, the sentences evaluated as true are jointly logically consistent and metaphysically compossible on their intended interpretations. or false depends on the real state of the device, and more generally of the physical world, not on what anyone happens to know about it. Thus, unless one already expects hyperintensionality to be non-worldly, one might expect hyperintensionality in counterpossibles to constitute worldly hyperintensionality.
Standardly, the semantics of counterfactuals is done within an intensional framework, in the tradition of Stalnaker (1968) and
Lewis (1973). The general idea—which Stalnaker and Lewis implement in slightly different ways—is that the counterfactual 'If it were that A, it would be that C' is true at a world w if and only if 'C' is true at the closest world(s) to w at which 'A' is true. In the special case where 'A' is true at no world, the counterfactual counts as true, since a fortiori there is no world at which 'A' is true and 'C' is not.4
In brief, if all worlds are possible, then all counterpossibles are vacuously true. My preferred intensional approach to counterfactuals delivers the same verdict on counterpossibles. It treats 'if ' itself as the material conditional, but the whole conditional as in the scope of 'would', read as a contextually restricted local necessity operator; composing these yields a contextually restricted strict conditional. In other words, 'If it were that A, it would be that C' is true at w if and only if, at every world contextually relevant to w at which 'A' is true, 'C' is also true. Thus, if the counterfactual is a counterpossible, it is vacuously true because 'A' is not true at any world (Williamson 2020).
Now take these two counterpossibles:
(7A)
If 7 +5 were 13, 7 +5 would be 13.
(7B) If 7 +5 were 13, 7 +5 would both be 13 and not be 13.
4 Strictly speaking, what Stalnaker (1968) offers is an impossible worlds semantics, since he handles counterpossibles by giving each model one 'absurd' world where every sentence is true, so all counterpossibles still come out true everywhere. This has no hyperintensional effect in the object-language because he could have achieved the same result by eliminating the absurd world and directly stipulating that every counterpossible is true at every world. The variant semantics is strictly intensional. People are naturally inclined to assess (7A) as true and (7B) as false.
Indeed, (7A) sounds utterly truistic, while (7B) is dissonant. On the supposition that 7 +5 =13, one accepts that very supposition and rejects a contradiction. But, on the intensional semantics for counterfactuals, both (7A) and (7B) are vacuously true. Indeed, any treatment of counterfactuals in the standard intensional framework will assign them the same truth-value, because their antecedents are necessarily equivalent (both are impossible) and their consequents are necessarily equivalent (both are impossible). Consequently, some philosophers advocate a hyperintensional treatment, to capture the apparent difference in truth-value between (7A) and (7B).
A similar example can be given with a non-obviously logically inconsistent sentence in the language of ordinary truth-functional propositional logic in place of the sentence '7 +5 is 13', which states a mathematical impossibility.
One can easily validate (7A) and invalidate (7B) in impossible worlds semantics, using Lewis's or Stalnaker's semantic clause for the counterfactual conditional at all possible worlds in all models.
Trivially, (7A) is true at any possible world (including the actual world) in any model, because its consequent is true at all the closest worlds at which its antecedent is true, since its antecedent and consequent are identical. To invalidate (7B), just take a model where, at one of the closest worlds to the actual world at which '7 +5 is
13' is true, '7 +5 is and is not 13' is not true. In that model, (7B) is not true, because at one of the closest worlds to the actual world at which its antecedent is true its consequent is not true. Thus, impossible worlds semantics is well designed to give the desired verdicts on (7A) and (7B).
Impossible worlds semantics pays a high price for such results.
The guiding principle of systematic semantics is compositionality: it aims to show how the meaning of each complex expression of the object-language is determined by the meanings of its constituent expressions and how they are put together. Compositionality is central to explaining language users' ability to understand unfamiliar sentences composed of familiar words. But impossible worlds 'semantics' sacrifices compositionality. It is like a kind of alternative mathematics where the value of 'x + y' is not determined by the values of 'x' and 'y'.
Compositionality is not an all-or-nothing matter. Without more constraints on meanings, it can be trivialized in various ways: most blatantly, by assigning all expressions the same meaning, or by assigning all distinct expressions different meanings. With more constraints on meanings, minor violations of compositionality may be explicable and tolerated. The term 'compositional' is not perfectly precise (for a nuanced account, see Szabó 2000). Still, we have both a schematic understanding of the general principle and paradigms of its implementation in standard semantic theories, which together act as strong guidelines for semantic theorizing.
In graded terms, the more compositional the semantic theory, the better. But standard impossible worlds semantics violates the spirit of compositionality so grossly that we can legitimately characterize it as non-compositional.
To see how compositionality fails in standard impossible worlds semantics, take the case of negation. In effect, both standard models of possible worlds semantics and standard models of impossible worlds semantics equate the meaning of a sentence with its intension, which for present purposes we can simply treat as the set of all worlds in the model at which the sentence is true. In standard possible world semantics, the semantic clause for negation is simply this: in any model, ¬α is true at a world w if and only if α is not true at w. Thus, the intension of ¬α in a model is simply the complement of the intension of α in the set W of all worlds in the model. That is perfectly compositional. The same applies to the evaluation of ¬α at all possible worlds in impossible worlds semantics. But the semantic clause for negation does not apply at impossible worlds. Thus, there are impossible worlds models like this: two atomic sentences p and q are true at exactly the same possible and impossible worlds, but at some impossible world, ¬p is true but ¬q is not true. Consequently, in the model, although p has the same intension as q, ¬p has a different intension from ¬q; the intension of p and q does not determine the intension of ¬p and ¬q. This shows that negation does not in general behave compositionally in models for impossible worlds semantics. The same applies to conjunction, disjunction, and conditionals.
A defender of impossible worlds semantics might retreat by consigning the impossible worlds to a purely instrumental role in the semantics, and identifying the meaning of a sentence in a model with its intension restricted to the possible worlds of the model, where the standard semantic clauses still apply. That would restore compositionality to negation, conjunction, disjunction, and the other truth-functors. But it would not restore compositionality to the counterfactual conditional. The kind of model used above to invalidate (7B) shows exactly that. In it, the antecedent of (7A) has the same restricted intension as the antecedent of (7B), and the consequent of (7A) has the same restricted intension as the consequent of (7B), the empty set, but (7A) does not have the same restricted intension as (7B), since (7A) but not (7B) is true at the actual world, which is a possible world. The very features for which the impossible worlds semantics was designed make it non-compositional with respect to restricted intensions. Whether meanings are equated with restricted intensions or (more plausibly) with unrestricted ones, the semantics is not compositional.
Advocates of impossible worlds semantics rarely mention its violation of the central constraint of systematic semantics. Indeed, they often seem unaware of it. At a conference a few years ago, having heard a talk in favour of impossible worlds semantics, I asked the speaker about its non-compositionality; he replied that it had never occurred to him. Someone could argue that non-compositionality is a cost worth paying, but to do that they would first have to acknowledge that it is a cost.
The way compositionality fails in impossible worlds semantics carries with it a massive increase in degrees of freedom. As already noted, the nature of the subject-matter of semantics implies that each non-logical atomic expression of the object-language adds its own degree of freedom; its meaning has to be written into each model 'by hand'. In a compositional semantics the complex expressions add no further degrees of freedom; their meanings are determined by the meanings of their atomic constituents and how they are put together. By contrast, in impossible worlds semantics, the intension of each complex sentence over the impossible worlds also has to be written into the model 'by hand'. This deprives such models of much of the explanatory power one hopes for in a scientific model, where simple assumptions generate complex effects.
A fan of impossible worlds could restore the letter, though not the spirit, of semantic compositionality by expanding the models with extra worlds to differentiate the input sentences in meaning while fencing the extra worlds off in order not to disturb other hyperintensional features of the model. But that would provide virtually none of the illumination available from standard compositional semantic theories, which explain compositionality in terms of simple, natural semantic clauses for the relevant operators. It would achieve compositionality by brute force, and complicate the models still further.
To their credit, Franz Berto and Mark Jago explicitly confront the problem of non-compositionality on behalf of impossible world semantics (2019: 180–4). They restore the letter of compositionality by an elaborate construction that involves a hypothetical 'world-making' language distinct from the object-language under study.
Their approach is purely generic, in the sense that it does not depend on any specific features of the object-language operators to which it is applied. This makes it quite uninformative about the object-language. Its hypothetical success consists in sterilizing the compositionality constraint, while the constraint's value to semantics has consisted in its fruitfulness.
One could achieve a similar effect more directly with a new semantics on which the meaning of each expression E is the ordered pair <M(E), E>, where M(E) is the meaning of E on the old non-compositional semantics. For any monadic operator O
of an appropriate type in the object-language, the new meaning of O(E) is <M(O(E)), O(E)>, which is a function of <M(E), E>
through being a function of E, which is in turn a function of the new meaning of E, <M(E), E>; the case of polyadic operators is similar. Tellingly, the new semantics forbids any distinct expressions E1 and E2 from having the same new meaning, even if they have the same old meaning, for although M(E1) =M(E2),
<M(E1), E1> ≠ <M(E2), E2> because E1 ≠ E2. Thus, the new semantics respects the letter of compositionality, but not its spirit. Such trivializations of compositionality offer nothing to our understanding of natural language semantics, or counterfactuality, or propositional attitudes. Compositionality has contributed so much to the development of systematic semantics because it is a demanding yet natural constraint; reducing it to a form of words to which lip-service must and can be paid is a retrograde step.
On the evidence, impossible worlds semantics is a classic case of overfitting of the distinctive kind that sometimes arises in logic and formal semantics, discussed in chapter 2.
The threat of overfitting immediately raises the question: how safe were the originally motivating data? In particular, how safe was the assessment of (7B) as false?5 The judgment is just what one would predict from the application of the suppositional heuristic.
On the counterfactual supposition '7 +5 is 13', one assesses '7 +5
both is and is not 13' and denies it; applying the heuristic, one denies (7B) itself. The processing is shallow; it does not take the impossibility of the antecedent into account, but simply reacts in the usual way to 'A and not-A' on the supposition 'A'. Strictly speaking, the heuristic has to be adapted to the presence of the modal operator, by combining it with a heuristic for 'would', but the combined
5 The original judgment that (7A) is true agrees with its evaluation on standard intensional approaches and is not in question. heuristic turns out to be structurally similar to the original heuristic for 'if ' itself; the role of 'would' was acknowledged by qualifying
'supposition' with 'counterfactual' (Williamson 2020: 189–213).
But the combined heuristic for 'would if ', like the original heuristic for plain 'if ', is implicitly inconsistent. Moreover, the heuristic for
'would if ' generates contradictions specifically when applied to counterpossibles (Williamson 2020: 205–7). It would be rather rash to rely on the heuristic-generated verdict on (7B) in the very type of case for which the heuristic is known to be unreliable. Other alleged examples of false counterpossibles can be explained in similar ways (Williamson 2020: 256–9).
One could be reassured if the pre-theoretic verdict on (7B) were confirmed by a tight explanatorily powerful semantic theory. But confirmation by a semantic theory as profligate with degrees of freedom as impossible worlds semantics carries little weight. With so many degrees of freedom, one can model almost any behaviour someone might attribute to counterpossibles.
Without even seeing examples, one could have predicted on more general grounds that standard forms of conditional thinking might well run into trouble with impossible suppositions. One need only consider the mathematics of conditional probability; there is a well-documented tendency to associate the probability of a conditional with the corresponding conditional probability, as predicted by the suppositional heuristic (for an introduction to the literature, see Williamson 2020: 31–4). Usually, the conditional probability Pr(X | Y) of X on Y is defined as the ratio Pr(X ∩ Y)/Pr(Y)
of unconditional probabilities, where X and Y are events, subsets of the probability space, analogous to sets of possible worlds.
Informally, the conditional probability of X on Y is the proportion of the Y-region that is also in the X-region. When Pr(Y) =0, the ratio involves dividing by zero, and so is undefined. Schoolchildren are often fascinated by sophistical arguments for mad conclusions such as 0 =1, which non-obviously involve dividing by zero: one shows that xz = yz and divides through by z to conclude that x = y. In thinking with counterpossibles, we must be careful not to do the analogue of dividing by zero.
Admittedly, for conditional probability, we have the alternative of treating it as primitive, rather than trying to define it in terms of unconditional probabilities. Of course, we need some constraints on primitive conditional probabilities. Here is a plausible candidate:
[i]‌
If Y ⊆ X then Pr(X | Y) =1
For if every point in the Y-region is in the X-region, the probability of being in the X-region conditional on being in the Y-region should be maximal. Here is another plausible candidate:
[ii]
If X ∩ Y ={} then Pr(X | Y) =0
For if no point in the Y-region is in the X-region, the probability of being in the X-region conditional on being in the Y-region should be minimal.
Now if Y ={}, Y ⊆ X, so by [i]‌Pr(X | Y) =1, but also X ∩ Y ={}, so by [ii] Pr(X | Y) =0, a contradiction! Despite their plausibility, [i] and
[ii] cannot both hold in this special case. Considering probabilities conditional on the null event is the probabilistic analogue of considering counterpossibles. But, for conditional probabilities, we have a clear, agreed mathematical framework to correct our thinking when we stray off the straight and narrow path. By contrast, for conditionals, we have no such clear, agreed framework.
The probabilistic analogy is available before we decide what to make of counterpossibles. It warns us that when we consider them, we are entering a space where normally reliable ways of thinking are liable to break down. With warning signs like that, and the inconsistency of the heuristic for 'would if ', to trust our off-the-cuff judgment that (7B) and similar counterpossibles are false, to the point of abandoning a well-tried theoretical framework and taking up instead one with well-known hallmarks of bad science, is an act of alarming methodological naivety. Sancta simplicitas!
The perspective before we have decided what to make of counterpossibles is also useful for considering another question: if impossible worlds semantics involves treating counterpossibles as implicitly metalinguistic, what symptoms of that would we expect to see? The suspicion arises naturally, because the evaluation of sentences at impossible worlds bypasses their semantic structure, as if it were irrelevant.
One salient hypothetical prediction is that if impossible worlds semantics treats counterpossibles as implicitly metalinguistic, substituting synonyms in a counterpossible can change its truth-value, because the sentence is at least partly about the words themselves. Take this pair of counterpossibles:
(8A)
If furze were not gorse, furze would not be gorse.
(8B)
If furze were not gorse, furze would not be furze.
Here 'furze' and 'gorse' are synonymous terms for the same natural kind. Assessing (8A) and (8B) in the same pre-theoretic way as (7A)
and (7B), we are naturally inclined to assess (8A) as true and (8B)
as false. On the counterfactual supposition 'Furze is not gorse', one trivially assents to that very sentence and dissents from the logically inconsistent sentence 'Furze is not furze': disregarding botany does not force one to disregard logic. Again, the processing is shallow; it does not take the impossibility of the antecedent into account but simply reacts in the usual way to an obviously inconsistent sentence on an apparently consistent supposition. Applying the suppositional heuristic, one therefore assents to (8A) and dissents from
(8B). The impossible worlds semantics can then vindicate these verdicts on (8A) and (8B), just as it vindicated the corresponding verdicts on (7A) and (7B). On this view, merely substituting the word 'furze' for its synonym 'gorse' turned the true (8A) into the false (8B). This reinforces the suspicion that the approach treats counterpossibles as implicitly metalinguistic. More generally, rather than contributing to the development of hyperintensional metaphysics, the impossible worlds framework seems to be used as a device for staying on the linguistic surface.6
In short, the impossible worlds framework is bad science.
3.4 Hyperintensional semantics: truthmakers
A less profligate framework for hyperintensional semantics involves truthmakers. I will focus on a version developed by Kit
Fine (2017a, 2017b, 2017c), since it represents the current state of the art. More specifically, I will assess it primarily as a semantic theory, since Fine presents it as such, not as a metaphysical theory.
Nevertheless, it is a leading candidate for a systematic framework for hyperintensional metaphysicians to use in explaining how their characteristic statements can be meaningful and true.
In truthmaker semantics, when sentences are true, they are made true by states, their truthmakers; a verifier for a sentence is a state that would, if it obtained, make the sentence true. Similarly, when sentences are false, they are made false by states, their falsehoodmakers; a falsifier for a sentence is a state that would, if it obtained, make the sentence false. Unlike worlds, states are typically partial, involving only some local aspect of things. Some states are possible: they can obtain. Others are impossible: they cannot obtain. The natural connections with truth and falsity themselves
6 For a long-running debate on counterpossibles and impossible worlds, see Nolan
1997, Dorr 2008: 37, Brogaard and Salerno 2013, Berto, French, Priest, and Ripley 2018, and Williamson 2007: 172–76, 2017c, 2018b, and 2020: 256–9. I hope that setting the debate in a wider methodological context will help to clarify the issues. Of course, since furze =gorse, the claim that (8A) and (8B) differ in truth-value also violates Leibniz's
Law, and so is bad logic too, for closely related reasons—a concern to which I have found proponents of impossible worlds semantics strikingly insensitive. Leibniz's Law is not a distinctively intensionalist principle. are that a sentence α is true if and only if some verifier of α obtains, and α is false if and only if some falsifier for α obtains.7
States have mereological structure: some states are parts of other states. Any set of states has a fusion, the minimal state of which they are all parts: it is part of any state of which they are all parts. In this semantics, a model assigns each sentence of the object-language a set of verifiers and a set of falsifiers, whose ordered pair is in effect the meaning of the sentence in the model. Unlike impossible worlds semantics, truthmaker semantics is compositional: the meaning of a complex sentence is determined by the meanings of its constituents and how they are put together.
The mereological structure is needed for compositional purposes. In the simplest version of Fine's semantics, for example, since making a conjunction true involves making each conjunct true, a verifier of α ∧ β is a fusion of a verifier of α with a verifier of
β. But since making a conjunction false just involves making one or other conjunct false, a falsifier of α ∧ β is simply a falsifier of α or a falsifier of β. Similarly, since making a disjunction false involves making each disjunct false, a falsifier of α ∨ β is a fusion of a falsifier of α with a falsifier of β. But since making a disjunction true just involves making one or other disjunct true, a verifier of α ∨ β is simply a verifier of α or a verifier of β.
The apparatus of verifiers and falsifiers smoothly handles the semantics of negation: the verifiers of ¬α are the falsifiers of α, and the falsifiers of ¬α are the verifiers of α.
7 Fine's postulation of non-obtaining states undermines one philosophical motivation for truthmaker theory: the idea that a true proposition needs some thing to make it true
(Armstrong 1997: 115). For if there is a state s which, if it obtained, would make α true, although in fact α is false and s does not obtain, then s itself is insufficient for α to be true; what is needed is for s to obtain. The distinction between obtaining and not obtaining is just the analogue for states of the distinction between being true and being false; in effect, the property of truth for propositions and sentences gets explained in terms of a truthlike property for states, whereas the original ambition was to explain it in radically different terms: by things themselves. For more on these issues, see Williamson
2013a: 391–403. The critique of truthmaker theory there is independent of, and consistent with, the critique in this section. The semantics is hyperintensional because necessarily equivalent sentences sometimes differ in their verifiers or falsifiers. The most dramatic case is that α ∧ α can differ from α in its verifiers: repetitiousness is logically significant. For the fusion of two verifiers of
α is a verifier of α ∧ α even though it may not be a verifier of α itself.
However, Fine shows how to avoid that oddity by tweaking the semantics to make every fusion of verifiers of a sentence itself a verifier of it. A more robust hyperintensional feature is that, although the sentence α ∨ (α ∧ β) has the same truth-conditions as plain α, they often differ in their verifiers and falsifiers. For some verifiers of
α ∨ (α ∧ β) will include verifiers of β as parts, and some falsifiers of
α ∨ (α ∧ β) will include falsifiers of β as parts; but if α and β are about quite different topics, no verifier of α will include any verifier of β as a part, and no falsifier of α will include a falsifier of β as a part. For
Fine understands verification and falsification as exact, so the fusion of a verifier or falsifier of a sentence with some quite irrelevant state is not another verifier or falsifier of that sentence. Capturing such differences in subject matter is an aspect of what Fine intends truthmaker semantics for, so from his perspective the semantic difference between α ∨ (α ∧ β) and α is a feature, not a bug.
One might have the impression that states are in effect partial worlds, and the state parameter is just Fine's analogue of the world parameter in intensional semantics. But that is not Fine's intended understanding of his framework. He treats the apparatus of states as fundamentally amodal. Although he permits a distinction between possible and impossible states to be introduced, it is extraneous to the underlying structure of states. Moreover, a one-off distinction between possible and impossible states would not by itself provide for all the more restricted modalities in continual use by speakers of natural languages. The point is not that there is any block in principle to adding parameters capable of handling such modalities to the truthmaking framework; it is just that the extra methodological costs associated with states and their mereological structure may not be adequately compensated for by economies elsewhere. Truthmaker semantics adds another degree of freedom by treating the verifiers and falsifiers of a sentence as independent of each other. Fine uses a complicated example to argue that even when α has the same verifiers as β, ¬α does not always have the same verifiers as ¬β, in which case α does not have the same falsifiers as β
(Fine 2017a: 564). With verifiers alone, or with falsifiers alone, the semantics would not be compositional. If a state s is not a verifier of a sentence γ, it does not follow that s is a falsifier of γ, for s may simply be irrelevant to γ. Equally, though less obviously, if s is a verifier of γ, it does not follow that s is not also a falsifier of γ. On Fine's semantics, some states are both verifiers and falsifiers of the same sentence.8
The quasi-independence of verifiers and falsifiers clearly adds a degree of freedom to the models, by comparison with classical semantics, which in effect equates falsity with non-truth for sentences.
This aspect of the semantics is most striking for atomic sentences.
Imagine that you are being taught a foreign language. Your teacher explains to you exactly what would make a given atomic sentence true. Could you then complain to her: “You've only done half your job! You've told me what this sentence's verifiers are, but you haven't told me anything about its falsifiers”? That sounds quite unreasonable. Your teacher has already done enough to enable you to understand the sentence, by normal linguistic standards. You are not missing half its meaning. Normally, what would make a sentence true does determine what would make it false.
8 Proof: Let s be a verifier of α, t a falsifier of α, and s ⨆ t the fusion of s with t. Then s ⨆ t is a verifier of (α ∨ ¬α) ∧ (α ∨ ¬α) because s is a verifier of α ∨ ¬α and t is a verifier of ¬α and so of α ∨ ¬α. But s ⨆ t is also a falsifier of (α ∨ ¬α) ∧ (α ∨ ¬α) because s is a falsifier of ¬α, and t is a falsifier of α, so s ⨆ t (= t ⨆ s) is a falsifier of α ∨ ¬α. The text describes Fine's bilateral semantics, with truthmakers and falsehoodmakers treated separately. He also has an alternative unilateral semantics, with only truthmakers. To handle negation, it postulates a primitive relation of exclusion between states, which is another complication in the models, compensating for the loss of falsehoodmakers. Unlike the bivalent semantics, the univalent semantics fails to treat ¬¬α as expressing the same proposition as α
(Fine 2017b: 634–5). That is a loss in both simplicity and strength. These reflections suggest that, with respect to negation, although the truthmaker semantics complies with the letter of compositionality, it violates the spirit. The slack between α and
¬α on the truthmaking outlook has been dressed up as slack between two components of the meaning of α. Truthmakers are something like old-fashioned facts, and the lack of co-ordination between the verifiers and falsifiers of a given sentence is reminiscent of Bertrand Russell's difficulties in finding a metaphysically plausible account of negative facts in The Philosophy of Logical
Atomism (Russell 1918/1919, lecture III). Stephen Yablo's account of truthmakers faces a similar problem in its treatment of negation
(Yablo 2014: 58).
From the truthmaker semantics, Fine extracts a general account of a proposition, a candidate for being expressed by a declarative sentence in a context, as an ordered pair of sets of states, the first conceived as the set of its verifiers, the second as the set of its falsifiers. On this approach, true contradictions come very cheap, without need of independent support from paradoxes such as Russell's, the Liar, or the Heap. Let s be any actually obtaining state. Taking {s} as both the set of verifiers and the set of falsifiers yields a perfectly good Finean proposition; as already noted, on
Fine's semantics a state may be both a verifier and a falsifier for the same sentence, and so for the proposition it expresses. This proposition <{s}, {s}> is both actually true and actually false, since s is both a verifier and a falsifier for it and actually obtains. If a sentence α expresses <{s}, {s}>, then the sentence α ∧ ¬α is true (and false) on the truthmaker semantics. Of course, Fine could postulate rules of natural languages forbidding such propositions from being expressed, but that would be ad hoc, and in any case would not prevent us from constructing artificial languages in which such propositions are expressed. If truthmaker semantics is on the right lines, such languages could be easily understood.
Fine mentions that one might 'impose' a constraint of Exclusivity on propositions, 'No verifier is compatible with a falsifier' (Fine 2017b: 629). Exclusivity implies that <{s}, {s}> is not a proposition, for if s actually obtains then s is possible, and so compatible with itself.
Two comments are in order.
First, the use of a modal constraint to demarcate propositions violates what Fine himself presents as the spirit of his approach. For he writes (Fine 2017a: 566):
[T]‌he present point of view is that there is nothing in the general notion of content or meaning or in the most general logical devices that requires us to draw the distinction between possible and impossible states. This freedom from the modal thinking that has been so characteristic of the more usual approaches to semantics is, I believe, one of the most distinctive and liberating aspects of the present approach.
By contrast, an intensional account of propositions requires no such restriction.
Second, by imposing more or less ad hoc constraints on which combinations of verifiers and falsifiers constitute propositions,
Fine adds yet more complexity, and more degrees of freedom, to his semantic framework, thereby intensifying the danger of overfitting.
Such speculations are alarmingly under-constrained. They indicate that we have helped ourselves to too many degrees of freedom. At first, Fine's separation of truth and falsity looked like a very mild liberalization of the usual practice. But when we take its implications seriously, we find ourselves glibly talking as though we had forgotten what truth and falsity are. Although truthmaker semantics is much better constrained than impossible worlds semantics, it is still not constrained enough.9
9 I have not attempted here to discuss Fine's application of truthmaker semantics to specific linguistic issues: for example, he mentions partial content, subject-matters, counterfactuals, imperatives, and scalar implicature. Elsewhere, I have argued in detail that his case for his alleged counterexamples to intensional accounts of counterfactuals neglects independently confirmed context-sensitivity in counterfactuals (Williamson
2020: 217–21). 3.5 Hyperintensional semantics:
Russellian propositions
When hyperintensionality is approached through impossible worlds or truthmakers, the unsatisfactory accounts of propositions are overtly inspired by the semantic framework. An alternative hyperintensional account of propositions is covertly inspired by syntax. The picture is that a declarative sentence expresses a proposition with an overall constituent structure—perhaps that of an inverted branching tree—like that of the syntactic constituent structure of the sentence. The qualifier 'overall' is needed because syntactically simple constituents of the sentence may express complex constituents of the proposition: for instance, the single word
'vixen' may express a complex with constituents corresponding to
'female' and 'fox'. In some cases, the syntactic form of the sentence misrepresents its underlying logical form, the constituent structure of the proposition it expresses: famously, that was Russell's view of sentences of natural language with definite descriptions.
So far, the account is consistent with treating propositions and their constituents as something like Fregean senses, or concepts.
For Russellian propositions, however, the constituents are more worldly: the objects, properties, and relations the sentence is about, and complexes of them. For instance, the atomic sentence 'Brutus stabs Caesar' may express a proposition whose form is something like the ordered pair <stabs, <Brutus, Caesar>>, whose constituents include the stabbing relation and the men Brutus and Caesar themselves, not concepts of them, still less their names. Such propositions and their constituents are individuated in a fine-grained way.
More precisely, if the operators O and O* figure in the build-up of propositions, where O is m-place, O* is n-place, C1, . . ., Cm in that order are suitable inputs for O, and C*1, . . ., C*n in that order are suitable inputs for O*, then this principle holds:
FINEGRAIN If O (C1 , ..., C m ) = O*(C*1 , ..., C*n ), then O = O*, m = n, and C i = C *i for1 ≤ i ≤ n In other words, not only do the inputs of applying an operator uniquely determine the output, the output uniquely determines the input. Forming ordered pairs works like that, for <w, x> =<y, z> if and only if w = y and x = z. FINEGRAIN implies a hyperintensional conception of propositions, given minimal assumptions about the proposition-building operations. For example, if they include negation (¬) and conjunction (∧), then, if p and q are distinct propositions, by FINEGRAIN the logically contradictory propositions p ∧ ¬p and q ∧ ¬q are also distinct from each other, despite being necessarily equivalent.10
Unfortunately for such a fine-grained conception of propositions, it is inconsistent on natural background assumptions.
The best-known reason for this is the Russell-Myhill Paradox
(Russell 1903: 527, Myhill 1958, Dorr 2016, Goodman 2017). Here is an informal version of such an argument. Let pp be any plurality of propositions. Then we can define a propositional operator Opp where, for any proposition q, Opp(q) is the proposition that q is one of the pp. For any two extensionally distinct pluralities of propositions pp and pp*, some proposition q is either one of the pp but not one of the pp* or one of the pp* but not one of the pp, so the propositions
Opp(q) and Opp*(q) differ in truth-value, so Opp and Opp* are distinct operators. Hence, for any given proposition q*, Opp(q*) and Opp*(q*)
are distinct propositions by FINEGRAIN. Thus, the mapping that takes each plurality of propositions pp to the proposition Opp(q) is one-one. This means that there are at least as many propositions as there are pluralities of propositions. But, by Cantor's diagonal argument, there are more pluralities of propositions than there are propositions. Contradiction.
10 In this section, when expressions of the formal language of any type occur in
English sentences, unless otherwise specified they are being used as singular terms to refer to what they would ordinarily express on the Russellian semantics. Here, as elsewhere in the book, for ease of reading I also ride roughshod over type distinctions, but the proofs do not exploit that sloppiness. A more exact statement could be laboriously given in higher-order terms. Many variations can be played on that theme, for example, by using properties of propositions rather than pluralities of them, or by constructing different propositions out of them (Kment 2022; see also Fritz 2022 for a related paradox for fine-grained theories of grounding). Later, Russell evaded the paradox by adopting his
'multiple relation theory of judgment' and denying the reality of propositions. The paradox does not arise in his intricately complicated ramified type theory, though the ramification was not needed to preserve consistency (see Hodes 2015 for discussion of Russell's thinking on these matters).
Since the paradoxical argument is in essence Cantorian, as
Russell recognized, one naturally gets the impression that the problem is to be solved by some analogue of measures used in set theory to avoid Russell's paradox of the set of all sets that are not members of themselves, by imposing an iterative hierarchy of propositions, or a limitation of size constraint, or whatever. But the underlying problem is both simpler and deeper than that.
We can begin to appreciate the issues by considering definitions.
For instance, the material biconditional is often defined in terms of the one-way material conditional and conjunction. We can treat that definition as an equation of propositions:
DEF ↔
( p ↔ q) = (( p → q) ∧ (q → p))
But applying FINEGRAIN to DEF ↔ gives this absurd result:
DEF ↔ !
↔ = ∧, p = ( p → q), and q = (q → p) Overfitting and heuristics in philosophy
The common definition of the necessity operator ◽ as the dual of the possibility operator ◊ creates an analogous problem:
DEF
p = ¬◊¬p
Applying FINEGRAIN to DEF◽ gives this absurd result:
DEF!
 = ¬ and p = ◊ ¬p
For the main operator of the left-hand side of DEF◽ is ◽, while the main operator of the right-hand side is ¬. The result is absurd not merely because the operator it equates ◽ with is not the one we intended; when p is a necessary truth, it is falsely equated with the falsehood ◊¬p.
A fan of structured propositions might respond that definitions of operators yield only identities of operators, not of the propositions to which they are applied. We might express the identities with the abstraction device λ:
DEF ↔ λ
↔ = λpq.(( p → q) ∧ (q → p))
DEFλ
 = λp.(¬◊¬p)
The trouble is that the characteristic effect of applying the λ-operator is given by the standard principle of β-conversion:
βCONV
(λv1  vn .ϕ)a1  an = ϕ[ai /vi ]1≤i ≤n
As a rather trivial special case of βCONV, abstracting the operator and then re-applying it to the same variables gives back what one started with:
ABST ↔ λ
λpq.(( p → q) ∧ (q → p)) pq = (( p → q) ∧ (q → p))
Case study: hyperintensionalism
ABSTλ Combining DEF↔λ with ABST↔λ yields DEF ↔ (rewriting ↔pq as p ↔ q), and combining DEF◽λ with ABST◽λ yields DEF◽; but
DEF ↔ and DEF◽ are exactly what we are trying to avoid, given
FINEGRAIN. Thus, the fan of structured propositions would have to reject βCONV, and in particular its instances ABST↔λ and
ABST◽λ. But the general principle of βCONV is the central constraint on the behaviour of the λ-operator. Without it, we are left wondering what λ does, and so what DEF↔λ and DEF◽λ mean.
Although the symbol λ looks reassuringly familiar, it is cast adrift without its usual logical moorings.
The problem is not confined to definitions. On a structured view of propositions, we can build up more and more complex propositions in stages by applying operators iteratively (to use a more or less dead construction metaphor). This requires that proposition-building operators can be composed: given proposition-building operators O1 and O2, there is a proposition-building operator O1,2 whose result when applied to a proposition p is the result of applying O2 to the result of applying O1 to p. Trivially, therefore, we have this equation:
COMP
O1,2 p = O2 O1 p
But COMP too yields hopeless results, given FINEGRAIN:
COMP!
O1,2 = O2 and p = O1 p Overfitting and heuristics in philosophy so is pointless. This trivializes the picture of building up structured propositions iteratively.
One might hope to rescue something from the rubble by postulating that, although proposition-building operators cannot strictly be composed, they can somehow be combined in ways that have a roughly equivalent effect. The idea is to replace identity in
COMP by something slightly weaker, an equivalence relation ≈ on propositions short of identity:
COMP ≈
O1,2 p ≈ O2 O1 p
At the very least, COMP≈ should imply that O1,2p and O2O1p have the same truth-value. Similarly, one could weaken the propositional identities DEF↔, DEF◽, ABST↔λ, and ABST◽λ to the corresponding ≈-equivalences:
DEF ↔≈
( p ↔ q) ≈ (( p → q) ∧ (q → p))
DEF≈
 p ≈ ¬◊ ¬p
ABST↔ λ ≈
(λpq.( p → q) ∧ (q → p)) pq ≈ (( p → q) ∧ (q → p))
ABSTλ ≈
(λp.¬◊¬p) p ≈ ¬◊¬p
DEF↔≈ follows from DEF↔λ and ABST↔λ≈, while DEF◽≈
follows from DEF◽λ and ABST◽λ≈. But the lack of a good explanation of ≈ leaves the metaphysical picture cloudy, because we have no prior understanding of ≈. A natural temptation is to interpret ≈
in terms of necessary equivalence, though that risks compromising the hyperintensionalist vision, on which intensions are not where the action is.
Worse, FINEGRAIN undermines even the conversion principles ABST↔λ≈ and ABST◽λ≈. For presumably they are to be explained as special instances of a more general underlying weak
β-conversion principle of this form:
βCONV ≈
(λv1  vn ϕ)a1  an ≈ ϕ[ai /vi ]1≤i ≤n
For the principles with ≈ to be of any use, ≈ must at least imply material equivalence, so βCONV implies this extensional β conversion principle:
βCONV ↔
(λv1  vn. ϕ)a1  an ↔ ϕ[ai /vi ]1≤i ≤n
But, when combined with FINEGRAIN, even βCONV↔ suffices for a version of the Russell-Myhill paradox (Dorr 2016). Without
ABST↔λ≈ and ABST◽λ≈ even on a minimal material reading of ≈
as ↔, the 'definitions' DEF↔≈ and DEF◽≈ are of little use.
There are other concerns too about COMP≈, even on a minimal reading of ≈. For example, on the fine-grained picture, we might expect a monadic proposition-building operator R which, applied to a proposition of the form Op (where O is a propositional operator), re-applies O to Op and then applies negation to the result:
DEFR
ROp ≈ ¬OOp
FINEGRAIN forbids a proposition Op to also be O*q for some other operator O*, so O can be uniquely extracted from Op: the definition is not ambiguous. Since O and ¬ are well-defined propositional operators, there is such a proposition as ¬OOp. For present purposes, what R does to propositions of other forms is irrelevant. Then, in the special case of
DEFR where R =O, we have DEFR!, and so by hypothesis DEFR!↔:
DEFR!
RRp ≈ ¬RRp
DEFR! ↔ Overfitting and heuristics in philosophy
DEFR!↔ is a classical contradiction.
Friends of a fine-grained view of propositions may reply that the argument shows only that there is no such operator as R. But that response is inadequate, since it was the fine-grained view itself that made it seem natural for there to be such an operator as R in the first place. Given FINEGRAIN, proposition-building operators are basic to the individuation of propositions, so what proposition-building operators there are should be a central question for such a theory of propositions. We need a more positive, general account of how proposition-building operators can be defined; post hoc denials in particular cases are not enough.
The λ operator seemed to provide for just such a general account of proposition-building operators. However, given FINEGRAIN,
λ is unconstrained even by βCONV↔, and in most cases we have very little idea how it behaves. For example, given two monadic predicates F and G, we can define the predicate λx.(Fx ∧ Gx), but we have no guarantee that it will behave conjunctively: (λx.(Fx ∧ Gx))a may not be materially equivalent to Fa ∧ Ga. In natural language,
'This is such that it is red and it is round' may differ in truth-value from 'This is red and this is round'. Metaphysically, having the 'conjunction' of some properties would not be equivalent to having each of those properties. Similarly, although we can define the predicate λx.¬Fx, we have no guarantee that it will behave negatively: (λx.¬Fx)a may not be materially equivalent to ¬Fa. In natural language, 'This is such that it is not round' may differ in truth-value from 'It is not the case that this is round'. Metaphysically, having the
'negation' of a property would not be equivalent to not having the property. Such a λ gadget is not well-designed for the purposes of either semantics or metaphysics.
At first sight, the picture of structured propositions seems to present a clear, systematic vision of the structure of propositions.
On closer inspection, it turns out to be all, or almost all, smoke and mirrors. The central result is the incompatibility of COMP
with FINEGRAIN: if one tries composing the operators needed to build structured propositions in non-trivial cases, FINEGRAIN
collapses. Since the composite operators are perfectly well-defined proposition-building operators, FINEGRAIN holds only within some unspecified, privileged subclass of proposition-building operators; it is not the advertised general principle for individuating propositions.
One may wonder how the idea of structured propositions can be incoherent, given that Carnap in Meaning and Necessity seems in effect to have provided a good formal model of them as what he calls 'intensional structures' (Carnap 1947: 56–64, applied in
Lewis 1970). For present purposes, an intensional structure is the kind of thing one gets by taking an analysis tree for a sentence and replacing the expression at each node by its intension, so the result is not language-specific. As usual in linguistics, trees are inverted, branching outwards from the top node.
Intensional structures satisfy FINEGRAIN. For if the expressions O(C1, . . ., Cm) and O*(C*1, . . ., C*n) are associated with the same intensional structure, then the number of nodes immediately below the top node is the same, so m = n, and the same intensional sub-structures are associated with corresponding nodes immediately below the top node (counting from the left, say), so the expressions O and O* are associated with the same intensional structure, as are the expressions Ci =C*i for 1 ≤ i ≤ n.11 For example, if the sentences α and β have different intensions, then although the sentences α ∧ ¬α and β ∧ ¬β have the same intension, they are associated with different intensional structures, because the second of the nodes immediately below the top node of the intensional structure associated with α ∧ ¬α is labelled with the intension of α, whereas the second of the nodes immediately below the top node of
11 This paragraph talks about expressions rather than the structured propositions or complexes they express because the existence of the latter is not assumed. This involves some abuse of notation, but the intended meaning should be clear in practice, and the notational measures needed to avoid ambiguity in principle would be quite cumbersome. the intensional structure associated with β ∧ ¬β is labelled with the intension of β. Why is that not a 'proof of concept' for structured propositions?
The trouble is that although intensional structures encode operators, those are not operators on intensional structures, but operators on intensions. If propositions are intensional structures, then the operators encoded in propositions are not operators on propositions. It is analogous to associating the expression '2 +2' with the ordered triple <+, 2, 2>, which encodes addition, but it is still addition of numbers, not addition of ordered sequences, and <+, 2, 2> is no more the number 4 than is the ordered triple <+, 3, 1>; two ordered triples cannot both be identical with the same thing. Intensional structures cannot square the circle; nothing can. Whatever propositions are, they cannot encode operators on propositions with full generality, because that would involve satisfying both FINEGRAIN and
COMP, which is impossible.
Intensional structures are not proof of concept for a full-blooded theory of structured propositions, because intensional structures are parasitic on intensions. That also explains what is wrong with the putative propositional operator R: its definition depends on extracting the operator O from the proposition
Op, and so does not correspond to any operation on intensions.
Similarly, the Russell-Myhill argument fails for intensions, because the intensions corresponding to Opp(q) and Opp*(q) may be identical even when the pluralities of intensions corresponding to pp and pp* are distinct, so the relevant function is not one-one.12
In general, intensionalism faces no analogue of the Russell-Myhill paradox; it is much more robust. Of course, with enough restrictions, some theories of somehow structured propositions may also avoid Russell-Myhill. The danger is that they are inadequately
12 For an attempted solution on behalf of structured propositions to the Russell-Myhill paradox and a critique of it, see Menzel 2024 and Williamson 2024. motivated.13 The picture of Russellian propositions looked like a principled, attractively simple fine-grained view. Patching it up in a semi-fine-grained way promises much greater complexity for no commensurate gain—some kind of half-hearted overfitting.
Rather than labour the problems for hyperintensional theories of propositions still further, I will turn to examining the motivation for adopting hyperintensional theories in the first place. As throughout this chapter, the focus will be on alleged metaphysical hyperintensionality, in phenomena conceived as non-representational.
3.6 The 'why?' heuristic
In section 3.3, we saw how flimsy are the data of one kind often used to support claims of non-representational hyperintensionality, for counterpossibles. The data are exactly what one would expect on the independently confirmed hypothesis that we use the relevant variant of the suppositional heuristic to assess counterfactuals. That heuristic is implicitly inconsistent, and its inconsistency shows up with counterpossibles, as well as in other cases. Consequently, our pre-theoretic judgments of counterpossibles are an untrustworthy source of evidence for their hyperintensionality.
However, counterpossibles are far from the only cases of alleged metaphysical hyperintensionality. Other, perhaps more central examples come from our pre-theoretic judgments about explanations. These are often elicited by the use of the word 'because', or similar words in other languages. For instance, in section
13 Bacon 2023 develops an unorthodox but systematic account of fine-grained structured propositions that avoids the Russell-Myhill paradox by restricting the available operations. For example, conjunctive and negative predicates are indefinable in his canonical language. On whether the theory is well-motivated, Bacon himself expresses doubts. Another watering-down of the theory of structured propositions that avoids the Russell-Myhill paradox is the theory discussed as 'Generalized Qualitative Atomic
Structure' in chapter 7 of Dorr, Hawthorne, and Yli-Vakkuri 2021. 3.1, we considered the contrasting schematic pair (2A) and (2B), the opposed 'because' statements about propositional truth. For concreteness, we can instantiate them:
(9A)
The proposition that snow is white is true because snow is white.
(9B)
Snow is white because the proposition that snow is white is true.
The normal pre-reflective judgments are that (9A) is true and (9B)
false. Nevertheless, on standard views of truth for propositions, necessarily, the proposition that snow is white is true if and only if snow is white. Thus, if the normal pre-reflective judgments are correct, 'because' is hyperintensional.
The statement 'A because B' is naturally understood as proposing
'B' as an answer to the question 'Why A?' Indeed, in some languages, such as Italian, the word for 'why' is the same as the word for 'because' ('perché'). Thus, an obvious principle for assessing 'because' statements is what we may call the 'Why?' principle:
Accept [reject] 'A because B' if you find 'B' a good [bad] answer to the question 'Why A?'.
The questioner wants to understand why A: a good answer helps them understand why A; a bad answer does not. In effect, the questioner asks the addressee to explain why A. Philosophers of science have produced a vast literature on the nature of explanation; as its track record attests, the attempt to give informative and precise necessary and sufficient conditions for explaining something is unlikely to succeed; what yields the desired understanding is too sensitive to the vagaries of conversational context, background knowledge, and human psychology. We can usually recognize whether we understand, though of course we often think we understand when in fact we do not. Even when we do understand, we often have difficulty in pinning down just what our understanding consists in. The 'Why?' principle enables us to judge the truth-value of 'A because B' by using our unreflective capacity to recognize whether the answer 'B' would help one as questioner to understand why A, without the need for explicit, detailed criteria.
The use of the words 'why' and 'because' depends on conversational context. More specifically, 'why' can be used in causal, constitutive, or evidential ways, and 'because' varies correspondingly. For instance, someone may ask 'Why was NN a murderer?', intending to get at what caused him to become a murderer, so the answer 'His parents violently abused him' would be relevant; the answerer might also say 'NN was a murderer because his parents violently abused him'. Someone else may ask 'Why was
NN a murderer?', intending to get at what NN did that counted as murder, so the answer 'He intentionally killed his wife by poisoning her' would be relevant; the answerer might also say 'NN
was a murderer because he intentionally killed his wife by poisoning her'. A third person may ask 'Why was NN a murderer?', intending to get at what evidence there is for NN's guilt, so the answer 'He confessed the murder to the police' would be relevant; the answerer might also say 'NN was a murderer because he confessed the murder to the police'. All these cases fit the 'Why?'
principle.
The 'Why?' principle also correctly predicts that we will find 'because' doubly factive, in the sense that we accept 'A because B' only if we accept both 'A' and 'B'. For if we do not accept 'A', we will not accept the question 'Why A?', since it presupposes 'A', and if we do not accept 'B', we will not accept it as an answer to 'Why A?'
We can apply the 'Why?' principle to (9A) and (9B). Here, the intended reading of 'because' is neither causal nor evidential but constitutive. The questioner seeks some kind of constitutive explanation. In dialogue form, (9A) and (9B) correspond to the question-and-answer pairs (9A^) and (9B^), respectively:
(9A^)
Q: Why is the proposition that snow is white true?
A: Snow is white.
(9B^)
Q: Why is snow white?
A: The proposition that snow is white is true.
The explanation is much better in (9A^) than in (9B^), even though both rely on the schematic equivalence of 'P' and 'The proposition that P is true'. But in (9A^) the explanation starts with the simple, easy, familiar, and obvious ('Snow is white')
and moves to the more complex, harder, less familiar, and less obvious ('The proposition that snow is white is true'), which is what the most helpful explanations typically do, whereas in
(9B^) the explanation moves in the opposite direction (on the psychological preference for simplicity in explanations, see
Lombrozo 2007, 2016). More generally, the 'Why?' principle predicts our pre-theoretic preference for schema (2A) over schema (2B).
For similar reasons, we will accept instances of the schemas
(10A), (10B) and (10C), given that the sentences flanking 'because'
express truths:
(10A)
(A or B) because A.
(10B)
(A or B) because B.
(10C)
Something is F because a is F.
In each case, the explanation moves from the simpler and easier to the more complex and harder. Here is another pair of 'because' statements:
(11A)
Furze is as prickly as gorse because furze is gorse.
(11B)
Furze is as prickly as gorse because furze is furze.
Pre-theoretically, (11A) sounds good, while (11B) sounds bad. In dialogue form, (11A) and (11B) correspond to (11A^) and (11B^), respectively:
(11A^)
Q: Why is furze as prickly as gorse?
A: Furze is gorse.
(11B^)
Q: Why is furze as prickly as gorse?
A: Furze is furze.
The explanation is much better in (11A^) than in (11B^). In
(11A^), the answer will satisfy a reasonable questioner; it supplies exactly the required information. In (11B^), the answer is likely to baffle a reasonable questioner, since to anyone who needs to ask the question it sounds quite irrelevant.
The trouble is that (11A) differs from (11B), and (11A^) from
(11B^), only by the substitution of synonymous terms, 'furze'
and 'gorse'. The difference is purely verbal; it corresponds to no difference in a single kind of shrub, which is as prickly as itself.
It is not a case of metaphysical, or at least non-representational, hyperintensionality.
One response is to postulate a reading of 'because' on which it creates a metalinguistic context. That is a dubious interpretation of the example, for 'because' is correlative with 'why', and the questioner who asked 'Why is furze as prickly as gorse?' did not intend
'why' in a metalinguistic sense. In any case, going metalinguistic is a dangerous move for hyperintensionalists to make, since it immediately raises the question whether their alleged examples of non-representational hyperintensionality in 'because' should also be understood metalinguistically, and so representationally.
More generally, in using the 'Why?' principle to assess 'A because
B', we assess 'B' as an answer to the question 'Why A?', and an answer can be good or bad for almost any mixture of linguistic and non-linguistic reasons. An explanation can be good because it is perspicuous, or bad because it is confusing, which may depend on the order in which information is given, and on whether the explainer follows the stylistic maxim of elegant variation, to refer to the same thing by different terms to avoid plodding repetition, and on whether the explanation is given in common words and short sentences or in uncommon words and long sentences, and so on. The difficulty or ease of following a written explanation depends on the font style and size, the degree of contrast between the colour of the print and the colour of the page, and how well the lines in a graph are differentiated in colour. Likewise, in a spoken explanation, the speaker's accent, diction, speed of speech, and loud or soft voice, and ambient noise all make a difference to comprehension. So do the hearer's familiarity or unfamiliarity with the material, and their levels of alertness and motivation. In evaluating an explanation or argument, it is notoriously difficult to separate in one's own case the influence of form from the influence of content. We don't exactly know what hit us.
Psychologists have studied closely related metacognitive illusions
(Undorf, Navarro-Báez and Zimdahl 2022).
In consequence, little is to be gained from hiving off special metalinguistic uses of 'why' and 'because', for even when we stipulate that our use of the words is non-metalinguistic, in practice we shall still be applying them under the influence of linguistic as well as non-linguistic factors. The linguistic factors may play the role of unconscious biases, and sometimes lead us into error. One cannot stipulate oneself free of bias. Thus, in practice, the 'Why?' principle is less than perfectly reliable. In recognition of that, we may rename it the 'Why?' heuristic. Since the interesting kind of alleged hyperintensionality is not metalinguistic, we may as well specify that for present purposes the intended readings of 'why' and 'because' are non-metalinguistic.
Postulating an imperfectly reliable heuristic here is not gratuitous. We have independent reason to classify our assent to (11A)
and dissent from (11B) as not both correct, on general semantic grounds. Some mechanism is needed to explain the error, and an imperfectly reliable heuristic is a natural candidate. Compatibly with that, it is a charitable option, since it still allows the mechanism to have a high degree of reliability, short of infallibility.
The problem for hyperintensionalists is that pairs such as (9A)
and (9B) become dialectically ineffective as alleged counterexamples to intensionalism, since intensionalists can predict and explain our verdicts on them by our reliance on the 'Why?' heuristic, and observe that an error in those verdicts would be of the same kind as the error in our verdicts on (9A) and (9B): a projection of the pragmatics of explanation onto the semantics of 'because'. That would not make the 'Why?' heuristic too generally unreliable to be useful.
Another indication that 'because' statements may elicit distinctive errors is that, as summaries of explanations, they are structurally awkward, in a subtle way. To see this, we must stake a step back. On a constitutive reading of 'explain', just as any true disjunct explains a true disjunction, by the natural deduction rule of disjunction-introduction, so the true conjuncts jointly explain a true conjunction, by the natural deduction rule of conjunction-introduction. Both inferential steps go from simpler premises to more complex conclusions. The explanatory steps of disjunction-introduction are naturally summarized in statements where 'because' takes wide scope, in the forms 'A or B
because A' and 'A or B because B'. But when one tries to summarize the explanatory step of conjunction-introduction in the same way, one gets only 'A and B because A and B', which is circular. A 'because'
statement presents the explanandum and the explanans each in a single sentence, but the point of conjunction-introduction is to unify separate sentences into a single complex one: the syntactic form of a 'because' statement forces the explanans into a form where that step has already been taken, and so misses the point. The form of a 'because' statement represents the explanation in a Procrustean way. In
Benjamin Schnieder's logic of 'because', this awkwardness manifests itself in the striking similarity of his rule for conjunction to his rule for disjunction: his system allows for partial explanations of a conjunction by one or other conjunct but not for a full explanation of it jointly by both conjuncts (Schnieder 2011).
Hyperintensionalists themselves sometimes show uncertainty in where to locate the line between linguistic form and non-linguistic content. For example, as noted in section 3.4, Kit Fine presents two versions of truthmaker semantics: in one, the repetitious conjunction α ∧ α can have truthmakers α lacks, so the difference in linguistic form corresponds to a difference in non-linguistic content; in the other, α ∧ α and α always have the same truthmakers and falsemakers, so the difference in linguistic form corresponds to no difference in non-linguistic content. The same principle, under the title of 'idempotence', is also a crux for Cian Dorr (2016). The remark 'It's starting to rain and it's starting to rain' sounds boringly insistent, not like a subtle point about the state of the weather.
Compare (12A) and (12B):
(12A)
This ball is round and round because this ball is round.
(12B)
This ball is round because this ball is round and round.
The explanatory direction is clearly better in (12A) (from the simpler to the more complex) than in (12B) (the opposite). The question is whether the difference in linguistic form between 'This ball is round'
and 'This ball is round and round' corresponds to a genuine difference in non-linguistic content. If not, on a non-metalinguistic reading of 'because', as a standard intensionalist view implies, (12A)
and (12B) have the same truth-value, and appearances to the contrary are an illusion created by the 'Why?' heuristic. Here is a more extreme example:
(13A)
This ball is either round or both round and red because this ball is round.
(13B)
This ball is round because this ball is either round or both round and red.
The interchanged sentences are necessarily equivalent to each other because α ∨ (α ∧ β) is truth-functionally equivalent to α. The explanatory direction is clearly much better in (13A) than in (13B). Not only is the explanatory direction from the simpler to the more complex in (13A) and the opposite in (13B), the explanation introduces irrelevant subject matter in (13B) but not in (13A). The question is whether that linguistic intrusion corresponds to a genuine difference in non-linguistic content. If not, on a non-metalinguistic reading of 'because', (13A) and (13B) have the same truth-value, and appearances to the contrary are an illusion created by the 'Why'
heuristic. Compare the property of being round to the property of being either round or both round and red. They sound different on first hearing, but do properties have subject matters?14
Should we rely on the 'Why?' heuristic as applied to (9A) and
(9B)? Does the difference in linguistic form between 'Snow is white'
and 'The proposition that snow is white is true' correspond to a genuine difference in non-linguistic content? If not, on a non-linguistic reading of 'because', (9A) and (9B) have the same truth-value, and appearances to the contrary are another illusion created by the
'Why?' heuristic. The difference between (9A) and (9B) in direction of explanation may feel metaphysical, but that does not mean that it is. If we had a well-working hyperintensional framework in which to explain the difference in metaphysical terms, that would
14 For hyperintensional theories of subject matter and aboutness see Yablo 2014, Fine
2017c, and Brast-McKie 2021. support the heuristic-driven verdicts. However, the considerations in sections 3.3–5 indicate that hyperintensionalists are not in that happy position. Instead, their case is still largely driven by examples, and the examples are turning out to be quite shaky.
To widen the inquiry, we can recall another example of alleged hyperintensionality: Sober's alleged difference between the properties of being a triangle and being a trilateral. In brief, his argument was that, in the causal-explanatory context of his example,
(14A) is true while (14B) is false:
(14A)
The figure was outputted because it was a triangle.
(14B)
The figure was outputted because it was a trilateral.
When we apply the 'Why?' heuristic, we have two rival answers to the same causal-explanatory question, as in these question-and-answers pairs:
(14A^) Q: Why was the figure outputted?
A: It was a triangle.
(14B^)
Q: Why was the figure outputted?
A: It was a trilateral.
Uncontroversially, the figure's angles played a more significant role than its sides in the causal process which led to the outputting of the figure; being an angle of a given figure and being a side of that figure are extensionally different properties. Consequently, a good answer to the causal-explanatory question will be cast in terms of angles, not sides. Moreover, speakers of English are more likely to connect the word 'triangle' with the description 'figure with three angles' and the word 'trilateral' with the description 'figure with three sides' than the other way around (the difference may be more marked for those who know some Latin and pick up the etymology). Thus, the causal explanation will be more perspicuous if it uses the word 'triangle' than if it uses the word 'trilateral'; speakers will tend to make the required inferential connections more easily.
But none of that requires being a triangle and being a trilateral to be distinct properties.
Here is an analogy. Imagine a student canteen where it is common knowledge that an alarm sounds if anyone takes twelve or more pieces of fruit. The alarm sounds. Compare two dialogues:
(15A^)
Q: Why did the alarm sound?
A: A student took 7 apples and 5 oranges, so they took
7 +5 pieces of fruit, and 7 +5 =12.
(15B^)
Q: Why did the alarm sound?
A: A student took 7 apples and 5 oranges, so they took
6 +6 pieces of fruit, and 6 +6 =12.
Surely the answer in (15A^) is more perspicuous than the answer in
(15B^); it is a better explanation. But none of that requires 7 +5 and
6 +6 to be distinct numbers.
What about Fine's signature example for a hyperintensionalist account of essence?
(1A)
It is essential to Socrates that he is Socrates.
(1B)
It is essential to Socrates that he is a member of {Socrates}.
The words 'because' and 'why' do not occur in (1A) and (1B), nor do those sentences purport to explain anything. However, the kind of essentialism that Fine uses such examples to motivate is broadly
Aristotelian in spirit. In that tradition, essences are regarded as starting-points for explanation (see Posterior Analytics 75a42–b2, Metaphysics 1041a25–32, and Charles 2000: 197–309 on Aristotle's explanatory conception of essence). After all, what is special about essential natures if they play no explanatory role? Thus, explanatory considerations should be relevant to (1A) and (1B). The introduction of the singleton set in (1B) will indeed tend to detract from the quality of explanations, by interpolating an irrelevant complication. In response to the question 'Why does that man keep accosting people in the street?', 'He is Socrates' makes a better starting-point than 'He is a member of {Socrates}'. A more natural case involves a less trivial essentialist claim than (1A):
(16A)
It is essential to Socrates that he is a human.
(16B)
It is essential to Socrates that he is a member of the set of humans.
Necessarily, all and only humans are members of the set of humans
(in the world in question). Still, 'He is a human' is a better explanatory starting-point than 'He is a member of the set of humans'.
The introduction of sets in (16B) will also tend to detract from the quality of explanations, by interpolating an irrelevant complication. But the question remains: do such differences in the linguistic form of explanations correspond to differences in non-linguistic content? As the earlier examples suggest, we may be quite susceptible to illusions of difference in non-linguistic content created by differences in the linguistic form of explanations. Thus, Fine's examples are far from decisive.
Other kinds of example are also used to argue for hyperintensionalism about causal contexts. Here is one of a kind I have heard used:
(17A)
The plane crash made Mary an orphan.
(17B)
The plane crash made Mary a self-identical orphan. The plane's crash killed Mary's parents, so (17A) is true. But one is tempted to assess (17B) as false, on the grounds that the plane crash did not make Mary self-identical; she was self-identical already.
Nevertheless, 'orphan' is necessarily equivalent to 'self-identical orphan'. If (17A) and (17B) differ in truth-value, the causal verb
'made' has created some sort of hyperintensional context.
Here is a similar example. It concerns events in 1461, during the English War of the Roses. Richard is Richard Neville, Duke of
Warwick, known as Warwick the Kingmaker; Edward is Edward
Plantagenet, who became King Edward IV.
(18A)
Richard's actions made Edward a king.
(18B)
Richard's actions made Edward a male monarch.
Richard's actions, given other contributory factors, brought it about that Edward became king, so on the relevant causal reading (18A) is true as a matter of historical fact. But one is tempted to assess (18B)
as false, on the grounds that Richard's actions did not make Edward male; he was male already. Nevertheless, 'king' is necessarily equivalent to 'male monarch'. If (18A) and (18B) differ in truth-value, the causal verb 'made' has again created some sort of hyperintensional context.
The trouble is that 'male monarch' is an easily available reading of
'king' in standard English, and that reading is applicable to (18A).15
Thus, by compositional semantics, (18A) is synonymous with
(18B), so they cannot differ in truth-value. Since (18A) is a well-known historical truth, (18B) is true too. Thus, although Richard's actions did not make Edward male, it does not follow that they did not make Edward a male monarch. But that has implications for
15 Are emperors male monarchs without being kings? An emperor is sometimes defined as a king of kings; on that definition, emperors are kings. In any case, the differential reactions to (18A) and (18B) are not sensitive to such issues. Quibbling about the particular case is pointless because there are so many similar ones—for example, the old-fashioned words 'actress' and 'poetess'. our assessment of (17B) too: although the plane crash did not make
Mary self-identical, it does not follow that it did not make her a self-identical orphan. Making a conjunction hold does not entail making a given conjunct hold. Consequently, the example of (17A) and (17B)
constitutes a poor case for the hyperintensionality of making.
What has gone wrong this time? Most likely, it is a very ordinary case of Gricean conversational implicature. As a hearer (or reader), one expects the speaker (or writer) to have bothered including the apparently redundant words 'self-identical' and 'male' for some purpose, and the best one's brain can come up with on the spot is that they (foolishly) meant to suggest that the self-identity or maleness was also made the case by the plane crash or Richard's actions.
That is another case where there is evidence of comparatively superficial linguistic phenomena having been misunderstood as manifestations of hyperintensionality. More specifically, one can connect it to the 'Why?' heuristic: we assess 'The plane crash' as a better answer to the causal-explanatory question 'Why did Mary become an orphan?' than to the causal-explanatory question 'Why did Mary become a self-identical orphan?'
Reading all this metaphysics into the pragmatics of explanation looks like a classic case of overfitting.16 Pre-theoretic verdicts on examples have been uncritically accepted as refuting intensionalism and motivating hyperintensionalist theories with many more degrees of freedom. Since philosophers did not recognize the proliferation of degrees of freedom as a serious cost, they were comfortable accepting the data at face value and accommodating them within such a theory. They felt no incentive to scrutinize the data more carefully, and to check for potential sources of error. As a result, those most concerned to separate metaphysical reality from the linguistic appearances have become the most susceptible to mistaking the appearances for the reality.
16 Philip Kitcher (2023: 69) briefly makes the related suggestion that 'logics of ground'
look like projections of the pragmatics of explanation.
4
Frege Puzzles
4.1 Representational hyperintensionality
On the evidence of chapter 3, hyperintensionality in metaphysics is an illusion, an artefact of overfitting heuristic-generated data.
On a conservative interpretation of this outcome, extending hyperintensionality to metaphysics was always implausible: its natural home is in matters of representation, not in the world as it is prior to being represented. Once things start being represented, the same thing can be represented in different ways, for instance, as
Hesperus or as Phosphorus, which naturally yields familiar, harmless forms of hyperintensionality, in knowledge, belief, hope, fear, and other intentional attitudes.
We have already seen evidence that the conservative interpretation is too complacent. Both impossible worlds and structured propositions have been used in attempts to capture the supposedly hyperintensional semantics of propositional attitude ascriptions, but the representational nature of the states ascribed does not magic away the methodological problems those frameworks face (chapter 3), though it might somehow make those problems a price worth paying. We also glimpsed how heuristics for belief ascription can generate errors in describing
Frege puzzles (chapter 1.5), which substantiates the concern that apparent hyperintensionality may be an artefact of overfitting even in representational matters. The case for representational hyperintensionality is weaker than it looks.
In formal epistemology, especially epistemic and doxastic logic and Bayesian probabilistic approaches, the most useful and most
Overfitting and Heuristics in Philosophy. Timothy Williamson, Oxford University Press.
© Oxford University Press 2024. DOI: 10.1093/oso/9780197779217.003.0004 used models are coarse-grained and purely intensional: they obliterate cognitively significant differences for the sake of mathematical simplicity, tractability, and power. Although one can add complications to such models to induce hyperintensional behaviour, the results tend to be unilluminating, since one has to insert by hand the very features one is trying to explain. In sharp contrast, when model-building is done well, one learns from the model: its behaviour can take one by surprise.
In natural language, ascriptions of knowledge and belief look more fine-grained: they seem sensitive to the cognitive differences the formal models flatten. Yet developments in the formal semantics of natural language threaten to undermine that contrast by analysing the truth-conditions of propositional attitude ascriptions as less sensitive to cognitive differences than they seem.
These issues matter for epistemology, because it is mostly done in natural language, which even formal epistemologists use to explain the intended applications of their mathematical models. If discourse in natural language about knowledge, belief, and other epistemologically interesting relations does not work in the way it seems to do, then arguments in epistemology may be led astray by misleading appearances. For instance, when in testing an epistemological generalization we have to assess sentences of the form
'S knows that P' as true or false in actual or hypothetical cases, our assessments may go wrong because we confuse semantic and pragmatic aspects of knowledge ascriptions in English, perhaps through relying on a fallible heuristic. Although indiscriminate scepticism about our assessments would be unwarranted, they may well need some fine-tuning.
Traditionally, Frege puzzles have been central to discussion of the semantics of propositional attitude ascriptions. But we can also use them as a clue to the heuristics on which we rely in making such ascriptions. Once we appreciate the role of those heuristics, we should be much less inclined to treat propositional attitude ascriptions as hyperintensional. This chapter explores such issues around Frege puzzles in detail, though far from comprehensively.1
4.2 The Fregean consensus
In the old days, philosophers took it as a datum that someone can believe that Hesperus is Hesperus without believing that Hesperus is Phosphorus. Thus, substituting co-referential proper names in the 'that'-clause of a belief ascription does not always preserve truth. Presumably, one who believes the truism that Hesperus is
Hesperus also knows that Hesperus is Hesperus, while one who fails to believe that Hesperus is Phosphorus also fails to know that
Hesperus is Phosphorus, because knowing requires believing.
Hence someone can also know that Hesperus is Hesperus without knowing that Hesperus is Phosphorus. Thus, substituting co-referential names in the 'that'-clause of a knowledge ascription also fails to preserve truth. Ascriptions of other propositional attitudes such as wondering, doubting, hoping, and fearing behave likewise.
Some version of Frege's distinction between sense and reference was widely (though not universally) taken to explain this phenomenon. The names 'Hesperus' and 'Phosphorus' have different senses, different modes of presenting the same planet, which their occurrences contribute as components of the senses of simple sentences in which the names occur; the senses of the sentences are
1 Much of this chapter draws from 'Epistemological consequences of Frege puzzles',
Philosophical Topics, (2021) 49: 287–319 (Williamson 2021b), which benefitted from written comments by Daniel Kodsi, Anna Mahtani, Jennifer Nagel, Luis Rosa, Mona
Simion, and Juhani Yli-Vakkuri, and conversation with Jeremy Goodman. Section 4.8
is based on part of 'Where did it come from? Where will it go?', in Arturs Logins and
Jacques-Henri Vollet (eds.), Putting Knowledge to Work: New Directions for Knowledge-First Epistemology. Oxford: Oxford University Press, forthcoming (Williamson forthcoming-b). The second half of section 4.10 and all of sections 4.11–12 are new. This chapter does not address the critique of the reliability of attitude ascriptions in natural language implicit in the 'negative programme' of experimental philosophy; it was briefly discussed in chapter 1.7. Fregean thoughts or propositions. Thus, the sentences 'Hesperus is Hesperus' and 'Hesperus is Phosphorus' express different propositions. There is no obstacle in principle to having an attitude to one proposition without having it to the other. On Frege's own version of the view, words in the 'that'-clause of an attitude ascription refer to their usual senses, not their usual referents, so the names were not even co-referential in the context in which the substitution was made, though the general consensus did not extend to that reference-shifting mechanism. The consensus was just that some account or other of the semantics of attitude ascriptions would explain how the propositional content of the ascribed attitude depends on the ordinary senses, not just the ordinary referents, of expressions in the 'that'-clause.2
On that consensus, Frege puzzles presented no special danger to epistemology. One had to be careful not to make illicit substitutions when characterizing what was putatively known or believed, but that was a matter of fairly straightforward professionalism.
4.3 The failure of the Fregean consensus
Famously, the work of Saul Kripke (1972, 1979, 1980) and others overturned the consensus. Proper names in natural language have no Fregean senses, at least of anything like the kind traditionally assumed by Fregeans. A more promising approach to the semantics of both names and indexicals treated them as directly referential: such an expression contributes only its ordinary referent and not also a sense to the proposition expressed by a sentence in which it occurs (Kaplan 1989). But the direct reference view gives new menace to Frege puzzles, since it seems to make the relevant
2 Throughout this chapter, occurrences of terms in the complement clause of an attitude-ascribing verb are treated as semantically in its scope; if the distinction makes sense, they are de dicto, not de re. substitutions truth-preserving for names and other directly referential terms, though not for definite descriptions. A long and complicated debate ensued, and still rumbles on, about the semantics and pragmatics of attitude ascriptions. I will not attempt to summarize all the moves and counter-moves, though I will sketch some reasons why Fregeanism failed to fulfil its initial promise. This chapter considers some implications of anti-Fregeanism for both general methodology and specific epistemological theses.
Frege puzzles gave Fregeanism a large head start over direct reference theories, of which Fregeans proved unable to take much advantage. What gradually became clear was that even where it seems most promising to associate an expression with a mode of presentation of its referent, that mode does not play the semantic role in natural language that Fregeanism would lead one to expect.
An example is the first-person pronoun. For Fregeans, the indexical 'I' is naturally associated with the distinctive mode of presentation of oneself to oneself as oneself, as 'I', which we can call the first-personal mode of presentation. Now consider my ascription of a belief to you:
(1)
You believe that I was born on 6 August 1955.
Background: I was indeed born on that date; for the sake of the example, I will assume that you were not. Let p be the proposition which, in uttering (1), I report you as believing. Since 'I' occurs in (1) firmly within the 'that'-clause, on the most straightforward
Fregean approach it contributes a mode of presentation to p. Since
'I' is associated with the first-personal mode of presentation, it presumably contributes that mode of presentation to p. Thus, in uttering (1), I say that you believe p, where p is the proposition made up of the first-personal mode of presentation and a mode of presentation of something like the property of having been born on
6 August 1955. But, in your beliefs, the first-personal mode of presentation picks out you, not me, as the referent. Thus, in uttering (1), I end up attributing to you a false belief about your own birthday, not a true belief about mine. That is absurd. Such a reading is just not available for the indirect speech ascription (1), by contrast with a direct speech ascription such as (2):
(2)
You accept 'I was born on 6 August 1955'.
Of course, Fregeans can and do postulate various more convoluted readings of my utterance of (1), on which I am saying in effect that you have a belief in some non-first-personal proposition q suitably related to the first-personal proposition which I express by the sentence 'I was born on 6 August 1955', while not myself expressing q.
But the supposed availability of such readings is not to the point, which is rather the unavailability of the absurd reading generated by the flat-footed application of the Fregean approach, on which
I am attributing to you a false belief about your own birthday. As a normal speaker of English, I cannot hear such a reading, no matter how hard I try. I do not hear it only to exclude it immediately on pragmatic grounds; I just do not hear it in the first place. Something is wrong with an approach that gets anywhere near such a reading.
How might some version of Fregean semantics avoid generating the absurd reading of (1)? Suppose that the customary referent of an expression E (for example, 'I') in the given context of utterance is x (for example, me). Then a Fregean might propose that in that context, an occurrence of E in the content clause of an ascription of an attitude to a subject S (for example, you) refers only to a sense under which S can think about x. But one can meaningfully utter
(1) without grasping any such sense, indeed, even when there is no such sense—for example, when I address (1) to someone I see on television, under the narcissistic illusion that they must have heard of me. That utterance of (1) is simply false. Even if S can think about x, the speaker may not grasp the sense under which S does so. In response, the Fregean might be tempted to interpret the speaker as quantifying over senses under which S can think about x. But that would miss the intended point of the Fregean semantics, for to think about Hesperus just is to think about Phosphorus, so the senses under which S can think about Hesperus just are the senses under which S can think about Phosphorus; thus, substituting
'Hesperus' for 'Phosphorus' in the content clause of an attitude ascription will not affect the ascription's truth-value, on the revised semantics.
The sheer complexity of the Fregean apparatus, how many moving parts or degrees of freedom it offers a theorist to play with, tends to obscure the lack of progress—especially when the focus is on making ad hoc moves for particular examples, instead of proposing a more general, systematic compositional semantics for the constructions at issue. That lack of progress after more than a century is good evidence that, despite its initial promise, the distinction between sense and reference is not the key to the semantics of Frege puzzles. The Fregean approach is in deep trouble even with very simple cases that seem at first sight well-suited to such a distinction.
Although philosophers from Descartes on are used to giving the first-person very special treatment, there is no evidence that the semantics of natural language affords it any such privilege.
Linguistically, it would be quite implausible to dismiss examples like (1) as a special case.3 As seen in chapter 1.5, the required transformations of personal pronouns and similar devices are automatically applied in semi-disquotational reports of others' propositional attitudes, with a focus on preserving reference, not on preserving sense.
Of course, such examples will not silence Fregeans; nothing will.
But they do suggest that the appeal to modes of presentation in semantics is much less natural, much less in tune with the workings
3 For relevant discussion of the supposed 'de se', see Cappelen and Dever 2013 and
Magidor 2015. of natural language and the needs of communication, than it first seemed.
We may well have to live with the conclusion that, despite appearances, the substitutions in Frege puzzles are truth-preserving. I will use some ideas in Kripke's classic paper 'A Puzzle about Belief ' (1979, 1988) as a starting-point from which to explore and extend a non-Fregean approach to Frege puzzles, though I will intersperse further comments about Fregean approaches. In the closing sections, I will discuss some implications for issues about evidence and subjective or epistemic probability.
'A Puzzle about Belief ' is most famous for its examples, especially
Pierre, who asserts 'Londres est jolie' but denies 'London is pretty', and Peter, who does not realize that the pianist Paderewski is the statesman Paderewski. Here, we will be more concerned with some of the more general themes in Kripke's discussion.
4.4 Frege puzzles and synonymy
Kripke emphasizes that Frege puzzles can arise for expressions of many kinds, even when the two expressions are normally regarded as synonymous, not just as co-referential. Thus, one cannot simply diagnose Frege puzzles as arising when two terms have the same reference but different meanings, for by normal standards they can arise even for two terms with the same meaning. Of course, whether meaning is anything more than reference is itself contested in the semantic debate, but that is not our present concern. Many direct referentialists hold that co-reference varies with context while synonymy requires co-reference across all contexts; thus 'Timothy
Williamson' and 'I' are co-referential in my context, but not synonymous, for they are not co-referential in your context.
One of Kripke's examples concerns the synonyms 'furze' and
'gorse', which are simply two terms for the very same kind of shrub
(1988: 134). The two words may have originated in different dialects of English. The shrub itself changes in appearance from one season to another, sometimes having dull brown needles and no flowers, sometimes bright green needles and yellow flowers. There is no general correlation between how the shrub appears and which word is applied, though for accidental reasons there may be such a correlation in how a particular speaker applies the words.
Suppose that Penny learns the term 'furze' somewhere by being shown various samples with bright green needles and yellow flowers, and learns the term 'gorse' separately somewhere else by being shown various samples with dull brown needles and no flowers. By normal linguistic standards, she understands both terms. Nevertheless, she may be in no position to know that the two terms co-refer. In that case, if one uses both terms with their normal meanings and happens to know that they co-refer, one may still feel tempted to describe Penny's situation by asserting (3) and denying (4):
(3)
Penny believes that furze is furze.
(4)
Penny believes that furze is gorse.
But, as discussed in chapter 3.3, the guiding principle of formal semantics is semantic compositionality, according to which the meaning of a complex expression is determined by the meanings of its simpler constituents and the way in which they are put together. Since (3) and (4) are put together in the same way out of corresponding words with the same meanings, in the absence of semantic 'funny business' compositionality requires (3) and (4) to have the same meaning too. But since meaning and context determine truth-value, it follows that they also have the same truth-value in any given context, such as a context in which one both asserts
(3) and denies (4). Thus, such a combination can hardly be the right way to describe Penny's situation. One might worry that the repetition in (3) and lack of repetition in (4) make a structural difference between (3) and (4). That would be insufficient to block the argument from a standard version of semantic compositionality, but we can anyway finesse the issue by using a pair without repetition, such as (5) and (6):
(5)
Penny believes that furze has yellow flowers.
(6)
Penny believes that gorse has yellow flowers.
There is the same temptation to assert (5) and deny (6), but there is also the same semantic reason as before to resist that temptation.
What kind of 'funny business' could make trouble for the arguments from semantic compositionality? In principle, verbs like
'believe' could introduce some sort of covert sensitivity to context, where uttering 'S believes that P' creates a context in which that sentence is true only if S assents to the proposition expressed by
'P' as presented in some way contextually relevant to the sentence
'P'. Without violating semantic compositionality, such an account permits a situation where uttering (3) would create a context in which (3) and (4) were both true, whereas uttering (4) would create a context in which (3) and (4) were both false, or uttering (5) would create a context in which (5) and (6) were both true, whereas uttering (6) would create a context in which (5) and (6) were both false. For example, when the speaker is using the choice between
'furze' and 'gorse' to mark a contrast, uttering (5) might create a context in which the truth of (5) and (6) requires Penny to assent to the proposition that furze has yellow flowers under the guise of the sentence 'Furze has yellow flowers', whereas uttering (6) would create a context in which the truth of (5) and (6) requires her to assent to the same proposition under the guise of the sentence 'Gorse has yellow flowers'. Since Penny assents to the proposition only under the guise of the sentence 'Furze has yellow flowers', an utterance of (5) would be true while an utterance of (6) would be false.4 Strictly speaking, none of that yields a single context in which (3) and (4) or
(5) and (6) differ in truth-value, but the effect is similar.
However, such contextualist hypotheses look ad hoc. Normally, just one of 'furze' and 'gorse' is used in a given conversation, and, although the example made Penny a native English speaker, the truth of (5) or (6) does not require her to know a word of English; she could use a natural kind term in her own language for the shrub.
More radically, nothing in the semantics of English requires Penny to have a language of any kind for (3)–(6) to be true. Imagine a species of languageless animals whose diet consists solely of gorse
(like giant pandas with bamboo shoots); they need and have a recognitional capacity for gorse, to which the belief that gorse has yellow flowers is crucial. Various forms of functionalism about the metaphysics of belief allow such a case; to exclude those theories in the philosophy of mind seems to be no business of the semantics of English. But then, if the truth-conditions of belief ascriptions are normally indifferent to the guise (if any) under which a believer believes a proposition, it seems unlikely that natural languages would have a special semantic mechanism waiting to spring into action just to resolve Frege puzzles and a few related difficulties.
Theoretically, a more explanatory account of Frege cases would be derived from more general principles needed far beyond Frege cases, rather than relying on semantic structure postulated ad hoc just to handle those very cases.
Grice's category of conversational implicature has the requisite generality, since he combines quite general principles of conversation with simple semantic assumptions to predict context-sensitive conversational implicatures (Grice 1989). Indeed, in some contexts, a speaker might well refrain from uttering (4) because uttering
4 See Crimmins and Perry 1989 for a similar account, and Goodman and Lederman
2021 for a more recent version, with extensive references to the literature. Salmón
1986 uses the apparatus of guises but his account is not of the envisaged kind. For the differences between Salmón's guises and Fregean senses, see Branquinho 1990. (4) would have the false conversational implicature that Penny would assent to 'Furze is gorse'. In the same context, the speaker might also utter (5) rather than (6) because uttering (6) would have the false conversational implicature that Penny would assent to 'Gorse has yellow flowers'. That is compatible with (4) and (6) semantically expressing true non-metalinguistic propositions in that context, which do not entail those metalinguistic conversational implicatures. In Nathan
Salmón's terminology (1986), the metalinguistic information is pragmatically imparted, not semantically encoded.
Unfortunately, even granted that there are such conversational implicatures, they do not explain all the phenomena in Frege cases.
For speakers do not merely refrain from asserting (4) and (6); they may actively deny (4) and (6), regard them as false, and assert their negations. Normally, if uttering a sentence would have a false conversational implicature, that does not justify one in uttering the negation of that sentence. If saying 'The Professor is sober this morning' would have the false conversational implicature that the
Professor is often drunk, that does not justify one in saying 'The
Professor is not sober this morning'. On an anti-contextualist anti-Fregean semantics, (4) and (6) are true in the example, their negations are false, and whoever asserts them speaks falsely.
Similar behaviour is observable with other attitude verbs, such as
'realize', for which parallel issues arise. For example, a botanically well-informed native speaker of English may well assert both (3r)
and (3rn), or both (5r) and (6rn):
(3r)
Penny realizes that furze is furze.
(4rn)
Penny does not realize that furze is gorse.
(5r)
Penny realizes that furze has yellow flowers.
(6rn)
Penny does not realize that gorse has yellow flowers. If one asks the speaker 'Do you mean that literally?', the answer is likely to be an impatient 'Of course'. Thus, some sort of error theory is needed.5 Even if the error involves some confusion between conversational implicatures and truth-conditional consequences, that confusion would need to be explained, since it is untypical of conversational implicatures.
If anti-contextualist anti-Fregeans can resort to error theories, so can contextualist anti-Fregeans.6 However, positing both contextualist and error-theoretic mechanisms to explain the data is unattractively uneconomical. If one has to posit an error-theoretic mechanism anyway, why not let it do all the work, and avoid the need to posit a contextualist mechanism as well? Contextualist anti-Fregeans might respond that a principle of charity in interpretation demands that we posit as little error as possible, and so explain as much of the data as we can with the contextualist mechanism. But if the errors are systematic, not just random performance errors, a well-developed error theory will posit a specific mechanism to explain them, which should indicate how widespread we can expect the errors to be. Thus, we will need to know more about the putative error mechanisms before adjudicating the issue. Section 4.6 will discuss such mechanisms in detail.
Faced with these difficulties, some philosophers deny that such differences in cognitive significance between synonyms can arise for competent speakers. One form of denial is to insist that Penny is not fully competent with the terms 'furze' and 'gorse', perhaps on the grounds that her understanding of them involves deference to expert botanists. That is not a promising strategy, for several reasons. First, the original description of the case did not mention semantic deference or a recognized scientific community, and does not require such elements. It simply involves some people being
5 There is no sign that the negation used in denying (4) and (6) has to be metalinguistic, as in 'The food wasn't good, it was great'. For evidence of error even in assessments of simple sentences in Frege cases, see Saul 1997 and 2010.
6 See, for example, the section on 'Error' in Goodman and Lederman 2021. better than others at recognizing particular natural kinds, which happens in any community and does not entail semantic deference.
Second, the strategy does not vindicate the observed combinations at issue, asserting (3) and (5) while denying (4) and (6). For if
Penny's alleged lack of full competence with the terms is relevant at all, it undermines reading off what she believes from her use of those terms; but we are happy to assert (3) and (5) on the basis of such reading off. Third, more generally, if having attitudes about a natural kind requires a perfect recognitional capacity for that kind, virtually no one has attitudes about any natural kind. Given that imperfect recognitional capacities suffice, Frege puzzles like this cannot be excluded.
Another form of denial is to insist that Penny has her own personal senses for 'furze' and 'gorse', which are different from each other and from ours. That too is an unpromising strategy. It rests on a misunderstanding of how attitude ascriptions work in natural language. When we make such ascriptions, the words in the
'that'-clause mean what we mean by them, not what the subject to whom we are ascribing the attitude does. That already emerged in the discussion of the role of 'I' in sentence (1). Similarly, if Penny happened not to know the word 'yellow', which is quite consistent with the original scenario, that would not make 'yellow' in (5) and
(6) meaningless; at worst, (5) and (6) might turn out to be false.
Nor do we somehow try to make 'furze' and 'gorse' in (3)–(6) mean what Penny personally means by them. After all, we do not know exactly what she means by them, in the intended personal sense.
If we simply defer to her for their meanings in these sentences, we undermine the individualistic conception of meaning on which the objection initially relied, with its talk of Penny's personal senses.
Anyway, vicariously using the agent's meaning is not an option once we generalize over the agent parameter: for example, when one asks 'How many people know that gorse has yellow flowers?', the embedded sentence 'Gorse has yellow flowers' does not have someone else's meaning. What matters for what (3)–(6) mean in our mouths is what
'furze' and 'gorse' mean in our mouths; they are synonymous in our mouths, and remain so when we utter (3)–(6). Thus, denying that Penny uses the words 'furze' and 'gorse' in their normal English senses is not just implausible; like the previous strategy for denial, it fails to vindicate the combinations at issue, asserting (3) and
(5) while denying (4) and (6).
Of course, there are metalinguistic variants of the sentences at issue. For example, instead of (5) and (6), we can consider:
(5m)
Penny believes that the sentence 'Furze has yellow flowers'
expresses a truth.
(6m)
Penny believes that the sentence 'Gorse has yellow flowers' expresses a truth.
There is no Frege puzzle here, because the metalinguistic beliefs are about distinct sentences. Even if (5m) is true, it obviously does not follow that (6m) is true. But that does not explain the Frege puzzle with (5) and (6). After all, (5m) and (6m) are not in general good paraphrases of (5) and (6), respectively. In a quite different scenario, where 'Penny' refers to someone who knows no English,
(5m) and (6m) are typically false, while (5) and (6) may easily be true—for example, she may be an expert botanist, who would express the knowledge ascribed in each of (5) and (6) using the same word for the shrub in her own language.
In short, we must learn to live with the conclusion that, read strictly and literally, (3) has the same truth-value as (4), and (5) the same as (6), even when are talking about someone like Penny.
Analogous considerations apply when 'believes' is replaced by
'knows' or 'realizes' in (3)–(6). More generally, epistemologists should not assume that Frege puzzles can be handled in some vaguely Fregean or contextualist way. We must be ready to be much more revisionary in treating the initial judgments. 4.5 Frege puzzles from the inside
A Fregean might concede that the sense-reference distinction is ill-adapted to the semantics of natural language, which is tailored to the needs of inter-personal communication, but still insist that it is just right for the needs of individual thought, including reflection on the epistemic status of one's own beliefs. On this view, the problems we have in saying what Pierre, Peter, or Penny believes are fundamentally problems in using a public natural language to describe a private cognitive perspective. This concession would have been unwelcome to Frege himself, for he emphasized that thoughts
(the senses of declarative sentences) can be part of the common heritage of humankind—for example, in the case of mathematical theorems. But we can still consider individualistic Fregeanism in its own right.
By itself, the restriction to first-person ascriptions is insufficient.
When Pierre later learns that 'Londres' and 'London' refer to the same city, and when Penny later learns that 'furze' and 'gorse' refer to the same shrub, they can wonder what beliefs they had before the discovery, and find the case just as puzzling to describe as we outsiders do. To avoid such problems, what is needed is at least a restriction to first-person present-tense ascriptions. But that is still not enough. For
Pierre and Penny can entertain the possibility of co-reference even before they know or believe that it obtains. Suppose that Penny is agnostic as to whether 'furze' and 'gorse' co-refer. She can think to herself: 'Perhaps furze is gorse; in that case, since I believe that furze has yellow flowers, do I also believe that gorse has yellow flowers?' Pierre can ask himself analogous questions. Even in the first-person present-tense, such questions remain puzzling.
The Fregean must go further, by postulating new attitudes to
Fregean thoughts, rather than using the natural language apparatus for attitude ascription. Let the underlined expression 'e' refer to the postulated Fregean sense which the sentence 'e' has for Penny right now, in her agnostic state. The idea is that furze and gorse are distinct, since 'furze' and 'gorse' currently differ in sense for Penny.
Thus, furze has yellow flowers and gorse has yellow flowers are distinct Fregean thoughts, for the sense of a complex expression is supposed to be a structured entity built of the senses of its simpler constituents, a strong form of semantic compositionality for senses.
Let beliefs be the attitude analogous to belief which one has to some
Fregean thoughts.7 The idea is that Penny believess furze has yellow flowers but does not believes gorse has yellow flowers; there is no paradox in her believing one Fregean thought and not another. She can use this apparatus to reflect on her own beliefs and their epistemic status. Presumably, she knows both that she believess furze has yellow flowers and that she does not believes gorse has yellow flowers, from which she can infer that furze and gorse are distinct, by compositionality. At this level, Frege puzzles are easily resolved.
When Penny later learns that 'furze' and 'gorse' are synonyms, she can conveniently fuse the information she associates with each, thereby giving the two words the same sense for her. Since they have distinct senses right now, at least one of the words will change its sense for her; by the symmetry of the situation, both will. Any sentence in which either word occurs will change its sense for her correspondingly. Hence, she cannot now rely on underlining (or her mental equivalent of it) to characterize her future thoughts, since underlining is tied to the senses expressions have for her right now.
This already indicates a serious limitation of the envisaged Fregean apparatus for purposes of her epistemic deliberation. In considering what to believe, she must think about what her belief state will be after a potential change. For example, when she considers whether to accept 'Furze is gorse' or 'Gorse has yellow flowers', she must think about what senses they will have for her after she has
7 Belief need not be some sort of secondary meaning of 'belief ' in English; it is just s a theoretically postulated attitude to Fregean thoughts loosely modelled on belief.
Presumably, there would be analogous attitudes loosely modelled on knowledge, hope, fear, and so on, though the subscript 's' does not refer to an operation defined for all expressions of English. accepted them, which depends on the new sense 'furze' and 'gorse'
will have for her; but it is not the sense of any of her current words, and it is unclear how she can even entertain it until she has made the very belief change whose merit she is currently trying to asses.
By contrast, if Penny works in a natural language, these difficulties do not arise: if she makes the envisaged change, she will believe that furze is gorse, but presumably will not believes furze is gorse, since she will no longer have words with the senses furze and gorse.
A further concern for the Fregean apparatus can be explained with a variant of Penny's case. Pat acquired 'furze' and 'gorse'
separately as natural kind terms, in a completely normal ostensive way, though in circumstances she no longer remembers.
She applies 'furze' by using a reliable recognitional capacity, and she applies 'gorse' by using an exactly similar and so equally reliable recognitional capacity. For her, the only differences between
'furze' and 'gorse' in associated descriptions and recognitional capacities are metalinguistic: 'furze' and 'gorse' are different words. However, she does not treat them completely interchangeably, for she has a slight concern that they may not co-refer: she worries that she may have been introduced to 'furze' as a word for one kind of shrub and to 'gorse' as a word for a different kind of shrub, though they are so similar in appearance that she cannot recognize the difference. In fact, that is not what happened; she was shown the same kind both times. Still, her doubt need not be neurotic: she may have had ample experience of lookalike species. Thus, she is slightly more confident of 'Furze is furze' than of
'Furze is gorse'. In Fregean terms, she is slightly more confidents of furze is furze than of furze is gorse (here the underlinings are for Pat's senses, not Penny's). Consequently, furze and gorse are different senses. But, for Pat, 'furze' and 'gorse' do not differ qualitatively or in individualistic meaning in any non-metalinguistic way at all; the difference is purely verbal.
Although Pat was described as thinking about the words themselves, that is not crucial to the example. Her slightly greater confidences in furze is furze than in furze is gorse suffices for the argument and does not require her to think metalinguistically.
What is wrong with building the words themselves into their
Fregean senses for a given thinker? Such metalinguistic senses do not fit the usual conception of Fregean senses, but that is not the main problem. Instead, it is an issue of motivation. The required theoretical apparatus of individualistic Fregean senses is elaborate, unclear, and ill-developed. It is not useful for natural language semantics. Nor does it look useful for epistemology, given the problem of incommensurability of senses between different cognitive states.
After all, a significant part of epistemology concerns the communication of knowledge across such differences—by memory, from earlier to later states of the same individual, and by testimony, from states of one individual to states of another. Learning itself—the acquisition of knowledge—constitutes a change in cognitive state.
What gets preserved through such transactions is likely to be at least somewhat coarse-grained.
Once the senses of words are individuated in terms of the words themselves, the senses risk being redundant. We already have the words themselves, and their meanings in natural language. The senses add another level of theoretical entities with no clear explanatory value. We can make the distinctions we need without them.
4.6 The necessary a posteriori and the contingent a priori
As Kripke recognizes, his revisionary treatment of Frege puzzles affects even some of his own signature doctrines in Naming and
Necessity, especially concerning the necessary a posteriori and the contingent a priori (1988: 135, 147n44). For example, on Kripke's view of the necessary a posteriori as often expounded, we know the necessary truth that Hesperus is Phosphorus only a posteriori, so while (7) is of course true, (8) is false—otherwise the case would not illustrate the key claim that some necessary truths are knowable only a posteriori:8
(7)
We know a priori that Hesperus is Hesperus.
(8)
We know a priori that Hesperus is Phosphorus.
This is just another Frege puzzle. Kripke is open to the possibility that, on the correct semantics, (7) and (8) have the same truth-value (with 'Hesperus' and 'Phosphorus' treated as directly referential proper names).
Kripke suggests a metalinguistic fallback for the problematic claim 'It was once unknown that Hesperus is Phosphorus': 'we can still say that there was a time when men were in no epistemic position to assent to “Hesperus is Phosphorus” for want of empirical information, but it nevertheless expressed a necessary truth'
(1988: 135). He explains: 'I was aware of this question by the time
“Naming and Necessity” [Kripke 1972] was written, but I did not wish to muddy the waters further than necessary at that time'.
For the contingent a priori, imagine a variant of Kripke's scenario in which we fix the reference of the rigid, directly referential term
'metre' by the non-rigid description 'the length of stick S', and we fix the reference of the rigid, directly referential term 'metre*' by the non-rigid description 'the length of stick S*'. As it happens, and unknown to us, the two sticks S and S* are exactly the same length.
Consider these four statements:
(9)
We know a priori that stick S is one metre long.
(10)
We know a priori that stick S* is one metre* long.
8 Here and elsewhere, some readers may prefer to insert 'if Hesperus exists' after 'that'; doing so makes no difference for present purposes.
Frege puzzles
(11)
We know a priori that stick S is one metre* long.
(12) On Kripke's view of the contingent a priori as often expounded, in all four cases, the embedded proposition about the length of the stick is contingent; (9) and (10) are true, but (11) and (12) are false.
For (9) and (10) follow the definitional connections, while (11)
and (12) cut across them. But 'metre' and 'metre*' are directly referential terms for the very same length; on the revisionary view of Frege puzzles, substituting one for the other in such contexts preserves truth-value. Thus (11) has the same truth-value as
(9) and (12) the same truth-value as (10). Moreover, since (9) and
(10) uncontentiously have the same truth-value as each other because the two cases are exactly parallel, (9)–(12) all have the same truth-value. That is quite contrary to the standard account.9
As with the necessary a posteriori, metalinguistic fallbacks may still be available, for example about people in no epistemic position to assert 'Stick S is one metre* long' or 'Stick S* is one metre long' for want of empirical information. More generally, Kripke comments that when he wrote his (1972), 'I regarded the distinction between epistemic and metaphysical necessity as valid in any case and adequate for the distinctions I wished to make' (1988: 147n44).10
A problem for Kripke's fallbacks is that both epistemic necessity and empirical informativeness are also subject to problems of substitutivity:
(13)
It is epistemically necessary that Hesperus is Hesperus.
(14)
It is epistemically necessary that Hesperus is Phosphorus.
9 Salmón 1987/
88 raises some epistemologically relevant issues about Kripke's example.
10 In semantics, epistemic necessity and epistemic possibility can be relativized to any given stock of knowledge. For Kripke, they concern specifically a priori knowledge. (15)
The information that Hesperus is Hesperus is empirical.
(16)
The information that Hesperus is Phosphorus is empirical.
We might expect (13) and (16) to be true and (14) and (15) to be false. But if substituting 'Phosphorus' for 'Hesperus' preserves truth from (7) to (8), as Kripke holds it may do, it should also preserve truth from (13) to (14) and from (16) to (15). Thus 'epistemic necessity' and 'empirical information' will have to be reconstructed in some other form if they are to play the required role in proofing the categories of the necessary a posteriori and the contingent a priori against substitutivity problems. A more thoroughly metalinguistic approach may be needed.
To some, Kripke's appeal to the distinction between epistemic and metaphysical necessity will suggest two-dimensional semantics, for example, as developed by David Chalmers (2006), with one dimension epistemic and the other metaphysical. Chalmers conceives his semantics as Fregean in spirit, by contrast with two-dimensional semantics in the tradition of David Kaplan (1989), which is motivated by more purely linguistic considerations, treats proper names as directly referential, and has no epistemic dimension. For instance, Kaplan assigns exactly the same semantic properties to the names 'Hesperus'
and 'Phosphorus', whereas Chalmers distinguishes them on the epistemic dimension of his semantics. In 'A Puzzle about Belief ', Kripke holds open the possibility of a semantic theory such as Kaplan's with directly referential terms, and so cannot simply appeal to Chalmers'
quite different approach.
In effect, for Chalmers a word has a Fregean sense (or 'narrow content') only relative to a given individual at a given time. The individualistic Fregean senses in section 4.5 might be fitted into the framework of Chalmers's semantics, but that gives a hint of the difficulties it faces. It also contrasts methodologically with Kripke's strong emphasis on the sharing of linguistic meaning, for instance, as names are passed down reference-preserving historical chains. A further concern for the use of Chalmers's framework to stabilize the distinction between epistemic and metaphysical modality is his appeal to a priori knowability in characterizing epistemic modality, given that the distinction between a priori and a posteriori knowledge is itself destabilized by substitution arguments, as in (7)–(12). Clearly, this is not the place for a detailed assessment of Chalmers's grand programme, with its speculative reductionist ambitions, though the problems raised in section 4.5 are very relevant.11 Were his Fregean programme on the right lines, that would have many ramifications for epistemology. In what follows, I will assume that his programme is not on the right lines, so we face the task of working out the epistemological consequences of an anti-Fregean approach.
Clearly, the anti-Fregean treatment of Frege puzzles has non-trivial consequences for the epistemological distinction between a priori and a posteriori knowledge. In particular, it raises concerns about the reliability of our pre-theoretic assessments of attributions of those types of knowledge. That leaves us with a picture significantly less clear than the one to be found in Naming and Necessity.12
4.7 Heuristics for belief ascription
In 'A Puzzle about Belief ', Kripke suggests an explanation for our difficulties in knowing what beliefs to ascribe in Frege puzzles. He formulates three principles which he takes to guide our ascription of beliefs but which jointly generate problematic consequences when applied to cases like that of puzzling Pierre. The first he calls
11 For a recent book-length critique of Chalmers's approach, see Yli-Vakkuri and
Hawthorne 2018.
12 For a debate on the significance or otherwise of the a priori/a posteriori distinction, see Boghossian and Williamson 2020. the 'disquotational principle' (1988: 112–13; I have made the schematic letter 'p' upper-case to conform with the rest of this book):
DP
If a normal English speaker, on reflection, sincerely assents to 'P', then he believes that P.
The second is a strengthened biconditional form of the disquotational principle (1988: 113):
SDP
A normal English speaker who is not reticent will be disposed to sincere reflective assent to 'P' if and only if he believes that P.
The third he calls the 'principle of translation' (1988: 114); unlike
DP and SDP, it is not specifically about belief, or even propositional attitudes in general:
PT
If a sentence of one language expresses a truth in that language, then any translation of it into any other language also expresses a truth (in that other language).
Kripke stipulates that the schematic letter 'P' in DP and SDP 'is to be replaced, inside and outside all quotation marks, by any appropriate standard English sentence', which 'is to lack indexical or pronominal devices or ambiguities that would ruin the intuitive sense of the principle' (1988: 112–13). Kripke seems to understand both
DP and SDP as implicitly generalized to other natural languages too—in particular, to French. While admitting that DP may need further qualifications, he says of DP: 'Taken in its obvious intent, after all, the principle appears to be a self-evident truth' (1988: 113).
To appreciate the interplay between these principles, we start with DP. Working in English, we apply DP to Pierre's linguistic behaviour in English, and conclude 'Pierre believes that London is not pretty', because he is a normal English speaker who on reflection sincerely assents to 'London is not pretty'. Working in
French, we then apply DP for French to Pierre's linguistic behaviour in French and reach the French translation of 'Pierre believes that
London is pretty', because he is a normal French speaker who on reflection sincerely assents to 'Londres est jolie'. Finally, by applying
PT, we conclude 'Pierre believes that London is pretty'. Thus, we are led to ascribe contradictory beliefs to Pierre: he both believes that London is pretty and believes that London is not pretty. That is paradoxical because (we may assume) by normal standards Pierre is eminently rational; he may even be the world's greatest classical logician.
When we apply SDP and PT to Pierre's linguistic behaviour in French and English, we ourselves are led to make contradictory statements about Pierre's beliefs—unlike the previous case, where we just attribute contradictory beliefs to Pierre. Working in English, we apply the right-to-left direction of SDP to Pierre's linguistic behaviour in English, and conclude 'Pierre does not believe that London is pretty', because he is not reticent yet is not disposed to sincere, reflective assent to 'London is pretty'. Working in
French, we then apply the left-to-right direction of the analogue of SDP for French to Pierre's linguistic behaviour in French. Since he is a normal French speaker who is not reticent and is disposed to sincere reflective assent to 'Londres est jolie', we again reach the
French translation of 'Pierre believes that London is pretty'. Finally, applying PT as before, we again conclude 'Pierre believes that
London is pretty'. Thus, we have contradicted ourselves.
Kripke argues that since our normal practice of belief attribution suffices to generate the problem, given a mild principle of translation, with no appeal to substitutivity, it would be wrong-headed to blame the problem on the latter. Indeed, as he notes, not even the principle of translation PT is really essential to the underlying problem, since similarly paradoxical cases arise for synonymous pairs in the same language. The principle that synonymous sentences have the same truth-value (in a given context) will do instead. We have already been using one of his examples: the synonymous natural kind terms 'furze' and 'gorse'. The example also shows that the underlying problem is not specific to proper names.
Kripke concludes his paper by saying that the puzzle cases lie
'in an area where our normal apparatus for the ascription of belief is placed under the greatest strain and may even break down'
(1988: 136). But what would it be for 'our normal apparatus for the ascription of belief ' to 'break down'? Kripke writes of it as an extreme outcome which 'may even' occur. Thus, it must be something worse than just our finding ourselves unsure what to say about the puzzle cases, since, as he emphasizes, that obviously does occur.
Is Kripke hinting that the very distinction between believing and not believing may not apply to such cases? That is what some people would expect if, for example, SDP had some sort of analytic status, making it quasi-definitional of 'believe'. But SDP is nothing like analytic. For instance, a congenital liar may believe that P
without being at all disposed to sincere reflective assent to 'P'; he may non-reticently deny 'P' (he is still a normal English speaker in his linguistic capacities). Even DP may have counterexamples, unless 'sincerely' is tied too closely to the expression of belief for
DP to be a helpful guide to belief ascription; if 'P' is a complicated sentence with several negations, a normal English speaker might make a performance error in processing it and, even on reflection, sincerely assent to 'P' although it in fact expresses the opposite of what he believes. Kripke himself expresses doubts on the matter: he writes of DP 'I fear that even with all this [qualification] it is possible that some astute reader—such, after all, is the way of philosophy—
may discover a qualification I have overlooked, without which the asserted principle is subject to counterexample', and of SDP 'Maybe again the formulation needs further tightening, but the intent is clear' (1988: 113–14).
Disappointingly, the subsequent literature has treated 'A Puzzle about Belief ' mainly as a source of especially recalcitrant Frege puzzles, with not much focus on the suggested breakdown of our practice of ascribing belief. Perhaps Kripke's conclusion has had so little take-up because it was felt to be too radical. After all, our practice of belief ascription is crucial to the mature human capacity for mindreading, without which we could hardly survive as language-using social animals. How could that capacity be comparable to a broken-down machine? But just rejecting Kripke's conclusion does not explain how DP and SDP relate to our practice of belief ascription.
A more promising view of DP and SDP is that they are versions of a standard heuristic for belief ascription, in both speech and verbalized thought, of the kind discussed in chapter 1 (especially
1.5 on disquotation). Kripke's puzzle cases then illustrate just the sorts of limitation we might expect of such heuristics. That hypothesis explains our pre-theoretic reactions when faced with cases like that of Pierre. Our sheer puzzlement, confusion, ambivalence, rightly emphasized by Kripke, are not well explained as outcomes of a smoothly functioning semantics alone (such as a contextualist semantics). In Kripke's cases, we don't know what to say. Our reactions make much more sense on the hypothesis that, at some level, we are relying on an imperfectly reliable heuristic, whose outputs are not always mutually consistent.
A much simpler basic heuristic may indeed underlie both DP
and SDP:
BDP
English speakers assent to 'P' if and only if they believe that P.
The idea is that the putative assent is in circumstances where the question whether P arises.
All the qualifications in DP and SDP about normality, reflection, sincerity, reticence, and dispositionality look like exception-barring clauses inserted to guard against defeaters. BDP is easier to use than DP or SDP: not only is it simpler, but it provides an overt criterion—assent to a sentence—for belief in a proposition, while all the qualifications concern less easily observed matters (normality, reflection, sincerity, reticence, dispositionality) from the perspective of another person. Of course, our capacity to recognize such exceptions shows that BDP does not exhaust our understanding of belief, but such defeasibility is typical of heuristics. As
Kripke's uncertainty over the formulation of DP and SDP suggests, being a native speaker does not put one in a position to survey all possible ways for the heuristic to be defeated; as one tries to think of as many as one can, pre-theoretical reflection gradually becomes more theoretical. When we use a heuristic, we may easily be unaware of its merely heuristic status, or indeed of what principle we are using, if any.13
Heuristics are very different from conversational implicatures.
Unlike the latter, heuristics play a direct role in assessing statements as true or false. Also, conversational implicatures are more or less predictable on general social grounds, whereas heuristics are cognitive devices applicable to specific kinds of statement. Of course, heuristics may help to generate conversational implicatures. For instance, if John asks 'Does Penny believe that gorse has yellow flowers?', and Mary replies 'She believes that furze has yellow flowers', John may take Mary to imply that the literally correct answer to his question is negative, or at least that she does not know it to be positive, since otherwise the switch from 'furze' to 'gorse'
would be pointless. But such conversational phenomena are derivative.
One limitation of DP, SDP, and BDP is that they are applicable only to the ascription of beliefs to speakers of a language. But we
13 Our reliance on a disquotational heuristic such as BDP in belief ascription may explain the data used by various authors to argue that belief is weak in the sense that one's
'best guess' amounts to belief (Hathorne, Rothschild, and Spectre 2016, Rothschild 2020,
Holguín 2022). In restricted circumstances like those envisaged in the literature, one assents to (or says) one's best guess; although that is a marginal case of assent, it may easily be enough to trigger the disquotational heuristic and so to generate the corresponding belief ascriptions. That is shaky evidence for the truth of 'belief is weak'. For other reasons to doubt that belief is weak, see Williamson forthcoming-e. often ascribe beliefs to non-speakers, such as non-human animals and very young children, by observing their non-verbal behaviour.
For example, to explain why the cat jumped into the bathtub, we assume that she believed (falsely) that it was empty. Frege cases arise for such creatures too. To explain why a cock robin in his own territory who sees himself in a mirror flies aggressively at the mirror, we assume that he believes (falsely) that he is a rival. To keep track of the robin's mental states, we may distinguish guises: he believes that he [under a visual demonstrative guise] is a rival, but does not believe that he [under a self-relating guise] is a rival. In effect, we treat the robin as having a belief state aptly manifested by saying
'He is my rival' but no belief state aptly manifested by saying 'I
am my rival', although of course we know that the robin himself cannot manifest his belief in words. Obviously, such verbalized belief states will not be fully faithful to how the robin thinks, but they may still be a decent first approximation. Similar examples could be given for very young children. Like non-human animals, they can be tricked by Frege cases into false belief without being able to grasp what false belief is.14 To grasp such cases firmly, we may need to conceive them in terms of such as-if saying, and make implicit notional use of BDP. Unsurprisingly, given the limitations of BDP, we may have difficulty in trying to describe the situation consistently: does the robin believe that he is his rival?
Of course, we can ascribe beliefs to older children and adult humans on the basis of either linguistic or non-linguistic behaviour.
Which sort of heuristic is more reliable, and which is more convenient, depends on the case. If we lack the time or opportunity to observe someone's non-linguistic behaviour but want to know whether they believe that P, just asking them 'P?' is often a good way to find out. Overfitting and heuristics in philosophy
A more general limitation of Kripke's account in the paper is that it is specific to belief, although Frege puzzles arise just as much for other attitudes, such as knowledge, hope, and fear. It is not obvious how to generalize DP, SDP, or BDP to those other attitudes. Still,
DP, SDP, and BDP are a start. Given that knowledge entails belief, whenever SDP indicates the absence of belief, it also indicates the absence of knowledge. On the positive side, someone's assent to 'P'
might be taken as a highly defeasible sign that they know that P; our knowledge that it was not the case that P would be a salient defeater.
At a more general level, the same mindreading capacity used for knowledge ascription is also used for belief ascription (Nagel 2013).
The case of knowledge ascription will be discussed in more detail in section 4.8.
For any propositional attitude φ, if one wants to know whether a normal speaker φs that P, in many circumstances a quick and moderately reliable way to find out is by asking them 'Do you φ that P?'
We can call this the 'Just Ask' heuristic. It is not quite a generalization of DP, SDP, or BDP, for in the case of belief it tells one to ask
'Do you believe that P?', whereas for DP, SDP, and BDP one would ask simply 'P?' The questions are not equivalent. If you ask honest agnostics 'Do you believe that there is a god?' they will answer 'No'
(agnostics are not theists); by contrast, if you ask them 'Is there a god?' they will not answer 'No' (agnostics are not atheists), but instead 'I don't know', or the like. Nevertheless, the 'Just Ask' heuristic has a key feature in common with DP, SDP, and BDP: all these tests are sensitive to differences between the sentences 'P' and 'Q', even if the propositions that P and that Q are identical. Consequently, they may help explain our troubles in Frege cases for any attitude. If the propositions that P and that Q are identical, a rational person may still give conflicting answers to the questions 'Do you φ that P?' and
'Do you φ that Q?' Heuristics for attitude ascription with this feature are language-sensitive.
By contrast, the factivity principle 'If not-P, the agent does not know that P' is language-insensitive. For if the propositions that P and that Q are identical, then not-P if and only if not-Q, so the principle never yields conflicting answers to the questions 'Does the agent know that P?' and 'Does the agent know that Q?', though we may of course misapply the principle if we are confused about the relation between 'P' and 'Q'.
When φing is a factive attitude, the question 'Do you φ that P?'
normally presupposes that P. For example, the question 'Do you regret that you never told him what you thought of him?' presupposes that the addressee never told the relevant male what they thought of him. The fact itself is taken for granted; the question concerns the addressee's affective attitude to the fact. That in itself poses no problem for the 'Just Ask' heuristic.
However, when φing is a more purely cognitive factive attitude, such as knowing, seeing, or remembering, often one asks whether someone φs because one wants to learn the fact at issue; one is in no position to ask 'Do you φ that P?' because one does not yet know whether P. In such cases, a slightly more complex variant of the 'Just
Ask' heuristic is needed. Unless one already knows that the train stops at Ardlui, one does not ask 'Do you know that the train stops at Ardlui?' (which could elicit the answer 'I do now'); one asks 'Do you know whether the train stops at Ardlui?' If one gets the rather uncooperative answer 'I do', leaving one still not knowing whether it stops there, one can follow up with 'So does it stop there?' More generally, the variant of the 'Just Ask' heuristic has one ask 'Do you
φ whether P?', with 'P?' as the potential follow-up to an uncooperatively minimal positive answer. Similarly, one might ask 'Do you remember whether I locked the door?' or 'Can you see whether the light is on?' Rather than directly asking the question one is really interested in, one checks whether one's interlocutor is in a position to answer it. This variant of 'Just Ask' is, of course, equally language-sensitive.
'Just Ask' and its variants are more general than DP, SDP, and
BDP because one can apply the former but not the latter to any attitude one can articulate. Obviously, they are not fully reliable, because even a speaker who is trying to be honest may lack self-knowledge or be self-deceived. Nevertheless, they may be better than the available alternatives. One can also use 'Just Ask' in the past tense to probe the speaker's past mental states, by asking questions of the form 'Did you believe/hope/fear that . . . ?', 'Did you already know that . . . ?', 'Did you remember that . . . ?', 'Could you see whether . . . ?' By contrast, DP and SDP target only the speaker's present beliefs; if 'P' is in the past tense, they target the speaker's present beliefs about the past.
The primary use of these language-sensitive heuristics is 'online', to find out the attitudes of a living person with whom one can communicate. But of course that is not what readers of Kripke's article are doing when they wonder what Pierre in the story believes.
If they are applying DP or SDP, they are doing it 'offline', in their imaginations. Such offline uses of heuristics for attitude ascription are quite common; we make them all the time when reading novels.
In the case of Pierre, we need not imagine him talking to us or anyone else; we can simply imagine him saying 'Londres est jolie' or
'London is not pretty' to himself; DP and SDP are still applicable.
When we read works of analytic epistemology, we are often expected to do something similar, although the attitude at issue may be knowledge or justified belief rather than plain belief. The reader is asked to imagine fictional cases and, within the fiction, to make positive or negative attitude ascriptions. The content of the putative attitude is normally presented to the reader as expressed by a sentence. Naturally, we will use offline whatever heuristics we have for ascribing the attitude at issue, which will often involve a language-sensitive heuristic. This is a potential source of error in our use of the case method in epistemology. Of course, if the fictional scenario involves an obvious Frege case, experienced philosophers are likely to be on the alert for associated problems, but in some cases even the unmentioned possibility of a Frege case may make problems.
For instance, when one considers the assertive use of Moore-paradoxical sentences of the form 'I falsely believe that P', it may not be immediately obvious that, given anti-Fregeanism, such uses can be legitimate in Frege cases (Crimmins 1992).
Our reliance on imperfectly reliable heuristics in assessing attitude ascriptions also threatens the standard methodology for studying the semantics of such ascriptions. The assessments of attitude ascriptions with respect to hypothetical cases are standardly treated as the central data for that study. Normally, a semantic theory of the truth-conditions of attitude ascriptions is expected to explain the data by vindicating the assessments, predicting their correctness. But if the assessments are the outputs of imperfectly reliable heuristics, then they may be incorrect, in which case a semantic theory should not predict their correctness. Thus, the literature on the semantics of propositional attitudes may have fallen into the trap of overfitting, producing increasingly complicated theories to fit unreliable data (see chapter 2). If the errors result systematically from reliance on comparatively simple heuristics, semanticists need to know what those heuristics are, so that they can be taken into account in a correspondingly systematic way. We can still expect a semantic theory to treat the heuristics as charitably as possible, by not imputing errors needlessly, but to do that we must first understand how the heuristics work. A more sophisticated methodology is called for, with a more critical attitude to the data.
One consoling thought is that when the heuristics for ascribing attitudes are shared by the participants in a conversation, the errors they induce may often 'cancel out'. For example, if—in that limited context—they all erroneously treat 'Penny believes that furze has yellow flowers' as if it expressed the proposition that Penny believes that furze has yellow flowers under the guise of the sentence 'Furze has yellow flowers', they may still succeed in communicating the latter information among themselves. For reasons already explained, one should not conclude that in that context the sentence really did express that proposition about the guise. After all, if the participants in a conversation all misconstrue the grammar of a sentence in the same way, among themselves they may succeed in using it to communicate a thought quite different from the one it really expresses. Such error-based communicative successes tend to be local, but they still help explain why the heuristics' limitations do much less harm than one might have expected.
4.8 Heuristics for knowledge ascription
Knowledge ascription is arguably more fundamental than belief ascription and works in rather different ways. It therefore deserves a section to itself. In this section, Frege puzzles will be marginal, even though they do of course arise for knowledge ascription too; instead, the focus will be on differences between knowledge ascription and belief ascription. But heuristics for knowledge ascription will later cast light on our difficulties with Frege puzzles.
In Knowledge and Its Limits, I made a case for knowing as a core mental state, based mainly on general philosophical considerations about externalism, causal explanation, self-knowledge, the logical form of attitude ascriptions, and so on (Williamson 2000).
One footnote cites a discussion by the psychologist Josef Perner
(1993) of evidence that children understand knowledge and ignorance before they understand belief and error, and so do not understand knowledge in terms of belief. I found that encouraging, but did not build on it. However, as Jennifer Nagel later noted (2013), psychologists routinely classify knowing as a mental state. That is not just a terminological point; it draws substance from how they treat the attribution of knowledge as just as central and basic an application of the human mindreading capacity as the attribution of beliefs or desires (see also Nagel 2017). In effect, the human cognitive system thrives on treating knowledge as a mental state.
There is increasingly strong evidence that the capacity to distinguish knowledge from ignorance is cognitively more basic than the capacity to distinguish true belief from error (for an introduction to the recent literature, see Phillips, Buckwalter, Cushman, Friedman, Martin, Turri, Santos, and Knobe 2020 and associated discussion). Humans attribute knowledge and ignorance before they can attribute true belief and error, and they tend to do it faster and more automatically. Non-human primates attribute knowledge and ignorance to each other, but not true belief or error.
Indeed, that combination may extend much more widely across species. The best available explanations of much animal behaviour interpret them as making such distinctions. Reductive attempts to re-explain the behaviour in terms of mere reflexes become ever more ad hoc when faced with the complexity and flexibility of the behaviour. Claims to have found belief attribution at much earlier stages have not proven robust (see Nagel forthcoming for discussion).
What very young children and nonhuman primates attribute is clearly knowledge-like, not some doxastic ersatz such as true belief. It is even sensitive to Gettier cases. For example, here is the experimenters' summary of two experiments with rhesus macaques
(Horschler, Santos, and MacLean 2019):
In Experiment 1, monkeys watched an agent observe a piece of fruit
(the target object) being hidden in one of two boxes. While the agent's view was occluded, either the fruit moved out of its box and directly back into it, or the box containing the fruit opened and immediately closed. We found that monkeys looked significantly longer when the agent reached incorrectly rather than correctly after the box's movement, but not after the fruit's movement. This result suggests that monkeys did not expect the agent to know the fruit's location when it briefly and arbitrarily moved while the agent could not see it, but did expect the agent to know the fruit's location when only the box moved while the agent could not see it. In Experiment 2, we replicated and extended both findings with a larger sample, a different target object, and opposite directions of motion in the test trials. Overfitting and heuristics in philosophy is that if the fruit is somewhere, it continues to be there, and that if the agent knows that it is there, the agent continues to know that it is there. In effect, when the monkeys see the agent see the fruit put in the box, they treat the agent as coming to know that it is in there. They continue to treat the agent as knowing that it is in there when the agent's view is temporarily occluded but the fruit remains in there. Thus, they are surprised if the agent reaches for the wrong box, presumably in order to get the fruit. But when the fruit moves out of the box, the monkeys cease to treat the agent as knowing that the fruit is in there, since they can see that it isn't.
When the fruit moves back into the box, they do not treat the agent as again coming to know that the fruit is in it, since they can see that the agent did not see it moving back. Thus, they are not surprised if the agent reaches for the wrong box. Had the monkeys been thinking in doxastic terms, they would have treated the agent in both conditions as believing throughout that the fruit is in the box (this is simply a point about belief; it does not depend on the assumption that knowledge entails belief). Thus, there would be no difference in surprise between the two conditions when the agent reaches for the wrong box. Indeed, the belief that the fruit is in there is true in the final stage of both conditions, and even justified, given the presumption of persistence. Since the monkeys reasonably treat the agent as not knowing that the fruit is in there after it has moved and returned, that is in effect a Gettier case—although, of course, the monkeys do not think of it as a case of justified true belief.
The experimenters themselves interpret the monkeys as attributing only an 'awareness relation' rather than knowledge to the agent. However, their distinction between knowledge and awareness is unclear, and seems to depend on an unnecessarily doxastic conception of knowledge. The results of the experiments make just as good sense on the assumption that the monkeys are distinguishing between knowledge and ignorance (see Nagel forthcoming for more discussion, including of similar results for young children). Many philosophers have found the idea that attributing knowledge is easier than attributing belief 'counterintuitive'. They assume that attributing knowledge must be harder, and require more sophistication, than attributing belief. Sometimes, the assumption comes from a vision of attributing knowledge as attributing some post-Gettier multi-clause analysans of knowledge in terms of belief, truth, and other factors, which would of course be much harder, and require much more sophistication, than attributing belief alone.
But even philosophers who do not envisage knowledge as having such an analysis often seem to assume that attributing knowledge must require more than attributing belief, simply because knowledge itself requires more than belief. Even on the knowledge-first view in Knowledge and Its Limits, knowledge entails belief, while belief does not entail knowledge. At a more general level, a similar thought may influence many internalists in epistemology: broad mental states must be harder to identify than narrow mental states because identifying broad states requires monitoring both the internal and the external, whereas monitoring narrow states only requires monitoring the internal.
Such preconceptions are not surprising for self-attributions of mental states. But if, as is likely, mindreading capacities evolved through social life, their primary role is in attributing mental states to others. For that task, states purely internal to the other may be harder to determine than states involving the mutually observable environment. A simple initial case is the absence of factive states.
Just from knowing that you didn't eat the banana, you can conclude that I don't know that you ate the banana—but you may still wonder whether I believe that you ate the banana.
Of course, attributions of positive mental states are central too.
A good place to start is with seeing an object. When you see an apple and I see it too, typically, each of us can also see that the other sees it. We can check open eyes, direction of gaze, potential occlusions.
That will not satisfy sceptics about other minds, but their sceptical scenarios were scarce in our evolutionary history. Similarly, when two people walking together both hear a loud noise, typically, each of them also knows that the other heard it. On the negative side, one may know that the alpha male can't see the apple, because a bush is in the way, or one may know that he is too far away to hear one's breathing. Such knowledge about what others do or don't perceive plays a large role in communication—for example, in the use of perceptual demonstratives. When young children interact with other children or adults, mutual gaze at an object is often crucial to communication.
The internal analogue of object-seeing is as-if object-seeing, being in a mental state internally the same as (really) seeing an object. Attributing as-if object-seeing is much more laborious. When
I see that you see the apple, I can reason that since every mental state is internally the same as itself, you also as-if see an apple, but that is an artificial intellectual exercise. To consider cases where really seeing and as-if seeing come apart, we can suppose that dreaming that one sees an object involves as-if seeing an object without really seeing it. If you see me when I'm asleep, gently snoring with my eyes shut, you know that I am not really seeing an apple, but you cannot tell whether I am as-if seeing an apple.
Although object-seeing is not itself a propositional attitude, it is closely related to propositional attitudes. One can see an apple without seeing that it is an apple, because it has an unusual shape, or one thinks it might be a wax replica, or one has been brought up in ignorance of apples. Still, normally, when one sees an apple, one also sees that it is an apple. Conversely, when one doesn't see an apple, one also doesn't see that it is an apple. Thus, it is unsurprisingly typical that when we see an apple together, each of us is in a position to know that the other sees that it is an apple. Seeing-that,
'fact-seeing', is a propositional attitude.
Psychologically, perhaps we model seeing that P on seeing an object, treating the state of affairs that P like an object. Just as you can't
(really) see what isn't there, you can't (really) see what isn't the case.
On this analogy, we treat the non-obtaining of the state of affairs that P like the absence of an object. Just as an object o must be there for you to see o, it must be that P for you to see that P. Moreover, both object-seeing and seeing-that normally require a suitable causal connection to what is seen: a merely accidental match of your visual image to something external, e, does not constitute seeing e.
In Knowledge and Its Limits, I argue that seeing that P is a specific form of knowing that P. Thus, when we see the apple together, typically, each of us is in a position to know that the other knows that it is an apple. There would be little point in my judging merely that you believe that it is an apple, for why should I make that judgment if I doubt that you see that it is an apple?
Psychologically, seeing-that seems to be treated as a paradigm of knowing-that. 'See' is often used in an extended sense for a wide range of cases of knowing or recognizing (coming to know): 'I see your point'; 'I don't see how that follows'. What drives the generalization from literal seeing and other forms of sense perception to knowing?
A key factor is memory. When you turn away, you no longer see that there are apples on the tree, but you still remember that there are (or at least were), and many of the effects on action are similar—you may still go to the tree when hungry. Remembering that P is another form of knowing that P. Having seen the agent see the fruit put somewhere, the rhesus macaques continue attributing knowledge that it is there to the agent even when they can see that the agent can no longer see the fruit. A large part of the excess of knowledge over sense perception is simply what remains when sense perception ceases.
In light of these considerations, knowledge attribution looks rather easier and more natural than philosophers' preoccupations make it seem. We should not be surprised that the level of cognitive sophistication required for attributing knowledge turns out to be lower than the level of cognitive sophistication required for attributing belief—just as it can take less to recognize whether someone knows that P than to recognize whether they have an attitude internally similar to knowing that P. Knowing also takes primacy when we learn from others about the world (Phillips et al. 2020). If you want to know whether P, but are not in a position to perceive whether P, it matters to you whether I know whether P. If I do, you can learn from me (whether
I happen to have a belief as to whether P is not the issue). Imagine us facing each other. You can see things behind my back that I can't see; I can see things behind your back that you can't see. We may wish to share our knowledge: one of us sees signs of a predator and sounds the alarm. Or we may wish not to share our knowledge: one of us sees some delicious food and tries not to react, hoping to eat it once the other has gone. The other can benefit by spotting tell-tale signs that the first has spotted something. In such cases, to focus on the other's internal states is to miss the point.
A converging line of argument comes from considerations of cognitive efficiency, as Robert Gordon has observed (Gordon
2000, 2021, forthcoming). Minded creatures put huge effort into learning about their environment and what is happening in it, and into keeping their information up to date—it can literally be a matter of life and death, as it is for predators and prey. Creatures capable of mindreading use it to keep informed of similar cognitive states and processes in others. Imagine that whenever they represent something they must also separately represent how each of the others represent it (for instance, whether they believe, disbelieve, suspend judgment, or have some degree of a credence). That is a massive multiplication of effort. Indeed, it threatens to be infinite: I represent X, you represent how I represent X, I represent how you represent how I represent X, you represent how I represent how you represent how I represent X, . . . For example, each creature maintains something like a map of its environment. But it also needs to track how each of the others maps the environment, so for each of the others it maintains another map of the environment, representing the other's map. That already threatens to be computationally infeasible, even before we start worrying about the infinite regress of maps of maps. A much more efficient method would be to maintain just one map, but to try to mark the location of other knowers on it. That already captures something of their different perspectives on the world. For example, it encodes information about what you can see but others can't, because their view is obstructed by an intervening obstacle. Similarly, it also encodes information about places they can see but you can't. Of course, that is only a start. The rhesus macaques already go further by tracking which present states of affairs another can still access through memory though no longer through sight. The older child, in attributing false beliefs, is doing something much more complex. Still, the underlying principle may be the same: in mindreading, the default is to treat the other as knowing; the work goes into tracking deviations from that. In
Gordon's terms, the default is 'the shared world' (Gordon 2021
connects his arguments about the shared world and cognitive efficiency to the predictive coding model of perception). Harvey
Lederman, crediting Taylor Carman for the observation, pointed me to a passage in Merleau-Ponty 1945: 407–8 about the cognitive attitude of young children where he seems to endorse a similar conception of the shared world. By contrast, on the mistaken but widespread alternative, the default is to treat the other as a tabula rasa, so that attributing any positive mental state requires work.
Watering down the default from knowledge to true belief would make no sense. By default, everything lies open to everyone's view; in those circumstances, there is knowledge, not just true belief.
To make knowledge the default is not to assume that most agents know most truths. Even when that assumption is restricted to simple truths about the environment, it is surely false: think of all the truths about what insects are under what stones, and the like.
In practice, mindreading is typically used for matters of actual or potential interest to the agents concerned. The point is that, on such matters, it is typically easier to work down from an initial hypothesis of total knowledge than to work up from an initial hypothesis of total ignorance. Of course, so far as the world is open to everyone's view, there are no Frege cases, since they involve something hidden. But the shared world default still leaves room for such cases to arise, because the default's inhibitors may be guise-sensitive. Imagine this.
You and I both know Snežana. I can see both you and her, and that you are in a position to hear her but not to see her. She sneezes.
Pre-theoretically, I do not assume that you know 'Snežana is the sneezer'.
The shared world default may well have been ecologically valid in the conditions under which mindreading evolved: small groups of conspecifics in a local environment, interactions between a predator and prey, and so on. One can worry, though, how much sense it makes in the modern world of highly complex, diverse societies.
But that worry may underestimate the epistemic diversity already present under those evolutionary conditions. Even in a small group of hunter-gatherers, there are obvious epistemic asymmetries between adults and children. Children know that they know less than adults, and adults know that they know more than children.
Mindreading in both directions guides how children learn from adults. Within a group, differences in life history, recent experience, skills, and abilities, can all make for significant differences in knowledge and belief. When one group of hunter-gatherers encountered a new group, perhaps with alien customs, how each group mindread the strangers in those sensitive circumstances could make the difference between things going very well and things going very badly—crudely, between sex and death. Human history is not a simple narrative of increasing diversity; notoriously, imperialism and globalization work in the opposite direction. Even in the modern world, people of very different cultures and mindsets do manage to communicate, using a robust capacity for mindreading that evolved under radically different conditions.
For that to happen, the shared world is a more effective default than the tabula rasa. The shared world default may also help solve a long-standing problem in game theory and theoretical economics. Many results depend on the hypothesis that various background conditions such as rationality are common knowledge amongst the relevant agents: everyone knows that everyone is rational, everyone knows that everyone knows that everyone is rational, everyone knows that everyone knows that everyone knows that everyone is rational, and so on ad infinitum. Demanding such common knowledge of normal humans seems unrealistic. One might expect that, in practice, a finite approximation to common knowledge would do instead, but that is not always so. Some apparently realistic forms of coordinated action can be achieved under common knowledge but not under 'almost common knowledge' (Rubinstein 1989).
Moreover, even a few iterations of 'everyone knows' can be unachievable for epistemological reasons explained in Knowledge and
Its Limits, since each iteration requires a further margin for error
(see also Hawthorne and Magidor 2009, 2010; for a different approach to the problem see Lederman 2018a, 2018b). Yet an announcement over a loudspeaker can surely seem to create common knowledge amongst the people in a room. What is going on?
The knowledge default is implicitly a common knowledge default. For substituting 'everyone knows that P' for 'P' in the default schema 'If P, everyone knows that P' gives 'If everyone knows that
P, everyone knows that everyone knows that P', and so by transitivity 'If P, everyone knows that everyone knows that P'. Repeating the argument yields arbitrarily many iterations of 'everyone knows that'. Obviously, an articulated inferential process like that is psychologically unrealistic. The point is rather that if everyone treats the world as open to view by default, and nothing inhibits the default, then the effect is in many ways similar to common knowledge. Of course, the default does not mean that there really is common knowledge, in the sense of infinitely many levels of iterated knowledge. It just means that, when nothing inhibits the default, everyone acts as they would if everything were common knowledge. But that may suffice for coordination to be achieved.
It may even be achieved, just as it often seems to be, with no iteration of epistemic operators, indeed with no epistemic operators at all: the phenomenology is just that of a world open to view. Since the coordination is the predictable result of deeply rooted forms of human thinking, it may even be safe enough for those involved to know in advance that they will coordinate. Naturally, all this needs to be worked out in much more detail. But it promises to be a far more psychologically realistic picture of the cognitive processes underlying apparent common knowledge than any elaborate reconstruction in epistemic logic.
Whatever our heuristics for ascribing knowledge, belief, or other epistemic states, we will be relying on them in epistemology too, when we ascribe such states with respect to hypothetical cases. That does not warrant the panicky response that in epistemology we should stop using our ordinary means of ascribing attitudes, any more than visual illusions warrant the response that in science we should stop using vision. But it does indicate that we need some checks and balances. In particular, we should beware of letting epistemology be a largely data-driven inquiry, where so much of the data is supplied by our ordinary means of ascribing epistemic states. We need to put more weight on theoretical virtues, such as simplicity and strength.
4.9 Evidence
We can now return to exploring consequences of an anti-Fregean treatment of Frege cases. For simplicity, I will assume that the anti-Fregean can explain all the systematically recalcitrant data in Frege cases as effects of reliance on imperfectly reliable heuristics for attitude ascription without resort to contextualist semantics. In that respect, our anti-Fregean will henceforth be an anti-contextualist anti-Fregean.
Normally, whether it is rational for one to believe a proposition p is sensitive to how p relates to one's total evidence. Thus, if one's evidence can be non-transparent, in the sense that what it seems to one to comprise is not what it does comprise, one may be in no position to know how p does relate to one's total evidence, and so in no position to know whether it is rational for one to believe p. Similarly, whether it is rational for one to do an action A is normally sensitive to how A relates to one's total evidence. Thus, if one's evidence can be non-transparent, one may be in no position to know how A does relate to one's total evidence, and so in no position to know whether it is rational for one to do A. Even the cleverest agents can be in such circumstances, whether they know it or not. Such possibilities matter for how we understand the normative claims of rationality.
But can evidence be non-transparent? Anti-Fregeanism about
Frege puzzles suggests that it can. For the time being, we may assume that evidence consists of propositions, since it can be incompatible with hypotheses and stand in other such propositional relations (Williamson 2000: 194–200). In particular, we may assume that it can include such propositions as that furze has yellow flowers. Recall Penny from section 4.3. Under the guise of the sentence 'Furze has yellow flowers', but not under the guise of the sentence 'Gorse has yellow flowers', she knows that furze has yellow flowers. We may assume that her evidence includes that furze has yellow flowers; after all, she observed that furze has yellow flowers when she was introduced to the word 'furze'.
If you ask her 'Does your evidence include that furze has yellow flowers?', on reflection she will sincerely answer 'Yes'. If you ask her 'Does your evidence include that gorse has yellow flowers?', on reflection she will sincerely answer either 'No' or 'I don't know'
or 'Perhaps', in part depending on whether she is a Fregean or an anti-Fregean. But, if anti-Fregeanism is indeed correct, for her evidence to include that furze has yellow flowers just is for her evidence to include that gorse has yellow flowers. Thus, her evidence includes that gorse has yellow flowers. Consequently, her failure on reflection to answer 'Yes' to the question 'Does your evidence include that gorse has yellow flowers?' looks like a case of non-transparency. After all, by normal linguistic standards, she understands the question.
We must go carefully here. Consider (17) and (18):
(17)
Penny knows that her evidence includes that furze has yellow flowers.
(18)
Penny knows that her evidence includes that gorse has yellow flowers.
In the scenario, (17) may well be true. One can know something by knowing it under one linguistic guise without knowing it under all its linguistic guises. Penny has the knowledge attributed in (17)
under the guise of sentence (19), even though she does not have it under the guise of sentence (20), and that seems enough for the truth of (17):
(19)
My evidence includes that furze has yellow flowers.
(20)
My evidence includes that gorse has yellow flowers.
But, given anti-Fregeanism, (17) and (18) have the same truth-value. Thus (18) is true too. Since Penny knows that her evidence includes that gorse has yellow flowers, where is the alleged non-transparency?
Unfortunately, (18) does not resolve the problem of non-transparency. For Penny also has a psychologically real attitude of doubt towards the same proposition, where doubt is understood as an active attitude, not simply as absence of knowledge. Consider
(21) and (22):
(21)
Penny doubts that her evidence includes that furze has yellow flowers.
(22)
Penny doubts that her evidence includes that gorse has yellow flowers.
In the scenario, (22) seems true, because she doubts the proposition under the guise of sentence (20), even though she does not doubt it under the guise of sentence (21). If the knowledge attributed in
(17) under the guise of (19) is enough for the truth of (17), why should the doubt attributed in (22) under the guise of (20) not be enough for the truth of (22)? After all, the doubt in (22) is just as psychologically present as the knowledge in (17). But, given anti-Fregeanism, (21) and (22) have the same truth-value, so (21) is also true. Yet Penny knows the very truth she doubts, because she knows it under the guise of (19), even though she does not know it under the guise of (20).15 In such a case, once we eliminate the relativization to guises, the non-transparency takes the form of the presence of doubt, rather than the absence of knowledge.
In some variants of the scenario, Penny believes that furze and gorse are distinct kinds. In that case, presumably, she will on reflection sincerely answer 'No' to the question 'Does your evidence include that gorse has yellow flowers?'. Consider (23) and (24):
(23)
Penny believes that her evidence does not include that furze has yellow flowers.
(24) Salmón 1986: 111 gives a similar treatment of withholding belief. In this scenario, (24) seems true because Penny believes the proposition under the guise of the negation of sentence (20), even though she does not believe it under the guise of the negation of sentence (19).
Given anti-Fregeanism, (23) and (24) have the same truth-value, so
(23) is also true. Thus, Penny believes contradictory propositions about her evidence. She believes that it includes that furze has yellow flowers (under the guise of (19), because she knows it under that guise and knowledge entails belief), but she also believes that it does not include that furze has yellow flowers (under the guise of the negation of (20)). The non-transparency takes the form of mutually contradictory beliefs as to what her evidence includes.
Even where there is no Frege case, the epistemic threat of a Frege case may result in non-transparency which may take the form of ignorance. For example, suppose that Dominic suspects that K2
(under that name) and Kangchenjunga (under that name) are the very same mountain. For all he knows, 'K2' and 'Kangchenjunga'
co-refer. He knows that K2 is 8,611 metres high. He is not sure how high Kangchenjunga is, though of course he suspects that it is 8,611 metres high. In fact, they are different mountains, and
Kangchenjunga is slightly lower than K2. Thus, we may assume, his total evidence includes that K2 is 8,611 metres high but does not include that Kangchenjunga is 8,611 metres high. Consider (25):
(25)
Dominic knows that his evidence does not include that
Kangchenjunga is 8,611 metres high.
In this scenario, given anti-Fregeanism, (25) is false. Everything
Dominic knows is compatible with a scenario in which 'K2'
and 'Kangchenjunga' co-refer and his evidence includes that
Kangchenjunga is 8,611 metres high, because it includes that K2
is 8,611 metres high. Although he entertains the proposition that
Kangchenjunga is 8,611 metres high, and his evidence does not include it, he is in no position to know that his evidence does not include it. Dominic is ignorant of the limits of his evidence. Incidentally, not even the supposition that Fregeanism is true rules out this example of non-transparency, for it does not entail that Dominic knows that Fregeanism is true; thus, everything he knows may be compatible with a scenario in which anti-Fregeanism is true, 'K2' and 'Kangchenjunga' are intersubstitutable in propositional attitude ascriptions, and his evidence includes that Kangchenjunga is 8,611 metres high, because it includes that K2 is 8,611 metres high. By itself, the truth of Fregeanism would not put Dominic in a position to know the limits of his evidence.
Despite all these problems, some anti-Fregeans may suspect that there is something right about the transparency of evidence. The preceding discussion makes one fallback salient: to postulate transparency of evidence at the level of guises, instead of at the level of propositions. On this view, although it is not transparent to Penny whether her evidence includes the proposition that gorse has yellow flowers, and not even transparent to her whether it includes that proposition under the guise of the sentence 'Furze has yellow flowers' (since she doubts that 'Furze has yellow flowers' is a guise of the proposition that gorse has yellow flowers), it is transparent to her that her evidence includes whatever proposition is expressed by the sentence 'Furze has yellow flowers'. More generally, the strategy would be to finesse the problem of non-transparency by doing as much of the epistemological work as possible with the guises themselves.
Kripke's example of Paderewski the pianist and Paderewski the statesman raises immediate questions for the metalinguistic strategy. Non-transparency can arise even at the level of names and sentences. Similarly, as David Kaplan (1989) points out, it may be unclear whether two occurrences of 'that' as a perceptual demonstrative refer to the same object. Thus, individuating guises by expression types in a natural language is insufficient.
Proponents of the strategy are likely to respond by going ever more psychological, perhaps treating the word types as mere proxies for underlying 'mental files'.16 For example, Peter has one mental file associated with the phrase 'Paderewski the pianist' and another associated with the phrase 'Paderewski the statesman'; each time we use 'that' non-anaphorically as a perceptual demonstrative, we open a new associated temporary mental file, and so on. Such mental files are reminiscent of the individualistic Fregean senses discussed in section 4.4, and raise related questions.
There may indeed be the postulated mental files, but they are not well-suited to rehabilitating the transparency of evidence, because they face their own Frege puzzles.17 After all, a paper file can have one label on the front and another on the back. I do not know whether I associate the English word 'dog' and the French word 'chien' with the same mental file or with two different but cross-referenced mental files, possibly with different contents. Nor is it clear to me how much my postulated mental file(s) contain.
Similarly, Pat in section 4.4 may not know whether her words 'furze'
and 'gorse' are associated with the same mental file or two different ones. The mere difference of words enables her to ask herself the non-trivial question 'Is furze really gorse?', irrespective of how the words are hooked up to mental files. Issues about the underlying organization of our mental filing system call for investigation by cognitive psycholinguistics; they are not settled by introspection. The problem is not with the specific metaphor of mental files, but with the more general strategy of postulating unconscious cognitive architecture in order to solve the problem of the non-transparency of evidence. Such architecture cannot do the job it was called in to do.
A further problem for the attempt to do epistemology with propositional guises rather than propositional contents is that many epistemological relations are best understood at the level of content.
For example, suppose that you are trying to determine whether a
16 See, for example, Recanati 2012; the application of the idea to Frege puzzles goes back to Strawson 1971, 1974, and is made in the Fregean theory of Forbes 1990.
17 For more detailed discussion, see Goodsell 2013 and Yli-Vakkuri and Hawthorne
2018: 149-66. tree is dead by looking at it. The hypothesis to be assessed has a primarily linguistic guise: 'This tree is dead'. The evidence by which it is to be assessed has a quite different, primarily visual format. Yet the latter may bear strongly on the former. At a first pass, we can put it in terms of a space of possible worlds: let S be the region where what you can see to be the case holds, and D be the region where the tree is dead; then most of S may be inside D (the hypothesis is very probable on your evidence), or most of S may be outside D (the hypothesis is very improbable on your evidence), or neither (the hypothesis is neither very probable nor very improbable on your evidence). That is a relation between the content (truth-conditions)
of the evidence and the content (truth-conditions) of the conclusion. By contrast, if we compare the visual guise of the evidence with the linguistic guise of the hypothesis, they are quite disparate; the evidential relations cannot be properly understood at that level.
We need the common currency of content.
All this suggests that there is no level at which evidence or some proxy for it is transparent. Elsewhere, I have argued for the same conclusion on more purely epistemological grounds (Williamson
2000); here, my interest is in showing that it can also be reached by consideration of Frege puzzles.
Still, for modelling purposes, we can mitigate the problem in ad hoc ways (see Williamson 2017a for a general discussion of model-building in philosophy). For instance, to see how things look from the perspective of Penny or Pat, we can treat 'furze' and 'gorse' as if they were semantically independent, by allowing metaphysically impossible pseudo-worlds at which they are not coextensive, but which otherwise behave normally. Such worlds may later be epistemically ruled out for the agent by subsequently acquired evidence. That is not a semantic insight, for the words are in fact synonymous, but it does help us understand how Penny and Pat are thinking. Similarly, to see how things look from the perspective of Kripke's Peter, we can work as if there were referentially distinct names 'Paderewski1' and 'Paderewski2', by allowing metaphysically impossible pseudo-worlds at which they do not co-refer, but which otherwise behave normally. Such worlds may later be epistemically ruled out for Peter by evidence he subsequently acquires. That is not a semantic insight, for the names would in fact be synonymous (on a direct reference account, since they are actually co-referential), but it does help us understand how Peter is thinking and predict how he will act. The models enable us to apply the formal apparatus of content-based evidential relations to such cases, in a way which takes account of agents' distorted perspectives on their own contents. These artificial modelling devices require nothing as elaborate as a fully developed framework of propositional guises, nor do they rehabilitate a genuine distinction between metaphysical and epistemic modality.
Sometimes, of course, as theorists we want to step back from such models and talk about their limitations. In that case, we need to drop the semantic fictions and separate the real contents from their various guises. We need to be able to track how the agent may have conflicting attitudes to the same content under different guises. But our ability to do so does not mean that guises are transparent after all. Quite generally, in describing specific ways in which a given model over-simplifies messy reality, we have to be opportunistic, using ad hoc means to capture specific differences. For example, in
Penny's case, the ordinary English words 'furze' and 'gorse' suffice as guises, whereas in Peter's we need to manufacture new names,
'Paderewski1' and 'Paderewski2'. For agents uncertain or confused about the individuation of their own mental files, still further layers of differentiation may be needed, and so on.
If we had a one-size-fits-all framework for perspicuously characterizing all the complexities the model ignores, there would be much less need of the model in the first place. In reality, a one-size-fits-all framework would not enable us to characterize anything perspicuously, because it would be cluttered with far too many parameters. Building perspicuous models requires ruthlessly paring away any such clutter. Once we recognize that transparency is an unattainable ideal, we cannot even use it as a constraint to narrow down what guises must be for that constraint to be satisfied, although under given conditions some things may do better than others in the role of guises, by permitting a closer approximation in relevant cases to the ideal of transparency. Unsurprisingly, on this view, real-life cognition is non-transparent all the way down.
4.10 Probability
Frege puzzles arise for subjective and epistemic probability too.
Subjective probabilities (credences) are meant to be degrees of (rational) belief. For Fregeans, just as one can believe that Hesperus is Hesperus without believing that Hesperus is Phosphorus, that Hesperus is Hesperus can be subjectively more probable for one than that Hesperus is Phosphorus; that furze has yellow flowers is subjectively more probable for Penny than that gorse has yellow flowers. The same applies to epistemic probabilities, such as probabilities on one's evidence; they are in effect graded forms of epistemic modality. For Fregeans, one's evidence can entail that Hesperus is Hesperus without entailing that Hesperus is
Phosphorus; that Hesperus is Hesperus can be more probable on one's evidence than that Hesperus is Phosphorus; that furze has yellow flowers is more probable on Penny's evidence than that gorse has yellow flowers.
For reasons analogous to those Kripke explains in 'A Puzzle about Belief ', such Fregean claims are deeply problematic. Indeed, the traditional use of someone's betting behaviour to measure their credences is a paradigm of a language-sensitive heuristic for attitude ascription. Whether one accepts a bet depends on how it is specified to one. Penny may be willing to bet on 'Furze has yellow flowers' but unwilling to bet on 'Gorse has yellow flowers' at the same odds. In this respect, the betting criterion is like the heuristics BDP, DP, and SDP for belief ascription. As is now widely agreed, betting behaviour is not definitional of credences, it is at best a fallible heuristic guide to them. For instance, someone may belong to a religious sect which considers all betting sinful; she would start accepting bets only if she left the sect, in which case her credences would be different, so her (absence of) betting behaviour does not measure her current credences. She is actually certain that betting is sinful, but if she were willing to accept bets, she would bet that betting is not sinful.
Anna Mahtani has recently highlighted ways in which Frege puzzles make trouble for current practice in welfare economics
(2017, 2023). Standardly, a person's prospect under a policy is defined as their expected welfare under that policy. In welfare economics, such expectations are normally calculated in terms of notional subjective or epistemic probabilities. One policy is ex ante Pareto inferior to another if and only if no one has a better prospect under the first policy than under the second and someone has a better prospect under the second policy than under the first. A reasonable principle seems to be that one should not adopt a policy if it is ex ante Pareto inferior to an alternative policy, which is to say that one should adopt only Pareto optimal policies. But, on a Fregean view, the prospect for a particular person under a policy can depend on how that person is presented, as Mahtani shows in realistic cases, because the subjective or epistemic probabilities used to define the prospect so depend. That seems to make the standard definition of the 'prospect' for the person under the policy break down, since it specifies nothing about modes of presentation. That in turn undermines the definitions of standard welfare-economic ideas such as ex ante
Pareto optimality. If prospects are ill-defined, so is ex ante Pareto optimality. Mahtani proposes complex ways of defining something reminiscent of ex ante Pareto optimality within the Fregean framework, by generalizing across a range of admissible assignment functions from people to modes of presentation. The problem raised by Mahtani is not solved by the modelling devices sketched at the end of the previous section. They merely enable one to simulate Fregean effects artificially, from an anti-Fregean starting point: but Fregean effects are the source of
Mahtani's problem. On a resolutely anti-Fregean approach, subjective or epistemic probabilities are assigned to coarse-grained propositions, such as the proposition that x has π, where x is a person and π a property, with no mediating modes of presentation, so the original definition of expected welfare would stand, and
Mahtani's objection would not arise.
The trouble for the resolutely anti-Fregean approach is that it is unclear how to determine the subjective or epistemic probability of a coarse-grained proposition, given the cognitive impact of modes of presentation. Indeed, the problem is even sharper for probability than for ordinary propositional attitudes. In the case of belief, we may consistently suppose that one believes a proposition p if and only if one believes p under at least one guise; such a guideline was tacitly followed in the discussion of Frege cases above. But if we try ruling that one's subjective probability for p is v if and only if it is v under at least one guise, the result is inconsistency, since in Frege cases the rule will assign conflicting values to the agent's subjective probability for p.18 The mathematical structure of probability as a function from propositions to numbers forbids such a rule.
The same problem arises for epistemic probability too. This does not mean that resolute anti-Fregeans cannot postulate subjective or epistemic probabilities at all, just that their relation to linguistic behaviour and verbalized thought will be even more indirect than for ungraded attitudes.
However, even for Fregeans, the relation of numerical credences to linguistic behaviour and verbalized thought is already quite indirect. Without (rational) betting behaviour, it is very unclear
18 For a proposed non-Fregean treatment of this problem, see Braun 2016; for a
Fregean approach, see Chalmers 2011. how to determine specific numbers. The task is no easier for epistemic probabilities. They cannot simply be read off the linguistic behaviour and verbalized thought. Similar difficulties face anti-Fregeans if they try to assign specific numerical credences to coarse-grained propositions relative to guises.
Further challenges arise for diachronic or inter-personal applications of subjective or epistemic probabilities. Imagine a shipwrecked sailor trying to keep track of time on a desert island.
When he updates his probabilities overnight, his new probability for
'Today is my birthday' should be his old probability for 'Tomorrow will be my birthday', not his old probability for 'Today my birthday'.
Similarly, imagine a young boy deferring to his mother's opinions.
His probability for 'Today is my birthday' should be her probability for 'Today is your birthday', not her probability for 'Today is my birthday'. In such cases, letting the probabilities follow sentential guises, or Fregean senses that behave in a similar way, gives exactly the wrong results. The probabilities need to follow something more like objective states of affairs or events. To model properly what is going on, we need both yesterday's probabilities and today's, or both the mother's probabilities and her son's, to be defined over the same space of events. Individuating those events in terms of sentential guises or their Fregean analogues would send us in quite the wrong direction.
Invoking numerical subjective or epistemic probabilities at all is a matter of model-building, not of observation, though it still might be justified by an appropriate level of explanatory success. That is not to say that subjective or epistemic probabilities have no basis in reality, just to acknowledge that for theoretical purposes they vastly simplify and tidy up a complicated, messy reality in order to give us some understanding of it. On that view, the simplification built into assigning subjective or epistemic probabilities to objective events may often be the best modelling choice, because it is so unclear how to do better in diachronic and inter-personal cases. The objective approach promises to be a better match with the semantics of natural language, and its capacity to make sense of theoretically powerful welfare-economic ideas such as ex ante Pareto optimality as they stand can be used as another argument in its favour. Greatly complicating a good model for a small gain in descriptive detail is often a poor bargain.
Probability theory itself is a case in point. The insights it provides depend crucially on its perspicuous and tractable mathematical structure. When one tries to model extremely bounded rationality in terms of subjective or epistemic probability, it becomes very tempting to weaken the standard Kolmogorov axioms. The result tends to be only slightly closer to psychological reality, but much less mathematically tractable. The point is worth exploring in more detail.
A standard probability space is in effect a space of possible worlds, though the terminology is different. The probability space has an underlying set Ω, whose members are outcomes, conceived as mutually exclusive and jointly exhaustive; subsets of Ω, sets of outcomes, are events. Thus, outcomes correspond to worlds, events to intensional propositions, and Ω to W, the set of all possible worlds. Probabilities are real numbers assigned to some or all events, in conformity with the usual Kolmogorov axioms. For example, if an event X is a subset of an event Y, then the probability of Y is at least as high as the probability of X. This looks like a strong form of logical omniscience for probability (including subjective probability). At the level of propositions as sets of worlds, no proposition is more probable than a proposition it entails, and mutually entailing propositions are equiprobable (indeed, identical). The probability assignment can be extended to sentences by mapping them to events (propositions), and assigning to each sentence the probability of the event to which it is mapped. A natural mapping of sentences to events treats logically complex sentences in the obvious ways: a conjunction is mapped to the intersection of the events to which its conjuncts are mapped; a disjunction is mapped to the union of the events to which its disjuncts are mapped; the negation of a sentence is mapped to the complement in Ω of the event to which the unnegated sentence is mapped. Thus, a form of logical omniscience for probability also holds at the level of sentences: the conclusion of any valid argument in classical truth-functional logic is at least as probable as the conjunction of the premises.
The credences of a boundedly rational agent may violate those constraints: most obviously for computational reasons, but also because the agent may be ideologically committed to a non-classical logic. One can model such failures of logical omniscience at the level of sentences by not constraining the mapping from sentences to events in the natural ways. For example, a conjunction may be mapped to an event other than the intersection of the events to which its conjuncts are mapped; a disjunction may be mapped to an event other than the union of the events to which its disjuncts are mapped; the negation of a sentence may be mapped to an event other than the complement in Ω of the event to which the unnegated sentence is mapped. Thus, at the level of sentences, the conclusion of a valid argument in classical truth-functional logic may be less probable than the conjunction of the premises.
From the perspective of this book, ditching the structural constraints on mappings from sentences to events looks like an obvious case of overfitting. Just as in impossible worlds semantics, each complex sentence introduces another degree of freedom.
The explanatory power of the probabilistic framework is thrown away, because no general non-trivial probabilistic calculations can be done at the sentential level. Of course, one may be able to do such calculations for a particular model, but that is just articulating what one has put into the model by hand. In the by now familiar way, removing or weakening the structural constraints removes or weakens one's ability to learn from probabilistic models.
Although these general reflections on weakening standard probability theory do not by themselves solve problems such as Mahtani's, they do suggest a relevant methodological moral, consonant with the broader themes of this book: beware of tailoring your theoretical framework to fit the limitations of individual agents.
In the case of welfare economics, that moral may have already been flouted by the definition of the key theoretical term 'prospect'
in terms of credences, used to calculate the agent's 'expected welfare' under the given policy. This in turn led to the difficulty that prospects must be attached to individuals, irrespective of guise, to play their role in a well-motivated criterion of ex ante Pareto optimality, whereas subjectively expected welfare varies over different guises for the same individual.
An alternative is to understand 'expected welfare' and 'prospect'
in terms of more objective probabilities. Such probabilities may simulate a better-informed perspective—possibly unoccupied—
for which no relevant Frege puzzles occur, though not so well informed as to exclude the possibility that any given policy under consideration will be implemented, otherwise expectations conditional on its implementation would be ill-defined.
One might worry that objectifying prospects only postpones the problem, without solving it, for when someone comes to apply the objective Pareto criterion, Frege puzzles can still affect their beliefs about the quasi-objective prospects of individuals under policies.
Fortunately, that worry is mistaken. In effect, the subjective Pareto criterion risks unintelligibility because it involved quantification into a relevantly guise-sensitive epistemic context: a quantifier over individuals (unrelativized to guises) binds the variable 'i' in the context 'the expected welfare of i under the policy', which is sensitive to the guise of i. By contrast, the quasi-objective Pareto criterion runs no such risk of unintelligibility, since it does not involve quantification into a relevantly guise-sensitive context: on the quasi-objective reading, 'the expected welfare of i under the policy' is not sensitive to the guise of i. Of course, the policymaker may still be uncertain or mistaken about whether one policy is ex ante Pareto inferior to another, given their ignorance about the individuals in the relevant population, but that is just ordinary uncertainty or error, to be treated in the ordinary way (whatever that is): it is not a problem specific to the Pareto criterion.
Extreme subjectivists may still complain that the quasi-objective
Pareto criterion is not 'operational' because it can be unclear which policy, if any, meets it. But that complaint rests on a fanciful standard of epistemic transparency which no reasonable criterion for decision-making could meet (Williamson 2000). Even our own subjective dispositions are often unclear to us, as well as to others. In making a difficult decision, the advice 'Maximize subjective expected utility' is in practice no more useful than 'Do the best thing': it is just as unclear to the agent which choices would maximize their subjective expected utility as it is which would be doing the best thing. In particular, it is often unclear which policy, if any, meets the original subjective Pareto criterion or any given variation on it. Which option an agent chooses can depend on context, mood, or whim. Full operationality is a will-o'-the-wisp.
At first sight, the trouble Frege cases make for welfare economics is surprising. If general decision theory can take Frege puzzles in its stride, why should they be so disruptive for more specific applied inquiries in economics and politics? On second thoughts, however, it is less strange. In economic and political inquiry, theorists must engage with the structure of the world external to any one agent's perspective on it—in particular, with the presence of all the actual individuals in a given society, irrespective of the guises under which they may appear to themselves or to any other agent. A case in point is the quantification over all those individuals in the Pareto principle. As a natural by-product, structural mismatches can occur between the real world and the agent's representation of it—for instance, when the same individual appears to the agent under many different guises (representations). By contrast, when general decision theory is done in the usual subjectivist fashion, it ignores the actual structure of the world, dealing only with the structure of the given agent's representations of it (to which subjective credences and utilities are attached), so no mismatch can arise. On such a subjectivist approach, rationality is understood as a purely formal matter of internal coherence. Troubles with Frege cases manifest one limitation of such an approach.
More generally, if decision theory is to cast light on behaviour, not just on internal representations of behaviour, the actions between which the agent is supposed to be deciding must involve behaviour, at the very least bodily movements, not just internal representations of such movements. Typically, the agent's options involve the environment beyond their body, such as buying one or other item on sale. Since decision theory studies the interplay of a rational agent's probabilities, preferences, and actions, the events for which those probabilities are defined must also involve the external world: for example, probabilities conditional on a given action. In practice, and with good reason, even subjective Bayesians usually describe the contents of agents' credences in external terms: 'a credence of 75% that it will rain this afternoon'.
Agents who mindread each other have even more need to ascribe intentional attitudes to contents in a shared space of possibilities, as we have repeatedly seen in various ways. If I want to ascribe credences to you in trying to predict your actions, I will not make much progress by constructing a new possibility space for you incommensurable with my own possibility space and then ascribing to you credences and preferences defined on events in the new space, since I have to map those events to events in my own space to understand what you believe and want.19 At most, to interpret you, I may have to expand and refine my own space in order to separate possibilities between which you distinguish (a 'fusion of horizons'). In game theory, such a shared space of possibilities is normally taken for granted, as when the structure of the game is assumed to be common knowledge amongst the players (it is
19 The space also includes one impossible event, the empty set of outcomes. Of course, an agent may assign probability 0 to some possible (that is, non-empty) events. common knowledge that player 2 can make move M). This is all just as one would expect given the shared world heuristic for knowledge ascription (section 4.8).
When a game theorist comes to study the game, the shared world heuristic still operates. The theorist works with a possibility space that incorporates the players' own possibility spaces. If the game is just hypothetical, as often in game theory, the theorist incorporates the players' possibility spaces hypothetically.
None of this means that agents cannot in practice differ from each other, and from reality, in their possibility spaces. Of course they can, and do. But the best case for understanding involves a shared possibility space, deviations from which must be handled in more or less opportunistic ways.
For a rough analogy, imagine a formal dance. Mostly, what the dancers do can be explained in terms of the rules of the dance. But when the line the dancers form is not straight, or a clumsy dancer trips and falls, or the dance is interrupted by a fire alarm, the rules do not explain what has happened. A different sort of explanation is needed, even though a general intention to deviate as little as possible from the rules may still guide the dancers' reactions. Should we conclude that the rules the dancers are really following are more general, and specify what to do in such eventualities? That sounds like a case of being vicariously wise after the event. The rules are just the original ones, and make no pretence of covering such mishaps and interruptions. The latter should be understood as deviations from the simple rules, not as exemplifications of more complicated rules.
Similarly, with Mahtani's puzzle case in welfare economics, we do best to understand expected welfare and Pareto optimality in terms of probability assignments to coarse-grained propositions, and leave Frege puzzles to be dealt with ad hoc when they arise, as epistemic problems for applying the criterion. In particular, we should not think of guise-insensitive credences as somehow derivative from guise-sensitive credences. Instead, we should regard guise-sensitive credences as ad hoc variations on guise-insensitive credences. After all, as already seen (sections 4.4–5), Frege puzzles can arise even when the underlying content is the same, so guise-sensitivity introduces an extra dimension.
Confusingly, we can often be more precise about guise-sensitive credences than about guise-insensitive ones. For example, we may determine on the basis of betting behaviour that someone has an
80% credence in a proposition p under the guise of the sentence
'George Eliot wrote Middlemarch' and only a 5% credence in p under the guise of the sentence 'Mary Ann Evans wrote Middlemarch', while being merely confused as to their guise-independent credence in p. But such cognitive asymmetries make a poor guide to explanatory priority. Another analogy: it may be very clear that an action was unfair according to Janet and fair according to John, yet very unclear whether the action was fair; nevertheless, such examples do not show that what is fair or unfair is somehow derivative from what people think is fair or unfair. Instead, the distinction between being thought fair and being thought unfair is derivative from the distinction between being fair and being unfair.
Similarly, guise-relative distinctions may be derivative from guise-independent distinctions.
Even for credences, the asymmetry can run in the opposite direction to that with 'George Eliot' and 'Mary Ann Evans': it may be very clear that a bird knows and has high credence roughly that its nest is in that tree, yet very unclear under what guise it has the knowledge.
Such cognitive asymmetries are natural by-products of our reliance on heuristics in ascribing intentional states. For example, the use of betting behaviour to measure credence is a language-dependent heuristic, mediated by the bettor's understanding of the sentences the bookie uses to state the terms of the bet, so its results are naturally sensitive to those sentential guises. By contrast, when we judge that the bird knows and has high credence that its nest is in that tree, we do so to explain the bird's non-linguistic behaviour. Our heuristic or method is not mediated by the bird's understanding of a sentence, and no alternative guise is salient. We may guess that the bird has the knowledge and credence under some visual guise or other, but our guess is vague and unspecific. What is a guise for the content of a non-linguistic creature's background intentional state? Whatever the guise, an ascriber's awareness or unawareness of the state will be sensitive to the heuristic used (if any) in ascribing the state, not just to the nature of the specific knowledge or credence itself.
4.11 Epistemic and doxastic logic
The challenges raised by guise-sensitivity for epistemic and subjective probability have simpler analogues for epistemic and doxastic logic, as applications of possible worlds semantics, in a tradition going back to Hintikka (1962). Both traditions use models based on the mathematical framework of state spaces (section 4.10). Both do so in ways that naturally validate strong forms of logical omniscience. That is the main source of their computational and explanatory power, but also of their apparent lack of psychological reality.
Yet both traditions have played a significant role as frameworks for formal inquiry in social sciences. For example, subjective Bayesian probabilistic approaches to welfare economics and decision theory are widespread, while epistemic logic provides the natural framework for articulating standard game-theoretic assumptions of agents' common knowledge of their rationality and the structure of the game.
For both epistemic logic and epistemic probability, quantification into epistemic contexts is a crucial test case. We have already seen its key role for epistemic probability in welfare economics. For epistemic logic, it is needed to formalize statements such as 'I don't know what anyone else prefers', when the speaker quantifies over the members of a large anonymous crowd. More generally, in the standard framework of epistemic logic, common knowledge is implicitly treated as guise-independent.
When a state of affairs is assumed to be common knowledge for a group of agents, typically no account is taken of differences between them in their guises for that state. Taking account of such diversity would undermine the usual game-theoretic arguments that rely on those assumptions; likewise for applications of doxastic logic to common belief. If one is serious about guises, one will not treat them as uniform across agents.
To see the problem from another angle, recall that if a proposition p entails a proposition q in a model of epistemic or doxastic logic, in the sense that every world in p is also in q, then any agent who knows p also knows q, and any agent who believes p also believes q.20 Call two worlds w1 and w2 indiscriminable for an agent S just
20 In the paragraph, knowledge, belief, and indiscriminability are all ascribed with respect to a fixed world in a fixed model. In standard models for epistemic logic, an agent knows a proposition p at a world w if and only if every world epistemically accessible for the agent from w is in p. Consequently, if a set of propositions X entails a proposition p
(every world in the intersection of the members of X is in p), an agent who knows each member of X at w automatically also knows p at w: a strong form of logical omniscience, multi-premise closure (the argument in the text uses only the special case where X is a singleton set, single-premise closure). Neither multi-premise closure nor single-premise closure follows from the treatment of propositions as sets of worlds alone; they depend on the specific way in which knowledge is characterized in terms of accessibility. The model's constituents include a binary relation between worlds for each agent, informally understood as epistemic accessibility, in the sense that a world x is epistemically accessible from the world w just in case whatever the agent knows at w is true at x (for all the agent knows at w, they are at x). Although epistemic accessibility is informally understood in terms of knowledge, formally it is the other way round, with knowledge defined in terms of epistemic accessibility: think of the epistemic accessibility relations as encoding epistemology in the model, and the formal definition of knowledge as decoding it. Standard models for doxastic logic work analogously, with doxastic accessibility relations informally understood in terms of the agent's belief instead of knowledge. The main formal difference is that epistemic accessibility is required to be reflexive
(every world has epistemic access to itself), corresponding to the factiveness of knowledge: an agent knows p at w only if w is in p (p is true at w). By contrast, doxastic accessibility is not required to be reflexive, since some beliefs are false, though it may be required to be serial (every world has doxastic access to some world), corresponding to the postulated consistency of (rational) belief: an agent who believes p at w does not also believe ¬p at w. Of course, guises make trouble for the consistency condition for rational belief: a logically impeccable agent may accept both 'Hesperus is inhabited' and
'Phosphorus is uninhabited'. By contrast, guises make no trouble for the factiveness condition for knowledge, which also entails the consistency condition for knowledge. in case for every proposition p for which S has a guise, w1 is in p if and only if w2 is in p (S has no way of distinguishing between w1 and w2). Suppose that two worlds w1 and w2 are indeed indiscriminable for a given agent S, and that under some guise S knows some q that excludes w1 (w1 is not in q). Since w1 and w2 are indiscriminable for
S, and S has a guise for q, w2 is also not in q. But S has no guise for the proposition q ∪ {w1}, since it contains w1 but not w2. However, since q entails q ∪ {w1}, and S knows q, S also knows q ∪ {w1}, by standard epistemic logic. Thus, S knows something for which S has no guise. Similarly, using standard doxastic logic, one can set up cases where S believes something for which S has no guise. In both the epistemic and the doxastic case, the required assumptions are realistic. But cases of guiseless knowledge or belief undermine the theoretical role guises were introduced to play.
Could we ban such cases by stipulating that the worlds in the model must be individuated only as finely as the relevant agent S
can discriminate? The trouble is that, for purposes of game theory and other applications of epistemic and doxastic logic to the social sciences, we need multi-agent models. Often, in such models, some agent other than S will discriminate between w1 and w2, so the model must separate them. To model common knowledge or common belief, we need a common space of possibilities.
In principle, we can expand the model by building in guises for each agent, and specifically excluding guiseless knowledge and belief. In practice, however, doing so may be a bad bargain, buying a little more faithfulness to the phenomena at the price of enormous complication, perhaps to the point of mathematical intractability, or more likely forcing theorists to put into the model by hand whatever they hope to get out of it: yet another case of overfitting.
For many purposes, assuming logical omniscience and ignoring guises is a legitimate modelling choice. It can be compared to the use of differential equations to model population-sized processes over time, such as the recurrent rise and fall of interacting predator and prey populations, or the spread of a pandemic. Differential equations presuppose differentiable functions, which are continuous, 'smooth'. But the biological processes under study involve populations of many discrete animals and so are not really continuous in the way presupposed: answers to the question 'how many?'
are natural numbers, not arbitrary real numbers. Of course, one can try to model the process at the level of individual animals, but that involves throwing away the mathematical power of the differential equations and using different methods and different assumptions instead: even if feasible, that may not provide the same global overview or the same insights.
Similarly, throwing away the mathematical power of epistemic and doxastic logic involves using different methods and different assumptions instead: again, even if feasible, it may not provide the same global overview or the same insights. Obviously, if one's aim is to study ways in which real-life agents violate the strong simplifications of epistemic logic, one cannot make those very assumptions: doing so would stipulate away one's subject matter.
But if one's aim is instead to study different cognitive effects, such as perceptual limitations, then stipulating away other cognitive limitations may be a good strategy for isolating the effects under study by filtering out interference and noise.
4.12 Drawing the threads together
To see better how the pieces in this chapter fit together, we can work through an example of action explanation, building up a series of increasingly complex explanations by bringing in more pieces as we go on.
We start from the external world. H is a human, D a dog.
Unusually, H has been keeping out of the garden. Someone asks: 'Why is H keeping out of the garden?' Here is an initial answer: First Pass
D has rabies.
D is in the garden.
In many circumstances, First Pass would be a quite adequate explanation, by normal conversational standards. Obviously, its two conjuncts 'D has rabies' and 'D is in the garden' jointly fall well short of deductively entailing the explanandum 'H is keeping out of the garden', but explanations in both natural science and ordinary life are not normally required to entail the explanandum deductively. Normally, a looser connection will suffice: for example, one that holds 'for the most part', or 'other things being equal', or 'by default'. In the present case, the two conjuncts of First Pass together provide a good reason for keeping out of the garden.
Of course, the questioner may grant the two conjuncts but not know whether, if so, H would be aware of those facts. Then a more informative explanation is needed, such as:
Second Pass
H knows that D has rabies.
H knows that D is in the garden.
In effect, First Pass relied on the open world heuristic. When that default is inhibited, we fall back on the more complex Second Pass.
In such cases, people sometimes say that the knowledge ascription is 'understood'—for example, that First Pass is 'elliptical' for Second
Pass. But such ad hoc metalinguistic manoeuvres are unwarranted.
In First Pass, 'D has rabies' means what it says; 'H knows that' is not an unvoiced constituent. It is just that, unless the open world heuristic is inhibited, it allows us to move from First Pass to Second
Pass, if we so wish.
A less informative alternative to Second Pass has 'thinks' or
'believes' in place of 'knows', for one occurrence or both. But when the open world heuristic is uninhibited, there is no need to throw away the extra information in Second Pass. We can leave the retreat from knowing to thinking for when needed, if H's alleged knowledge is cast into serious doubt. In any case, whether the attitude verb in Second Pass is 'know', 'think', or 'believe', the content to which the agent is said to have the attitude still links back to First
Pass, and so to the external world, on pain of losing touch with the external action to be explained: keeping out of the garden.
Philosophers may notice that not even Second Pass excludes the possibility that it is a Frege case. 'D' is just our term for the dog; for all Second Pass says, H is in no position to use 'D' in expressing the knowledge attributed to them. For example, H might know that D has rabies only under the guise of the sentence 'That dog has rabies', where 'that dog' is a memory demonstrative—last week someone pointed out D to H as a rabid dog—while H knows that
D is in the garden only under the guise of the sentence 'This dog is in the garden', where 'this dog' is a current perceptual demonstrative. The terms 'this dog' and 'that dog' here are anaphorically unrelated; H might fail to notice that it is the same dog again, and so fail to put the two pieces of knowledge together in the way required. When the open world heuristic is uninhibited, it allows the co-reference to be taken for granted, but of course something may inhibit it. In that case, if H does recognize the dog in the garden as
'that dog with rabies', then a still more informative explanation is needed, such as:
Third Pass
H knows that D has rabies under the guise 'This dog has rabies'.
H knows that D is in the garden under the guise
'This dog is in the garden'.
Here both occurrences of 'this dog' are associated with the very same state of H's visual-perceptual attention to D, and Third Pass is not a Frege case.
Just as First Pass is not elliptical for Second Pass, so Second
Pass is not elliptical for Third Pass, or for any other explanation that invokes guises. Just as Second Pass invokes a new level of complexity absent from First Pass—a mental state with content—
so Third Pass invokes a new level of complexity absent from Second
Pass—the guise of the mental state's content. Expanding the theoretical framework with those new levels of complexity may be warranted by the need to explain subtler phenomena, but that does not mean that the extra complexity was there in the framework all along, nor even that it should have been, otherwise we should have to start with an infinitely complicated theoretical apparatus.
Even the two conjuncts of Third Pass jointly fall short of deductively entailing the explanandum, 'H is keeping out of the garden'. For example, H may not know how deadly rabies is, or H
may have a death wish. But even once we have plugged such holes by attributing suitable intentional states, and specifying appropriate guises for their contents as in Third Pass, the result will still fall short of deductively entailing the explanandum. For H, being human, may still fail to put two and two together. Such a failure does not imply a deeply divided mind; a momentary lapse in attention or memory can have the same effect. The stereotype of the absent-minded professor is a reminder that not even a leading expert on rationality is immune to such effects. The finest brain can suffer a quantum-mechanical blip. Expanding the explanation with further conjuncts to rule out such eventualities may not yield much further insight into the action to be explained.
At least in this case, the more complex explanations do not falsify the simpler ones: quite the opposite. The two conjuncts of Second
Pass entail the respective conjuncts of First Pass, the two conjuncts of Third Pass at least come close to entailing the respective conjuncts of Second Pass, and so on for the further elaborations.
What the more complex explanations make salient are ways in which the simpler ones fall short of being strictly sufficient for the explanandum. They tighten the connection, but still without providing strict sufficiency.
Formal frameworks such as epistemic and subjective Bayesian probability theory, epistemic and doxastic logic, decision theory and game theory articulate general principles to tighten the connection further, such as various forms of logical omniscience.
Applied to real agents rather than idealized rational ones, those principles are typically false: simplifying assumptions conducive to illuminating models in the scientific sense.
Heuristics for mindreading make a different sort of bridge between explanans and explanandum. They are more likely than formal models to generate inconsistency, as Kripke's puzzle about belief illustrates. That is a cost they pay for their greater flexibility and (for some of them) their sensitivity to linguistic form. Their function is not to capture universal laws, not even of an idealized type, but to act as practical problem-solvers. In good cases, they still provide local knowledge, though not as a corollary of some global principle.
Both the formal models and natural language semantics work at the level of Second Pass, using state spaces. In a historic act of pattern recognition, they have located an efficient trade-off between generality of understanding and fidelity to particular cases. The compromise is not perfectly stable, for the need to make sense of a particular case continually drags us to Third Pass or even further.
But there is no equally efficient alternative trade-off in that direction, only hybrid fixes of limited though real utility—as the artificiality of the formulations in Third Pass hints. Still less should we expect to find a purely internal explanation at the limit of the endless series of passes, the El Dorado of internalism. They do not even tend in that direction, and each is intelligible only in relation to its predecessor. For mindreading heuristics, and the semantics of natural language, and theoretically sophisticated action explanations, the starting-point is still First Pass, firmly rooted in the shared external world.
5
Intensional Metametaphysics
5.1 Semantic challenges to metaphysics
This final chapter takes the approach developed in previous chapters, applying it to semantic arguments against the possibility of substantive metaphysics. Addressing these arguments will provide an opportunity to test and develop the present approach.1
Of all branches of philosophy, metaphysics has probably attracted the most opprobrium. It is the one most easily represented as a lazy, dogmatic, obsolete rival of natural science. It is also the most discursively abstract branch. Predictably, it is the one most often accused of being nonsense.2
When meaning is understood in epistemic terms, the charge of meaninglessness turns into the charge that metaphysics is epistemically inadequate: it lacks proper methods for achieving knowledge, or even reasonable belief, in its domain. The logical positivists gave a salient version of such a critique, wielding their verification principle as a blunt instrument. Since putative truths of metaphysics are neither analytic nor empirically verifiable, they are meaningless by logical empiricist standards. Of course, such an accusation is largely bluff without an adequate verificationist theory of meaning
1 This chapter is adapted from 'Metametaphysics and semantics', Metaphilosophy,
53 (2022): 162–75 (Williamson 2023a). I am grateful to participants in the 2021 'New
Directions in Metaphilosophy' conference at the University of Kent and a Lugano
Philosophy Colloquium (both virtual), to Daniel Kodsi and Luis Rosa (in correspondence), and to two anonymous referees for Metaphilosophy in addition to those for this volume for helpful comments on earlier versions of this material.
2 I use the term 'metaphysics' as it is standardly used in contemporary philosophy, with a standard view of what counts as metaphysics. The arguments of this chapter are robust to minor variations in that respect.
Overfitting and Heuristics in Philosophy. Timothy Williamson, Oxford University Press.
© Oxford University Press 2024. DOI: 10.1093/oso/9780197779217.003.0005 in the background, and the logical positivists made very little progress towards developing such a theory. Nevertheless, the logical empiricist dichotomy of all cognition into 'empirical' and 'conceptual' aspects continues to have its adherents: for example, the work of Amie Thomasson (2015, 2020) is in the tradition of Rudolf
Carnap (1950), and more distantly of David Hume's dichotomy of
'relations of ideas' and 'matters of fact', though she has more interest than Carnap in non-scientific language. Between the conceptual and the empirical, no room seems left for substantive unconfused metaphysical theorizing.
Unfortunately, or perhaps fortunately, the terms 'conceptual' and
'empirical', like 'analytic' and 'synthetic', are far more problematic than they first appear. There is a crude stereotype of the conceptual, and a crude stereotype of the empirical, but the assumptions built into those stereotypes are unclear. What is clear is that both stereotypes, separately and together, are utterly inadequate for making sense of logic and mathematics, let alone of metaphysics.
For example, dialetheist logicians such as Graham Priest assert, 'The Russell set is and is not a member of itself ', because they take it to be a theorem of the best theory of logic and mathematics, on broadly abductive grounds—simplicity, strength, fit with evidence, and so on. In response, classical logicians like me reject what dialetheists say as just false. We take the best theory of logic and mathematics to be classical, with no contradictions as theorems, again on broadly abductive grounds—simplicity, strength, fit with evidence, and so on. In these respects, it is just like a highly theoretical dispute in natural science. On both sides are competent speakers of English (or whatever natural language the dispute is being conducted in), using words in their current senses in the public language, and meaning what they say. In particular, 'The Russell set is and is not a member of itself ' is a well-formed, meaningful sentence of English; it violates no rule of
English grammar (just as 0 = 1 ∧ 0 ≠ 1 is a well-formed, meaningful sentence of a formal language for Peano arithmetic). Neither side is implicitly or explicitly proposing to change the meaning of
'and' or 'not' or any other word or construction of the language, for each side takes itself to have stated its view correctly without need of linguistic reform. Although each side may use an artificial formal language to develop its approach in more detail and with more rigour, still the underlying disagreement can be and is expressed in the shared natural language. Clearly, the dispute does not fit the stereotype of the empirical: there is no prospect of resolving it by experiment, observation, or measurement.
Equally clearly, the dispute does not fit the stereotype of the conceptual: there is no prospect of resolving it by conceptual clarification either. Logicians are very familiar with the possibility that an apparent disagreement may not be what it seems, because the two sides are using the same symbols with different senses. It is insulting to suggest that, had the two sides been talking past each other, or just disputing about what to mean by the symbols, they would not have worked that out for themselves. The only charitable interpretation of the dispute, as a conversation between two parties, is as a genuine non-metalinguistic disagreement, which is how the participants treat it. More generally, there is no prospect of resolving the dispute between classical and dialetheist logicians by a combination of stereotypically empirical and stereotypically conceptual methods: conceptual clarification and experiment, observation, or measurement.
Of course, those who rely on the dichotomy of the empirical and the conceptual will insist that their understanding of it goes much deeper than the usual stereotypes. However, in my experience, their attempts to clarify the dichotomy always make it vulnerable to counterexamples by their own standards, from which it can be defended only by a retreat to the same old obscurity, perhaps disguised by new terminology. In contemporary philosophy, the contrast between 'empirical' and 'conceptual' serves—in effect, though not in intention—as an instrument of obscurantism and is best avoided. I have discussed these issues at length elsewhere and so will spare the reader the gory details here (Williamson 2007,
2021a, forthcoming-c).
This chapter addresses a different but related challenge to metaphysics. This challenge is more urgent, because its starting point is less hostile. The new challenge is semantic, like the logical empiricist critique, but unlike the latter it does not depend on an epistemic conception of semantics. Instead, one might even say, it depends on a metaphysical conception of semantics. But that does not make the new challenge self-defeating. For if metaphysics is already in tension with a metaphysics-friendly approach to semantics, that is bad news for metaphysics.
Uncompromising metaphysics, both ancient and modern, aspires to discover the necessary nature and structure of reality. Its primary interest is in the world, not in our thought or talk about the world—of course, our thought and talk are part of the world, but
(except under extreme forms of idealism) only a very small part.
Thus, a worldly approach to semantics, on which the semantic value of a linguistic expression in a context is a worldly item, looks like a good fit with metaphysics. For example, such a theory may identify the semantic value of a declarative sentence in a context with a proposition, understood as the set of possible worlds at which the sentence is true, or as a complex of the objects, properties, and relations the sentence is about (in both cases, relative to that context).
In brief, such semantics correlates metaphysicians' words with the very metaphysical entities they wish to discuss (if there are such entities). That suggests a fully cooperative attitude of semantics to metaphysics. Any tension between the two is therefore all the more disturbing—as though semantics, with the best will in the world, still leaves no room for metaphysics.
The challenge to metaphysics arises in an especially stark form within just the kind of intensional framework that is mainstream in contemporary formal semantics as a branch of linguistics, and was defended in chapters 3 and 4, as section 5.2 explains. 5.2 The coarse-grained challenge to metaphysics
We first consider the challenge in the simplest framework of intensional semantics, where the only parameter of semantic evaluation is for worlds. Each sentence expresses a proposition, a total function from worlds to truth-values (truth or falsity). Thus, 'There is a god' expresses the proposition that there is a god, the function mapping each world in which there is a god to truth and each world in which there is no god to falsity.
In line with the arguments of chapter 3, semantic evaluation is compositional in the usual way. Thus, 'Not A' is true at a world w if and only if A is not true at w, 'A and B' is true at w if and only if A is true at w and B is true at w, and so on. The semantics has no truck with 'impossible worlds' in the sense of chapter 3.3. This semantic orthodoxy only makes the relevant challenge to metaphysics harder to avoid, and so for our purposes it is dialectically harmless. Some elaborations and modifications of the intensional framework will later be considered, consistent with semantic compositionality, but they turn out not to solve the problem for metaphysics.
Any standard intensional model determines a distinguished modality, by the condition that, for any sentence A of the object-language, 'Necessarily A' is true at a world w if and only if A is true at every world, while 'Possibly A' is true at w if and only if A
is true at some world. For present purposes, the object-language is interpreted—it has an intended interpretation—so there is an intended intensional model, and a corresponding intended distinguished modality. From now on, the words 'possible' and 'necessary' will be used for that modality. In that sense, the worlds in the intended framework are all and only the possible worlds. Given the compositional semantics and a classical metalogic, the logical connectives behave classically at each world, so any truth of classical propositional logic is true at every world. Consequently, every theorem of the well-known modal system S5 is true at every world on this interpretation. In particular, it validates the thesis that whatever is necessary is true (the T axiom), and the more distinctive theses that whatever is necessary is necessarily necessary
(the S4 axiom) and whatever is possible is necessarily possible (the
S5 axiom): matters of necessity or possibility are not themselves contingent.
Since our interest is in metaphysically oriented semantic theories, we understand this distinguished modality as broadly objective rather than merely epistemic. Indeed, we may conceive it as the broadest kind of objective possibility, since it excludes no world in the model. An attractive hypothesis is that this maximal objective modality is just what is usually called 'metaphysical modality'
(Williamson 2016a). But that is controversial. For example, the S4
and S5 axioms have both been denied for metaphysical modality
(Salmón 1989), and the S5 axiom has been denied for the broadest modality (Bacon 2018, but see Goodsell and Yli-Vakkuri in preparation). A further complication is that, in more perspicuous frameworks for modality, worlds may be less basic than the distinction between possibility and impossibility itself, perhaps in the setting of higher-order logic (Williamson 2013a), where impossibility may even be reduced to identity with a contradiction (Bacon 2018).
Still, such alternatives are compatible with versions of intensional semantics. They all face the challenge to be discussed. We can ignore the differences between them.
As an immediate corollary of this intensional approach, already noted, propositions are coarse-grained. Necessarily equivalent propositions are identical: they output the same truth-value for any given world as input, and so are the same function. In particular, there is only one necessary proposition and only one impossible proposition. If you know one necessary truth, you know them all.
For the sake of an example, read 'god' in a strong sense, on which being a god is a necessary property: whatever has it in a possible world has it in any other possible world too (it may also entail other standard attributes, such as omniscience, omnipotence, omnipresence, omnibenevolence, and eternity; for present purposes we omit ineffability, since it might cause distinctively semantic problems).
So, it is either necessary or impossible that there is a god. If it is necessary, the proposition that there is a god is just the proposition that all cats are cats. If it is impossible, the proposition that there is a god is just the proposition that some cats are not cats. So, on this view, when atheists argue with theists, the two propositions in dispute are that all cats are cats and that some cats are not cats, one way round or the other. Isn't such a dispute a waste of time? The moral seems to be: insofar as metaphysics concerns the non-contingent, intensionalism trivializes metaphysics.
Unlike empiricist and logical positivist critiques of metaphysics, the argument from intensionalism has no epistemological premises, and its conclusion is not distinctively epistemological; the argument is just semantic. Nevertheless, it reaches a similar conclusion: there is nothing non-trivial for metaphysical claims to mean. Such arguments have had significant influence. They can be traced back to Wittgenstein's Tractatus Logico-Philosophicus, where ultimately every declarative sentence is to be analysed as a truth-function of atomic sentences expressing simple, mutually independent states of affairs. If it is true on every assignment of truth-values to those atomic sentences, it is merely tautologous. If it is false on every assignment, it is merely contradictory. If it is true on some assignments and false on others, it is merely contingent. This taxonomy leaves nowhere for metaphysics to hide.
A conception of impossibilities as all trivially false may explain the claim, widespread even amongst contemporary Wittgensteinians, that it is meaningless to assert an impossibility. In contemporary philosophy, Robert Stalnaker has been a leader in pressing the radical consequences of intensionalism, though with a scaffolding of possible worlds rather than simple, mutually independent states of affairs (1984, 1999).3 Such intensionalist sympathies can also be found in the works of David Lewis (1970, 1996) and, in less committed form, Saul Kripke (1979), despite their major contributions to metaphysics. More recently, Eli Hirsch (2021) has extended his nuanced semantic critique of (some) metaphysics by connecting it with the kinds of coarse-grained, worldly, semantics, including intensionalism, which at first sight look friendly to out-and-out metaphysics.
Of course, intensionalist trivialization threatens more than metaphysics. It concerns any inquiry into the non-contingent. Logic and mathematics are salient examples. They can hardly be dismissed as trivial. If the proof of Fermat's Last Theorem was just a proof that all cats are cats, why did it take centuries to find? Curiously, many philosophers find less difficulty in convincing themselves that logic and mathematics are somehow purely formal, not really concerned with how the world is, so not in need of non-trivial content. By contrast, traditional metaphysics stubbornly enquires into the necessary nature of the world; for it, the threat that only triviality that way lies is existential. Indeed, the question 'Is there a god?' is not easily understood as purely formal.
In what follows, the focus will be on metaphysics, not logic and mathematics as such, but the conclusions will apply to the latter too, providing a way for them to be as worldly as metaphysics, with which they indeed overlap (Williamson 2013a).
5.3 Generalizing the problem
How robust are the trivializing consequences of intensionalism?
Do they survive motivated generalizations of the intensional framework?
3 For an exchange on the Wittgensteinian claim about impossibility, see Marconi 2011
and Williamson 2011c. For an exchange on Stalnaker's view see Stalnaker 2011 and
Williamson 2011b. For a view that combines ideas from Wittgenstein and Stalnaker, see
Rayo 2013. First indications offer metaphysics little hope. For instance, many versions of intensional semantics add a parameter for times to that for worlds in semantic evaluation, to handle tense. Then sentences express the same content if and only if they have the same truth-value at every world-time pair. But that makes no significant difference to the problem. On the operative reading of the word
'god', we may assume, the property of being a god is eternal as well as necessary: something is a god at a world and time if and only if it is a god at every world and time. Hence either there is a god at every world and time or there is a god at no world and time. So, as before,
'There is a god' has the same content as either 'All cats are cats' or
'Some cats are not cats'.
A more far-reaching modification of the framework is to work with possible situations instead of possible worlds, to handle the locality of much discourse (for instance, Elbourne 2005). Situations are something like world-fragments. A sentence is neither true nor false in situations which include too little to determine its truth-value. Presumably, then, sentences express the same content if and only if they have the same truth-value (if any) in every situation.
But that still makes no crucial difference to the problem. For on the operative reading of the word 'god', we may assume, something is a god in a situation if and only if it is a god in every situation (a form of necessary omnipresence). Hence either there is a god in every situation or there is a god in no situation. If a situation s has a god in it, 'There is a god' is true in s. If s has no god in it, there must be no god, so 'There is a god' is false in s. Thus if 'All cats are cats' is true and 'Some cats are not cats' false in every situation, 'There is a god'
still has the same content as either 'All cats are cats' or 'Some cats are not cats'. There is a slight complication: some versions of situation semantics may determine no truth-value for those 'cat' sentences in situations which exclude some cats. By contrast, 'There is a god' is true or false in such situations, as just explained. In that case, 'There is a god' differs in content from both 'All cats are cats' and 'Some cats are not cats'. But this technicality will not solve the problem.
For we can introduce a logically constant sentence ⊥ for absurdity, governed by the stipulation that ⊥ is false, and so its negation ¬⊥
true, in each situation. Then 'There is a god' has the same content as either the trivially false ⊥ or the trivially true ¬⊥.
These radical problems for intensional metaphysics may tempt metaphysicians to go hyperintensional. Doing so would be bad news for metaphysics, given the methodological problems discussed in chapter 3. For now, we can temporarily bracket those problems, despite their gravity, in order to see more directly how ineffective is the resort to hyperintensionality as a response to the threat of semantic trivialization.
Ignoring the warnings of chapter 3.3, one form of hyperintensional metaphysics adds impossible worlds to the semantics, understood in an ontologically harmless way as arbitrary sets of sentences of the object language. A sentence is evaluated as true at such a world if and only if it is a member of that world. To individuate content more finely in this framework, we can stipulate that sentences express the same content if and only if they are true at the same worlds, possible and impossible. Then 'There is a god' differs in content from any other sentence S, for the simple reason that 'There is a god' is true at the world {'There is a god'}, while S is not true at that world. But this strategy trivializes sameness of content by reducing it to sameness of sentence. For even if the words 'god' and 'deity' are synonyms by normal standards, the sentences 'There is a god' and 'There is a deity' still count as differing in content, for the reason just given (let S ='There is a deity'). No such verbal manoeuvre will rescue the ambitions of traditional metaphysics. Of course, impossible worlds theorists may impose semantic constraints on their preferred model, for instance one requiring it to treat 'god' and 'deity' interchangeably, but that is just another case of the now familiar move of putting the desired outputs of the model into it by hand. Such ad hoc manoeuvres go nowhere towards explaining how metaphysical statements could express non-trivial necessary truths. Ignoring the warnings of chapter 3.5, a more explanatory-looking move is to abandon the identification of sentential contents with (perhaps partial) functions from circumstances of evaluation to truth-values, and adopt a more structured conception instead. In particular, one might identify the content of a declarative sentence with a Russellian proposition, a complex built out of the objects, properties, and relations the sentence is about, and structured according to the structure of the sentence. For example, the proposition that there is a god might be something like <∃, divinity>, the ordered pair of the second-order property ∃ of being instantiated and the first-order property divinity, of being a god. Then a proposition p is the proposition that there is a god only if p has divinity as a constituent.
An immediate concern is that the individuation of Russellian propositions is itself hostage to the individuation of properties and relations. In particular, suppose that properties are identical if and only if they are necessarily coextensive. Then if it is in fact impossible to be a god, the property of being a god is necessarily coextensive, and so identical, with the property of being a round square; thus, the proposition <∃, divinity> is just the proposition
<∃, round-squarehood>, and the threat of trivialization returns. So far, this is just an isolated case; there is no such elementary argument on the alternative hypothesis that it is possible to be a god.
However, Russellian propositions in metaphysics face a much more general threat of trivialization. We keep 'There is a god' as our sample sentence of metaphysics, but without exploiting its specific details. We introduce a new singular term 'D' by stipulating thus:
If there is a god, 'D' names 1.
If there is no god, 'D' names 0.
The stipulation is to be understood as belonging to the metasemantics of 'D', not to its semantics, in Kripkean terms, to fix the reference of 'D', not to give its meaning (Kripke 1980). Thus 'D'
is not to be understood as abbreviating a definite description like
'the number n such that either there is a god and n =1 or there is no god and n =0'. Rather, 'D' is simply a name of a natural number; the stipulation specifies which number. Consequently, the Russellian proposition semantically expressed by the equation 'D =1' has none of the complex structure of the definite description, but is simply something like <identity, <D, 1>>. Obviously, the sentences
'There is a god' and 'There is no god' have the same truth-values as the equations 'D =1' and 'D =0', respectively. If we want to argue about whether there is a god, we can argue about whether D =1; it makes no dialectical difference.
Of course, whichever side is wrong about the metaphysics also has a false belief about the reference of 'D', given that they have been introduced to the name by the stipulation above. If there is a god, atheists falsely believe that 'D' names 0; if there is no god, theists falsely believe that 'D' names 1. But that does not mean that one side or the other misunderstands the name 'D'. It is like the name 'Jack the Ripper', introduced by the description 'whoever committed the grisly Whitechapel murders'. Some people may still falsely believe the wild theory that Edward VII committed the grisly Whitechapel murders, so that Jack the Ripper was Edward VII; familiar with the name 'Jack the Ripper' in the usual way, they falsely believe that it names Edward VII, but they do not thereby misunderstand the name 'Jack the Ripper'.4
On the Russellian view, if there is a god, the sentence 'D =1'
expresses the same proposition as the trivially true sentence '1 =1'; if there is no god, the sentence 'D =0' expresses the same proposition as the trivially true sentence '0 =0'. On intensionalism, the corresponding necessary propositions are identical too.
4 For relevant discussion of what counts as understanding, see Williamson 2007: 97–8
and the exchange between Stalnaker 2011 and Williamson 2011b. More generally, the discussion of analyticity in Williamson 2007 and 2021a support the arguments of this section. The threat of trivialization has returned in completely general form. One could substitute any other sentence for 'There is a god'
in the preceding argument. Nothing here depends even on the non-contingency of 'There is a god'. The argument works in the same way if one substitutes 'There is intelligent life in other galaxies' for
'There is a god':
If there is intelligent life in other galaxies, 'G' names 1.
If there is no intelligent life in other galaxies, 'G' names 0.
Everything proceeds as with 'D'. In particular, since 'G' is a proper name, it is a rigid designator, even though it is contingent whether there is intelligent life in other galaxies. Thus, if there is intelligent life in other galaxies, we use 'G' to designate 1 even with respect to counterfactual possibilities in which there is no intelligent life in other galaxies. Equally, if there is no intelligent life in other galaxies, we use 'G' to designate 0 even with respect to counterfactual possibilities in which there is intelligent life in other galaxies.
Thus, we are in an epistemic position to assert both 'There is intelligent life in other galaxies if and only if G =1' and 'Either there could have been no intelligent life on other planets while G was 1 or there could have been intelligent life on other planets while G was
0'. The biconditional is similar to proposed examples of contingent a priori truths (Kripke 1980). If we want to argue about whether there is intelligent life in other galaxies, we can argue about whether
G =1; it makes no dialectical difference. If there is intelligent life in other galaxies, the sentence 'G =1' expresses the same Russellian proposition as the trivially true sentence '1 =1'. If there is no intelligent life in other galaxies, the sentence 'G =0' expresses the same
Russellian proposition as the trivially true sentence '0 =0'. Again, in both cases, the corresponding necessary propositions in the intensional framework are identical too.
Such examples cast doubt on any attempt to interpret the semantic considerations as revealing some pathology of metaphysics, for the question whether there is intelligent life in other galaxies is uncontentiously non-pathological.
Related examples occur quite naturally, with no need of artificial stipulations. Take the go-to example of synonymy from previous chapters, the natural kind terms 'furze' and 'gorse'. As we saw there, although they have the same meaning in English, by normal standards someone can understand both words without recognizing that they co-refer. On the Russellian approach (if not that of the historical Russell), the English sentence 'Furze is gorse'
expresses the Russellian proposition <identity, <furze, gorse>>, which just is the obviously true Russellian proposition <identity,
<furze, furze>>. Yet you could sensibly ask yourself 'Is furze gorse?'
out of simple non-pathological botanical interest. A similar issue arises on a natural implementation of the intensional approach, since 'furze' and 'gorse' are rigid designators of the same genus, so
'Furze is gorse' is true at all possible worlds.5
The problems with 'D =1', 'G =1', and 'Furze is gorse' are not specific to a Russellian account of propositions. They are just as pressing for versions of truthmaker semantics (chapter 3.4) and impossible worlds semantics (chapter 3.3) that respect the key observation that competent speakers of a language can understand synonyms without appreciating their co-reference.
The evidence so far supports at least two conclusions. First, the problem of trivialization is just as hard for hyperintensionalist as for intensionalist semantics. Second, the problem is generic; it shows nothing distinctive about specific forms of enquiry. In particular, it shows nothing pathological about metaphysics. Nor does it show anything special about logic or mathematics. Overfitting and heuristics in philosophy
5.4 The metalinguistic strategy
Some philosophers are still tempted by the idea that the ignorance or at least non-triviality displayed in the cases above is fundamentally semantic, that there are serious obstacles to knowing what the relevant words or sentences mean: for instance, it is hard to know which numbers the names 'D' and 'G' designate. 6 This ignorance would be of a familiar, unpuzzling kind and pose no threat to the favoured semantic framework.
Consider yet again 'furze' and 'gorse'. The obvious line for proponents of the metalinguistic strategy is to insist that anyone—
such as an expert botanist—
with full, non-deferential understanding of both 'furze' and 'gorse' is in a position to know that they co-refer. Everyone else has at most partial understanding of at least one of the two terms. Thus, the problem is fundamentally one of semantic ignorance.
Such an account may apply to this particular case, though what the 'full understanding' might be with which 'partial understanding' is implicitly contrasted is far from clear. In any case, we can vary the example. In one variant, set many centuries ago, the shrub in question is rare and grows only in remote places. It has been seen only occasionally, but never studied scientifically, and no specimens have been observed over extended periods. The term
'furze' was introduced by travellers who saw green bushes with yellow flowers, and in practice only bushes in that condition are recognized as 'furze'. Similarly, the term 'gorse' was introduced by travellers who saw brown bushes with no flowers, and in practice only bushes in that condition are recognized as 'gorse'. Not even the best botanists in our community realize that 'furze' and 'gorse'
6 The leading defender of intensionalism about content is Robert Stalnaker (1984,
1999). Since I have engaged in detail with his application of intensionalism to content in philosophy elsewhere (Stalnaker 2011, Williamson 2011b), I will not do so here. In effect, his approach is a version of the metalinguistic strategy; my concern in this section is with the general strategy. co-refer; they may regard it as an open question. Nevertheless, despite the community-wide difference between 'furze' and 'gorse' in associated recognitional capacities, there is no strictly semantic difference between the two words. They are both simply natural kind terms for what is in fact the very same natural kind. In that sense, they are synonyms. In these circumstances, a fully non-deferential understanding of both terms does not put one in a position to recognize their co-reference. To resolve our ignorance, our primary need is to know more botany, not more semantics.
In another variant, everything is like the original case, but without deference, since the community does not recognize the status of scientific expertise. Instead, natural kind terms are treated more as words like 'if ' and 'know' are actually treated. Although some people devote themselves to studying conditionals or knowledge, they play no privileged role in the social practice of using the corresponding words, because the community has no tendency to defer to them in applying the words. Similarly, in the imagined case, even if some people devote themselves to studying shrubs, they play no privileged role in the social practice of using the words
'furze' and 'gorse', because the community has no tendency to defer to them in applying the words. At least for those who have been introduced to them ostensively, the ethos in applying them is that everyone is entitled to their own opinion. For that large, at least minimally competent group, there is no deferential partial understanding, because there is no deference to a higher level of competence. 'Furze' and 'gorse' are still treated as natural kind terms, but in an unscientific spirit. Many speakers fully competent by communal standards with both terms cannot recognize that they co-refer. Unlike the previous case, there is no community-wide difference between 'furze' and 'gorse' in associated recognitional capacities; such differences obtain only at the level of individual speakers. There is also no strictly semantic difference between the two words. They are both simply natural kind terms for what is in fact the very same natural kind. They are synonyms. In these circumstances too, a fully non-deferential understanding of both terms does not always put one in a position to recognize their co-reference. To resolve one's ignorance, one's primary need is to know more botany, not more semantics.
At first sight, the artificially introduced names 'D' and 'G' look more promising as candidates for semantic ignorance. The associated stipulation might plausibly be denied by itself to enable one to know which number 'D' or 'G' designates. Currently, someone familiar with the stipulation may be uncertain whether 'D' co-refers with '1' or with '0'. But that is because they are uncertain whether there is a god: the semantic ignorance seems to depend on prior metaphysical ignorance, contrary to the metalinguistic strategy. However, proponents of the strategy may respond that the relevant semantic ignorance is at the level of the sentence, not the singular terms: the underlying uncertainty is as to which proposition the sentence 'There is a god' expresses. This may seem more promising. Semantic ignorance of individual words in the sentence would be mere linguistic incompetence, which is an implausible diagnosis of the problems of metaphysics. Of course, the word 'god' is hardly straightforward, but for present purposes we may assume that it has been stipulatively defined in terms of a list of attributes. The picture is that we know the semantic values of the atomic constituents of the sentence, but cannot work out which proposition results from composing them in the relevant way.
Such an account makes more sense for intensional than for
Russellian propositions. For the latter, if we know that a sentence is composed of a constituent expressing the second-order property ∃ predicated of a constituent expressing the first-order property of divinity, we can easily work out that the sentence as a whole expresses the Russellian proposition <∃, divinity>: there is no mystery as to which proposition that is, because the notation is already so perspicuous.7 By contrast, if the proposition is a function from worlds to truth-values, but one is uncertain whether it maps all worlds to truth or all to falsity, one might well be counted uncertain as to which function the sentence expresses. If sentences are individuated syntactically, not semantically, it is contingent which proposition a sentence expresses, so the apparent metaphysical uncertainty has finally been traced to uncertainty about something contingent.
However, the proposal does not withstand further scrutiny. Let
'S' abbreviate whichever is false of the quotations 'There is a god'
and 'There is no god', so S is the false one of those two sentences.
Whatever proposition S semantically expresses is impossible.
Consider a metaphysician uncertain whether S expresses a true proposition. Of course, that uncertainty is uninteresting if it results from lack of native speaker knowledge of English. We must assume our metaphysician to know what the words and modes of composition in S mean. Thus, we assume that she knows that S has semantic features F, fully characterizing the semantics of S's atomic constituents and modes of composition. Consequently, since our metaphysician is rational, she is also uncertain over the conjunction that S both has F and expresses a true proposition. But the conjunction is itself impossible, for since the semantics is compositional, a necessary consequence of the first conjunct (that S has F) is that the proposition S expresses is impossible, which is incompatible with the second conjunct. Each conjunct is possible, but they are not compossible. Thus, our metaphysician's uncertainty extends to something impossible, contrary to the metalinguistic strategy of confining the relevant uncertainty, ignorance, or error to contingent linguistic matters.
7 The notation is perspicuous because <X, Y> =<X*, Y*> just when X =X* and Y =Y*, so one can individuate the whole by individuating its constituents. This justifies the ordered pair notation, though Russellian propositions need not literally be ordered n-tuples. But this fineness of grain also generates the Russell-Myhill paradox, which makes a pure Russellian account inconsistent (see chapter 3.5). A back-up tactic for the metalinguistic strategy is to divide an agent's beliefs into separate subsystems, individually possible but jointly incompossible (Stalnaker 1984). However, in the present case, separating the metaphysician's belief that S expresses a truth from her belief that S has F misses the depth of the problem. She does not have to ignore her understanding of S in order to believe that it expresses a truth; she believes that S is true in the light of her understanding of S. Positing a cognitive wall between her belief that S expresses a truth and her belief that it has the semantics F
makes no sense of the example.
Although one could develop other ways of implementing the metalinguistic strategy, they are all vulnerable to the sort of problem just explained (to my knowledge, first pointed out by Kripke in an unpublished lecture). Thus, the metalinguistic strategy fails.
5.5 Reconceiving the problem
In order to make progress, what one must take to heart is that the underlying problem is not about necessary or impossible propositions.8 It is about necessarily equivalent propositions, whether they are contingent or not. For instance, the sentences
'There is furze in Edinburgh' and 'There is gorse in Edinburgh'
express the same contingent proposition, on the worldly approach to semantics under discussion, even though a speaker who understands both sentences may be in no position to appreciate that they have the same truth-value.
Of course, this is just a variant on the problem of cognitive significance, which Frege introduced his distinction between sense and reference to solve. Some philosophers may still hope that switching to a Fregean framework would help, by building modes of presentation into the semantics. However, chapter 4 explained why the
8
The approach in this section builds on the proposal in Williamson 2007: 66ff. Fregean account, despite its initial appeal, does not get to the heart of the problem. We need not go over that ground again.
There is also a further concern about the big picture for metaphysics, if it needs to be rescued by Fregean semantics. Fregean thoughts—the senses of declarative sentences—are perspectival in a sense in which worldly intensional or Russellian propositions are not. A Fregean thought is a mode of presentation of a truth-value, presumably to a notional subject. By contrast, functions from worlds to truth-values and structured complexes of objects, properties, and relations are normally presentation-and subject-independent.9 Thus Fregean thoughts seem less apt than such worldly propositions for being what is objectively at stake in an out-and-out metaphysical dispute, as traditionally conceived (in a way
Kantians might describe as pre-Kantian). For thoughts can differ while the relevant non-presentational objects, properties and relations stay the same. In such cases, one might think, what is objectively at stake stays the same, while Fregean thoughts vary, so what is objectively at stake is no Fregean thought. Of course, Frege himself did not treat mathematics as lacking in objectivity; his approach was explicitly, indeed prototypically, anti-psychologistic.
The commitments inherent in a Fregean semantic framework are unclear. Nevertheless, those engaged in a dispute over what they understand as a purely objective metaphysical question may be suspicious of treating what is at stake as a Fregean thought.
In any case, the moral to draw from 'furze' and 'gorse' and similar cases is not that semantic properties are Fregean. It is that cognitive significance does not supervene on semantic properties. At both the individual and the community levels, two sentences may have all the same semantic properties, yet differ in cognitive significance. Tracking cognitive significance is not just a semantic
9 David Lewis (1979) turned the intensional framework perspectival by reworking it in terms of centred worlds, with a distinguished agent and time, although he did not build in other aspects of modes of presentation. For criticism of such hybrid approaches, see Cappelen and Dever 2013 and Magidor 2015. exercise. Cognitive significance often depends on form as well as content. More specifically, for inquiries where the primary medium of expression is linguistic, as in logic, mathematics, and metaphysics, cognitive significance typically depends on the linguistic form in which content is semantically expressed in the given context, not just on the content itself. To track cognitive significance, we must track the words and sentences in play, not just the contents themselves. In chapter 4's terminology, we can distinguish between believing the proposition that furze is gorse under the guise of the sentence 'Furze is gorse' and believing the same proposition under the guise of the sentence 'Furze is furze'. Similarly, we can distinguish between believing the proposition that 172 =289 under the guise of the equation '172 =289' and believing it under the guise of the equation '289 =289' or '0 =0', and between believing that there is a god under the guise of the sentence 'There is a god', believing it under the guise of the equation 'D =1', and believing it under the guise of the equation '1 =1' or '0 =1' (depending on its truth-value).
By using linguistic guises to track cognitive significance, we liberate semantics itself from pressure to make cognitive distinctions it is ill-suited to make; we thereby avoid distorting the semantic framework. Even the quasi-syntactic structure of Russellian propositions arguably reflects such inappropriate pressure on the semantics, by contrast with a purely intensional approach (Salmón
1986 invokes linguistic guises but works within a broadly Russellian framework). Just as we should not project the difference between
'furze' and 'gorse' onto their worldly semantic values, so we should not project differences in syntactic structure between sentences onto their worldly semantic values.
In short, linguistic guises are not what we think, and not normally what we think of; they are what we think with, when we think in words. Similarly, in speech, when you make an assertion, a guise is not what you assert, and not normally what you assert it of; it is more like what you assert it with (though the hearer may receive it under a different guise). We must keep track of linguistic or, more generally, representational differences, without confusing them with differences at the level of reference or content.
Often, as seen in chapter 4, more than the linguistic expression type must be put into the guise to capture cognitive significance.
This is clear for demonstratives: in the same context, someone may wonder 'Is that gull that gull?', where the first occurrence of 'that gull' refers to a seagull as she sees it in the distance, while the second refers to the same bird as she hears its cry. Kripke's case of someone who does not realize that the politician Paderewski and the pianist
Paderewski are the same man also calls for such further differentiation of guises. Since full guises are not normally what need to be communicated, individuating them very finely carries little cost.
Nor need guises always include something linguistic: the guise of a spatial thought might be more like a picture, seen or imagined. What sort of Russellian proposition would correspond to an impressionist landscape painting?
As also seen in chapter 4, this separation of content from guise is not transparent to normal language-users in producing and comprehending ascriptions of propositional attitudes.
In any case, we can provisionally use the approach of ascribing acceptance or rejection of coarse-grained intensional propositions under guises to track what is going on in enquiries into non-contingent matters, such as logic, mathematics, and metaphysics.
In those enquiries, propositions usually come under sentential guises, but not always: in geometry, for example, a proposition may come under a diagrammatic guise. The trap to avoid is that of taking the need for tracking sentential guises to show something distinctive about those fields—for instance, that they are somehow partly linguistic inquiries in some sense in which more 'empirical'
inquiries are not.
Admittedly, fields may differ in how far we can use differences in proposition expressed as convenient proxies for cognitive differences between sentences—doing so works much better in history than it does in mathematics—but in principle the two levels are never equivalent, and in practice the inequivalence will sometimes obtrude in every field, though more frequently in some than in others. For example, in ancient history, doubt is not uncommon as to whether the same name on different tablets or inscriptions refers to one person or two. Again, there is a practical difference between knowing how many tiles are needed to cover the floor under the guise of the sentence '172 tiles are needed' and knowing it under the guise of the sentence '289 tiles are needed'; the necessity of mathematical truths is not the issue.
Another way to see that the problem is not specific to non-contingent propositions is to consider an object-language with a rigidifying modal operator, 'actually'. On the intended reading, for any declarative sentence 'P' of the object-language, 'Actually P' is true at a world w if and only if 'P' is true at the actual world. Thus 'P
if and only if actually P' is guaranteed to be true at the actual world, so you can cheaply know the biconditional. But, if 'P' expresses a truth, whether contingent or non-contingent, 'Actually P' (as uttered in your world) is true at every world, so the biconditional is necessarily equivalent to 'P', so you know something necessarily equivalent to 'P'. Similarly, if 'P' expresses a falsehood, whether contingent or non-contingent, 'Actually P' (as uttered in your world) is false at every world, so the biconditional is necessarily equivalent to 'Not P', so you know something necessarily equivalent to 'Not P'.
For an intensionalist, that is uncomfortably close to omniscience on the cheap (see Hawthorne and Yli-Vakkuri 2022 for more details).
One response is that, although you know the biconditional sentence to express a true proposition, you do not know which proposition it expresses (the proposition that P or the proposition that not P). However, as the previous section explained, the metalinguistic strategy does not in general provide an effective defence of intensionalism. In the present case, once you understand 'P' and the relevant logical constants, the biconditional 'P if and only if actually P' is easy to understand. In the relevant sense, knowing which proposition a given sentence expresses is not a matter of being able to enumerate the worlds at which it is true, since we are unable to do that for the simplest, most everyday true sentences. The claim that you do not know which proposition the biconditional expresses is just too unclear to be of any help.
A more effective strategy is to invoke guises and distinguish between knowing a true proposition under the guise 'P' (or under the guise 'Not P') and knowing the same true proposition under the guise 'P if and only if actually P'. Although we saw in chapter 4.10 and 4.11 some limitations of the guise-relative strategy, some cases call out for it, and the case with 'actually' was artificially designed for exactly that purpose. Just about any scientific model is vulnerable to such tricks. They reveal limitations of the model, but that is not to say that they justify its abandonment. In particular, the strategy of relativizing attitudes to linguistic guises is well-suited to describing inquiry in metaphysics, logic, and mathematics, not because they concern non-contingent matters but because their principal medium is a shared language, typically written, which facilitates the use of linguistic types as cognitive guises.
Naturally, the envisaged separation of semantic content from cognitive significance forms a coherent picture only if systematic connections link the two levels. Compositional semantics provides such connections. Although the semantic structure of a sentence is not even roughly similar to any structure intrinsic to the proposition it expresses, the former determines the latter in more or less principled ways, described by a compositional semantic theory for the language. Even in discourse where the only propositions are the necessary truth and its contradictory, a multitude of properties and relations are normally in play as the semantic values of predicates.
Thus, a standard first-order language for arithmetic can express infinitely many distinct monadic properties (intensions) of natural numbers. The case of metaphysics is analogous. When things go well, we learn how the properties and relations of interest are necessarily interconnected. One might still feel puzzled. For when we learn how those properties and relations are necessarily interconnected, what we learn are necessary truths, which by intensionalist lights are all one.
Indeed, if metaphysical truths are all necessary, how do we learn anything in metaphysics, since presumably we already knew the trivial necessary truth before we started doing metaphysics? In response, a first point is that calling the necessarily true proposition 'trivial' already confuses the issue, because the distinction between 'trivial' and 'non-trivial', like that between 'obvious' and 'non-obvious', arises primarily at the cognitive level: the trivial is the very easily known. The necessarily true proposition is trivial under the guise of the equation '2 +2 =4' but highly non-trivial under the guise of a statement of Fermat's Last Theorem. Similarly, in such cases, learning and discovery must themselves be understood with respect to guises: mathematicians who already knew the necessary truth under one guise came to know it under another. The novelty was in the guise, not in the proposition known. Again, the same points apply to logic and metaphysics.
But if you know a truth under one guise, why bother to learn it under another? That would be a good question if knowledge were valued as a miser's hoard of true propositions. But not even true propositions have intrinsic value: the value is in how we are cognitively related to them. We can bear dramatically different cognitive relations to the same proposition under different guises. In learning an old truth under a new guise, we acquire a potentially valuable new cognitive relation to the old truth.
None of this involves a return to the discredited metalinguistic view. The latter makes the mistake of trying to get the content to do all the cognitive work, forgetting that even a metalinguistic content can be presented to the subject under different guises. The point is rather that any content is present to a subject at a time only in some form or other; that form is its guise. Even physical aspects of linguistic form are cognitively significant, because they facilitate or impede cognitive manipulation. Mathematicians know this well; metaphysicians would be well-advised to know it too. As Bertrand Russell observed, 'a good notation has a subtlety and suggestiveness which at times make it seem almost like a live teacher'; 'Notational irregularities are often the first sign of philosophical errors' (1922: xix). That is why definitions matter in metaphysics, even though they merely abbreviate longer forms of words: a good definition makes salient and handy a distinction which cuts at the joints. In that respect, even metaphysics is a kind of embodied cognition.
5.6 In brief
According to some philosophers, the non-contingency of metaphysics, logic, and mathematics undermines their capacity to provide substantive knowledge. That is a disastrously mistaken diagnosis of a genuine problem. The misdiagnosis results in damaging pseudo-cures. The underlying problem is not about necessary truth; it is about necessarily equivalent propositions, irrespective of their modal status. It is yet another manifestation of the non-transparency to thinkers of the contents of their thought. It arises eye-catchingly for intensionalism, but hyperintensional remedies mislocate the problem, and harm the patient in other ways. The proper cure is to make a radical cut between content and cognitive significance. It poses no threat to intensionalism.

Preface to the Second Edition

It was Marissa Koors, Philosophy editor at Wiley-Blackwell, who in 2018 proposed renewing The Philosophy of Philosophy in a second edition, with extra material on developments since 2007, when the book was first published. I liked the idea, without feeling tempted to rewrite the first edition. Since its publication, I have continued to stand behind all its main ideas and most of the details. In subsequent writings, I have further clarified and developed its lines of thought, responded to critics, and filled in omissions. However, those later pieces were scattered about, hard to survey and in some cases hard to find even for me, let alone anyone else. It may be helpful for readers to have all this material collected together into one volume, constituting a more comprehensive philosophy of philosophy, with replies to the sorts of questions and objections it tends to provoke.
My other projects delayed work on the second edition for over two years. This preface, written in the Oxford of 2020, under partial lockdown as a result of Covid-19, is an opportunity to look back, and forward, in briefly introducing the new material.
The most constructive additions are Sections 9.1–9.4, four essays that substantially extend the first edition’s picture of philosophy, both its methods and its recent history. Each was written not so much as a contribution to an ongoing conversation as an attempt to start a new one. Those attempts already seem to be succeeding. Section 1, 'Widening the picture,' explains the topics of the new conversations, and how I came to be interested in them.
The other new sections, most of them quite short, and some of them quite polemical, were all written in something more like responsemode. Thus the distribution of topics in them is some evidence of what was happening in the philosophy of philosophy in the years after the publication of the first edition. The two response-mode sections of full article length, Sections 10.2 and 10.4, are defenses of armchair philosophy against attacks from 'experimental philosophers.' Of the shorter sections, twenty were my invited replies to book symposia on the first edition, in Analysis, Philosophical Studies, Philosophy and
Phenomenological Research, Analisi (the bulletin of SIFA, the Italian
Society of Analytic Philosophy), and the Croatian Journal of Philosophy, and to a symposium in Epistemology and Philosophy of Science
(Moscow) on a paper in which I briefly summarized my updated view of philosophical methods (2019c).1 Another five short sections originated as book reviews invited for The Times Literary Supplement,
Philosophy, the European Journal of Philosophy, and The Journal of Philosophy. One commentary (14.5) originated in an invitation to review a large group of works of popular philosophy collectively for
The Times Literary Supplement, another (14.6) in an invitation to contribute to the blog Daily Nous. Section 11.5 developed out of an invited reply for the New York Times’ philosophy blog 'The Stone' to a defense of naturalism by Alex Rosenberg against my original post, out of which developed Section 11.4, itself provoked by 'naturalist'
responses to the first edition. I usually accept invitations to contribute to symposia on my books and articles, and to review books on topics on which I am currently working, though for many years my policy has been not write unsolicited replies to reviews or criticisms of my work; life is too short. Thus the balance of topics discussed in the additional response-mode sections is not an artefact of my selection.
All the sections have been written to be readable by themselves, which occasionally involves some local repetition. The responsemode material is overtly one-sided, since it includes only my half of each exchange – altogether, with nearly thirty philosophers, based in Australia, Canada, Croatia, Italy, Russia, the United Kingdom, and the United States. Of course, to judge properly whether I have been fair to my interlocutors, readers will have to read their side too. In any case, I am deeply grateful to all those who have spent so much time and effort carefully reading my work and articulating their responses.
In contrast to the first edition, the additional material is designed to be read selectively, according to the reader’s interests. It also varies in how wide a readership it was written for, depending on its original place of publication, another dimension on which readers may wish to choose. But the underlying view of philosophy is the same throughout.
Sections 2 to 5 of this Preface briefly introduce the new responsemode material. Section 1 concerns the more spontaneous sections.
1. Widening the picture
My deepest instincts about the nature of philosophy have changed little over my career. For instance, I recall thinking as an undergraduate that transposing philosophical questions from the material to the formal mode, Carnap’s way of unmasking them as inviting linguistic decisions, really just disguised quite intelligible non-linguistic questions behind linguistic masks. Taken all the way, the 'Linguistic Turn'
struck me as in practice not clarifying but obscuring. Such critical instincts are manifest in The Philosophy of Philosophy.
However, soon after the book was published, I started to regret not having said more in it about aspects of philosophy which had long mattered greatly to me, but had been occluded by my more urgent preoccupations in writing the book. One such occluded topic was the abductive nature of theory choice, in philosophy as it should be, and to some extent in philosophy as it is. Just like theories in natural science, philosophical theories can be compared for fit with the evidence –
both their consistency with it and their ability to bring it under illuminating and powerful generalizations – but also for strength, in the sense of informativeness, and for simplicity, elegance, and avoidance of the ad hoc. The method is sometimes called inference to the best explanation, though philosophical explanations are constitutive rather than causal. The first edition is quite consistent with the abductive aspect of philosophy, which is implicit in the chapter on evidence in philosophy, but somehow it remained in the background.2 The omission was brought home to me when I gave a week-long colloquium based on the book at the University of Göttingen in 2009, invited by the students: I found myself answering question after question with reference to the role of abduction in philosophy, and wondering why I had not said more about it in the book itself. For the abductive aspect of philosophy was nothing new to me. During my doctoral studies at Oxford in 1976–1980, my closest friend amongst my fellow graduate students in philosophy was Peter Lipton, whose DPhil thesis later turned into his classic treatment Inference to the Best Explanation.
The relevance of the topic to assessing philosophical theories was salient to me even then. In my book Vagueness, the overall case for classical logic was fundamentally abductive (e.g. 1994a: 186). In this second edition, the additional Section 9.2, 'Abductive Philosophy,' fills this gap in the first edition; Section 9.5 briefly responds to some criticisms of the approach.
Abductive arguments in philosophy are mentioned in the first edition (184, 210, this volume). Unless specified otherwise, page references in this preface are to the first edition of this book, as reprinted here. Another omission was the methodology of model-building. I had started thinking seriously about it thanks to having the economist Hyun Song Shin as a colleague at University College Oxford in 1990–1994, trained in philosophy too, with a degree in PPE (Philosophy, Politics, and Economics) from Oxford. We shared an interest in epistemic logic, on which we published two joint papers (Shin and Williamson 1994, 1996). Our collaboration gave me fascinating experience of the differences in research culture between two disciplines when dealing with the same phenomena, in this case knowledge and ignorance of one’s own or another’s knowledge and ignorance. As an economist, he was used to a model-building approach, on which models are assumed from the outset to involve drastic simplifications of the reality under study, so that a mere discrepancy between model and reality is not news, and just pointing it out is not considered a significant intellectual contribution. Rather, what displaces a model is a better model.
He once remarked to me, of Gettier’s seminal paper (1963) refuting the analysis of knowledge as justified true belief by counterexamples, that in economics it would have been considered unpublishable. As a philosopher, used to treating counterexamples as the gold standard, I was shocked. Did these economists not care about truth? On second thoughts, however, I realized that the model-building methodology was just as oriented towards truth as the potentially naïve
Peter died far too young, in 2007. His work reminds me of Beethoven’s view of
Handel: a master of achieving great effects by simple means.
4
My work in continued defense of an abductive methodology for choosing between rival candidates for the first principles of logic and mathematics (2013a: 423–9, 2017b,
2018b) is too specialized to be appropriately included in the present volume. For a more 'popular' account of abduction in philosophy see 2018a: 66–81.

3 falsificationism of conjectures and refutations by counterexamples
(thought experiments), though in a subtler and less direct way. One of our joint papers used an explicitly model-building methodology, and it was employed in an increasingly prominent role in some of my own publications from that period on.5 'Must Do Better,' the Afterword to the first edition, recommends the use of mathematical models to test philosophical ideas (293, this volume), though without discussing such methods in detail. Later reflection on the nature of progress in philosophy convinced me that, like progress in natural science, much of it takes the form of building better and better models of the phenomena under study, rather than discovering exceptionless universal laws, and that failure to recognize the model-building methodology is one of the reasons for widespread overestimation of the difference between philosophy and natural science. In that respect, the additional
Section 9.3, 'Model-Building in Philosophy,' goes far beyond the first edition, while Section 9.6 briefly considers a proposed alternative.6
A recent side interest, which played no role in the first edition, has been the surprisingly effective dialectical role of moral and political considerations in philosophical debates which seem to have nothing specifically to do with the moral or political – for example, over general relativism, general skepticism, and general internalism in epistemology. The story of how I first came to notice this phenomenon tempts me into a digression.
As a graduate student at Oxford, I used to attend meetings of the
Radical Philosophy group, associated with the journal Radical Philosophy. In practice, what was philosophically radical about it was its rejection (and often ignorance) of analytic philosophy, in favor of just about anything which then counted as 'continental' – they discussed Nietzsche, Saussure, Althusser, Derrida, the more arid parts of Foucault’s corpus, and so on, with varying degrees of reverence. The
'analytic'-'continental' distinction cut at an obvious joint in the sociology of philosophy, however artificial it may have been in other respects. I experimented with those alternative traditions because I
felt oppressed by the style and assumptions of the kind of analytic

For uses of model-building in my work see Shin and Williamson 1996, various passages in 2000a, and 2013c, 2014b, 2015a, 2019b, 2020b.
6
For a more 'popular' account of model-building in philosophy see 2018a: 127–40.
5 philosophy then most fashionable in Oxford, and hoped that I might find different ideas for use in my own work. I didn’t get much out of the experiments, though I enjoyed reading Nietzsche and Saussure. I
came to realize that those who led the discussion often understood the obscure texts they talked about no more clearly than I did, although they certainly had a far more extensive acquaintance with them than mine, and were willing to 'go on in the same way' as their authors.
On the rare occasions when I asked a question or made an objection, they never seemed in danger of getting the point. There were one or two exceptions, fully open to rational discussion of ideas from both sides of the divide – one was Michael Rosen, now at Harvard. After
I had left Oxford for my first proper teaching job, at Trinity College
Dublin, I felt liberated to discover that what had really oppressed me about the then-predominant style of Oxford philosophy was not that it was too analytic but that it was not analytic enough. However, one of the things I did learn from my Oxford experience of Radical Philosophy was this: within such an intellectual world, much of the resistance to the relativist-sounding extremes of Post-Modernism came from Marxists and others on the far Left, who feared relativism as a threat to their political hopes. How far will those who view the case for revolution from a relativist stance commit to the revolutionary cause? In that world, objections to relativism from common sense, natural science, or logic had much less credibility. Later, while in Dublin (1980–1988), I was intrigued to hear from a talk by Richard Kearney (now at Boston College) of Richard Rorty describing absolutism about justice as much harder to give up than absolutism about truth. I was never tempted to give up either, but I could imagine how someone more concerned with morality and politics than with logic might feel that way.
I did nothing with those thoughts at the time, but they stayed with me. Much more recently, in responding to Paul Boghossian’s epistemological internalism, I found myself objecting that it counts as justified (though false) a consistent neo-Nazi’s belief that he ought to kill members of a target group, and wondering whether such a view would also count as justified (though wrong) his acting on that belief (Boghossian and Williamson 2020). That got me thinking more carefully about why emotive cases are dialectically effective, and whether invoking them is some kind of cheat. That is an obvious danger, especially in the current philosophical climate, where morally or politically wrong-footing one’s opponent is all too often used as a convenient excuse for not engaging properly with their arguments or objections. Nevertheless, I came to the conclusion that it is legitimate to use such examples in order to make vivid the practical consequences of a philosophical theory, especially one which had seemed to have none. The justification of belief and the justification of action should not be treated as orthogonal issues: the considerations for and against internalism are similar in the two cases, and after all the distinguishing mark of a belief is the agent’s willingness to act on it.
The additional Section 9.4, 'Morally Loaded Cases in Philosophy,'
encapsulates my reflections on these issues.
The Preface to the first edition starts by expressing my long-held view that the self-images then salient for contemporary philosophy failed to fit its actual development over the preceding decades. The book aimed to help put that right. I had also long been aware of a related strangely growing gap in the historiography of analytic philosophy. When I started as an undergraduate at Oxford in 1973, historical narratives of analytic philosophy tended to stop the story around 1960. Naturally, I expected that, as time went on, the lag between the time of writing and the end of the period written about in narratives of analytic philosophy would remain roughly constant.
It did not happen. Thirty years later, historical narratives of analytic philosophy still tended to stop the story around 1960. Although that generalization is not exceptionless, there really was very little serious historical work on post-1960 developments in analytic philosophy.
The time lag was far longer than needed to gain some historical perspective on the past – it was far shorter for serious historical work on post-1960 (and indeed post-1989) developments in politics, society, and culture. Many younger philosophers felt that Saul Kripke, David
Lewis, and others had effected a revolution in philosophy after 1960.
I found it frustrating that no one seemed interested in achieving a proper historical understanding of so significant a change.
It was as though such a revolution was not supposed to happen.
Whether historians of analytic philosophy preferred its logical positivist or its ordinary language strand, its predicted further development would not be in the direction of pre-Kantian metaphysics. From an older perspective, philosophers such as Kripke and Lewis looked like anomalies, anachronisms, to be swept away by the zeitgeist, unworthy of serious historical treatment. Instead, the opposite happened. Their ways of doing philosophy gradually prevailed, to an extent increasingly hard to marginalize historically, whether one approved of them or not. The first edition of this book was obviously a product of that turn in philosophy, but did not say very much about its history.
Some years later, the historian of philosophy Miroslava Trajkovski encouraged me to give a talk at the University of Belgrade, to help bring later developments in analytic philosophy alive for her students by drawing on my personal acquaintance with many of the protagonists. I used the opportunity to reflect historically on the transition from linguistic philosophy to contemporary metaphysics, and describe how it felt to one person at the time. The result was my article 'How did we get here from there? The transformation of analytic philosophy', now included as the additional Section 9.1. It is not meant as a work of serious historical scholarship, but rather as a provocation to others to produce such works on post-1960 developments in analytic philosophy. Indeed, things had already begun to improve in that respect. Such historiography is now flourishing.
For example, the massive influence of David Lewis has become wellrecognized, and his key role in the history of post-1960 analytic philosophy is being analyzed in detail. After all, the period from 1960 to
2020 is just as long as that from 1900 to 1960, and just as deserving of historical study.7,8
The reception of the first edition and of 'How did we get here from there?' was in many ways gratifying. However, I will not resist one grumble. The experience brought home to me that not all historians of philosophy read a contemporary philosophical text with the professional accuracy or empathy one might expect. I give samples without naming names. Where I wrote 'looked,' it was irritating to be read as if I had written 'is'; I used the past (not present) tense and the verb 'to look' (not 'to be') for a reason. It was irritating too to be read as if I must be using the word 'analytic' in Kant’s sense, not in the clearly broader sense standard in analytic philosophy for the last half-century. It was also irritating when my deliber-

Incidentally, one of those now engaged in this much-needed work is Paolo Tripodi, with an earlier incarnation of whom I take issue in Chapter 13.5.
8
For a more general and 'popular' discussion of the relation between philosophy and its history see 2018a: 98–110.
7 ately casual introduction of the phrase 'armchair knowledge' for an overtly heterogeneous range of cases was read as aiming to replace the term 'a priori' by a more precise substitute better suited to epistemological theorizing (171, this volume). Alas, no philosophical text is proof against determined attempts to interpret it to suit the interpreter’s purposes.
2. Experimental philosophy
The first edition treated another topic only briefly: the 'negative program' of some 'experimental philosophers' against 'armchair philosophy.' It explained why their talk of 'philosophical intuitions'
failed to pick out a psychologically distinctive kind, and why thought experiments are not cognitively exceptional, as they assumed, but I
did not engage with their texts in much detail.
However, the fashion for experimental philosophy was growing, and I often encountered (and still encounter) surprisingly crude misunderstandings of my objections to the negative program. Do the rejected obsolescent armchair methods include reading a philosophical text carefully and grasping its dialectical structure? In particular, many people took for granted that the book 'defended philosophical intuitions,' when in fact it argued that thinking in terms of philosophical 'intuitions' leads one hopelessly astray. I was also persistently classified as an 'enemy of experimental philosophy,' despite having engaged in it myself (Bonini, Osherson, Viale, and Williamson
1999). Indeed, given the book’s keynote anti-exceptionalism about philosophy, it would have been absurd for me to argue that experimental results are in principle irrelevant to assessing the reliability of a philosophical method. But to assess it properly, you must first understand both what the method is and how it is being applied in particular cases. In practice, proponents of the negative program often – though not always – violated these conditions, either by seeing the methodological issues through the distorting lens of the category
'philosophical intuitions,' or by making sundry naïve or impatient errors in handling the first-order philosophical issues themselves.
The negative program worried me because it had the potential to do serious damage to intellectual standards in philosophy – though its proponents’ intention was undoubtedly the opposite. Of course, no particular thought experiment is above criticism, just as no particular experiment in natural science is above criticism. But the negative program aimed at a much less banal conclusion: roughly, that no thought experiment in philosophy should carry significant weight until its result has been independently endorsed by a large and varied sample of non-philosophers. That is one step towards doing philosophy by opinion poll.
If the negative program were to triumph, its effect would be to drastically impede the use of ordinary examples in philosophy, since each example would require a large and expensive research program over several years to test whether folk worldwide agree that it exemplifies what the philosopher takes it to exemplify (the 'philosophical intuition'). That would constitute a strong disincentive to introducing new examples in the first place, since they could always be neutralized, at least for several years, by the generic demand for such experimental testing. Yet, from Socrates on, in both Western and non-Western philosophy, apt and ingenious ordinary examples have been one of the most effective ways of keeping philosophers honest.
Without them, high-sounding abstract generalities are liable to go unchecked. Examples bring us back down to earth.
But why should not experiments themselves provide an alternative reality-check on philosophical theorizing? The trouble is that experimental philosophers’ experiments do not test most philosophical hypotheses. They test psychological hypotheses as to whether people’s judgments accord with philosophical hypotheses. For example, they do not test the moral hypothesis that it is a wrong to torture a child for fun; they test the psychological hypothesis that most people think that it is wrong to torture a child for fun. Of course, one can derive a moral hypothesis from the psychological hypothesis that most people accept it, given the auxiliary hypothesis that a moral hypothesis is true if most people accept it, but how is the auxiliary hypothesis itself to be tested? One can experimentally test the psychological hypothesis that most people accept the auxiliary hypothesis, but that is just to embark on an infinite regress of auxiliary hypotheses. I have never seen a plausible account of how philosophy would in practice work better (or at least not worse) once reformed in line with the negative program.
Fortunately, within experimental philosophy, the negative program has receded in recent years. Perhaps the main reason has been that many of the original results suggesting variation with ethnicity and gender in verdicts on thought experiments have failed to replicate, when the experiments were repeated to higher standards. In other cases, the experiments were irrelevant because the questions asked of ordinary subjects involved terms (like 'refer') which philosophers use in technical senses. Indeed, to a surprising extent, philosophers’
thought experiments may be tapping into a universal human cognitive system. As one small branch of cognitive psychology, experimental philosophy is well-suited to investigating nuances of the human cognitive system, including how far they are products of nature, how far of culture. For that fruitful inquiry, an animus against thought experiments is merely a source of bias, conscious or otherwise. The five additional sections, 10.1–10.5, on experimental philosophy in this edition are mainly directed against the negative program, to combat the danger it posed to standards of argument in philosophy, although they also consider problems for the category of 'philosophical intuitions' irrespective of the negative program. However, none of this implies any hostility on my part to the general idea that experimentation sometimes plays a legitimate part in philosophical activity.
Reflection on the negative program did help persuade me that, by itself, the method of cases is insufficiently robust. In principle, there is nothing wrong with using thought experiments to learn about possibilities, some of which are counterexamples to philosophical generalizations. Our verdicts on thought experiments are not peculiarly liable to error. But, on the same anti-exceptionalist grounds, they are also not peculiarly immune to error. The general fallibility of human cognitive faculties applies as much to our verdicts on thought experiments as to our judgments in any other sphere. Of course, when a philosopher makes an idiosyncratic mistake, it will probably be picked up by other philosophers. But suppose that some glitch in our cognitive system disposes humans in general to misjudge a specific thought experiment, perhaps because we are unconsciously relying on a usually reliable heuristic which goes wrong in this special case. How will we notice our collective mistake? By hypothesis, in this case there is no significant variation in ethnicity or gender for experimental philosophy to identify. We may thus treat our false judgment as giving us a datum or Moorean fact, which we use as a counterexample to philosophical theories. If the rest of our data come from verdicts on other thought experiments, what is to alert us to our error about this thought experiment? The danger is that we treat the thought experiment as refuting what is in fact the true philosophical theory in the vicinity, sweep it off the table, and never return to it. That is naïve falsificationism at its worst.
A good strategy to deal with this problem is to hedge one’s bets, by using more than one method. Each method acts as a potential corrective to the others. Where different methods converge on the same answer, our acceptance of it is correspondingly more robust.
In particular, we can sometimes use both the case method and the method of model-building, neither having priority over the other. For example, I have used formal models of epistemic logic to argue that knowledge is not equivalent to justified true belief (as epistemologists traditionally use the word 'justified'), the same conclusion normally reached in epistemology by Gettier-style thought experiments. Thus the two methods converge on the same answer.9 Although each method by itself may provide knowledge under normal conditions, in the long run we can expect more reliable results from using two or more methods to explore overlapping aspects of an issue and keep a check on each other.
One kind of normal human judgment about hypothetical cases which may sometimes go systematically wrong concerns conditionals.
In Suppose and Tell: The Semantics and Heuristics of Conditionals
(2020a), I explore what is arguably the primary human heuristic for cognitively assessing conditionals, a procedure which works well under most conditions, allowing us to extract and communicate valuable information stored in our dispositions to judgment about hypothetical cases, which are miniature thought experiments. This procedure is what we use to make judgments for or against the sample 'if' sentences which provide most of the data for semantic and logical theories of conditionals in natural language. However, the heuristic cannot be fully reliable, for it is internally inconsistent. That explains why philosophers and linguists have had so much trouble agreeing on how
'if' works. But the usual methods of experimental philosophy would not bring the limitations of the heuristic to light, if it is indeed a human universal, since all those who apply it are liable to the same errors.
Rather, the heuristic’s inconsistency is demonstrated by logical and 18-08-2021 16:56:35

Preface to the Second Edition   xxiii

mathematical argument. The role of psychological experimentation lies elsewhere: in testing how far humans do indeed rely on that heuristic. That is a task for cognitive psychology, though not specifically for experimental philosophy.
In general, philosophy and cognitive psychology have much to learn from each other about the nature of human thought and its characteristic vices and virtues. Collaborations between philosophers and cognitive psychologists are likely to become increasingly fruitful, and trying to separate philosophy from psychology in the results may often be fruitless. Whether any of that should be described as 'experimental philosophy' is another matter. Anti-exceptionalism about philosophy suggests that the psychology of human philosophical thinking is best understood as just a special case of the psychology of human thinking in general. Schematically: philosophers will have most to bring to their collaboration with psychologists by cultivating their distinctively philosophical skills, not by aping the psychologists, just as psychologists will have most to bring to the collaboration by cultivating their distinctively psychological skills, not by aping the philosophers – though, in a successful collaboration, the philosophers will surely learn lots of psychology and the psychologists lots of philosophy. One reason for the qualifier 'schematically'
is that there is already a continuum between 'pure philosophy' and
'pure psychology,' with different people at home on different points of the continuum. That is as it should be, and as it is on the continua between 'pure philosophy' and 'pure mathematics,' 'pure physics,'
'pure biology,' 'pure computer science,' 'pure linguistics,' 'pure economics,' 'pure history,' and so on. Philosophy has deep natural connections with many other disciplines; to give exclusive privileges to any one of them is to misunderstand the nature of philosophy.10
3. Naturalism
Of philosophers who self-identify as 'naturalists,' the more extreme tend to dismiss The Philosophy of Philosophy as an anti-naturalist tract, while the more moderate tend to wonder why it does not make its implicit naturalism explicit. The first edition defends armchair (See 2018a: 111–26 for brief 'popular' discussions of some close links between philosophy and various other disciplines.) philosophy against extreme naturalistic attacks, while also defending anti-exceptionalism about philosophy as much less different from other sciences in nature and methods than many philosophers like to think. It presents philosophy as an investigation of the same world which other sciences investigate too, and philosophical knowledge as the product of ordinary human cognitive capacities.
As best I can tell, there is an asymmetry between those who regard the book as implicitly naturalist and those who regard it as anti-naturalist: the former are more likely than the latter to have read it. After all, reading a book is an armchair method of learning what it says.
For the front cover of the first edition, I chose Picasso’s 'Portrait of Olga in an Armchair,' because the sitter is a young woman, not the stereotypical philosopher in an armchair – an old man with a long beard and a pipe. The subliminal message was that armchair philosophy is not what you might think it is.
In a very loose sense of the term 'naturalist,' I probably count as one. The trouble is that the term is also often used much more narrowly, for one who takes the natural sciences (physics, chemistry, biology, …) to provide the model which all other attempts at systematic inquiry should emulate in method. By that standard, even mathematics falls short, since it does not use observation or experiment in the intended sense, even though all the natural sciences rely on mathematics. It is the most obvious example of a science which is not a natural science in any distinctive sense. Another example, I
suggest, is philosophy. The reliance on armchair methods is one of the most salient features of both mathematics and philosophy. That is not to deny the relevance of natural science to philosophy, or even to mathematics. It is just to insist that armchair methods have a central role to play in philosophy, and even more obviously in mathematics.
The second edition contains six short additional sections on naturalism, 11.1–11.6. Their main concerns are to separate extremist versions of naturalism from moderate ones, to emphasize the implausibility of the extremist versions, and to show that the moderate
versions are fully compatible with armchair methods.
4. Concepts, understanding, analyticity
Some reactions to the book made me wish that I had been more explicit about my terminology. For example, I often used the words
'concept' and 'conceptual,' but did little to define or clarify them. The reason was that I borrowed those words from my opponents, primarily to articulate their views and arguments – to the effect that philosophy is in some distinctive sense a 'conceptual' activity. I wanted to be fair to my opponents by not defining or clarifying the terms in ways which they might reject. Moreover, such views of philosophy come in numerous sub-varieties, which gloss the words in different ways, as I acknowledged (17, this volume). Since the same forms of argument often worked against different sub-varieties, I used the words 'concept' and 'conceptual' in a somewhat schematic way, to avoid unnecessary repetition.
The upshot of Chapter 4 is that there are no 'conceptual' truths or connections in any sense helpful to my opponents. If one likes, one can define a 'concept' to be the actual or potential meaning of a linguistic expression, which it shares with all synonymous expressions, appealing to whatever standard of sameness in meaning is made available by a well-developed semantic theory. However, I argued that such a standard will be too coarse-grained to serve my opponents’ purposes.
For example, it will not make even the most elementary logical truths
'conceptual' in any distinctive sense. Such conclusions should have made it clear that 'concept' and 'conceptual' were not load-bearing terms in my statements of my own positive views.
A little unwisely, I sometimes also wrote of applying 'concepts'
and of 'conceptual' practices in stating my own views, not only in going along with my opponents’ ways of talking for the sake of argument. I could just as well have written instead of applying words and of linguistic practices. In those cases, the step of abstraction from linguistic expressions to concepts was idle. For instance, all the work can be done by the word 'vixen' and the property of being a vixen, cutting out the useless middle man, the concept vixen.11 In retrospect,
I wish I had stuck to the more perspicuous metalinguistic formulations in stating my own views, and not muddied the waters by sentimentally continuing to employ the term 'concept.'
For similar reasons, it would be more open to replace currently fashionable talk of 'conceptual engineering' by talk of 'linguistic engineering.' After all, our direct conscious and social control is of 18-08-2021 16:56:36

xxvi   Preface to the Second Edition

linguistic practices rather than ways of thinking, and our indirect influence on the latter is typically through the former.12
For some readers, my use of the word 'analytic' was also misleading, since they adhered to its older, historically and etymologically justified sense in which analytic truths are corollaries of conceptual analyses. On that view, 'Vixens are female foxes' is both analytic and a conceptual truth, whereas 'Red shades are not green' is not analytic but may still be a conceptual truth. I followed much current philosophical usage, which treats 'analytic truth' and 'conceptual truth' as interchangeable.
With these health warnings, I have left the terminology of the chapters from the first edition unchanged, since readers may wish to see how I originally put things, for purposes of comparison.
The six short additional sections, 12.1–12.6, are all replies to philosophers who took issue with the book on these topics.
5. Other topics
As a student at Oxford in the 1970s, my exposure to Wittgenstein’s influence helped me build up enough antibodies to resist it for a lifetime (see Section 9.1). Although his influence had greatly declined by the time I wrote the first edition (and has since declined further), he was still too salient a landmark to be ignored in a discussion of philosophical methodology, especially since in some respects my viewpoint stood directly opposite his. Responses to the first edition showed that his ideas were still widespread in the international community of philosophers. The six short additional sections, 13.1–13.6, all reply to philosophers whose approach to the philosophy of philosophy is strongly marked by Wittgenstein’s influence.
In the book, I did not intend to cast Wittgenstein, or anyone else, as the villain of the piece. Obviously, I am no Wittgenstein scholar; I
am happy to leave detailed engagement with his texts to those with more interest in them. My primary interest has been in combating mistaken assumptions about philosophy widely held by living philosophers, without worrying too much about their historical origins.
But philosophers with Wittgensteinian sympathies were strongly represented amongst the authors whom I was invited to respond to or review, perhaps because editors hoped for a lively debate.
12

fpref.indd 26 The final group of additional sections, 14.1–14.6, contains six short pieces which did not fit neatly into any of the previous sections. Two discuss popular philosophy; two reply to critical responses to the first edition; two review books about the nature and value of philosophy.
6. Work published elsewhere
It may be useful to sketch other work in which I have developed themes from the first edition, which has not been included here because it took a more general approach, in either epistemology or the philosophy of language.
Chapter 6 of the first edition analyzed the arguments underlying thought experiments in terms of counterfactual conditionals. The latter were parsed in the traditional way, as the result of applying a twoplace sentential operator to a pair of input sentences, the antecedent and the consequent. The envisaged semantics was of the kind p
 roposed by David Lewis in his classic treatment. This approach involved some awkwardness in formalizing the natural language arguments, specifically in handling the anaphoric dependence of pronouns in the consequent (the judgment about the scenario) on quantified terms in the antecedent (the original description of the scenario). A technical
appendix is devoted to that issue (307–10, this volume). Another technical appendix concerns the derivation of the logic of metaphysical modality within the complex logic of the counterfactual conditional, given definitions of the former in terms of the latter (295–306, this volume). That appendix furthers the book’s anti-exceptionalism: as argued in Chapter 5 of the first edition, philosophers’ metaphysical modality is just a limiting case of counterfactual constructions integral to ordinary, practical thought.
Much more recently, I have come to a quite different view of the semantics of the counterfactual conditional. It is best understood as a contextually restricted strict conditional, the result of composing the contextually restricted local necessity operator 'would' with the ordinary 'if,' read as a material conditional (2020a: 103–58, 166–88).
In place of A◽ →B one has ◽(A ⊃ B), but with ◽ restricted to contextually relevant possible worlds. As a welcome side-effect, this drastically simplifies the treatment of anaphoric relations between antecedent and consequent, since they are no longer separated by a modal operator. It also provides greater flexibility in selecting the contextually relevant worlds to verify the scenario to suit the needs of the thought experiment. Metaphysical necessity becomes a straightforward limiting case of 'would.' The overall effect is to preserve the antiexceptionalist spirit of the original, but in a streamlined and more flexible framework (2020a: 229–41).13
The epistemology of counterfactual conditionals is correspondingly central to the epistemology of philosophers’ thought experiments and modal judgments, in the first edition. It emphasizes the key cognitive role of the imagination in determining what would hold on a counterfactual supposition. On my account of conditionals, our primary heuristic for cognitively assessing conditionals involves suppositional thinking, in a reinterpreted Ramsey test (2020a: 15–88). We apply a derivative form of the heuristic to assess counterfactual conditionals
(2020a: 189–213). I have also explored the general c ognitive function of the imagination more extensively (2016c, 2020c). This work on the cognitive role of supposing and imagining has not been at all specific to philosophical thinking, but subsumes allegedly puzzling aspects of it under much more general forms of human cognition, vindicating the anti-exceptionalist approach.
The first edition uses the role of the imagination in ordinary counterfactual and modal thinking to cast doubt on the idea that the distinction between a priori and a posteriori knowledge cuts at the cognitive or epistemological joints (167–171, this volume). In later work, I have sharpened and deepened that critique of the distinction, and replied to objections to it (2013b, 2021b, 2021c; Boghossian and
Williamson 2020). Again, those arguments are not at all specific to philosophical cognition, but also tend to vindicate anti-exceptionalism about its nature, insofar as it is taken to be a priori.
Chapter 4 of the first edition, on epistemological conceptions of analyticity, originated in a symposium with Paul Boghossian at the
2003 Joint Session of the Aristotelian Society and Mind Association, chaired by Crispin Wright – Paul and I talked at such length that no time was left for Crispin to present his comments; I still feel bad about that. Since then, Paul and I have had a series of further exchanges on understanding, the a priori, and intuition, culminating in our book (Boghossian and Williamson 2020). Section 12.2 is my 18-08-2021 16:56:36

Preface to the Second Edition   xxix

half of one of those exchanges, in a book symposium on the first edition. The later rounds are also relevant to the epistemological arguments of this book, although they are not specific to the epistemology of philosophy.
Chapter 7 of the first edition, on evidence in philosophy, in effect applies the general account of evidence defended in Knowledge and its Limits to the special case of philosophy. I have continued to u
 phold that account of evidence, though usually without special reference to philosophy (2021e).
I have also written for a much wider readership on what philosophy does and how (2018a, 2018d).14
The Preface to the first edition ends with an expression of my
enjoyment in doing philosophy. I am happy to report that, fourteen years later, it continues to provide just as much pleasure.

The present text of the first edition corrects mistakes which escaped my proofreading, on pages 166, 180, and 306: thanks to Andrew Melnyk, Chi-Yen Liu, and David
Etlin respectively. I have silently corrected a few similar mistakes in the added sections.
I have also made various verbal adjustments in the added sections for the sake of smooth reading in the new context of the second edition.

14 This book grew out of a sense that contemporary philosophy lacks a self-image that does it justice. Of the self-images that philosophy
inherited from the twentieth century, the most prominent – naturalism, the linguistic turn, post-modern irony, and so on – seemed obviously inadequate to most of the most interesting work in contemporary philosophy: as descriptions, false when bold, uninformative when cautious.
Less prominent alternatives too seemed implausible or ill-developed.
Although an adequate self-image is not a precondition of all virtue, it helps. If philosophy misconceives what it is doing, it is likely to do it worse. In any case, an adequate self-image is worth having for its own sake; we are not supposed to be leading the unexamined life. This is my attempt to do better.
I considered using the phrase 'philosophical method' in the title, but decided against on the grounds that it seemed to promise something more like a recipe for doing philosophy than I believe possible.
When asked for advice on some occasion, the Duke of Wellington is said to have replied 'Sir, you are in a devilish awkward predicament, and must get out of it as best you can.' My advice would be scarcely more useful. At the crucial point, I can only say 'Use your judgment.'
The primary task of the philosophy of science is to understand science, not to give scientists advice. Likewise, the primary task of the philosophy of philosophy is to understand philosophy, not to give philosophers advice – although I have not rigorously abstained from the latter.
I also rejected the word 'metaphilosophy.' The philosophy of philosophy is automatically part of philosophy, just as the philosophy of anything else is, whereas metaphilosophy sounds as though it might try to look down on philosophy from above, or beyond. One reason for the survival of implausible self-images of philosophy is that they have been insufficiently scrutinized as pieces of philosophy.
Passed down as though they were platitudes, they often embody epistemologically or logically naïve presuppositions. The philosophy of philosophy is no easier than the philosophy of science. And like the philosophy of science, it can only be done well by those with some respect for what they are studying.
The book makes no claim to comprehensiveness. For example, it does not engage in detail with critics of analytic philosophy who do not engage with it in detail. I preferred to follow a few lines of thought that I found more rewarding. I hope that philosophy as I
have presented it seems worth doing and not impossibly difficult. At any rate, I enjoy it. 18-08-2021 16:56:36

Acknowledgments

First come the acknowledgments from the first edition. My three
Blackwell/Brown lectures, given at Brown University in September
2005, constituted the occasion for the book, although the material had evolved considerably since then. I thank both Blackwell Publishing and Brown University for the invitation and their generous hospitality. Jeff Dean at Blackwell was a helpful and supportive editor.
My further debts of gratitude are huge. An earlier version of some of the material was presented as the Jack Smart Lecture at the Australian National University in July 2005. Various later versions were presented as four Anders Wedberg Lectures at the University of Stockholm in April 2006, where the commentators were Kathrin GlüerPagin, Sören Häggqvist, Anna-Sara Malmgren, and Åsa Wikforss, as eight José Gaos Lectures at the Instituto de Investigaciones Filosóficas of the Universidad Nacional Autónoma de Mexico in September–October 2006, and as three Carl G. Hempel Lectures at Princeton University in December 2006. Other occasions on which the material in one form or another came under scrutiny included a week-long graduate course at the University of Bologna in May–June 2005, a week-long Kompaktseminar at the University of Heidelberg in February 2006, three lectures I gave as the Townsend Visitor in Philosophy at the University of California, Berkeley, in September 2006, a lecture and workshop at the University of Munich in June 2005, two lectures
I gave as Tang Chun-I Visiting Professor at the Chinese University of Hong Kong in March 2007, and lectures at a graduate conference on epistemology at the University of Rochester in September
2004, where Richard Feldman was the commentator, the University of Arizona, Tucson, and the University of California, Los Angeles, and a meeting of the Aristotelian Society (my Presidential Address)
in October 2004, a workshop on the epistemology of philosophy at the University of Bristol in May 2005, a conference on philosophical methodology at the Research School of Social Sciences at the Australian National University in July 2005, a conference on philosophical knowledge in Erfurt, and at Rutgers University in September 2005, the University of Warwick in November 2005, an Arché workshop on modality at the University of St. Andrews in December 2005, a workshop on metaphysics at the University of Nottingham in January 2006, the first conference of the Dutch-Flemish Society for Analytic Philosophy at the University of Amsterdam and the University of Leeds in March 2006, the Universities of Turin and Milan, the
'Is there anything wrong with Wittgenstein?' conference in Reggio
Emilia and the third conference of the Portuguese Society for Analytic Philosophy at the University of Lisbon in June 2006, the Joint
Session of the Aristotelian Society and the Mind Association at the
University of Southampton in July 2006 (my address as President of the Mind Association), the GAP.6 conference of the German Society for Analytic Philosophy and the subsequent workshop on Implicit
Definitions and A Priori Knowledge, where Frank Hofmann was the commentator, at the Free University of Berlin in September 2006, the
University of Santiago de Compostela in November 2006, the Massachusetts Institute of Technology and the Eastern Division meeting of the American Philosophical Association, for which Gillian Russell was the commentator, in December 2006, the Royal Institute of Philosophy and the University of Calgary in February 2007, and the University of Cambridge in June 2007. I presented still earlier versions of the ideas at a workshop on intuition and epistemology at the University of Fribourg, where Manuel García Carpintero was the commentator, a conference on modalism and mentalism in contemporary epistemology hosted by Aarhus University at the Carlsberg Academy in Copenhagen, a conference in the Centre for Advanced Studies at the Norwegian Academy of Science and Letters in Oslo, which also hosted me for a term of leave in the summer of 2004, a workshop at the University of Amiens on John Cook Wilson and Oxford realism, a conference on externalism, phenomenology, and understanding in memory of Greg McCulloch at the Institute of Philosophy in the
University of London’s School of Advanced Study, a summer school on epistemology at the Sorbonne, and a conference on meaning and truth at St. Andrews, and talks at the universities of Bilkent, Edinburgh, Michigan, Minnesota, Padua, Rijeka, and Stirling. Most of the material had also been presented in classes and discussion groups at
Oxford. Much of the development of themes in this book was provoked by reflection on the questions and objections raised on those occasions. It would be hopeless to try to enumerate the questioners and objectors, but they may be able to trace their influence.
Those who had helped with discussion or written comments outside the occasions above include Alexander Bird, Stephan Blatti,
Davor Bodrožić, Berit Brogaard, Earl Conee, Keith DeRose, Dorothy Edgington, Pascal Engel, Tamar Szabó Gendler, Olav Gjelsvik,
John Hawthorne, Thomas Kroedel, Brian Leftow, Brian Leiter, Peter
Lipton, Ofra Magidor, Mike Martin, Nenad Miščević, Michael Pendlebury, Oliver Pooley, Gonzalo Rodriguez-Pereyra, Helge Rückert,
Joe Salerno, Laura Schroeter, Nico Silins, Jason Stanley, Scott Sturgeon, Hamid Vahid, Alberto Voltolini, and Ralph Wedgwood. John
Hawthorne, Joshua Schechter, and two referees read the book in manuscript and provided comments on which I drew extensively during the final revisions.
That list of acknowledgments is undoubtedly incomplete: special thanks to those who have been undeservedly omitted.
The book was based on a series of articles in which earlier versions of the ideas were formulated, although hardly any pages have survived completely unchanged. Chapters 1 and 2 derive from 'Past the Linguistic Turn?,' in The Future for Philosophy, edited by Brian Leiter
(Oxford: Oxford University Press, 2004), pp. 106–28. Most of Chapter 3 was new. The first section of Chapter 3 and much of Chapter 4
constitute an expanded version of 'Conceptual Truth,' Aristotelian
Society, supplementary volume 80 (2006), pp. 1–41, with much subsequent material (for example, on tacit knowledge and on normative conceptions of analyticity); the germ is to be found in 'Understanding and Inference,' Aristotelian Society, supplementary volume 77 (2003), pp. 249–93. Chapters 5 and 6 derive from an initial sketch in my
Presidential Address to the Aristotelian Society, 'Armchair Philosophy,
Metaphysical Modality and Counterfactual Thinking,' Proceedings of the Aristotelian Society, volume 105 (2005): 1–23. An intermediate step on the way to Chapter 5 was 'Philosophical Knowledge and
Knowledge of Counterfactuals,' Grazer Philosophische Studien, volume 74 (2007): 89–123, also appearing as P
 hilosophical Knowledge – Its Possibility and Scope, edited by Christian Beyer and Alex
Burri (Amsterdam: Rodopi, 2007), the proceedings of the Erfurt conference on philosophical knowledge. Chapters 7 and 8 derive from
'Philosophical ‘Intuitions’ and Scepticism about Judgement,' Dialectica 58 (2004), pp. 109–53; the volume constitutes the proceedings of the workshop on intuition and epistemology at the University of Fribourg, Switzerland, in November 2002 (the talk I gave there is not recognizable in this book; I gave it to make myself think seriously about the topic). Chapter 7 in particular was greatly expanded; sections 1
and 7 were new; the probabilistic material in section 4 was expanded from pp. 683–5 of 'Knowledge and Scepticism,' The Oxford Handbook of Contemporary Philosophy, edited by Frank Jackson and Michael Smith, (Oxford: Oxford University Press, 2005), pp. 681–700.
The Afterword is a slightly modified version of 'Must Do Better,' in
Truth and Realism, edited by Patrick Greenough and Michael Lynch
(Oxford: Oxford University Press: 2006), pp. 177–87; that volume constitutes the proceedings of the St. Andrews conference on meaning and truth.
The enlarged edition reprints the following previously published pieces, sometimes rearranged; for each, I was the sole author and all required permissions have been obtained, which I hereby acknowledge: 'Replies to Kornblith, Jackson and Moore,' Analysis Reviews,
69 (2009): 125–35; 'Replies to Ichikawa, Martin and Weinberg,'
Philosophical Studies, 145 (2009): 465–76; 'Plato Goes Pop,' Times
Literary Supplement, 5529 (2009): 15; review of Robert Brandom,
Reason in Philosophy, Times Literary Supplement, 5579 (2010):
22–3; 'Philosophical Expertise and the Burden of Proof,' Metaphilosophy, 42 (2011): 215–29; 'Reply to Peacocke,' 'Reply to Boghossian,' 'Reply to Stalnaker,' and 'Reply to Horwich,' Philosophy and
Phenomenological Research, 82 (2011): 481–7, 498–506, 515–23, and 534–42 respectively; 'Three Wittgensteinians and a Naturalist on
The Philosophy of Philosophy,' in Richard Davies (ed.), Analisi: Annuario e Bollettino della Società Italiana di Filosofia Analitica (SIFA)
2011, Milan: Mimesis (2011), 127–37; 'What is Naturalism?' and
'The Unclarity of Naturalism' in Matthew Haug (ed.), Philosophical
Methodology: The Armchair or the Laboratory?, London: Routledge
(2013): 29–31 and 36–8 respectively; review of Joshua Alexander,
Experimental Philosophy: An Introduction, Philosophy, 88 (2013):
467–74; 'Replies to Trobok, Smokrović, and Miščević on the Philosophy of Philosophy,' Croatian Journal of Philosophy, 13 (2013):
49–64; review of Paul Horwich, Wittgenstein’s Metaphilosophy,  uropean Journal of Philosophy, 21 (2013): e7–e10; 'How Did We
E
Get Here From There? The Transformation of Analytic Philosophy,'
Belgrade Philosophical Annual, 27 (2014): 7–37; review of Peter
Unger, Empty Ideas: A Critique of Analytic Philosophy, Times Literary Supplement, 5833 (2015): 22–3; 'Abductive Philosophy,' Philosophical Forum, 47 (2016): 263–80; 'Philosophical Criticisms of
Experimental Philosophy,' in Justin Sytsma and Wesley Buckwalter
(eds.), A Companion to Experimental Philosophy, Oxford: Wiley
Blackwell (2016): 22–36; 'Model-building in Philosophy,' in Russell Blackford and Damien Broderick (eds.), Philosophy’s Future: The
Problem of Philosophical Progress, Oxford: Wiley-Blackwell (2017):
159–73; review of Penelope Maddy, What Do Philosophers Do?
Skepticism and the Practice of Philosophy, Journal of Philosophy, 114
(2017): 492–7; 'Morally Loaded Cases in Philosophy,' Proceedings and Addresses of the American Philosophical Association, 93 (2019):
159–72; 'Reply to Dennett, Knobe, Kuznetsov, and Stoljar on Philosophical Methodology,' Epistemology and Philosophy of Science, 56
(2019): 46–52; 'Popular Philosophy and Populist Philosophy,' Daily
Nous (2020), http://dailynous.com/2020/06/08/popular-philosophypopulist-philosophy-guest-post-timothy-williamson. Many of those pieces were indebted to various philosophers for their feedback. They are acknowledged at the relevant places in the text, since that is more informative.
I thank Marissa Koors, the acquisitions editor at Wiley-Blackwell, for first suggesting an expanded edition of the book to me, and for her patience, flexibility, and enthusiasm in facilitating its implementation, and Charlie Hamlyn, also at Wiley-Blackwell, for his detailed help in the later stages of the project.
Finally, as in the first edition, thanks above all to my wife Ana, who still does not let me forget what matters. 18-08-2021 16:18:07

Part I
Introduction 18-08-2021 15:04:00

Introduction

What can be pursued in an armchair?
Every armchair pursuit raises the question whether its methods are adequate to its aims. The traditional methods of philosophy are armchair ones: they consist of thinking, without any special interaction with the world beyond the chair, such as measurement, observation or experiment would typically involve. To do justice to the social and not solely individual nature of philosophy, as a dialectic between several parties, we should add speaking and listening to thinking, and allow several armchairs, within earshot of each other, but methodologically that brings philosophy little closer to the natural sciences. For good or ill, few philosophers show much appetite for the risky business of making predictions and testing them against observation, whether or not their theories in fact have consequences that could be so tested. Without attempting to define the terms precisely, we may put the difference to a first approximation thus: the current methodology of the natural sciences is a posteriori; the current methodology of philosophy is a priori. What should we make of this difference?
Opposite reactions are possible. Crude rationalists regard philosophy’s a priori methodology as a virtue. According to them, it makes philosophical results especially reliable, because immune from perceptual error. Crude empiricists regard philosophy’s a priori methodology as a vice. According to them, it makes philosophical results especially unreliable, because immune from perceptual correction.
Few contemporary philosophers have the nerve to be crude rationalists. Given the apparent absence of a substantial body of agreed results in philosophy, crude rationalism is not easy to maintain. Many contemporary philosophers have some sympathy for crude empiri- Introduction

cism, particularly when it goes under the more acceptable name of
'naturalism.' However, that sympathy sometimes has little effect on their philosophical practice: they still philosophize in the grand old manner, merely adding naturalism to their list of a priori commitments.
A subtler response to naturalism, or empiricism, is to scale down the ambitions of philosophy. Holding fixed its a priori methodology, one asks what it could be good for. Not for answering ordinary factual questions, it is claimed: that is best left to the natural sciences with their a posteriori methodology. Nevertheless, what we already have in the armchair is the intellectual equipment we bring to a posteriori inquiry, our conceptual or linguistic competence. Perhaps philosophy can find some sort of legitimate employment by investigating, from within, what we bring to inquiry. Rather than trying to answer ordinary factual questions, it seeks to understand the very possibility of asking them – in some way, yet to be properly specified, that does not involve asking ordinary factual questions about the possibility of asking ordinary factual questions. The 'linguistic turn'
in twentieth-century philosophy comprises a variety of attempts in that general spirit. Since confinement to an armchair does not deprive one of one’s linguistic competence, whatever can be achieved through exercise of that competence and reflection thereon will be a feasible goal for philosophy. If one regards thought as constituting a more fundamental level of analysis than language, one may generalize the linguistic turn to the 'conceptual turn,' and consider what can be achieved through exercise of our conceptual competence and reflection thereon, but the outcome will be broadly similar: philosophical questions turn out to be in some sense conceptual questions.
Crude rationalists, crude empiricists, and linguistic or conceptual philosophers (those who take the linguistic or conceptual turn) share a common assumption: that the a priori methodology of philosophy is profoundly unlike the a posteriori methodology of the natural sciences; it is no mere difference between distinct applications of the same underlying methodology. One apparently distinctive feature of current methodology in the broad tradition known as 'analytic philosophy' is the appeal to intuition. Crude rationalists postulate a special knowledge-generating faculty of rational intuition. Crude empiricists regard 'intuition' as an obscurantist term for folk prejudice, a psychological or social phenomenon that cannot legitimately constrain truth-directed inquiry. Linguistic or conceptual philosophers treat intuitions more sympathetically, as the deliverances of linguistic or conceptual competence. Of course, the appeal to intuitions also plays a crucial role in the overt methodology of other disciplines too, such as linguistics.
One main theme of this book is that the common assumption of philosophical exceptionalism is false. Even the distinction between the a priori and the a posteriori turns out to obscure underlying similarities. Although there are real methodological differences between philosophy and the other sciences, as actually practiced, they are less deep than is often supposed. In particular, so-called intuitions are simply judgments (or dispositions to judgment); neither their content nor the cognitive basis on which they are made need be distinctively philosophical. In general, the methodology of much past and present philosophy consists in just the unusually systematic and unrelenting application of ways of thinking required over a vast range of non-philosophical inquiry. The philosophical applications inherit a moderate degree of reliability from the more general cognitive patterns they instantiate. Although we cannot prove, from a startingpoint a sufficiently radical skeptic would accept, that those ways of thinking are truth-conducive, the same holds of all ways of thinking, including the methods of natural science. That is the skeptic’s problem, not ours. By more discriminating standards, the methodology of philosophy is not in principle problematic.
Some may wonder whether philosophy has a method to be studied, especially if it is as methodologically undistinctive as just suggested.
Forget the idea of a single method, employed in all and only philosophical thinking. Still, philosophers use methods of various kinds: they philosophize in various ways. A philosophical community’s methodology is its repertoire of such methods. The word 'method'
here carries no implication of a mechanically applicable algorithm, guaranteed to yield a result within a finite time. On this loose understanding of what a methodology is, it is disingenuous for a philosopher to claim to have none.
Another main theme of this book is that the differences in subject matter between philosophy and the other sciences are also less deep than is often supposed. In particular, few philosophical questions are conceptual questions in any distinctive sense, except when philosophers choose to ask questions about concepts, as they may but need Introduction

not do. Philosophical questions are those philosophers are disposed to ask, which in turn tend, unsurprisingly, to be those more amenable to philosophical than to other ways of thinking; since the philosophical ways of thinking are not different in kind from the other ways, it is equally unsurprising that philosophical questions are not different in kind from other questions. Of course, philosophers are especially fond of abstract, general, necessary truths, but that is only an extreme case of a set of intellectual drives present to some degree in all disciplines.
In most particular cases, philosophers experience little difficulty in recognizing the difference between philosophy and non-philosophy.
Being philosophers, they care about the difference, and have a professional temptation to represent it as a deep philosophical one. But just about every institutionally distinct discipline acquires a professional identity, and its practitioners experience little difficulty in recognizing the difference between what 'we' do and what 'they' do in most particular cases. They care about the difference, and have a professional temptation to represent it in the terms of their own discipline.
But such temptations can be resisted. The distinction between the
Department of Philosophy and the Department of Linguistics or the Department of Biology is clearer than the distinction between philosophy and linguistics or biology; the philosophy of language overlaps the semantics of natural languages and the philosophy of biology overlaps evolutionary theory.
The unexceptional nature of philosophy is easier to discern if we avoid the philistine emphasis on a few natural sciences, often imagined in crudely stereotyped ways that marginalize the role of armchair methods in those sciences. Not all science is natural science. Whatever crude empiricists may say, mathematics is a science if anything is; it is done in an armchair if anything is. In no useful sense are mathematical questions conceptual questions. If mathematics is an armchair science, why not philosophy too?
Most philosophers are neither crude rationalists nor crude empiricists nor, these days, linguistic or conceptual philosophers. Many would accept the theses just enunciated about the methodology and subject matter of philosophy. But a third theme of this book is that the current philosophical mainstream has failed to articulate an adequate philosophical methodology, in part because it has fallen into the classic epistemological error of psychologizing the data. For example, our evidence is sometimes presented as consisting of our intuitions: not their content, since it is allowed that some of our intuitions may be false, but rather our psychological states of having those intuitions. We are then supposed to infer to the philosophical theory that best explains the evidence. But since it is allowed that philosophical questions are typically not psychological questions, the link between the philosophical theory of a non-psychological subject matter and the psychological evidence that it is supposed to explain becomes problematic: the description of the methodology makes the methodology hard to sustain. Again, philosophy is often presented as systematizing and stabilizing our beliefs, bringing them into reflective equilibrium: the picture is that in doing philosophy what we have to go on is what our beliefs currently are, as though our epistemic access were only to those belief states and not to the states of the world that they are about. The picture is wrong; we frequently have better epistemic access to our immediate physical environment than to our own psychology. A popular remark is that we have no choice but to start from where we are, with our current beliefs. But where we are is not only having various beliefs about the world; it is also having significant knowledge of the world. Starting from where we are involves starting from what we already know, and the goal is to know more (of course, how much more we come to know cannot be measured just by the number of propositions learnt). To characterize our method as one of achieving reflective equilibrium is to fail to engage with epistemologically crucial features of our situation. Our understanding of philosophical methodology must be rid of internalist preconceptions.
Philosophical errors distort our conception of philosophy in other ways too. Confused and obscure ideas of conceptual truth create the illusion of a special domain for philosophical investigation. Similarly, although perception clearly involves causal interaction between perceiver and perceived, crudely causal accounts of perceptual knowledge that occlude the contribution of background theory create the illusion of a contrast between world-dependent empirical beliefs and world-independent philosophical theory.
Clearly, the investigation of philosophical methodology cannot and should not be philosophically neutral. It is just more philosophy, Introduction

turned on philosophy itself. We have the philosophy of mathematics, the philosophy of physics, the philosophy of biology, the philosophy of economics, the philosophy of history; we also need the philosophy of philosophy.
The rethinking of philosophical methodology in this book involves understanding, at an appropriate level of abstraction, how philosophy is actually done. Philosophers of science know the dangers of moralizing from first principles on how a discipline should ideally be pursued without respecting how it currently is pursued; the same lesson applies to the philosophy of philosophy. The present opposition to philosophical exceptionalism is far from involving the idea that philosophers should model themselves on physicists or biologists. The denial that philosophical questions are conceptual questions is quite compatible with a heavy emphasis on issues of semantic structure in philosophical discussion, for the validity or otherwise of philosophical reasoning is often highly sensitive to delicate aspects of the semantic structure of premises and conclusion: to make our reasoning instruments more reliable, we must investigate those instruments themselves, even when they are not the ultimate objects of our concern.
That philosophy can be done in an armchair does not entail that it must be done in an armchair.1 This book raises no objection to the idea that the results of scientific experiments are sometimes directly relevant to philosophical questions: for example, concerning the philosophy of time. But it is a fallacy to infer that philosophy can nowhere usefully proceed until the experiments are done. In this respect, philosophy is similar to mathematics. Scientific experiments can be relevant to mathematical questions. For instance, a physical theory may entail that there are physically instantiated counterexamples to a mathematical theory. A toy example: one can specify in physical terms what it takes to be an inscription (intended or unintended) in a given font of a proof of '0 = 1' in a given formal system of Peano Arithmetic; a physical theory could predict that an event of a specified physically possible type would cause there to be In this respect Hilary Kornblith seems to misunderstand the claim that philosophy can be done in an armchair (2006: 19). I have even dabbled in experimental philosophy myself (Bonini, Osherson, Viale and Williamson 1999). such an inscription. Less directly, psychological experiments might in principle reveal levels of human unreliability in proof-checking that would undermine current mathematical practice. To conclude on that basis alone that mathematics should become an experimental discipline would be hopelessly naïve. In practice, most of mathematics will and should remain an armchair discipline, even though it is not in principle insulated from experimental findings, because armchair methods, specifically proof, remain by far the most reliable and efficient available. Although the matter is less clear-cut, something similar may well apply to many areas of philosophy, for instance, philosophical logic. In particular, on the account in this book, the method of conducting opinion polls among non-philosophers is not very much more likely to be the best way of answering philosophical questions than the method of conducting opinion polls among nonphysicists is to be the best way of answering physical questions.
Although this book is a defense of armchair philosophy, it is not written in a purely conservative spirit. Our ideas about philosophical methodology, however inchoate, are liable to influence the methodology we actually employ; bad ideas about it are liable to tilt it in bad directions. A reasonable hypothesis is that our current methodology is good enough to generate progress in philosophy, but not by much: ten steps forward, nine steps back. Nevertheless, we can improve our performance even without radically new methods. We need to apply the methods we already have with more patience and better judgment. A small increase in accuracy of measurement may enable scientists to tackle problems previously beyond reach, because their data lacked sufficient resolution. Similarly, small improvements in accepted standards of reasoning may enable the philosophical community to reach knowledgeable agreement on the status of many more arguments. Such incremental progress in philosophical methodology is a realistic prospect, for current standards in the profession exhibit large variations significantly correlated with differences between graduate schools. Philosophical methodology can be taught – mainly by example, but fine-tuning by explicit precept and discussion also makes a difference. For instance, the level of rigor in philosophical statement and argument which Frege achieved only by genius (with a little help from his mathematical training) is now available to hundreds of graduate students every year: and we know how to do even better.
That is not to imply, of course, that we must strive for maximum rigor at all times, otherwise this impressionistic introduction would be self-defeating. At any rate, if the philosophical community has the will, it can gradually bring up a much higher proportion of practice to the standard of current best practice, and beyond. Such progress in methodology cannot be relied on to happen automatically; not all of us love the highest at first sight. Although the envisaged incremental progress lacks the drama after which some philosophers still hanker, that hankering is itself a symptom of the intellectual immaturity that helps hold philosophy back. No revelation is at hand; any improvement in accepted standards of philosophical discussion will result from collective hard work and self-discipline. One hope with which this book is written is that by contributing to the current tendency towards increasing methodological self-consciousness in philosophy it will play some role, however indirect, in raising those standards. Philosophizing is not like riding a bicycle, best done without thinking about it – or rather: the best cyclists surely do think about what they are doing.
This book is an essay. It makes no claim to comprehensiveness. It does not attempt to compile a list of philosophical methods, or of theories about philosophical methods. It touches on historical matters only glancingly. Instead, it explores some interrelated issues that strike me as interesting and not well understood. It starts by inquiring into the nature of philosophical questions. It proceeds in part by detailed case studies of particular examples. Since all examples have their own special characteristics, generalizations from them must be tentative. But many long-standing misconceptions in philosophy are helped to survive by an unwillingness to look carefully and undogmatically at examples, sometimes protected by a self-righteous image of oneself and one’s friends as the only people who do look carefully and undogmatically at examples (some disciples of the later Wittgenstein come to mind).
It is difficult to displace one philosophical picture except by another.
Although discussion of philosophical methodology is itself part of philosophy, it is less often conducted with a clear view of the theoretical alternatives than is usual in philosophy. David Lewis once wrote that 'what we accomplish in philosophical argument' is to
'measure the price' of maintaining a philosophical claim; when his remark is cited as an obvious truth, it tends not to be noticed that it too is subject to philosophical argument, and has its price – not least

Introduction 11 1
The Linguistic Turn and the Conceptual Turn

The Linguistic Turn is the title of an influential anthology edited by
Richard Rorty, published in 1967. He credited the phrase to Gustav
Bergmann (Bergmann 1964: 3; Rorty 1967: 9). In his introduction,
Rorty (1967: 3) explained:
The purpose of the present volume is to provide materials for reflection on the most recent philosophical revolution, that of linguistic philosophy. I shall mean by 'linguistic philosophy' the view that philosophical problems are problems which may be solved (or dissolved) either by reforming language, or by understanding more about the language we presently use.

'The linguistic turn' has subsequently become the standard vague phrase for a diffuse event – some regard it as the event – in twentiethcentury philosophy, one not confined to signed-up linguistic philosophers in Rorty’s sense. For those who took the turn, language was somehow the central theme of philosophy.
The word 'theme' is used with deliberate vagueness. It does not mean 'subject matter,' for the linguistic turn was not the attempted reduction of philosophy to linguistics. The theme of a piece of music is not its subject matter. Those who viewed philosophy as an activity of dispelling confusions of linguistic origin did not see it as having a subject matter in the sense in which a science has a subject matter.
But merely to regard linguistic analysis as one philosophical method among many is not yet to have taken the linguistic turn, for it is not yet to regard language as central. We will be more precise below.
There is an increasingly widespread sense that the linguistic turn is past. We will ask how far the turn has been, or should be, reversed. Language has been regarded as central to philosophy in many different ways, which cannot all be treated together. A history of the many different forms that the linguistic turn took would be a history of much of twentieth-century philosophy. That is a task for another book, by another author. Self-indulgently, I will use a thin slice through history to introduce the contemporary issues by briefly considering some of my predecessors in the Wykeham Chair of Logic at
Oxford.
A. J. Ayer was the first holder of the Chair to take the linguistic turn.1 In 1936, back from Vienna and its Circle but not yet in the
Chair, he announced an uncompromisingly formal version of linguistic philosophy:
[T]he philosopher, as an analyst, is not directly concerned with the physical properties of things. He is concerned only with the way in which we speak about them. In other words, the propositions of philosophy are not factual, but linguistic in character – that is, they do not describe the behaviour of physical, or even mental, objects; they express definitions, or the formal consequences of definitions. (Ayer
1936: 61–2)

Ayer traced his views back ultimately to the empiricism of Berkeley and Hume (Ayer 1936: 11). His contrast between definitions of words and descriptions of objects is, roughly, the linguistic analogue of Hume’s contrast between relations of ideas and matters of fact.
For an empiricist, the a priori methods of philosophy cannot provide us with knowledge of synthetic truths about matters of fact ('the behaviour of physical, or even mental, objects'); they yield only analytic truths concerning relations of ideas ('definitions, or the formal consequences of definitions'). A rather traditional empiricism later overshadowed the linguistic theme in Ayer’s work.
Ayer was the predecessor of Sir Michael Dummett in the Wykeham
Chair. Dummett gave a much-cited articulation of the linguistic turn, attributing it to Frege:
Only with Frege was the proper object of philosophy finally established: namely, first, that the goal of philosophy is the analysis of the
1

Ayer’s three immediate predecessors were John Cook Wilson, H. H. Joachim and
H. H. Price. The Linguistic Turn and the Conceptual Turn structure of thought; secondly, that the study of thought is to be sharply distinguished from the study of the psychological process of thinking; and, finally, that the only proper method for analysing thought consists in the analysis of language. . . . [T]he acceptance of these three tenets is common to the entire analytical school. (Dummett
1978: 458)

On this view, thought is essentially expressible (whether or not actually expressed) in a public language, which filters out the subjective noise, the merely psychological aspects of thinking, from the intersubjective message, that which one thinks. Dummett’s own corpus constitutes one of the most imposing monuments of analytic philosophy as so defined. Unlike Ayer, he does not describe philosophical claims as definitions. Unlike Rorty, he characterizes the linguistic turn as involving distinctive claims about the subject matter of philosophy, not only about its method. On Dummett’s view, Frege’s insight replaced epistemology by philosophy of language as first philosophy.
But this methodological innovation is supposed to be grounded in the account of the proper object of philosophy.
Elsewhere, Dummett makes clear that he takes this concern with language to be what distinguishes 'analytical philosophy' from other schools (1993: 4). His account of its inception varies slightly. At one points (1993: 5), he says: '[A]nalytical philosophy was born when the ‘linguistic turn’ was taken. This was not, of course, taken uniformly by any group of philosophers at any one time: but the first clear example known to me occurs in Frege’s Die Grundlagen der
Arithmetik of 1884.' Later (1993: 27), we read: 'If we identify the linguistic turn as the starting-point of analytical philosophy proper, there can be no doubt that, to however great an extent Frege,
Moore and Russell prepared the ground, the crucial step was taken by Wittgenstein in the Tractatus Logico-Philosophicus of 1922.'
Presumably, in Frege the linguistic turn was a fitful insight, in
Wittgenstein, a systematic conception.
That 'analytical philosophers' in Dummett’s sense coincide with those usually classified as such is not obvious. Some kind of linguistic turn occurred in much of what is usually called 'continental [supposedly non-analytic] philosophy.' That Jacques Derrida did not subscribe in his own way to Dummett’s three tenets is unclear: if some stretching of terms is required, it is for the later Wittgenstein too. Conversely, Bertrand Russell did not subscribe to the three tenets, although often cited as a paradigm 'analytical philosopher.'
Over the past 20 years, fewer and fewer of those who would accept the label 'analytic philosophy' for their work would also claim to take the linguistic turn (I am not one of those few). Even philosophers strongly influenced by Dummett, such as Gareth Evans, Christopher
Peacocke, and John Campbell, no longer give language the central role he describes. For Dummett, they belong to a tradition that has grown out of 'analytical philosophy' without themselves being
'analytical philosophers' (1993: 4–5). In effect, they aimed to analyze thought directly, without taking a diversion through the analysis of language. In the 1980s it became commonplace in some circles to suggest that the philosophy of mind had displaced the philosophy of language in the driving seat of philosophy.
For philosophers of mind who accepted Jerry Fodor’s (1975) influential hypothesis of a language of thought, the priority of thought to public language did not imply the priority of thought to all language, since thought itself was in a language, the brain’s computational code. In principle, someone might combine that view with Dummett’s three tenets of analytic philosophy, contrary to Dummett’s intention; he did not mean a private language. Moreover, the first-personal inaccessibility of the language of thought makes such a version of the linguistic turn methodologically very different from the traditional ones.
For those who deny the methodological priority of language to thought, the minimal fallback from Dummett’s three tenets is to reject the third but maintain the first two. They assert that the goal of philosophy is the analysis of the structure of thought, and that the study of thought is to be sharply distinguished from the study of the psychological process of thinking, but deny that the only proper method for analysing thought consists in the analysis of language. If thought has constituents, we may call them 'concepts.' On this view, concepts take the place of words in Dummett’s analytical philosophy.
In practice, linguistic philosophers were often happy enough to speak of concepts rather than words, for they regarded a concept as what synonymous expressions had in common; their primary interest was in the features common to synonyms, not in the differences between them. It is therefore not too misleading to describe as conceptual philosophers those who accept Dummett’s first two tenets – The Linguistic Turn and the Conceptual Turn

that the goal of philosophy is the analysis of the structure of thought, and that the study of thought is to be sharply distinguished from the study of the psychological process of thinking – whether or not they accept the third. We may also describe them as doing conceptual philosophy, and as having taken the conceptual turn.
The conceptual turn constitutes a much broader movement than the linguistic turn. It is neutral over the relative priority of language and thought. We think and talk about things – truly or falsely depending on whether they are or are not as we think or say they are. The aboutness of thought and talk is their intentionality; the conceptual turn puts intentionality at the centre of philosophy. This terminology indicates how little the conceptual turn is confined to what would ordinarily be called 'analytic philosophy.' The phenomenological tradition may constitute another form of the conceptual turn. In the hermeneutic study of interpretation and various shades of postmodernist discourse about discourse the conceptual turn takes a more specifically linguistic form.
Have we stretched our terms so far that all philosophy is conceptual philosophy? No. On a natural view, concepts constitute only a small fraction of a largely mind-independent reality. That the goal of philosophy is in some sense to analyze that small fraction is no platitude. To put it very schematically, let absolute idealism about the subject matter of philosophy be the view that philosophy studies only concepts, in contrast to ontological absolute idealism, the wilder view that only concepts exist.2 Although absolute idealism about the subject matter of philosophy does not entail ontological absolute idealism, why should we accept absolute idealism about the subject matter of philosophy if we reject ontological absolute idealism? Of course, we might reject absolute idealism about the subject matter of philosophy while nevertheless holding that the correct method for philosophy is to study its not purely conceptual subject matter by studying concepts of that subject matter. This methodological claim will be considered later; for present purposes, we merely note how much weaker it is than those formulated by Ayer and Dummett.
The claim that concepts constitute only a small fraction of reality might be opposed on various grounds. Recall that concepts were
2

The 'absolute' is to distinguish these forms of idealism from the corresponding
'subjective' forms, in which concepts are replaced by psychological processes. defined as the constituents of thought. If thought consists of Russellian propositions, complexes of the objects, properties, relations, and other elements of reality the proposition is about, then those objects, properties, relations, and other elements of reality are by definition concepts. In that case, ontological absolute idealism may be a triviality, because whatever exists is a constituent of various Russellian propositions, and thereby counts as a concept. However, even conceptual philosophers who accept the Russellian view of propositions will distinguish conceptual structure, the structure characteristic of propositions, from other sorts of structure. For example, they will analyze the atomic proposition that this crystal is translucent as the object-property complex 〈this crystal, translucency〉, but they will not regard it as any of their business to analyze the structure of the crystal itself: that is chemical structure, not conceptual structure in the relevant sense, otherwise the proposition would not be atomic. Their goal for philosophy – to analyze the structure of thought – is still only to analyze one sort of structure among many. Thus one might accept the Russellian view of propositions and still oppose the conceptual turn, on the grounds that philosophy can appropriately investigate general features of nonconceptual structure too, such as the general mereological structure of physical objects.
Alternatively, take a more standard view of concepts, as something like modes of presentation, ways of thinking or speaking, or intellectual capacities. Still, the claim that concepts constitute only a small fraction of reality might be accused of violating Dummett’s second tenet by confusing thought with the process of thinking. Almost everyone agrees that psychological events constitute only a small fraction of reality, but that is not yet to concede that thought in a non-psychologistic sense is similarly confined. John McDowell (1994:
27), for instance, argues:3
[T]here is no ontological gap between the sort of thing one can mean, or generally the sort of thing one can think, and the sort of thing that can be the case. When one thinks truly, what one thinks is what is the
3

Although McDowell is sometimes classified as a 'post-analytic' philosopher, he finds his own way to accept Dummett’s 'fundamental tenet of analytical philosophy,'
that 'philosophical questions about thought are to be approached through language'
(1994: 125). The Linguistic Turn and the Conceptual Turn case. So since the world is everything that is the case . . . there is no gap between thought, as such, and the world. Of course thought can be distanced from the world by being false, but there is no distance from the world implicit in the very idea of thought.

For McDowell, the sort of thing one can think is a conceptual content: the conceptual has no outer boundary beyond which lies unconceptualized reality. He denies the accusation of idealism on the grounds that he is not committed to any contentious thesis of mind-dependence.
The sort of thing that can be the case is that a certain object has a certain property. McDowell’s claim is not that the object and the property are concepts, but merely that we can in principle form concepts of them, with which to think that the object has the property.
Indeed, we can in principle form many different concepts of them: we can think of the same object as Hesperus or as Phosphorus. In
Fregean terms congenial to McDowell, different senses determine the same reference. He admits 'an alignment of minds with the realm of sense, not with the realm of reference . . . thought and reality meet in the realm of sense' (1994: 179–80). For objects, his claim that the conceptual is unbounded amounts to the claim that any object can be thought of. Likewise for the sort of thing that can be the case: the claim is, for example, that whenever an object has a property, it can be thought, of the object and the property, that the former has the latter. But, on a coherent and natural reading of 'the sort of thing that can be the case,' such things are individuated coarsely, by the objects, properties, and relations that they involve. Thus, since Hesperus is Phosphorus, what is the case if Hesperus is bright is what is the case if Phosphorus is bright: the objects are the same, as are the properties. On this reading, McDowell’s claim 'When one thinks truly, what one thinks is what is the case' is false, because what one thinks is individuated at the level of sense while what is the case is individuated at the level of reference. Although McDowell’s claim is true on weaker readings, they will not bear the weight his argument puts on them.
McDowell’s argument in any case seems to require the premise that everything (object, property, relation, state of affairs, . . .) is thinkable. That premise is highly contentious. What reason have we to assume that reality does not contain elusive objects, incapable in principle of being individually thought of? Although we can think of them collectively – for example, as elusive objects – that is not to single out any one of them in thought. Can we be sure that ordinary material objects do not consist of clouds of elusive sub-sub-atomic particles? We might know them by their collective effects while unable to think of any single one of them. The general question whether there can be elusive objects looks like a good candidate for philosophical consideration. Of course, McDowell does not intend the conceptual to be limited by the merely medical limitations of human beings, but the elusiveness may run deeper than that: the nature of the objects may preclude the kind of separable causal interaction with complex beings that isolating them in thought would require. In Fregean terminology again, a sense is a mode of presentation of a referent; a mode of presentation of something is a way of presenting it to a possible thinker, if not an actual one; for all
McDowell has shown, there may be necessary limitations on thinking.4 Although elusive objects belong to the same very general ontological category of objects as those we can single out, their possibility still undermines McDowell’s claim that we cannot make 'interesting sense' of the idea of something outside the conceptual realm (1994:
105–6). We do not know whether there actually are elusive objects.
What would motivate the claim that there are none, if not some form of idealism very far from McDowell’s intentions? We should adopt no conception of philosophy that on methodological grounds excludes elusive objects.5
Suppose, just for the sake of argument, that there are no elusive objects. That by itself would still not vindicate a restriction of philosophy to the conceptual, the realm of sense or thought. The practitioners of any discipline have thoughts and communicate them,
4

McDowell’s invocation of humility (1994: 40) addresses contingent limitations, not necessary ones.
5
Mark Johnston (1993: 96–7) discusses 'the Enigmas, entities essentially undetectable by us.' He stipulates that they are collectively as well as individually undetectable; thus our elusive objects need not be his Enigmas. If we cannot have good evidence that there are no Enigmas, it may well be a waste of time to worry whether there are Enigmas. But it would not follow that it is a waste of time to worry whether there can be Enigmas. Their definition does not rule out knowledge of the possibility of such things; such knowledge may itself be philosophically useful (indeed,
Johnston uses it for his philosophical purposes). but they are rarely studying those very thoughts: rather, they are studying what their thoughts are about. Most thoughts are not about thoughts. To make philosophy the study of thought is to insist that philosophers’ thoughts should be about thoughts. It is not obvious why philosophers should accept that restriction.
Even within what is usually considered analytic philosophy of mind, much work violates the two tenets of conceptual philosophy.
Naturalists hold that everything is part of the natural world, and should be studied as such; many of them study thought as part of the natural world by not sharply distinguishing it from the psychological process of thinking. Those who study sensations or qualia without treating them as intentional phenomena are not usually attempting to analyze the structure of thought; their interest is primarily in the nature of the sensations or qualia themselves, not in our concepts of them. Even when the question of veridicality arises, it is not always conceded that there are structured thoughts: some philosophers claim that perception has a conceptually unstructured content that represents the environment as being a certain way. Their interest is in the nature of the nonconceptual content itself, not just in our concept of it.
Despite early hopes or fears, philosophy of mind has not come to play the organizing role in philosophy that philosophy of language once did. No single branch of philosophy does: philosophy is no more immune than other disciplines to increasing specialization. Nor is any one philosophical method currently treated as a panacea for philosophical ills, with consequent privileges for its home branch. Once we consider other branches of philosophy, we notice much more philosophizing whose primary subject matter is not conceptual.
Biology and physics are not studies of thought. In their most theoretical reaches, they merge into the philosophy of biology and the philosophy of physics. Why then should philosophers of biology and philosophers of physics study only thought? Although they sometimes study what biologists’ and physicists’ concepts are or should be, sometimes they study what those concepts are concepts of, in an abstract and general manner. If the conceptual turn is incompatible with regarding such activities as legitimately philosophical, why take the conceptual turn?
There is a more central example. Much contemporary metaphysics is not primarily concerned with thought or language at all. Its goal is to discover what fundamental kinds of things there are and what properties and relations they have, not to study the structure of our thought about them – perhaps we have no thought about them until it is initiated by metaphysicians. Contemporary metaphysics studies substances and essences, universals and particulars, space and time, possibility and necessity. Although nominalist or conceptualist reductions of all these matters have been attempted, such theories have no methodological priority and generally turn out to do scant justice to what they attempt to reduce.
The usual stories about the history of twentieth-century philosophy fail to fit much of the liveliest, exactest, and most creative achievements of the final third of that century: the revival of metaphysical theorizing, realist in spirit, often speculative, sometimes commonsensical, associated with Saul Kripke, David Lewis, Kit Fine,
Peter van Inwagen, David Armstrong and many others: work that has, to cite just one example, made it anachronistic to dismiss essentialism as anachronistic.6 On the traditional grand narrative schemes in the history of philosophy, this activity must be a throwback to pre-Kantian metaphysics: it ought not to be happening – but it is.
Many of those who practice it happily acknowledge its continuity with traditional metaphysics; appeals to the authority of Kant, or
Wittgenstein, or history, ring hollow, for they are unbacked by any argument that has withstood the test of recent time.
One might try to see in contemporary metaphysics a Quinean breakdown of divisions between philosophy and the natural sciences.
But if it is metaphysics naturalized, then so is the metaphysics of
Aristotle, Descartes, and Leibniz. Armchair argument retains a central role, as do the modal notions of metaphysical possibility and necessity. Although empirical knowledge constrains the attribution of essential properties, results are more often reached through a subtle interplay of logic and the imagination. The crucial experiments are thought experiments.
Might the contrast between the new-old metaphysics and the conceptual turn be less stark than it appears to be? Contemporary metaphysicians firmly resist attempts to reconstrue their enterprise as
6

On essentialism see, for example, Kripke (1980), French, Uehling, and Wettstein
(1986), Fine (1994, 1995) and Wiggins (2001). For a good statement of the outlook of contemporary metaphysics see Zimmerman (2004). the analysis of thought – unlike Sir Peter Strawson, who defined his
'descriptive metaphysics' as 'content to describe the actual structure of our thought about the world' (1959: 9). But can one reflect on concepts without reflecting on reality itself? For the aboutness of thought and talk is their very point. This idea has been emphasized by David Wiggins, Dummett’s successor and my predecessor in the
Wykeham Chair, and author of some of the most distinguished essentialist metaphysics, in which considerations of logic and biology harmoniously combine. Wiggins (2001: 12) writes: 'Let us forget once and for all the very idea of some knowledge of language or meaning that is not knowledge of the world itself.'
Wiggins is not just stating the obvious, that language and meaning are part of the world because everything is part of the world. Rather, his point is that in defining words – natural kind terms, for instance
– we must point at real specimens. What there is determines what there is for us to mean. In knowing what we mean, we know something about what there is. That prompts the question how far the analysis of thought or language can be pursued autonomously with any kind of methodological priority.
Dummett claimed not that the traditional questions of metaphysics cannot be answered but that the way to answer them is by the analysis of thought and language. For example, in order to determine whether there are numbers, one must determine whether number words such as '7' function semantically like proper names in the context of sentences uttered in mathematical discourse. But what is it so to function? Although devil words such as 'Satan' appear to function semantically like proper names in the context of sentences uttered in devil-worshipping discourse, one should not jump to the conclusion that there are devils. However enthusiastically devilworshippers use 'Satan' as though it referred to something, that does not make it refer to something. Although empty names appear to function semantically like referring names in the context of sentences uttered by those who believe the names to refer, the appearances are deceptive. 'Satan' refers to something if and only if some sentence with 'Satan' in subject position (such as 'Satan is self-identical')
expresses a truth, but the analysis of thought and language is not the best way to discover whether any such sentence does indeed express a truth. Of course, what goes for 'Satan' may not go for '7.'
According to some neo-logicists, '7 exists' is an analytic truth (what Ayer might have called a formal consequence of definitions), which 'Satan exists' does not even purport to be. Such a claim needs the backing of an appropriate theory of analyticity.
After this preliminary sketch, it is time to get down to detailed work. The next three chapters examine different forms of the linguistic or conceptual turn. Chapter 2 uses a case study to consider in a microcosm the idea that philosophers’ questions are implicitly about language or thought when they are not explicitly so. Chapters 3 and 4 assess a wide range of versions of the idea that the armchair methodology of philosophy is grounded in the analytic or conceptual status of a core of philosophical truths, which need not be about language or thought, even implicitly. In each case the upshot is negative. Although philosophers have more reason than physicists to consider matters of language or thought, philosophy is in no deep sense a linguistic or conceptual inquiry, any more than physics is. But it does not follow that experiment is an appropriate primary method for philosophy. Similar arguments suggest that mathematics is in no deep sense a linguistic or conceptual inquiry, yet experiment is not an appropriate primary method for mathematics. The second half of the book develops an alternative conception of philosophy, on which a largely armchair methodology remains defensible, as it does for mathematics.
From this perspective and that of many contemporary philosophers, the conceptual turn and a fortiori the linguistic turn look like wrong turnings. It is pointless to deny that such philosophers are 'analytic,' for that term is customarily applied to a broad, loose tradition held together by an intricate network of causal ties of influence and communication, not by shared essential properties of doctrine or method: what do Frege, Russell, Moore, Wittgenstein, Carnap, Ayer, Quine, Austin, Strawson, Davidson, Rawls, Williams, Anscombe, Geach, Armstrong, Smart, Fodor, Dummett, Wiggins, Marcus, Hintikka, Kaplan, Lewis, Kripke, Fine, van Inwagen and Stalnaker all have in common to distinguish them from all the nonanalytic philosophers? Many who regard the linguistic and conceptual turns as serious mistakes have ties of influence and communication that put them squarely within that tradition. 'Analytic philosophy'
is a phrase in a living language; the attempt to stipulate a sense for it that excludes many of the philosophers just listed will achieve nothing but brief terminological confusion. Historians of philosophy on the grand scale may be too Whiggish or Hegelian to regard the linguistic or conceptual turn as merely a false turning from which philosophy is withdrawing now that it recognizes its mistake. We are supposed to go forward from it, not back.
At the very least, we should learn from our mistakes, if only not to repeat them. But if the conceptual turn was a mistake, it was not a simple blunder; it went too deep for that. A new narrative structure is needed for the history of philosophy since 1960; it is clear only in the roughest outline what it should be.

2
Taking Philosophical
Questions at Face Value

How often are philosophical questions implicitly about thought or language when they are not explicitly so? As a case study, I will take a question closely related to the problem of vagueness, because it looks like a paradigm of a philosophical question that is implicitly but not explicitly about thought and language. For vagueness is generally conceived as a feature of our thought and talk about the world, not of the world itself. Admittedly, some philosophers find tempting the idea of mind-independently vague objects, such as Mount Everest, vague in their spatiotemporal boundaries and mereological composition, if not in their identity. That kind of vagueness is not my concern here. I will consider an example of a quite standard type, involving a vague predicate.1 Yet the reconstrual of the question as implicitly about thought or language turns out to be a mistake. If it is a mistake here, in such favorable conditions, it is a mistake far more widely.

1
Suppose that there was once plenty of water on the planet Mars; it was clearly not dry. Ages passed, and very gradually the water evaporated. Now Mars is clearly dry. No moment was clearly the first on which it was dry or the last on which it was not. For a long intermediate period it was neither clearly dry nor clearly not dry. Counting the water molecules would not have enabled us to determine whether
1

On vagueness in general see, for a start, Graff and Williamson (2002), Keefe
(2000), Keefe and Smith (1997), and Williamson (1994a). On vague objects see
Williamson (2003b) and references therein. it was dry; other measures would have been equally inconclusive. We have no idea of any investigative procedure that would have resolved the issue. It was a borderline case. No urgent practical purpose compels us to ask whether Mars was dry then, but only a limited proportion of thought and talk in any human society is driven by urgent practical purposes. We should like to know the history of
Mars. When necessary, we can always use words other than 'dry.'
Nevertheless, we reflect on the difficulty of classifying Mars as dry or as not dry at those intermediate times, even given exact measurements. We may wonder whether it was either. We ask ourselves:
Was Mars always either dry or not dry?

Henceforth I will refer to that as the original question. More precisely, I will use that phrase to designate that interrogative sentence, as used in that context (the word 'question' can also be applied to what interrogative sentences express rather than the sentences themselves).
The original question is at least proto-philosophical in character.
It is prompted by a difficulty both hard to identify and hard to avoid that we encounter in applying the distinctions in our repertoire. It hints at a serious threat to the validity of our most fundamental forms of deductive reasoning. Philosophers disagree about its answer, on philosophical grounds explored below. A philosophical account of vagueness that does not tell us how to answer the original question is thereby incomplete. Without an agreed definition of 'philosophy,'
we can hardly expect to prove that the original question or any other is a philosophical question; but when we discuss its answer, we find ourselves invoking recognizably philosophical considerations. More simply, I’m a philosopher, I find the original question interesting, although I think I know the answer, and I have no idea where one should go for an answer to it, if not to philosophy (which includes logic). But before we worry about the answer, let us examine the original question itself.
The question queries just the supposition that Mars was always either dry or not dry, which we can formalize as a theorem of classical logic, ᭙t (Dry(m, t) ∨ Dry(m, t)).2 In words: for every time t,
2

Classical logic is the standard logic of expressions such as 'every,' 'either . . .
or . . .' and 'not' on the assumption that there is a mutually exclusive, jointly exhaustive dichotomy of sentences into the true and the false. either Mars was dry at t or Mars was not dry at t. The question is composed of expressions that are not distinctively philosophical in character: 'Mars,' 'always,' 'either . . . or . . . ,' 'not,' 'was,' and
'dry.' All of them occur in a recognizably unphilosophical question such as 'Was Mars always either uninhabited or not dry?,' which someone might ask on judging that Mars is both uninhabited and dry and wondering whether there is a connection. Although philosophical issues can be raised about the words in both questions, it does not follow that merely in using those words one is in any way engaging in philosophy. One difference between the two questions is that it is not obviously futile to try to argue from the armchair that
Mars was always either dry or not dry, whereas it is obviously futile to try to argue from the armchair that Mars was always either uninhabited or not dry.
The original question does not itself ask whether it is metaphysically necessary, or knowable a priori, or analytic, or logically true that Mars was always either dry or not dry. It simply asks whether
Mars always was either dry or not dry. Expressions such as 'metaphysically necessary,' 'knowable a priori,' 'analytic,' and 'logically true' do not occur in the original question; one can understand it without understanding any such philosophical terms of art. This is of course neither to deny nor to assert that it is metaphysically necessary, or knowable a priori, or analytic, or logically true that Mars was always either dry or not dry. For all that has been said, the proposition may be any combination of those things. But that is not what the original question asks.
In other circumstances, we could have answered the original question on philosophically uninteresting grounds. For instance, if there had never been liquid on Mars, then it would always have been dry, and therefore either dry or not dry. In order to pose a question which could not possibly be answered in that boring way, someone who already grasped one of those philosophically distinctive concepts might ask whether it is metaphysically necessary, or knowable a priori, or analytic, or logically true that Mars was always either dry or not dry. The meaningfulness of the philosophical jargon might then fall under various kinds of suspicion, which would extend to the question in which it occurred. But the original question itself cannot be correctly answered in the boring way with respect to the originally envisaged circumstances. Its philosophical interest, however contingent, is actual. We could generalize the original question in various ways. We might ask whether everything is always either dry or not dry. Then we might notice that discussing that question is quite similar to discussing whether everything is either old or not old, and so on. We might, therefore, ask whether for every property everything either has it or lacks it. The coherence of such generalizing over properties might itself fall under various kinds of suspicion, which would extend to the question in which it occurred. Someone might even doubt whether there is such a property as dryness. But the original question itself does not attempt such generality. That it has the same kind of philosophical interest as many other questions does not imply that it has itself no philosophical interest. If that interest is obscured by problematic features of the apparatus with which we try to generalize it, we can refrain from generalizing it, and stick with the original question. In order not to be distracted by extraneous issues that arise from the apparatus of generalization, not from the original question, we do best to stick with the original question in its concrete form.3
We can still help ourselves not to be distracted by unimportant features of the question, if we remember that there are many other questions of a similar form.
What is the original question about? 'About' is not a precise term.
On the most straightforward interpretation, a sentence in a context is about whatever its constituents refer to in that context. Thus, taken at face value, the original question is about the planet Mars, the referent of 'Mars' in this context; perhaps it is also about dryness, the referent of 'dry,' and the referents of other constituents too. Since the original question contains no metalinguistic expressions, it is not about the name 'Mars' or the adjective 'dry.' Evidently, the original question is not explicitly about words.
Is the original question implicitly about language? Someone might claim so on the grounds that it is equivalent to questions that are explicitly about language, such as these:
Is the sentence 'Mars was always either dry or not dry' true? (Does it express a truth as used in this context?)
Did Mars always belong either to the extension of the word 'dry' or to the anti-extension of 'dry' (as the word 'dry' is used in this context)?
3

See also Quine (1970: 11). But parallel reasoning would lead to the conclusion that the unphilosophical question 'Was Mars always either uninhabited or not dry?' is also implicitly about language, since it is equivalent to these questions:
Is the sentence 'Mars was always either uninhabited or not dry' true?
(Does it express a truth as used in this context?)
Did Mars always belong either to the extension of the word 'uninhabited' or to the anti-extension of 'dry' (as the word 'dry' is used in this context)?

Indeed, we could make parallel arguments for all everyday and scientific questions. Since they are not all about language in any distinctive sense, the reasoning does not show that the original question was about language in any distinctive sense. Even if the equivalences did show that the original question was in some sense implicitly about language, they could be read in both directions: they would also show that the explicitly metalinguistic questions were in an equally good sense implicitly not about language.
The equivalences between the questions are in any case uncontroversial only if the corresponding disquotational biconditionals are:
(T1) 'Mars was always either dry or not dry' is true if and only if
Mars was always either dry or not dry.
(T2a) For any time t, Mars belongs to the extension of 'dry' at t if and only if Mars is dry at t.
(T2b) For any time t, Mars belongs to the anti-extension of 'dry'
at t if and only if Mars is not dry at t.
On the face of it, these biconditionals express at best contingent truths. For perhaps the word 'dry' could have meant wet, in which case Mars would have belonged to the extension of 'dry' when wet and to the anti-extension of 'dry' when dry: for we use the word
'dry' to mean dry even when we are talking about circumstances in which it would have meant something else, because we are not talking in those circumstances. If so, T2a and T2b do not express necessary truths. Similarly, perhaps the sentence 'Mars was always either dry or not dry' could have failed to express a truth even though Mars Taking Philosophical Questions at Face Value

was always either dry or not dry, since 'always' could have meant never. On this reading, T1 does not express a necessary truth. We should not assume that a useful notion of aboutness would transfer across merely contingent biconditionals. Perhaps we can instead interpret T1, T2a, and T2b as expressing necessary truths by individuating linguistic expressions so that their semantic properties are essential to them; whether that requires treating the quoted expressions as necessary existents is a delicate matter. In any case, some theorists of vagueness have denied even the actual truth of biconditionals such as T1, T2a, and T2b; they might respond to the original question in one way and to the explicitly metalinguistic questions in another.4 Thus the questions are not pragmatically, dialectically or methodologically equivalent within the context of debates on vagueness. For present purposes, we need not resolve the status of the disquotational biconditionals, because we have already seen that the sense in which they make the original question implicitly about words is too indiscriminate to be useful.
We can argue more directly that the original question is not implicitly about the word 'dry' by appeal to a translation test. For consider the translation of the original question into another language, such as Serbian:
Da li je Mars uvek bio suv ili nije bio suv?

The Serbian translation is not implicitly about the English word
'dry.' But since the questions in the two languages mean the same, what they are implicitly about (in the same context) should also be the same. Therefore, the original question is not implicitly about the word 'dry.' By similar reasoning, it is not about any word of English or any other language. Of course, given the informality of the notion of implicit aboutness, the argument is not fully rigorous. Nevertheless, the translation test emphasizes how far one would have to water down the notion of reference in order to reach a notion of implicit aboutness on which the original question would be implicitly about a word.
4

A recent example of a supervaluationist rejecting such disquotational equivalences for borderline cases is Keefe (2000: 213–20). For further discussion see Williamson
(1994a: 162–4) and McGee and McLaughlin (2000). The translation test does not show that the original question is not implicitly about a concept, something like the meaning of a word rather than the word itself, for the English word 'dry' and its Serbian synonym 'suv' both express the concept dry. But what basis is there for the claim that the original question is implicitly about the concept dry? We might argue that the original question is in some sense equivalent to a metaconceptual question:
Did Mars always belong either to the extension of the concept dry or to the anti-extension of dry?

For we might apply the notions of extension and anti-extension to concepts by means of biconditionals similar to T2a and T2b respectively:
(TC2a)

For any time t, Mars belongs to the extension of dry at t if and only if Mars is dry at t.
(TC2b) For any time t, Mars belongs to the anti-extension of dry at t if and only if Mars is not dry at t.

TC2a and TC2b can express necessary truths more easily than T2a and T2b can, for the apparently contingent relation between words and their meanings has no straightforward analogue for concepts.
Concepts are individuated semantically: rather than merely having meanings, they are meanings, or something like them.5 Nevertheless, the argument that the original question is implicitly about the concept dry in virtue of being equivalent to the metaconceptual question wildly overgeneralizes, just like the argument that the original
5

Even if a word retains its linguistic meaning, its reference may shift with the context of utterance ('I,' 'now,' 'here'). If 'dry' undergoes such contextual shifts,
T2a and T2b may fail when interpreted as generalizations about utterances of 'dry'
in contexts other than the theorist’s own. It might be argued that concepts can also undergo contextual shifts in reference: you use the concept I to refer (in thought) to yourself but I use the same concept to refer to myself; at noon we use the concept now to think of noon but at midnight we use the same concept to refer to midnight; at the North Pole we use the concept here to refer to the North Pole but at the South
Pole we use the same concept to refer to the South Pole. If so, TC2a and TC2b may also fail when interpreted as generalizations about uses of the concept dry in contexts other than the theorist’s own. Taking Philosophical Questions at Face Value

question is implicitly about the word 'dry' in virtue of being equivalent to the metalinguistic question. For parallel reasoning would lead to the conclusion that the unphilosophical question 'Was Mars always either uninhabited or not dry?' is implicitly about the concept dry, and likewise for any other unphilosophical question. Since those questions are not about concepts in any distinctive sense, the original reasoning does not show that the original question is about concepts in any distinctive sense. Even if the equivalences did show that the original question was in some sense implicitly about thought, they can be read in both directions: they would also equally show that the explicitly metaconceptual questions were in an equally good sense implicitly not about thought.
A Fregean might argue: the original question is explicitly about the concept dry, because it contains the predicate '. . . is dry' (in the past tense), which refers to the concept dry. In that sense, the question
'Was Mars always either uninhabited or not dry?' would also be explicitly about the concept dry. However, the Fregean is not using the word 'concept' with its contemporary meaning, on which concepts are something like mental or semantic representations, closer to the realm of sense than to that of reference. The Fregean referent of a predicate (a Fregean concept) is simply the function that maps everything to which the predicate applies to the true and everything else to the false: it could be treated as the extension of the predicate, except that in Fregean terms it is a function rather than an object. If the predicate refers to the property of dryness or to the set of dry things, then the original question is about the property of dryness or the set of dry things, but that has no tendency to show that it is about thought. Similarly, the Fregean claim has no tendency to show that the question is about thought, for the Fregean concept is in the realm of reference, not in the realm of thought. Like the property and the set, it is no sense but something to which a sense may determine reference. Since it is no sense, it is no constituent of a thought, on the
Fregean view, nor is it a concept in the current sense of 'concept.'
Thought and talk are not always about thought or talk. To judge by its overt compositional structure, the original question in particular is not about thought or talk. It is no metalinguistic or metaconceptual question. We have seen no reason to regard its overt structure as at all misleading in that respect. Our provisional conclusion must therefore be that the original question, although at least proto- philosophical, is not about thought or language in any distinctive sense. It does not support the linguistic or conceptual turn, interpreted as a conception of the subject matter of philosophy.

2
If the original question, read literally, had too obvious an answer, either positive or negative, that would give us reason to suspect that someone who uttered it had some other meaning in mind, to which the overt compositional structure of the question might be a poor guide. But competent speakers of English may find themselves quite unsure how to answer the question, read literally, so we have no such reason for interpreting it non-literally.
It is useful to look at some proposals and arguments from the vagueness debate, for two reasons. First, they show why the original question is hard, when taken at face value. Second, they show how semantic considerations play a central role in the attempt to answer it, even though it is not itself a semantic question.
The most straightforward reason for answering the original question positively is that 'Mars was always either dry or not dry' is a logical truth, a generalization over instances of the law of excluded middle (A ∨ A, 'It is either so or not so') for various times. In my view, that reasoning is sound. However, many think otherwise. They deny the validity of excluded middle for vague terms such as
'dry.'
The simplest way of opposing the law of excluded middle is to deny outright when Mars is a borderline case that it is either dry or not dry, and therefore to answer the original question in the negative.
For instance, someone may hold that Mars was either dry or not dry at time t only if one can know (perhaps later) whether it was dry at t, given optimal conditions for answering the question (and no difference in the history of Mars): since one cannot know, even under such conditions, whether it is dry when the case is borderline, it is not either dry or not dry. One difficulty for this negative response to the original question is that it seems to imply that in a borderline case Mars is neither dry nor not dry: in other words, both not dry and not not dry. That is a contradiction, for 'not not dry' is the negation of 'not dry.' Taking Philosophical Questions at Face Value

Intuitionistic logic provides a subtler way to reject the law of excluded middle without denying any one of its instances. Intuitionists ground logic in states of increasing but incomplete information, rather than a once-for-all dichotomy of truth and falsity. They deny that anything can be both proved and refuted, but they do not assert that everything can be either proved or refuted. For intuitionists, the denial of an instance of excluded middle ( (A ∨ A), 'It is not either so or not so') entails a contradiction ( A &
A, 'It is both not so and not not so'), just as it does in classical logic, and contradictions are as bad for them as for anyone else. Thus they cannot assert that Mars was once not either dry or not dry ( t (Dry(m, t) ∨ Dry(m, t))), for that would imply that a contradiction once obtained
( t ( Dry(m, t) &
Dry(m, t)), 'Mars was once both not dry and not not dry'), which is intuitionistically inconsistent. However, although intuitionists insist that proving an existential claim in principle involves proving at least one instance of it, they allow that disproving a universal claim need not in principle involve disproving at least one instance of it. The claim that something lacks a property is intuitionistically stronger than the claim that not everything has that property. Thus one might assert that Mars was not always either dry or not dry ( ᭙t (Dry(m, t) ∨ Dry(m, t))), on the general grounds that there is no adequate procedure for sorting all the times into the two categories, without thereby committing oneself to the inconsistent existential assertion that it was once not either dry or not dry.
Hilary Putnam once proposed the application of intuitionistic logic to the problem of vagueness for closely related reasons.6 Thus one might use intuitionistic logic to answer the original question in the negative.
On closer inspection, this strategy looks less promising. For a paradigm borderline case is the worst case for the law of excluded middle
(for a term such as 'dry' for which threats to the law other than from vagueness are irrelevant), in the sense that both proponents and opponents of the law can agree that it holds in a paradigm borderline case only if it holds universally. In symbols, if Mars was a paradigm borderline case at time τ: (Dry(m, ) ∨ Dry(m, ))
6

For intuitionist logic in general see Dummett (1977). For its application to the problem of vagueness see Graff and Williamson (2002: 473–506) and Chambers
(1998). ᭙t (Dry(m, t) ∨ Dry(m, t)) ('If Mars was either dry or not dry at time , then Mars was always either dry or not dry'). But on this approach the law does not hold always hold in these cases
( ᭙t (Dry(m, t) ∨ Dry(m, t)), 'Mars was not always either dry or not dry'), from which intuitionistic logic allows us to deduce that it does not hold in the paradigm borderline case ( (Dry(m, ) ∨ Dry(m, )),
'Mars was not either dry or not dry at '), which is a denial of a particular instance of the law, and therefore intuitionistically inconsistent
(it entails Dry(m, ) &
Dry(m, ), 'Mars was both not dry and not not dry at '). Thus the intuitionistic denial of the universal generalization of excluded middle for a vague predicate forces one to deny that it has such paradigm borderline cases. The latter denial is hard to reconcile with experience: after all, the notion of a borderline case is usually explained by examples.
The problems for the intuitionistic approach do not end there. One can show that the denial of the conjunction of any finite number of instances of the law of excluded middle is intuitionistically inconsistent.7 The denial of the universal generalization of the law over a finite domain is therefore intuitionistically false too. If time is infinitely divisible, the formula ᭙t (Dry(m, t) ∨ Dry(m, t)) generalizes the law over an infinite domain of moments of time, and its denial is intuitionistically consistent, but the possibility of infinitely divisible time is not crucial to the phenomena of vagueness. We could just as well have asked the original question about a long finite series of moments at one-second intervals; it would have been equally problematic. The classical sorites paradox depends on just such a finite series: a heap of sand consists of only finitely many grains, but when they are carefully removed one by one, we have no idea how to answer the question 'When did there cease to be a heap?' To deny that Mars was dry or not dry at each moment in the finite series is intuitionistically inconsistent. Thus intuitionistic logic provides a poor basis for a negative answer to the original question.
Other theorists of vagueness refuse to answer the original question either positively or negatively. They refuse to assert that Mars was always either dry or not dry; they also refuse to assert that it was not always either dry or not dry.
One proves by mathematical induction on n that if An is the conjunction of n instances of excluded middle then An is intuitionistically inconsistent. A simple version of this approach classifies vague sentences (relative to contexts) as true (T), false (F) or indefinite (I); borderline sentences are classified as indefinite. The generalized truth-tables of a three-valued logic are used to calculate which of these values to assign to a complex sentence in terms of the values assigned to its constituent sentences. The negation of A, A, is true if A is false, false if A
is true and indefinite if A is indefinite:
A
T
I
F

A
F
I
T

A conjunction A & B ('A and B') is true if every conjunct is true; it is false if some conjunct is false; otherwise it is indefinite. A disjunction A ∨ B ('Either A or B') is true if some disjunct is true; it is false if every disjunct is false; otherwise it is indefinite:
A
T
T
T
I
I
I
F
F
F

B
T
I
F
T
I
F
T
I
F

A&B
T
I
F
I
I
F
F
F
F

A∨ B
T
T
T
T
I
I
T
I
F

A universal generalization is treated as if it were the conjunction of its instances, one for each member of the domain: it is true if every instance is true, false if some instance is false, and otherwise indefinite. An existential generalization is treated as if it were the disjunction of the instances: it is true if some instance is true, false if every instance is false, and otherwise indefinite. The three-valued tables generalize the familiar two-valued ones in the sense that one recovers the latter by deleting all lines with 'I.'
Let us apply this three-valued approach to the original question. If
Mars is definitely dry or definitely not dry at t (the time denoted by t), then Dry(m, t) is true or false, so the instance of excluded middle Dry(m, t) ∨ Dry(m, t) is true. But if Mars is neither definitely dry nor definitely not dry at t, then Dry(m, t) is indefinite, so Dry(m, t)
is indefinite too by the table for negation, so Dry(m, t) ∨ Dry(m, t)
is classified as indefinite by the table for disjunction. Since
Mars was once a borderline case, the universal generalization
᭙t (Dry(m, t) ∨ Dry(m, t)) has a mixture of true and indefinite instances; hence it is classified as indefinite. Therefore its negation
᭙t (Dry(m, t) ∨ Dry(m, t)) is also indefinite. Thus three-valued theoreticians who wish to assert only truths neither assert
᭙t (Dry(m, t) ∨ Dry(m, t)) nor assert ᭙t (Dry(m, t) ∨ Dry(m, t)).
They answer the original question neither positively nor negatively.
Three-valued logic replaces the classical dichotomy of truth and falsity by a three-way classification. Fuzzy logic goes further, replacing it by a continuum of degrees of truth between perfect truth and perfect falsity. According to proponents of fuzzy logic, vagueness should be understood in terms of this continuum of degrees of truth.
For example, 'It is dark' may increase continuously in degree of truth as it gradually becomes dark. On the simplest version of the approach, degrees of truth are identified with real numbers in the interval from 0 to 1, with 1 as perfect truth and 0 as perfect falsity.
The semantics of fuzzy logic provides rules for calculating the degree of truth of a complex sentence in terms of the degrees of truth of its constituent sentences. For example, the degrees of truth of a sentence and of its negation sum to exactly 1; the degree of truth of a disjunction is the maximum of the degrees of truth of its disjuncts; the degree of truth of a conjunction is the minimum of the degrees of truth of its conjuncts. For fuzzy logic, although the three-valued tables above are too coarse-grained to give complete information, they still give correct results if one classifies every sentence with an intermediate degree of truth, less than the maximum and more than the minimum, as indefinite.8 Thus the same reasoning as before shows that fuzzy
8

This point does not generalize to the semantics of conditionals in fuzzy logic, given the popular rule that if the consequent is lower than the antecedent in degree of truth then the degree of truth of the conditional falls short of 1 by the amount by which the consequent falls short of the antecedent in degree of truth; otherwise the degree of truth of the conditional is 1. Hence if A has a higher degree of truth than B but both are indefinite then A
B is indefinite while B
A is perfectly true. Thus the information that the antecedent and consequent are indefinite does not determine whether the conditional is indefinite. Taking Philosophical Questions at Face Value

logicians should answer the original question neither positively nor negatively.
Although three-valued and fuzzy logicians reject both the answer
'Yes' and the answer 'No' to the original question, they do not reject the question itself. What they reject is the restriction of possible answers to 'Yes' and 'No.' They require a third answer, 'Indefinite,' when the queried sentence takes the value I. More formally, consider the three-valued table for the sentence operator ∆, read as
'definitely' or 'it is definite that':
A
T
I
F

∆A
T
F
F

Even for fuzzy logicians this table constitutes a complete semantics for ∆, since the only output values are T and F, which determine unique degrees of truth (1 and 0). A formula of the form
A &
A ('It is neither definitely so nor definitely not so')
characterizes a borderline case, for it is true if A is indefinite and false otherwise. In response to the question A?, answering 'Yes' is tantamount to asserting A, answering 'No' is tantamount to asserting A, and answering 'Indefinite' is tantamount to asserting
A&
A. On the three-valued and fuzzy tables, exactly one of these three answers is true in any given case; in particular, the correct answer to the original question is 'Indefinite.'
On the three-valued and fuzzy approaches, to answer 'Indefinite'
to the question 'Is Mars dry?' is to say something about Mars, just as it is if one answers 'Yes' or 'No.' It is not a metalinguistic response. For ∆ is no more a metalinguistic operator than is. They have the same kind of semantics, given by a many-valued truth-table.
Just as the negation A is about whatever A is about, so are ∆A and
A&
A. Thus the answer 'Indefinite' to the original question involves no semantic ascent to a metalinguistic or metaconceptual level. It remains at the level of discourse about Mars.
The three-valued and fuzzy approaches have many suspect features. For instance, they treat any sentence of the form ∆A as perfectly precise, because it always counts as true or false, never as indefinite,
A ('It is definite whether whatever the status of A; thus
A∨
it is definitely so') is always true. This result does not fit the intended interpretation of ∆. For 'Mars is definitely wet' is not perfectly precise. Just as no moment is clearly the last on which Mars was wet or the first on which it was not, so no moment is clearly the last on which it was definitely wet or the first on which it was not definitely wet. Just as it is sometimes unclear whether Mars is wet, so it is sometimes unclear whether it is definitely wet. This is one form of the notorious problem of higher-order vagueness: in other words, there are borderline cases of borderline cases, and borderline cases of borderline cases of borderline cases, and so on. The problem has never received an adequate treatment within the framework of threevalued or fuzzy logic; that it could is far from obvious.9
Some philosophers, often under the influence of the later Wittgenstein, deny the relevance of formal semantic theories to vague natural languages. They regard the attempt to give a systematic statement of the truth conditions of English sentences in terms of the meanings of their constituents as vain. For them, the formalization of 'Mars was always either dry or not dry' as ᭙t (Dry(m, t) ∨ Dry(m, t)) is already a mistake. This attitude suggests a premature and slightly facile pessimism. No doubt formal semantics has not described any natural language with perfect accuracy; what has not been made plausible is that it provides no deep insights into natural languages. In particular, it has not been made plausible that the main semantic effects of vagueness are not susceptible to systematic formal analysis. In any case, for present purposes the claim that there can be no systematic theory of vagueness is just one more theory of vagueness, although –
unless it is self-refuting – not a systematic one; it does not even answer the original question. Even if that theory were true, the other theories of vagueness, however false, would still exist, and would still have been accepted by some intelligent and linguistically competent speakers.
This is no place to resolve the debate between opposing theories of vagueness. The present point is just that different theories support contrary answers to the original question. All these theories have their believers. Any answer to the original question, positive, negative, or indefinite, is contentious. Of course, if everyone found their own answer obvious, but different people found different answers obvious, then we might suspect that they were interpreting the question in
9

See Graff and Williamson (2002: 279–351) on higher-order vagueness. different ways, talking past each other. But that is not so: almost everyone who reflects on the original question finds it difficult and puzzling. Even when one has settled on an answer, one can see how intelligent and reasonable people could answer differently while understanding the meaning of the question in the same way. If it has an obvious answer, it is the answer 'Yes' dictated by classical logic, but those of us who accept that answer can usually imagine or remember the frame of mind in which one is led to doubt it. Thus the original question, read literally, has no unproblematically obvious answer in any sense that would give us reason to suspect that someone who asked it had some other reading in mind.
Without recourse to non-literal readings, some theorists postulate ambiguity in the original question. For example, some three-valued logicians claim that 'not' in English is ambiguous between the operators (strong negation) and ∆ (weak negation): although A and
A have the same value if A is true or false,
A is true while A is indefinite if A is indefinite. While A ∨ A ('It is so or not so') can be indefinite, A ∨
A ('It is so or not definitely so') is always true. On this view, the original question queries ᭙t (Dry(m, t) ∨ Dry(m, t))
on one reading, ᭙t (Dry(m, t) ∨
Dry(m, t)) on another; the latter is true (Mars was always either dry or not definitely dry) while the former is indefinite. Thus the correct answer to the original question depends on the reading of 'not.' It is 'Indefinite' if 'not' is read as strong negation, 'Yes' if 'not' is read as weak negation. Although the threevalued logician’s reasoning here is undermined by higher-order vagueness, that is not the present issue.10
If 'not' were ambiguous in the way indicated, it would still not follow that the dispute over the original question is merely verbal.
For even when we agree to consider it under the reading of 'not' as strong negation, which does not factorize in the manner of ∆, we still find theories of vagueness in dispute over the correct answer. We have merely explained our terms in order to formulate more clearly a difficult question about Mars.
Still, it might be suggested, the dispute between different theories of vagueness is verbal in the sense that their rival semantics characterize different possible languages or conceptual schemes: our choice of which of them to speak or think would be pragmatic, based on
10

See Williamson (1994a: 193–5). considerations of usefulness rather than of truth. Quine defended a similar view of alternative logics (1970: 81–6).
To make sense of the pragmatic view, suppose that the original vague atomic sentences are classifiable both according to the bivalent scheme as true or false and according to the trivalent scheme as definitely true, indefinite or definitely false, and that the truth-tables of each scheme define intelligible connectives, although the connective defined by a trivalent table should be distinguished from the similarlooking connective defined by the corresponding bivalent table.
Definite truth implies truth, and definite falsity implies falsity, but indefiniteness does not discriminate between truth and falsity: although all borderline atomic sentences are indefinite, some are true and others false. As Mars dries, 'Mars is dry' is first false and definitely false, then false but indefinite, then true but indefinite, and finally true and definitely true. However, this attempted reconciliation of the contrasting theories does justice to neither side. For trivalent logicians, once we know that a sentence is indefinite, there is no further question of its truth or falsity to which we do not know the answer: the category of the indefinite was introduced in order not to postulate such a mystery. Similarly, for fuzzy logicians, once we know the intermediate degree of truth of a sentence, there is no further question of its truth or falsity to which we do not know the answer: intermediate degrees of truth were introduced in order not to postulate such a mystery. In formal terms, trivalent and fuzzy logics are undoubtedly less convenient than bivalent logic; the justification for introducing them was supposed to be the inapplicability of the bivalent scheme to vague sentences. If a bivalent vague language is a genuinely possible option, then the trivalent and fuzzy accounts of vagueness are mistaken. Conversely, from a bivalent perspective, the trivalent and fuzzy semantics do not fix possible meanings for the connectives, because they do not determine truth conditions for the resultant complex sentences: for example, the trivalent table for does not specify when A is true in the bivalent sense. It would, therefore, be a fundamental misunderstanding of the issue at stake between theories of vagueness to conceive it as one of a pragmatic choice of language.
We already speak the language of the original question; we understand those words and how they are put together; we possess the concepts they express; we grasp what is being asked. That semantic knowledge may be necessary if we are to know the answer to the original question.11 It is not sufficient, for it does not by itself put one in a position to arbitrate between conflicting theories of vagueness.
For each of those theories has been endorsed by some competent speakers of English who fully grasp the question.
Competent speakers may of course fail to reflect adequately on their competence. Although the proponents of conflicting theories of vagueness presumably have reflected on their competence, their reflections may have contained mistakes. Perhaps reflection of sufficient length and depth on one’s competence would lead one to the correct answer to the original question. But the capacity for such more or less philosophical reflection is not a precondition of semantic competence. Philosophers should resist the professional temptation to require all speakers to be good at philosophy.
We can distinguish two levels of reflection, the logical and the metalogical. In response to the original question, logical reflection involves reasoning with terms of the kind in which the question is phrased; the aim is to reach a conclusion that answers the question.
For example, one might conclude by classical logic that Mars was always either dry or not dry; one might conclude by fuzzy logic that it is indefinite whether it was always one or the other. The logical level is not purely mechanical. When the reasoning is complex, one needs skill to select from the many permissible applications of the rules one sequence that leads to an answer to the question. When the reasoning is informal, one needs good judgment to select only moves that really are permissible applications of the rules. But one is still thinking about whatever the question was about. One starts only at the metalogical level of reflection to think about the semantics of the logical connectives and other expressions one employed at the logical level. For example, at the metalogical level one may assert or deny Of course, monolingual speakers of another language may know whether Mars was always dry or not dry without ever hearing of the original question, which is an interrogative sentence of English; they use a synonymous sentence of their own language. They do not know whether the original English question has a positive answer.
Someone may even know whether the original English question has a positive answer without understanding the question, because the knowledge can be passed along a chain of testimony; understanding of the original question is needed only at one end of the chain. These quibbles do not affect the argument. that the sentence 'Mars was always either dry or not dry' is a logical truth. The rules used at the logical level are articulated only at the metalogical level.
It must be possible to think logically without thinking metalogically, for otherwise by the same principle thinking metalogically would involve thinking metametalogically, and so ad infinitum: our thinking never goes all the way up such an infinite hierarchy. What can prompt ascent to the metalogical level are hard cases in which one feels unclear about the permissibility of a given move at the logical level. One’s mastery of the language and possession of concepts leave one quite uncertain how to go on. In the case of the original question, a salient line of classical reasoning leads to a positive answer: it persuades some competent speakers while leaving others unconvinced. Even to discuss the contentious reasoning we must semantically ascend. We cannot hope to resolve the dispute undogmatically if we never leave the lower level.

3
The argument so far has reached two conclusions at first sight hard to reconcile with each other. First, the original question is not about thought or language. Second, to answer it adequately one must assess rival theories of vagueness in thought and language. How can that way of reaching an answer be appropriate to the original question?
We might, therefore, find ourselves tempted back to the idea that somehow the original question was surreptitiously about thought or language.
On further reflection, the combination of the two conclusions is less surprising. Many non-philosophical questions that are not about thought or language cannot be resolved without inquiry into thought or language. Suppose that a court of law must decide whether Smith killed Jones. The question is not who said or thought what. Nevertheless, the crucial arguments may be over whether to trust the witnesses’
testimony. How is what they say now related to what they think now or thought then? How is what they think now or thought then related to what actually happened? Are they lying or sincere? Are their memories confused or clear? Those are questions about their thought and speech. They hold the key to whether Smith killed Jones, even though that question is not about thought about language.12 Of course, the questions about the thought or talk are not about it in isolation from what it is thought or talk about: they are relevant because they concern the relation between the thought or talk and what it is about.
The court must decide the issue on the evidence before it. In a criminal case, does the evidence put it beyond reasonable doubt that
Smith killed Jones? In a civil case, does the evidence make it more probable than not? If the court is really deciding a question about testimonial evidence, that is already a question about talk.13 But the question about the evidence arises in virtue of its bearing on the primary question, whether Smith killed Jones. Indeed, the question about the evidence is exactly a question about its bearing on the primary question. So the point stands.
Historians are often in a similar position. They want to know what happened. The way to achieve that is largely by considering documents, linguistic accounts of what happened – not in isolation, but in relation to what they represent. Most obviously, historians want to know whether the documents accurately represent what happened, but to answer that question they must in turn ask about their provenance: who produced them, when and why? Thus the history of the events of primary interest requires a history of thought and talk about those events. Those histories typically overlap, for thought or talk about some part of a complex human event is often another part of the same complex event.
Something analogous occurs in the methodology of the natural sciences. We wish to know the value of some physical quantity. We must devise apparatus to measure it. We may find ourselves in disputes over the functioning of different devices. Although the primary The issue of Smith’s intentions concerns his thoughts, but we may suppose that the question immediately at issue is whether Smith was even involved in Jones’s death.
13
Non-testimonial evidence may be taken to include non-linguistic items such as a bloodied knife; this is what lawyers call 'real evidence.' For an argument that all evidence in an epistemologically central sense of the term is propositional see
Williamson (2000a: 194–200). For example, the evidence in this sense might include the proposition that the bloodied knife was found at the scene of the crime, but not the knife itself. question was not about those measuring devices, we cannot answer it adequately without considering them. We need a theory about the relation between the value of the quantity and the representations of it we record when we use our instruments. The scientific investigation of the physical quantity widens to include the scientific investigation of its interaction with our experimental equipment. After all, our apparatus is part of the same natural world as the primary topic of our inquiry.
These analogies make it less surprising that when we try to answer the original question, which is not a question about thought or language, our main task is to adjudicate between rival theories of vague thought and language. A theory of vagueness validates some deduction that concludes with an answer to the original question. That deduction uses but does not mention vague thought or language. It is formulated at the logical level, like the original question itself, not at the metalogical level. But discursively to justify trusting that deduction, rather than one that reaches another conclusion by other rules, one must assess the rival theories of vagueness.
That theories of vagueness conflict in their answers to the original question shows that they are not confined to claims about thought and talk. Theories such as epistemicism and supervaluationism which employ classical logic have 'Mars was always either dry or not dry'
as a theorem, once they are formulated in a suitably expressive language. To reiterate, that theorem is not about thought or talk.
For the three-valued and fuzzy approaches, the matter is only slightly more complicated. Their proponents assert:
(C)

It is indefinite whether Mars was always either dry or not dry.

On those approaches, C does not count as about thought or language.
Strictly speaking, however, C does not follow from the three-valued or fuzzy theory of vagueness itself; for all the theory implies, there was never any liquid on Mars, in which case it would always have been either dry or not dry, even by three-valued or fuzzy standards, and so would not have been indefinite. The theory implies only a conditional theorem:
(P1) If it was once indefinite whether Mars was dry then it is indefinite whether Mars was always either dry or not dry. Three-valued or fuzzy theorists can combine P1 with what they regard as an empirical truth about Mars:
(P2) It was once indefinite whether Mars was dry.
From P1 and P2 they use the rule of modus ponens (from 'If P then
Q' and 'P' infer 'Q') to infer C, the answer to the original question. Although their theorem P1 does not answer the question by itself, it is no more about thought or language than C is. Their theories are just as committed as classical ones to making claims that are not about thought or language.
In principle, just as the considerations relevant to adjudicating the dispute between theories of vagueness are relevant to answering the original question, so too may they be relevant to answering a question asked with no philosophical intention, such as 'Was Mars always either uninhabited or not dry?,' if it turns out to involve a borderline case. In practice, non-philosophers are often quite content to be told
'It’s unclear,' without wondering exactly how that statement addresses the question asked; they simply drop the matter. For their purposes that may be the best thing to do. By contrast, philosophers persist; they want to know at least whether there is a right answer, even if nobody can know what it is. The difference lies not in the content of the original question but in the interests with which it is asked. Those interests can amount to a tissue of associated questions: for our original question as asked by a philosopher, the associated questions query other instances of the law of excluded middle. Given those interests, it is rational to persist with the original question, and not take an unexplained 'It’s unclear' for an answer. But we should not underestimate the importance outside philosophy too – in science and even in politics – of sometimes persisting with a straight question, not allowing oneself to be fobbed off with the convenient claim that no practical purpose would be served by answering it. At other times, non-philosophers in effect assume without argument a particular treatment of vagueness (not always the same one), without realizing or caring that there are alternatives. The treatment may be good enough for their purposes, or not.
In this case study, our interest in giving a clear and critically reflective answer to a simple, non-technical, non-metalinguistic, nonmetaconceptual question forced us to adjudicate between complex, technical, metalinguistic, and metaconceptual theories. This phenomenon seems to have been overlooked by those who complain about the 'arid' technical minuteness of much philosophy in the analytic tradition. A question may be easy to ask but hard to answer. Even if it is posed in dramatic and accessible terms, the reflections needed to select rationally between rival answers may be less dramatic and accessible. Such contrasts are commonplace in other disciplines; it would have been amazing if they had not occurred in philosophy.
Impatience with the long haul of technical reflection is a form of shallowness, often thinly disguised by histrionic advocacy of depth.
Serious philosophy is always likely to bore those with short attention-spans.14
Why should considerations about thought and language play so much more central a role in philosophy than in other disciplines, when the question explicitly under debate is not itself even implicitly about thought or language? The paradigms of philosophical questions are those that seem best addressed by armchair considerations less formal than mathematical proofs. The validity of such informal arguments depends on the structure of the natural language sentences in which they are at least partly formulated, or on the structure of the underlying thoughts. That structure is often hard to discern. We cannot just follow our instincts in reasoning; they are too often wrong
(see Chapter 4 for details). In order to reason accurately in informal terms, we must focus on our reasoning as presented in thought or language, to double-check it, and the results are often controversial.
Thus questions about the structure of thought and language become central to the debate, even when it is not primarily a debate about thought or language.
The rise of modern logic from Frege onwards has provided philosophers with conceptual instruments of unprecedented power and precision, enabling them to formulate hypotheses with more clarity and determine their consequences with more reliability than ever before. Russell’s theory of descriptions showed vividly how differences between the surface form of a sentence and its underlying semantic structure might mislead us as to its logical relations and thereby create philosophical illusions. The development of formal
14

Popularization has its place, in philosophy as in physics, but should not be confused with the primary activity. model-theory and truth-conditional semantics by Tarski and others has provided a rigorous framework for thinking about the validity of our inferences. These theoretical advances have enormous intellectual interest in their own right. They may have made it tempting to suppose that all philosophical problems are problems of language: but they do not really provide serious evidence for that conjecture.
To deny that all philosophical questions are about thought or language is not to deny the obvious, that many are. We have also seen how in practice the attempt to answer a question which is not about thought or language can largely consist in thinking about thought and language. Some contemporary metaphysicians appear to believe that they can safely ignore formal semantics and the philosophy of language because their interest is in a largely extra-mental reality. They resemble an astronomer who thinks he can safely ignore the physics of telescopes because his interest is in the extra-terrestrial universe. In delicate matters, his attitude makes him all the more likely to project features of his telescope confusedly onto the stars beyond. Similarly, the metaphysicians who most disdain language are the most likely to be its victims. Again, those who neglect logic in order to derive philosophical results from natural science make frequent logical errors in their derivations; their philosophical conclusions do not follow from their scientific premises. For example, some supposed tensions between folk theory and contemporary science depend on fallacies committed in the attempt to draw out the consequences of common sense beliefs.
Analytic philosophy at its best uses logical rigor and semantic sophistication to achieve a sharpness of philosophical vision unobtainable by other means. To sacrifice those gains would be to choose blurred vision. Fortunately, one can do more with good vision than look at eyes.
Many have been attracted to the idea that all philosophical problems are linguistic or conceptual through the question: if the method of philosophy is a priori reflection, how can it lead to substantive knowledge of the world? Those who find that question compelling may propose that it informs us of relations of ideas rather than matters of fact, or that its truths are analytic rather than synthetic, or that it presents rules of grammar disguised as descriptions, or that its aim is the analysis of thought or language. In short, on this view, philosophical truths are conceptuals truths. We may suspect the pres- ence of empiricist presuppositions in the background – or, as with
Ayer, in the foreground. Not starting with such presuppositions, we should be open to the idea that thinking just as much as perceiving is a way of learning how things are. Even if one does not fully understand how thinking can provide new knowledge, the cases of logic and mathematics constitute overwhelming evidence that it does so.
The case of the original question, which is philosophical yet queries a theorem of classical logic, shows that we cannot segregate logic from philosophy and claim that armchair thinking illuminates the former but not the latter. In particular, conceptions of logic and mathematics as (unlike philosophy) somehow trivial or non-substantial have not been vindicated by any clear explanation of the relevant sense of 'trivial' or 'non-substantial.' Whether a given formal system of logic or mathematics is consistent is itself a non-trivial question of logic or mathematics. We know from Gödel’s second incompleteness theorem that the consistency of most standard systems of elementary mathematics cannot be decided in equally elementary mathematics, unless the original system is already inconsistent. The next two chapters investigate in more depth the prospects for conceptual truth and its role in philosophy.

3
Metaphysical Conceptions of Analyticity

1
'Philosophical questions are more conceptual in nature than those of other disciplines': that can easily pass for a statement of the obvious.1 Many philosophers consciously seek conceptual connections, conceptual necessities, conceptual truths, conceptual analyses.
In effect, they present themselves as seeking far more general and less obvious analogues of 'Vixens are female foxes.' The suggestion is that an armchair methodology is appropriate to their quest because it concerns truths in some sense less substantial, less world-involving than those of other disciplines: in Humean terms, relations of ideas rather than matters of fact. Our conceptual or linguistic competence, retained in the armchair, is to suffice for a priori knowledge of the relevant truths.
As already argued, philosophical truths are not generally truths about words or concepts. However, analytic truths are not supposed to be always about words or concepts, even if words or concepts are supposed to play a special role in explaining their truth. The sentence
'Vixens are female foxes' is in no useful sense about the word
1

To give just one example, even Jack Smart, whose work robustly engages the nature of the non-linguistic, non-conceptual world and who described metaphysics as 'a search for the most plausible theory of the whole universe, as it is considered in the light of total science' (1984: 138), could also write that philosophy is 'in some sense a conceptual inquiry, and so a science can be thought of as bordering on philosophy to the extent to which it raises within itself problems of a conceptual nature'
(1987: 25), although he admits that he 'cannot give a clear account of what I have meant when earlier in this essay I have said that some subjects are more concerned with 'conceptual matters' than are others' (1987: 32). 'vixen' or any other words; it is about vixens, if anything. Its meaning is not to be confused with that of the metalinguistic sentence
' ‘Vixens are female foxes’ is true.' Similarly, the thought vixens are female foxes is not about the concept vixen or any other concepts; it too is about vixens, if anything. It is not to be confused with the metaconceptual thought the thought VIXENS ARE FEMALE FOXES
is true.
How can a sentence which comes as close as 'Vixens are female foxes' does to being a definition of 'vixen' be about vixens rather than about the word 'vixen'? Uttering it in response to the question
'What does ‘vixen’ mean?' normally enables the questioner to work out the answer to the question, by pragmatic reasoning, even though the literal meaning of the sentence does not directly answer the question, just as does uttering 'That is a gnu' while pointing at one in answer to the question 'What does ‘gnu’ mean?.' If core philosophical truths are analytic, they may exhibit significant features of words or concepts without describing them.
Does the conception of philosophical truths as analytic or conceptual vindicate a form of the linguistic or conceptual turn without misrepresenting the subject matter of philosophy as itself linguistic or conceptual? The case study in the previous chapter gave no support to such a conjecture. Nevertheless, let us examine the matter more systematically.
Many philosophically relevant truths are clearly not conceptual truths in any useful sense. For instance, in arguing against subjective idealism, a defender of common sense metaphysics says that there was a solar system millions of years before there was sentient life.
Similarly, a defender of common sense epistemology says that he knows that he has hands; that he knows that he has hands is no conceptual truth, for it is consistent with all conceptual truths that he lost them in a nasty accident. Some philosophers of time argue that not only the present exists by appeal to Special Relativity. Philosophers of mind and language dispute whether there is a language of thought; whatever the answer, it is no conceptual truth. Naturalists and anti-naturalists dispute whether there is only what there is in space and time; again, the answer is unlikely to be a conceptual truth.
Moral and political philosophers and philosophers of art appeal to empirically discovered human cognitive limitations, and so on.
Such philosophical arguments cannot be dismissed on general Metaphysical Conceptions of Analyticity

methodological grounds. One must engage with them on their merits, in the normal way of philosophy.
Despite such examples, philosophy may be thought to have a central core of truths which are all conceptual; perhaps the rest of philosophy counts as such through its relation to the central core. Let us charitably read this restriction into the appeal to analyticity or conceptual truth in the epistemology of philosophy.
Notoriously, the idea of analyticity has been under a cloud ever since Quine argued that 'a boundary between analytic and synthetic statements simply has not been drawn' (1951: 34). Nevertheless, the idea is still active in contemporary philosophy, often under the less provocative guise of 'conceptual truth.' The terms 'analytic' and
'conceptual' will henceforth be used interchangeably.
Quine’s arguments are generally found much less compelling than they once appeared. Although he may succeed in showing that
'analytic' is caught in a circle with other semantic terms, such as
'synonymous,' he does not adequately motivate his jump from that point to the conclusion that the terms in the circle all lack scientific respectability, as opposed to the contrary conclusion that they all have it. Given any science, someone may insist that it define its terms, and the terms used to define them, and so on until it is driven round in a circle. By itself, that hardly demonstrates the illegitimacy of the science. Every discipline must use undefined terms somewhere or other. 'Two Dogmas of Empiricism' does not explain why we should regard the undefined terms of semantics as worse off than the undefined terms of other disciplines, except by dogmatic charges of unclarity. After all, semantics is now a thriving branch of empirical linguistics. It is not to be trashed without very good reason.2
Some terms may be so unclear by ordinary working standards that no circle of definitions will render them scientifically useful. But semantic terms are not like that. By ordinary working standards, the word 'synonymous' is quite clear enough to be useful. Although it is not perfectly precise – surely it has borderline cases – its degree of vagueness seems no worse than that of undefined terms in many other
2

The overall criticism of Quine’s procedure goes back to Grice and Strawson
(1956). Sober (2000) argues that Quine violates his own methodological naturalism in criticizing semantic notions on foundational grounds without considering their use in science. sciences. When clarification is needed in some specific respect, it can be achieved by stipulation or otherwise, as elsewhere in science.
Indeed, few contemporary philosophers feel special qualms in using the term 'synonymous.' Thus any objection they have to 'analytic'
can hardly be based on Quine’s arguments, since his only objection to defining 'analytic' in terms of 'synonymous' is to the use of
'synonymous' (1951: 24, 35).
The feeling remains that 'analytic,' unlike 'synonymous,' carries obsolescent philosophical baggage. For 'analytic,' unlike 'synonymous,' was once a central term in philosophical theorizing, notably in the work of logical positivists, such as Carnap, and of postwar linguistic philosophers, such as Strawson. The reason why it cannot recover that position lies not in Quine’s critique, which no longer seems compelling, but rather in Kripke’s widely accepted clarification of the differences between analyticity, apriority and necessity. Kripke did not deny that there is a boundary between the analytic and the synthetic; he merely distinguished it from other boundaries, such as the epistemological boundary between the a priori and the a posteriori and the metaphysical boundary between the necessary and the contingent (Kripke 1980: 39). He stipulated that 'analytic' entails both 'a priori' and 'necessary.' Since he argued that neither of 'a priori' and 'necessary' entails the other, he was committed to denying that either of them entails 'analytic' (by the transitivity of entailment).3 Thus 'analytic' does neither the purely epistemological work of 'a priori' nor the purely metaphysical work of 'necessary.'
Its current role inevitably looks less central than the one it occupied when 'a priori' and 'necessary' were treated as pretty much
3

Given Kripke’s arguments, defining 'analytic' as the conjunction of 'a priori'
and 'necessary' does not yield a natural notion, since a disjunction of an a priori contingency with an unrelated a posteriori necessity will then count as analytic: it is a priori because its first disjunct is and necessary because its second disjunct is. One does somewhat better by defining 'analytic' as 'a priori necessary,' which excludes that example, although the point of such a combination of epistemological and metaphysical elements remains to be explained. The arguments below apply to this notion too. Of course, Kripke’s main concern is the difference between the a priori / a posteriori and the necessary/contingent distinctions; he clarifies their differences from the analytic/synthetic distinction in passing. Nevertheless, the differentiation between the first two distinctions forces the demotion of the third from that of trying to play both the first role and the second. Metaphysical Conceptions of Analyticity

interchangeable and 'analytic' was taken to do the work of both.
But that does not yet imply that no work remains for it to do.
If we try to sort sentences as 'analytic' or 'synthetic' in the manner of chicken-sexers, we can usually achieve a rough consensus.
Of course borderline cases will occur, but so they do for virtually every distinction worth making: perfect precision is an unreasonable demand. The issue is what theoretical significance, if any, attaches to the rough boundary thus drawn. Even if 'analytic' is defined in terms of 'synonymous' and other expressions under better control than
'analytic,' we should not assume without checking that it has any of the consequences sometimes associated with it. In particular, we should not assume that analytic truths are insubstantial in any further sense.
Nothing in this book challenges the legitimacy of familiar semantic terms such as 'synonymous.' They will be used without apology, and they permit various senses of 'analytic' to be defined. But none of them makes sense of the idea that analytic truths are less substantial than synthetic ones, or that core philosophical truths are less substantial than the truths of most other disciplines. There is something robust about 'Two Dogmas of Empiricism': insights remain even when its skepticism towards meaning is stripped away.
On some conceptions, analytic sentences are true simply in virtue of their meaning, and analytic thoughts simply in virtue of their constituent concepts. They impose no constraint on the world, not even on that part of it which consists of words and concepts. That is why it is unnecessary to get up out of one’s armchair to investigate whether such a constraint is met. Analytic truths are less substantial than synthetic ones because the latter do impose constraints on the world, which it may or may not meet. This is another way of putting the idea that analytic truths are true in virtue of meaning alone while synthetic truths are true in virtue of a combination of meaning and fact, for if analytic truths did impose constraints on the world, they would be true partly in virtue of the fact that the world met those constraints, and so not true in virtue of meaning alone. Call such conceptions of analyticity metaphysical. Other conceptions dispense with the idea of truth in virtue of meaning, and treat analyticity as a privileged status in respect of knowledge or justification which a sentence or thought has in virtue of the conditions for understanding its constituent words or possessing its constituent concepts. Although the privileged truths impose constraints on the world, the task of checking that they are met is somehow less substantial than for other truths, for those who understand the relevant words or possess the relevant concepts. Call such conceptions of analyticity epistemological.4
This chapter examines a variety of attempts to develop a metaphysical account of analyticity. Some depend on misconceptions about meaning or truth. Others yield intelligible notions of analyticity, by watering down the traditional account to a point where it loses most of its usually supposed implications. They provide no reason to regard analytic truths as in any way insubstantial.5 Even if core philosophical truths are analytic in such a sense, that does not explain how we can know or justifiably believe them.6 At best it reduces the problem to the epistemology of another class of truths, such as necessary truths or logical truths. The next chapter will examine attempts to develop an epistemological account of analyticity, also with negative results. The overall upshot is that philosophical truths are analytic at most in senses too weak to be of much explanatory value or to justify conceiving contemporary philosophy in terms of a linguistic or conceptual turn.
The conclusion is not best put by calling purportedly analytic truths 'substantial,' because in this context the term 'substantial'
is hopelessly vague. Rather, appeals in epistemology to a metaphysical conception of analyticity tend to rely on a picture of analytic truths as imposing no genuine constraint on the world, in order to See Boghossian (1997) for the distinction between metaphysical and epistemological accounts of analyticity, and Tappenden (1993: 240) for a somewhat similar distinction.
5
Etchemendy (1990: 107–24) contrasts 'substantive' generalizations with logical ones. The idea is widespread. It occurs in different forms in Wittgenstein’s Tractatus
Logico-Philosophicus and in Locke’s 'Of trifling propositions' (An Essay Concerning
Human Understanding, Book IV, Chapter viii).
6
Since analytic truths are standardly taken to be sentences, the term 'true' will sometimes be applied to sentences, as well as to thoughts and propositions; where required, the context makes clear what kind of truth-bearer is intended. Talk of knowing or believing a sentence should be understood as elliptical for talk of having knowledge or belief which one can express with the sentence (on its standard meaning).
Thus someone who knows 'Grass is green' knows that grass is green and can express that knowledge by saying 'Grass is green'; this is not to be confused with the metalinguistic knowledge that the sentence 'Grass is green' is true. Metaphysical Conceptions of Analyticity

explain the supposed fact that knowing them poses no serious cognitive challenge. If that account could be made good, it would provide a useful sense for 'insubstantial,' which would refer to the pictured property, epistemological not in its nature but in its explanatory power. Substantial truths would be the ones that lacked this property.
But the account cannot be made good. The metaphysical picture cannot be filled in so as to have the required explanatory power in epistemology. Thus 'substantial' and 'insubstantial' are not provided with useful senses. The negation of a picture is not itself a picture. That is a problem for appeals to metaphysical analyticity, not for the present critique.

2
The distinction between analytic truth and synthetic truth does not distinguish different senses of 'true': analytic and synthetic truths are true in the very same sense of 'true.' That should be obvious.
Nevertheless, it is hard to reconcile with what many logical positivists, Wittgensteinians and others have said about analytic truths. For they have described them as stipulations, implicit definitions (partial or complete), disguised rules of grammar and the like. On such a conception, enunciating an analytic truth is not stating a fact but something more like fixing or recalling a notation: even if talk of truth as correspondence to the facts is metaphorical, it is a bad metaphor for analytic truth in a way in which it is not for synthetic truth.
In the face of this conception, we should remind ourselves why
'truth' is quite unequivocal between 'analytic truth' and 'synthetic truth.'
We can start by considering a standard disquotational principle for truth (where both occurrences of 'P' are to be replaced by a declarative sentence):
(T) 'P' is true if and only if P.
If 'true' is ambiguous between analytic truth and synthetic truth,
(T) must itself be disambiguated. Nevertheless, the left-to-right direction holds for both notions: (Talr) 'P' is analytically true only if P.
(Tslr) 'P' is synthetically true only if P.
Obviously, 'Bachelors are unmarried' is analytically true only if bachelors are unmarried, just as 'Bachelors are untidy' is synthetically true only if bachelors are untidy. The exact parallelism of (Talr)
and (Tslr) already casts doubt on the supposed ambiguity. Indeed, they are jointly equivalent to a single principle about the disjunction of analytic truth and synthetic truth ('simple truth'):
(Taslr) 'P' is analytically true or synthetically true only if P.
Worse, the right-to-left direction fails for both notions:
(Tarl) 'P' is analytically true if P.
(Tsrl) 'P' is synthetically true if P.
For (Tarl) has a false instance when a synthetic truth is substituted for 'P'; (Tsrl) has a false instance when an analytic truth is substituted for 'P.' There are no natural substitutes for the right-to-left direction of (T) in the form of separate principles for analytic truth and synthetic truth. Rather, the natural substitute for the right-to-left direction disjoins the two notions:
(Tasrl) 'P' is analytically true or synthetically true if P.
But (Tasrl) reinstates simple truth as the theoretically important characteristic.
One cannot avoid the problem by qualifying 'true' in (T) with
'analytic' for 'the relevant kind of sentence' and with 'synthetic'
for the rest. For the sentences of the relevant kind are presumably just the analytic truths and analytic falsehoods. Thus the schemas for analytic and synthetic truth amount to these:
(Ta) If 'P' is analytically true or analytically false, then 'P' is analytically true if and only if P.
(Ts) If 'P' is neither analytically true nor analytically false, then
'P' is synthetically true if and only if P. Metaphysical Conceptions of Analyticity

But (Ta) and (Ts) follow from (Taslr), (Tasrl) and the analogue for falsity of (Taslr):7
(Faslr) 'P' is analytically false or synthetically false only if not P.
Thus the information in (Ta) and (Ts) is in effect just information about the disjunction of analytic truth and synthetic truth. The attempt to treat analytic truth and synthetic truth separately just confuses the theory of 'true.' The same happens for other theoretically important applications of 'true.'
Consider the standard two-valued truth-table for the material conditional:
A
T
T
F
F

B
T
F
T
F

A

B
T
F
T
T

If 'true' is ambiguous between analytic truth and synthetic truth, what does 'T' mean in that table? We might try subscripting it as
Tanalytic and Tsynthetic, multiplying the possibilities in the first two columns accordingly and adding the appropriate subscript in the third column.
'F' will require corresponding subscripts too. Since the possibilities
Tanalytic, Tsynthetic, Fanalytic and Fsynthetic arise for both A and B, the new truth-table will have sixteen lines. Worse, consider this case: Proof: Assume (Taslr), (Faslr) and (Tasrl). To derive (Ta), note that it is equivalent to the conjunction of two claims: (i) if 'P' is analytically true, then 'P' is analytically true if and only if P; (ii) if 'P' is analytically false, then 'P' is analytically true if and only if P. Now (i) is logically equivalent to the claim that 'P' is analytically true only if P, which follows from (Taslr). Moreover, by (Faslr) 'P' is analytically false only if not P; as just seen 'P' is analytically true only if P, so 'P' is analytically false only if 'P' is not analytically true; thus if 'P' is analytically false then both sides of the biconditional in the consequent of (ii) fail, so (ii) holds. To derive (Ts), first note that 'P' is synthetically true only if P by (Taslr). Conversely, if P then 'P' is analytically true or synthetically true by (Tasrl); since by the antecedent of (Ts) it is not analytically true, it is synthetically true. Incidentally, by themselves (Ta) and (Ts) are weak in other ways too; in particular, they do not entail that nothing can be both analytically true and synthetically true. A
Tsynthetic

B
Tsynthetic

A

B
T?

What subscript is appropriate for the third column? Suppose that
Barbara is a barrister, and therefore a lawyer. Of the following four sentences, (1), (2) and (4) are synthetic while (3) is analytic (with 'if'
read as ):
(1)
(2)
(3)
(4)

Barbara is a barrister.
Barbara is a lawyer.
If Barbara is a barrister, Barbara is a lawyer.
If Barbara is a lawyer, Barbara is a barrister.

Since Barbara could easily not have been a lawyer at all, (1) and (2)
are synthetic. If there are analytic truths, (3) is one of them; 'barrister' simply means a lawyer with certain qualifications. Thus we cannot put 'synthetic' for the missing subscript in that line of the truth-table, for that gives the wrong result when we read A as (1)
and B as (2). Since Barbara could easily have been a lawyer without being a barrister, by being a solicitor, (4) is synthetic too. Thus we also cannot put 'analytic' for the missing subscript, since that gives the wrong result when we read A as (2) and B as (1). Therefore the truth-table cannot be completed. Whether a material conditional is analytically true and whether it is synthetically true are not a function of whether its antecedent is analytically true, whether its antecedent is synthetically true, whether its consequent is analytically true and whether its consequent is synthetically true.
The best we can do is to put the disjunction of Tanalytic and Tsynthetic in the third column. But then in order to apply the truth-table iteratively, when one occurrence of is embedded inside another, we shall need further lines in which such disjunctions appear in the first two columns as well as the third. In effect, we have merely recovered a single sense of 'true,' applicable to both analytic truths and synthetic truths, albeit awkwardly defined by a disjunction. The same conclusion can be reached by looking at combinations of other logical constants, such as conjunction and negation. What does the central work in the compositional semantics is that indiscriminate notion of truth, not the more specific notions of analytic truth and synthetic truth. Metaphysical Conceptions of Analyticity

A corresponding result holds for the theory of logical consequence.
Valid arguments preserve truth from premises to conclusion. What can we say if 'truth' must be disambiguated between analytic truth and synthetic truth? A valid argument whose premise is a synthetic truth may have either a synthetic truth or an analytic truth as its conclusion. For example, the conjunction of a synthetic truth with an analytic truth is itself a synthetic truth, and has each conjunct as a logical consequence. For logic, the significant generalizations concern the indiscriminate disjunction of analytic truth with synthetic truth, not either disjunct separately.8
Analytic truths and synthetic truths are true in exactly the same central sense of 'true.' That is compatible with their being true in very different ways, just as being a mother and being a father are two very different ways of being a parent; 'parent' is not ambiguous between mothers and fathers. But truth-conditional semantics undermines even that idea. For how are (3) and (4) true in very different ways? Each is a material conditional; the antecedent and consequent of each are true in relevantly the same way as the antecedent and consequent of the other respectively. Their compositional semantic evaluation proceeds in parallel. Yet (3) is analytic, (4) synthetic. From the perspective of compositional semantics, the analytic-synthetic distinction is no distinction between different ways of being true; it is just a distinction between some truths and others.

3
On the metaphysical conception, analytic truths differ from synthetic ones by being true 'in virtue of meaning.' The intended contrast seems to be this. A synthetic truth is true because it means what it does and things are as that meaning requires. For example, 'Barbara is a barrister' is true because it means that Barbara is a barrister, and
Barbara is a barrister. For an analytic truth, the second conjunct drops out. 'Barristers are lawyers' is true simply because it means that barristers are lawyers. Nothing else is needed. But the contrast is unconvincing. For that explanation of the truth of 'Barristers are lawyers' works only when we take for granted that barristers are
8

For related arguments see Williamson (1994b: 141–2) and Tappolet (1997). lawyers. It is no good to say 'Never mind whether barristers are lawyers; ‘Barristers are lawyers’ is true simply because it means that barristers are lawyers.' For any true sentence s whatsoever, a canonical explanation of the truth of s takes the overall form 's means that
P, and P.'9 To use the obscure locution 'in virtue of,' every true sentence is true in virtue of both its meaning and how things are.
This is another way of making the point that analytic truths and synthetic truths are not true in radically different ways.10
We can ask 'in virtue of' questions about non-metalinguistic matters too. In virtue of what are vixens female foxes? To use another obscure locution, what makes it the case that vixens are female foxes?
An appeal to semantic or other facts about the words 'vixen,'
'female' and 'fox' in answer to those questions would confuse use and mention. Vixens would have been female foxes no matter how we had used words. Presumably, vixens are female foxes in virtue of whatever female foxes are female foxes in virtue of; what makes it the case that vixens are female foxes is whatever makes it the case that female foxes are female foxes. Some may argue that female foxes are not female foxes in virtue of anything; nothing makes it the case that female foxes are female foxes. The suggestion may be that analytic truths require no truthmaker, unlike synthetic truths. An alternative suggestion is that analytic truths require truthmakers of a different kind from those of synthetic truths. Such suggestions are too unconstrained to be tractable for assessment. Still, two points stand out. First, they seem to conflict with general principles of See Boghossian (1997: 335–6). Quine says that we can say that the logical truth
'Everything is self-identical' depends for its truth 'on an obvious trait, viz., selfidentity, of its subject matter, viz., everything.' However, he claims that it makes no difference whether we say that or say that it depends for its truth 'on traits of the language (specifically on the usage of '='), and not on traits of its subject matter'
(1966: 106).
10
Another problem for the supposed contrast is that it seems to equivocate on
'means.' When we explain why 'Barbara is a barrister' is true by saying 'It means that Barbara is a barrister, and Barbara is a barrister,' 'means' can be paraphrased as 'expresses the proposition'; what proposition a sentence expresses may depend on the context in which it is uttered, if indexicals are present. By contrast, the appeal to meaning in the case of analytically true sentences is not to the proposition expressed on some particular occasion but rather to the linguistic meaning of the sentence, which is invariant across contexts, even if indexicals are present. Metaphysical Conceptions of Analyticity

truthmaker theory (in the unlikely event that such a theory is needed).
For instance, what makes a disjunction true is what makes one of its disjuncts true. Thus whatever makes (2) ('Barbara is a lawyer') true also makes both (5) and (6) true:
(5) Barbara is a lawyer or Barbara is not a lawyer.
(6) Barbara is a lawyer or Barbara is a doctor.
But (5) is a simple logical truth, while (6) is a straightforward synthetic truth. Second, no connection has been provided between truthmaker theory and epistemology. Knowing a truth need not involve knowing its truthmaker; one can know (6) without knowing which disjunct is true (Barbara works in a building where only lawyers and doctors work). No account has been given as to why it should be easy from an armchair to know a truth with no truthmaker, or a truthmaker only of the special sort supposedly appropriate to analytic truths.
Nevertheless, at least one clear difference between paradigms of
'analytic' and paradigms of 'synthetic' is in the vicinity. For meaning that barristers are lawyers is sufficient for being true, whereas meaning that Barbara is a barrister is not. More generally, call a meaning sufficient for truth just in case necessarily, in any context any sentence with that meaning is true.11 Thus the meaning of 'Barristers are lawyers' is sufficient for truth; the meaning of 'Barbara is a barrister' is not. One proposal is to explicate 'analytic truth' as
'truth whose meaning is sufficient for truth.' Call this 'modalanalyticity.'12 For non-skeptics about meaning and necessity, the

11
To handle ambiguity, treat it as homonymy: distinct sentences with the same superficial form. The reification of meanings in the definition can be eliminated at the cost of circumlocution. Note also that the utterance of a modal-analytic truth may be false if the context shifts during the utterance: consider 'If it is now exactly noon then it is now exactly noon.' Similarly, an utterance of 'If John is a bachelor then
John is unmarried' may express a falsehood if the wedding ceremony is completed between the utterance of the antecedent and the utterance of the consequent. Taking such complications into account would not help friends of analyticity.
12
The notion of modal-analyticity is similar to the notion of deep necessity in Evans
(1979), where the truth of the sentence does not depend on any contingent feature of reality. notion of modal-analyticity is quite intelligible. But what are its consequences?
Consider any non-indexical sentence s that expresses a necessarily true proposition. Necessarily, in any context, any sentence with the actual meaning of s expresses that necessary truth and is therefore true. Thus s is a modal-analytic truth, because its meaning is sufficient for truth. In that sense, it is true in virtue of meaning. But how little has been achieved in so classifying it! Nothing has been done to rule out the hypothesis that it expresses a profound metaphysical necessity about the nature of the world, knowable if at all only through arduous a posteriori investigation, for instance. No reason has been provided to regard s as 'merely verbal' or 'insubstantial' in a pretheoretic sense, unless one already had independent reason to regard all necessities as merely verbal or insubstantial. Similarly, mathematical truths count as modal-analytic; their so counting is by itself no reason to regard them as merely verbal or insubstantial.
Indeed, for all that has been said, even 'Water contains H2O' is modal-analytic, given that 'water' has a different meaning as used on Twin Earth to refer to XYZ, a different substance with the same superficial appearance.
To make the point vivid, call a meaning temporally sufficient for truth just in case at all times, in any context any sentence with that meaning is true. Read the quantifiers 'at all times' and 'in any context' non-modally, so they do not range outside the actual world.
Thus any sentence which expresses, in a time-independent way, an eternally true proposition, however contingent, has a meaning temporally sufficient for truth. For example, the meaning of 'No hotel ever has a billion rooms' is presumably temporally sufficient for truth.
We can call the sentence 'temporal-analytic' if we like, but that in no way implies that it is somehow insubstantial, because there is no background connection between eternity and some sort of insubstantiality. Similarly, calling a sentence 'analytic' in the sense of modalanalyticity does not imply that it is somehow insubstantial, in the absence of a background connection between necessity and some sort of insubstantiality. Yet the account of analyticity was what was supposed to substantiate the claim of insubstantiality. If we already had a background connection between necessity and insubstantiality, there would be little to gain from invoking modal-analyticity in order to argue that core philosophical truths are insubstantial, since Metaphysical Conceptions of Analyticity

we could do it more simply just by arguing that true philosophical sentences in the core express necessarily true propositions.
Admittedly, not all modal-analytic true sentences express necessarily true propositions. Examples of the contingent a priori such as 'It is raining if and only if it is actually raining' are modal-analytic, since the truth of 'It is raining' as uttered in a given context is necessarily equivalent to the truth of 'It is actually raining' as uttered in that context, because 'actually' refers rigidly to the world of the context, but the biconditional does not express a necessary truth, since the weather could have been relevantly different, in which case it would have been not raining if and only if it is actually raining. Thus modalanalyticity violates Kripke’s constraint that analyticity implies necessity; in this respect it may diverge from the traditional conception.
Conversely, not all sentences that express necessarily true propositions are modal-analytic: consider examples of the necessary a posteriori such as 'I am not Tony Blair.' Nevertheless, such examples seem marginal to the envisaged conception of core philosophical truths, most of which will both express necessarily true propositions and be modal-analytic.
A core of philosophical truths may indeed be modal-analytic. Some philosophers seek to articulate necessary truths without essential reliance on indexicals; if they succeed, the sentences they produce are modal-analytic. Even if contextualists are right, and key philosophical terms such as 'know' shift their reference across contexts, the relevant sentences may still both express necessarily true propositions and be modal-analytic: consider 'Whatever is known to be the case is the case.' The answers to philosophical questions of the forms 'Is it possible that P?' and 'Is it necessary that P?' will themselves express necessary truths, given the principle of the widely accepted modal logic S5 that the possible is non-contingently possible and the necessary non-contingently necessary; if the answers can be phrased in non-indexical terms, they will then be modal-analytic. But outside the envisaged core many philosophically relevant truths will not be modal-analytic, as the examples near the start of the chapter show.
Unfortunately, even for modal-analytic philosophical truths, classifying them as modal-analytic does not unlock their epistemology, any more than classifying a truth as necessary explains how we can know it. Of course, if a sentence is modal-analytic, then one is safe from error in uttering it with its given meaning. In that sense, one’s utterance is reliable. But such reliability falls well short of what knowledge requires, since otherwise any true mathematical assertion would count as an expression of knowledge, no matter how fallacious the 'proof' on which it was based. 'Vixens are female foxes' is utterly misleading as a paradigm for the epistemology of modal-analytic truths in general. To say that s is a modal-analytic truth whose constituent words and grammar we understand does very little way to explain how we can know or justifiably believe s.13 In particular, it does not imply that the mere linguistic understanding of s, which every competent speaker possesses, provides any insight into the truth of s, or constitutes more than the minimal starting-point for inquiry it does for ordinary synthetic truths.

4
Issues related to those just raised for modal-analyticity arise for what is sometimes called 'Frege-analyticity.'14 A sentence is Frege-analytic just in case it is synonymous with a logical truth. For example, 'All furze is furze' is a logical truth, roughly speaking because everything of the form 'All F is F' is true. 'All furze is gorse' is not a logical truth, because not everything of the form 'All F is G' is true ('All fungus is grease' is false). However, 'All furze is gorse' is Fregeanalytic, because it is synonymous with the logical truth 'All furze is furze,' since 'furze' is synonymous with 'gorse.' In 'Two
Dogmas,' Quine admits the notion of logical truth, and therefore allows that if 'synonymous' were legitimate, so would be 'analytic'
in the sense of Frege-analyticity. By present standards, the notion of
Frege-analyticity is quite intelligible. But what are its consequences?
Trivially, every logical truth is Frege-analytic, because it is synonymous with itself. Clearly, this alone does nothing to show that logical truths are somehow insubstantial in any metaphysical, epistemologically explanatory sense (see the end of Section 1). For instance, it is compatible with the hypothesis that there are truths of second-order logic which characterize the necessary structure of reality in profound
13

See n. 6 for this terminology.
The term 'Frege-analytic' is from Boghossian (1997), with reference to §3 of
Frege (1950) (as Boghossian suggests, the interpretation of the passage is not entirely clear). He classifies the notion of Frege-analyticity as neither epistemological nor metaphysical but semantic (1997: 363); for convenience, it is treated here under the heading of metaphysical notions of analyticity.
14 Metaphysical Conceptions of Analyticity

ways and can never be known by any mind. A fortiori, nothing has been done to show that Frege-analytic truths are insubstantial.15
To make the point vivid, call a sentence 'Einstein-analytic' just in case it is synonymous with a truth once uttered by Einstein. Trivially, every truth once uttered by Einstein is Einstein-analytic. That does nothing to show that truths once uttered by Einstein are in any sense insubstantial; a fortiori, nothing has been done to show that
Einstein-analytic truths are somehow insubstantial. Of course, if we had independent reason to regard all logical truths as somehow insubstantial, that would presumably give us reason to regard all
Frege-analytic truths as insubstantial in some related way, but the mere definition of 'Frege-analytic' provides no such reason. Quine devoted some of his most powerful early work to arguing that logical truths are not analytic in a less trivial sense (Quine 1936).
To explain why 'All furze is furze' is a logical truth while 'All furze is gorse' is not, use was made of Tarski’s standard model-theoretic account of logical consequence as truth-preservation under all interpretations which preserve logical form, and in particular of logical truth as truth under all such interpretations (Tarski 1983b). It lends no support to any conception of logical truths as somehow insubstantial.
The truth of a sentence under all interpretations which preserve its logical form in no way make its truth under its intended interpretation insubstantial.16 To use a style of argument from Section 2, consider this simple logical truth (with 'if' read as the material conditional):
(7) If Barbara is a barrister, Barbara is a barrister
Its compositional semantic evaluation proceeds in parallel to that for the non-logical analytic truth (3) and the synthetic truth (4); each is true because it is a material conditional with a true antecedent and a true consequent. All three are true in the same way. From the perspective of compositional semantics, logical truths are true in the same way as other truths.
In one good sense, sentences of the form 'P if and only if actually
P' are logical truths, and therefore Frege-analytic, because true in
15

Quine (1966: 111) notes that so-called truth by definitions ('Every vixen is a female fox') depends on prior logical truths ('Every female fox is a female fox').
16
Note that the epistemological issue is not how we can know that s is a logical truth; it is how, given that s is a logical truth, we can know the simple truth of s. every model (Davies and Humberstone 1980, Kaplan 1989). Nevertheless, they can express contingent truths on the same reading; it is not necessary for me to be my actual height. Although we could add a modal qualification to the definition of logical truth in order to exclude such examples, by requiring logical truths to be true at every world in every model, this mixing together of the modal dimension with the world dimension is bad taxonomy; perspicuous basic notions keep such different dimensions separate. Thus Frege-analyticity, like modal-analyticity, violates Kripke’s constraint that analyticity implies necessity. In this respect Frege-analyticity too may diverge from the traditional conception.
The mathematical rigor, elegance, and fertility of model-theoretic definitions of logical consequence depend on their freedom from modal and epistemological accretions. As a result, such definitions provide no automatic guarantee that logical truths express necessary or a priori propositions. This is no criticism. As a theoretical discipline, logic only recently attained maturity. Tarski’s model-theoretic notion of logical consequence has turned out to be a key theoretical notion. To reject it on the basis of preconceived extraneous constraints would subvert the autonomy of logic as a discipline. Pretheoretic conceptions of logical consequence are in any case too confused to provide much guidance on subtle issues.17 Still, those who do have a non-standard account of logical truth can feed it into the definition of 'Frege-analytic' if they like.
'All furze is furze,' unlike many logical truths, is obvious. That does not justify the idea that it imposes no constraint on the world, rather than one which, by logic, we easily know to be met (Wittgenstein, Tractatus Logico-Philosophicus, 4.461–4.4661 and 6.1–613).
What case does the constraint exclude? That not all furze is furze, of course. To complain that 'Not all furze is furze' does not express a genuine case is to argue in a circle. For it is to assume that a genuine constraint must exclude some logically consistent case. Since substantiality was being understood to consist in imposing a genuine constraint, that is tantamount to assuming that no logical truth is substantial, the very point at issue. Concentration on obvious logical truths obscures this circularity.
17 We may hope, given an epistemology for logical truths, to extend it to an epistemology for Frege-analytic truths. That task will not be trivial, for cognitive differences may arise between synonymous expressions, even for those who understand them. For example,
Kripke (1979) has argued persuasively that a competent speaker of
English can understand the synonymous expressions 'furze' and
'gorse' in the normal way without being in a position to know that they refer to the same thing. Such a speaker will assent to the logical truth 'All furze is furze' while refusing assent to the Frege-analytic truth 'All furze is gorse.' Similarly, on standard theories of direct reference, coreferential proper names such as 'Hesperus' and 'Phosphorus' are synonymous, so an astronomically ignorant competent speaker may assent to the logical truth 'If Hesperus is bright then
Hesperus is bright' while refusing assent to the Frege-analytic truth
'If Hesperus is bright then Phosphorus is bright.'
The epistemological consequences of such examples are contested.
According to some direct reference theorists, the proposition that if
Hesperus is bright then Phosphorus is bright is the proposition that if Hesperus is bright then Hesperus is bright, so whoever knows that if Hesperus is bright then Hesperus is bright ipso facto knows that if
Hesperus is bright then Phosphorus is bright.18 However, even granted that view of propositional attitude ascriptions, that speaker is in no position to know that if Hesperus is bright then Phosphorus is bright under the guise of the sentence 'If Hesperus is bright then Phosphorus is bright,' but only under the guise of the sentence 'If Hesperus is bright then Hesperus is bright.' In a sense the speaker cannot express their knowledge by using the merely Frege-analytic sentence, even though it expresses the content of that knowledge: if they do use the sentence, their utterance will not be causally connected to their knowledge state in the right way. In elliptical terms, the speaker knows 'If Hesperus is bright then Hesperus is bright' without being in a position to know 'If Hesperus is bright then Phosphorus is bright'; they know the logically true sentence without being in a position to know the merely Frege-analytically true sentence.
If propositions are individuated in that coarse-grained direct reference way, what matters for progress in philosophy is less which propositions we know than which sentential guises we know them under. Suppose, just for the sake of argument, that some form of
18

See Salmon (1986), especially 133–5. physicalism is true, and pain is in fact identical with π, where 'π' is a name whose reference is fixed by a neuroscientific description.
According to a hard-line direct reference theory, 'pain' and 'π' are synonymous. The hypothesis 'Pain is π' becomes a focus of philosophical controversy. On some direct reference theories, everyone knew all along that pain is π, because they knew all along that pain is pain and the proposition that pain is π just is the proposition that pain is pain. If that view is correct, it just shows that such attitude ascriptions constitute the wrong level of description for understanding philosophical activity. What matters is that although everyone knew the proposition under the guise of the logical truth 'Pain is pain,' they did not know or even believe it under the guise of the merely Frege-analytic truth 'Pain is π.' In elliptical terms, they knew
'Pain is pain' but not 'Pain is π.' Perhaps such physicalist theories are false, but we can hardly expect philosophy to be a discipline in which there are no informative identities; the moral of the example stands. The need for such finer-grained descriptions of propositional attitudes is even more urgent if propositions as the objects of knowledge and belief are identified with sets of possible worlds, for then all necessary truths are identical with the set of all possible worlds: anyone who knows one necessary truth knows them all (Lewis 1996,
Stalnaker 1999: 241–73). Thus a coarse-grained account of attitude ascriptions does not trivialize the problem of extending an epistemology for logical truths to an epistemology for Frege-analytic truths.
Opponents of direct reference theories usually hope to make synonymy a more cognitively accessible relation for competent speakers.
However, the prospects for making it perfectly accessible are very dubious. Pairs such as 'furze' and 'gorse' are pre-theoretically plausible cases of synonymous expressions that speakers can understand in the ordinary way without being in a position to know them to be synonymous.19 The extension of an epistemology for logical truths to an epistemology for Frege-analytic truths will probably have to allow for significant cognitive obstacles that cannot be overcome simply by speakers’ ordinary linguistic competence.
19

See Kripke (1979). This contradicts Dummett’s claim that 'It is an undeniable feature of the notion of meaning – obscure as that notion is – that meaning is transparent in the sense that, if someone attaches a meaning to each of two words, he must know whether these meanings are the same (1978: 131). For more general theoretical considerations against such claims see Williamson (2000a: 94–107). See also
Horwich (1998: 100–1). Metaphysical Conceptions of Analyticity

Even for sentential guises, identity and distinctness are not guaranteed to be transparent to speakers: someone may be confused as to whether 'Paderewski,' the name of the politician, is the same name as 'Paderewski,' the name of the pianist (Kripke 1979). A
single speaker at a single time may associate different mental files with the same word of a natural language, or the same mental file with different words of the language. Speakers may also be confused as to whether they are calling on two mental files or one. What needs to be found is not the mythical level of description at which perfect transparency to the subject is guaranteed but rather a perspicuous level of description at which the relevant cognitive phenomena are individuated in a way that is neither so coarse-grained that the most relevant distinctions cannot be drawn nor so fine-grained that they are drowned out by a crowd of irrelevant ones. Since philosophical debates involve many interacting individuals, sentential guises usually provide an appropriate level of description.
We also need an epistemology for logical truths in the first place.
To that, the notion of Frege-analyticity contributes nothing. In particular, that a sentence is Frege-analytic does not imply that mere linguistic competence provides any insight into its truth, or constitutes more than the minimal starting-point for inquiry it does for ordinary synthetic truths.
How many philosophical truths are Frege-analytic? As a simple example, take the true sentence 'Persons are not events' (if you think that persons are events, take 'Persons are events' instead). It is not itself a logical truth, on any standard conception of logic. In particular, 'person' and 'event' seem not to be logical constants, and the logical form 'Ps are not Es' has false instances such as 'Parisians are not Europeans.' What logical truth could 'Persons are not events' be synonymous with? 'Persons who are not events are not events' is a logical truth, but not synonymous with the original.
Granted, 'persons' and 'persons who are not events' have the same intension (function from circumstances of evaluation to extension) in every context of utterance.20 Still, they are not literally synonymous, for whatever the semantic structure of 'persons,' it is finite, and
20

The contexts of utterance and circumstances of evaluation here are not restricted to the actual world. If the content of an expression has a structure which reflects the grammatical structure of the expression, then sameness of intension does not imply sameness of content, and sameness of intension in every context does not entail therefore a proper part of the semantic structure of 'persons who are not events'; thus the two expressions differ in semantic structure.
One can try to construct non-circular analyses of 'person' and
'event' or both whose substitution into the sentence would yield a logical truth: 'To be a person is to be a QRS.' However, 'person'
and 'QRS' are unlikely to be literally synonymous. Almost certainly, someone will produce a purported counterexample to the analysis:
'Such-and-such would be a person but not a QRS' or 'So-and-so would be a QRS but not a person.' Direct reference theorists will tend to expect just such counterexamples to the claim that the apparently simple term 'person' and the complex description 'QRS' have the same intension; direct reference theories partly originate from
Kripke and Putnam’s counterexamples to a host of similar descriptivist claims. Opponents of direct reference may be less pessimistic about the prospects for a complex description with the same intension as
'person.' However, on their finer-grained views of meaning, on which synonymy is as transparent as possible to competent speakers, a purported counterexample need not be correct to defeat the claim of synonymy: what counts is that its proponent is neither linguistically incompetent nor fundamentally irrational. Contemporary proponents of a descriptivist view of meaning as a rival to direct reference theory usually envisage a loose semantic connection with a cluster of descriptions rather than strict synonymy with a single description.
Whichever side of the debate one takes, there are good grounds for skepticism about the supposed synonymy of 'person' and 'QRS.'
The best bet is that 'Persons are not events' is not Frege-analytic.
The point does not depend on peculiarities of the example; it could be made just as well for most other philosophical claims.21 In contemporary philosophy, few who propose complex analyses claim synonymy for them.22
One might react by loosening the relation of synonymy to some equivalence relation that would have a better chance of holding sameness of character, that is, sameness of content in every context. See Kaplan
(1989) for relevant background.
21
Boghossian argues that many a priori truths are not Frege-analytic (1997:
338–9).
22
This point is related to the paradox of analysis: how can a conceptual analysis be both correct and informative? The paradox goes back to Langford (1942). Metaphysical Conceptions of Analyticity

between the analysandum and the analysans in philosophically significant analyses. Call the looser equivalence relation 'metaphysical equivalence.' A wider class of philosophical truths might be transformable into logical truths by the substitution of metaphysically equivalent terms. Call the truths in the wider class 'quasi-Frege-analytic.' The poor track record of philosophical analysis does not suggest that the class of quasi-Frege-analytic truths will be very much wider than the class of Frege-analytic truths.23 In any case, the looser metaphysical equivalence is, the more problematic it will be to extend an epistemology for logical truths to an epistemology for quasi-Frege-analytic truths. The aim of the loosening is to permit some distance between the meaning of the analysandum and the meaning of the analysans; that will tend to make even the coextensiveness of the analysandum and analysans less cognitively accessible. There will be a corresponding tendency to make the material equivalence of the original quasiFrege-analytic truth to the logical truth less cognitively accessible too.
For instance, one might define 'metaphysical equivalence' as sameness of intension in every context. The question is then how the sameness of intension in every context of the substituted terms could enable one to advance from knowing or justifiably believing the logical truth to knowing or justifiably believing the merely quasiFrege-analytic truth. No guarantee has been provided that we can know or justifiably believe the universally quantified biconditional of the substituted terms. By hypothesis, that biconditional will in fact express a necessary truth in every context; the problem merely shifts to how such truths can be known, just as in the case of modalanalyticity. If that problem were already solved, there would be little to gain from appealing to quasi-Frege-analyticity in order to explain how core philosophical truths can be known.
Even if many philosophical truths are quasi-Frege-analytic, it does not follow that we can gain cognitive access to them simply on the basis of our logical and linguistic competence.
Yet another proposal is to consider as (metaphysically) analytic just the logical consequences of true (or good) semantic theories. It is presumably in the spirit of this proposal to interpret semantic theories not as stating straightforwardly contingent, a posteriori facts about how people use words but as somehow articulating the essential structure of semantically individuated languages; in this sense, the word 'green'
23

See Fodor (1998: 69–87) and Williamson (2000a: 31–3) for further discussion. could not have meant anything but green in English. Even so, the definition does nothing to trace any special cognitive access that speakers have to semantic facts about their own language to any special metaphysical status enjoyed by those facts. It also counts every logical truth as analytic, since a logical truth is a logical consequence of anything, without illuminating any special cognitive access we may have to logical truths. Of course, if someone knows the relevant semantic truths about their own language and is logically proficient, then they are also in a position to know the analytic truths as so defined. But, on this definition, we do nothing to explain how the semantics and logic are known in the first place by saying that they are analytic. As in previous cases, the account of analyticity merely shifts the burden from explaining knowledge of analytic truths to explaining knowledge of some base class of necessary or logical or semantic or other truths.
Once the analyticity card has been played to effect this shift of the explanatory burden, it cannot be played again to explain knowledge of the base truths, by saying that they are analytic, for they count as analytic simply because they belong to the relevant base class, and the question remains how we know truths in the base class.

5
Unless one is a skeptic about meaning or modality, one can define several notions of analyticity in semantic and modal terms, but none of them provides any reason to regard the truths to which it applies as somehow insubstantial, or as posing no significant cognitive challenge. That upshot may seem puzzling. Surely we sometimes make a sentence true by stipulative definition. For example, I might introduce the term 'zzz' (pronounced as a buzz) by saying 'A zzz is a short sleep' and thereby make 'A zzz is a short sleep' true. What prevents us from using such cases as paradigms to fix a semantic notion of analyticity on which analytic truths are insubstantial?
We can see the problems for the proposal more clearly by distinguishing the semantic from the metasemantic. Semantics facts are facts of the kind we attempt to systematize in giving a systematic compositional semantic theory for a language, facts as to what its expressions mean. Metasemantic facts are the nonsemantic facts on which the semantic facts supervene. The distinction is rough but clear enough to be workable. Thus the fact that 'horse' applies to horses Metaphysical Conceptions of Analyticity

is semantic, not metasemantic; the fact that utterances of 'horse' are often caused by horses is metasemantic, not semantic.24 Similarly, the fact that 'zzz' means a short sleep is semantic, while the fact that it was introduced by someone saying 'A zzz is a short sleep' is metasemantic. The semantic theory takes no notice of the act of stipulation, only of its outcome – that a given expression has a given meaning.
The act of stipulation makes the sentence true by making it have a meaning on which it is, in the quite ordinary way, true. My saying
'A zzz is a short sleep' did not make a zzz be a short sleep, because that would be to make a short sleep be a short sleep, and my saying
'A zzz is a short sleep' certainly did not make a short sleep be a short sleep. In particular, since there were many short sleeps before
I was born, there were many zzzes before I was born, independently of my later actions. At best, my saying 'A zzz is a short sleep' made
'zzz' mean a short sleep, and therefore 'A zzz is a short sleep' mean that a short sleep is a short sleep. This is simply the standard semantic contribution of meaning to truth, just as for synthetic truths. The peculiarity of the case is all at the metasemantic level; the use of stipulative definitions as paradigms does not yield a semantic notion of analyticity. Making 'zzz' mean a short sleep helps make 'A zzz is a short sleep' true only because a short sleep is a short sleep. 'A
short sleep is a short sleep' is a logical truth, but we have still been given no reason to regard logical truths as somehow insubstantial.
The use of stipulative definitions as paradigms of analyticity does not justify the idea that analytic truths are in any way insubstantial.
My stipulation may smooth my path from knowing the logical truth 'A short sleep is a short sleep' to knowing the Frege-analytic truth 'A zzz is a short sleep,' but of course that does not explain how I know 'A short sleep is a short sleep' in the first place.
The metaphysics and semantics of analytic truths are no substitute for their epistemology. If their epistemology is as distinctive as is often supposed, that is not the outcome of a corresponding distinctiveness in their metaphysics or semantics. It can only be captured by confronting their epistemology directly. We therefore turn to epistemological accounts of analyticity.
24
For helpful discussion see the essays in Part IV of Stalnaker (2003). He sometimes use the terminology of 'descriptive semantics' and 'foundational semantics' rather than 'semantics' and 'metasemantics' respectively.

4
Epistemological Conceptions of Analyticity

1
As observed in the previous chapter, metaphysical conceptions of analyticity do not themselves imply that linguistic or conceptual competence constrains one’s attitudes to analytic sentences or thoughts. If our interest is in such constraints, we had best consider them directly. We can then assess what role, if any, they play in explaining the armchair methodology of philosophy.
If someone is unwilling to assent to the sentence 'Every vixen is a female fox,' the obvious hypothesis is that they do not understand it, perhaps because they do not understand the word 'vixen.' The central idea behind epistemological conceptions of analyticity is that, in such cases, failure to assent is not merely good evidence of failure to understand; it is constitutive of such failure. Of course, it is not by itself constitutive of failure to understand the word 'vixen', since someone who understands that word may nevertheless not assent to the sentence, for example because they do not understand the word
'fox'; a monolingual speaker of another language may understand
'vixen' through the testimony of a bilingual without understanding any other word of English. Rather, failure to assent to the sentence can by itself only be constitutive of failure to understand the whole sentence An unqualified link from understanding to assent is this:
(UAl)

Necessarily, whoever understands the sentence 'Every vixen is a female fox' assents to it. understands s assents to s. We could go further, by articulating an explicitly constitutive and not merely modal connection, but for present purposes the question is whether even this proposed necessary connection holds.
Three obvious glosses on UAl must be taken as read throughout.
First, it concerns 'Every vixen is a female fox' with its current meaning, for of course if the phonetically individuated sentence had meant something different, someone might easily have understood it and refused to assent. Second, assent is dispositional, for of course we are not actively assenting to any sentence whenever we understand it. Third, assent is a mental attitude, not a merely verbal one, for someone might easily understand 'Every vixen is a female fox' while refusing to give it overt assent, for example because overt assent to a triviality looks uncool. We could speak of belief rather than assent, but the latter term sounds more natural in relation to inference rules, to which the notion of analyticity will be generalized.
A corresponding notion of analyticity can be defined for thoughts: a thought t is analytic just in case necessarily, whoever grasps t assents to t. If the thought every vixen is a female fox is analytic in this sense, then:
(UAt) Necessarily, whoever grasps the thought every vixen is a female fox assents to it.
On the simplest view, thinking a thought with any attitude towards it suffices for grasping it. Friends of principles like UAt should beware of straying too far from that simple view, by claiming that 'full grasp' of a thought requires much more than the ability to think it
(Peacocke 1992: 29–33, Bealer 1998: 221–2). For such a defence of
UAt risks trivializing it, by in effect writing the consequent into the antecedent by hand. At any rate, grasp of a thought should be a matter of normal conceptual competence, just as understanding of a sentence is a matter of normal linguistic competence. We shall return to these issues below.
Call UAl and UAt 'understanding-assent links' for language and thought respectively. The picture is that grasping a thought consists of grasping its constituent concepts and the way in which they have been put together just as understanding a sentence consists of understanding its constituent expressions and syntax. Assent is no metalinguistic or metaconceptual attitude: normally, in actively assenting to 'Grass is green,' one is saying or thinking that grass is green, not that the sentence 'Grass is green' or the thought grass is green is true. However, thinking grass is green cannot be uncontentiously equated with thinking that grass is green. For thinking that grass is green presumably has as its object the proposition that grass is green. On a Russellian view, that proposition is made up of grass and greenness themselves, not of the concepts grass and green. Thus the thought grass is green, which is composed of concepts, must be distinguished from the proposition that grass is green. The thought is something like a mental vehicle for the proposition. Moreover, the same proposition can have different vehicles. For example, on this Russellian view, the proposition that Hesperus, if it exists, appears in the evening is the proposition that Phosphorus, if it exists, appears in the evening. The friend of conceptual connections is still likely to distinguish the concept Hesperus from the concept
Phosphorus, and the thought Hesperus, if it exists, appears in the evening from the thought Phosphorus, if it exists, appears in the evening, on the grounds that the former embodies a conceptual connection while the latter does not. Thus understanding-assent links for thought must be articulated in terms of thoughts rather than propositions, in case there is a difference (for Fregeans, the proposition is the thought). Assenting to the thought grass is green is something like judging that grass is green under the guise of that thought. Similarly, assenting to the sentence 'Grass is green,' for someone who understands it, is something like believing that grass is green under the guise of that sentence. More generally, in a context in which the sentence s expresses the proposition p, assenting to s, for someone who understands it, is something like believing p under the guise of s. For you, assenting to 'I am hungry' is something like believing that you are hungry under the guise of the sentence 'I am hungry,'
since in your context that sentence expresses the proposition that you are hungry, not the proposition that I am hungry. Similarly, in a context in which the thought t expresses the proposition p, assenting to t is something like believing p under the guise of t.
The notion of an understanding-assent link can be generalized from individual sentences or thoughts to arguments at the level of language or thought. For example, if someone is unwilling to assent to the inference from 'This is red and round' to 'This is red,' the Epistemological Conceptions of Analyticity

obvious hypothesis is that they do not understand one of the sentences, most probably because they do not understand the word
'and.' For epistemological conceptions of analyticity, failure to assent in such cases is again not merely good evidence of failure to understand but constitutive of such failure. Gerhard Gentzen introduced the idea that some rules of his natural deduction systems of logic have definitional status. Following him, a tradition which includes Dag Prawitz, Michael Dummett, Per Martin-Löf,
Christopher Peacocke, Robert Brandom, Paul Boghossian and many others has developed in various ways the conception of acceptance of such inference rules as playing a constitutive role in understanding the logical constants, and therefore in understanding the sentences in which they occur. For many of these thinkers, this is one step towards a quite general 'inferentialist' account of meaning and understanding for expressions in terms of their conceptual roles.1
Understanding-assent links, or something like them, are also commonly thought to play a leading role in the understanding of theoretical terms in science: if you don’t assent to some core sentences of electron theory, in which the word 'electron' occurs, you don’t understand the word, and therefore don’t understand those sentences.
A natural project is therefore to try to explain the armchair methodology of philosophy as based on something like understandingassent links: our sheer linguistic and conceptual competence mandates assent to some sentences or thoughts and inferences, which form the starting-point for philosophical inquiry. This chapter assesses the prospects for such a project.
The envisaged method cannot accurately be characterized as
'reflection on our own concepts.' For that description specifies the method only as 'reflection,' which applies to virtually all forms of philosophy. Moreover, it specifies the subject matter as 'our own concepts,' whereas the envisaged method involves reflection with our own concepts, and is therefore reflection on whatever our concepts
1

The case of deductive logic is a useful reminder that many short, trivial steps of no apparent philosophical significance can be chained together into a long, non-trivial argument of obvious philosophical significance. The short steps were not really philosophically insignificant after all: no apologies for concentrating on them here. happen to refer to – in most cases, not concepts. The idea is rather to exploit whatever epistemic assets we have simply in virtue of our linguistic and conceptual competence. Suppose that a philosopher arrives at a theory about understanding, reference, and concepts by employing a battery of general armchair techniques that rely on far more than mere linguistic and conceptual competence. Say, for definiteness, that the theory gives a crude 'best fit' account of reference, and entails that justice is whatever best fits our beliefs about justice.
Pretend that the theory is true. Even so, it does not follow that
'Justice is whatever best fits our beliefs about justice' is epistemologically analytic. For it was not reached on the basis just of linguistic and conceptual competence. Similarly, a definition of 'conceptual truth' as 'truth of the theory of concepts' is unhelpful for present purposes, since it merely raises the question how the truths of the theory of concepts are known ('metaconceptual truth' would be less misleading terminology).
In what follows, we will consider more rigorously what is epistemically available simply on the basis of linguistic and conceptual competence. To a first approximation, the answer is: nothing.

2
We start with a provisional sketch of some obstacles to extracting epistemological consequences from understanding-assent links and of some attempts to overcome them. Then we turn in Section 3 to the main argument: that understanding-assent links simply do not hold.
Our concern is knowledge or justification, not just belief or assent.
On the most optimistic view, understanding-assent links generate understanding-knowledge links like these:
(UKl)

Necessarily, whoever understands the sentence 'Every vixen is a female fox' knows 'Every vixen is a female fox.'
(UKt) Necessarily, whoever grasps the thought Every vixen is a female fox knows Every vixen is a female fox.
Here, knowing 'Every vixen is a female fox' amounts to knowing that every vixen is a female fox under the guise of the sentence 'Every Epistemological Conceptions of Analyticity

vixen is a female fox,' and knowing every vixen is a female fox amounts to knowing that every vixen is a female fox under the guise of the thought every vixen is a female fox. Since knowing something entails assenting to it (we may assume), UKl and UKt entail UAl and
UAt respectively. But since assenting to something does not entail knowing it, how are understanding-knowledge links to be extracted from understanding-assent links? UAl and UAt do not entail UKl and
UKt in any obvious way.
An even more elementary problem arises. Knowledge is factive.
Thus understanding-knowledge links entail corresponding understanding-truth links:
(UTl)
(UTt)

Necessarily, someone understands the sentence 'Every vixen is a female fox' only if it is true.
Necessarily, someone grasps the thought Every vixen is a female fox only if it is true.

Thus if understanding-assent links somehow imply the corresponding understanding-knowledge links, a fortiori they also imply the understanding-truth links. Perhaps UTl and UTt hold because the sentence
'Every vixen is a female fox' and the thought every vixen is a female fox are necessarily true. But in other cases the question of truth becomes more urgent.
Consider theoretical terms from discredited theories. If an understanding-assent link holds for 'phlogiston,' and understanding
'phlogiston' necessitates assent to a core of phlogiston theory, how could it follow that someone understands sentences of phlogiston theory only if a core of it is true? Didn’t proponents of phlogiston theory understand their own theory, despite its untruth? The example is not completely straightforward, for at least two reasons. First, it requires the untruth of the core of phlogiston theory in the understanding-assent links, not just of phlogiston theory as a whole. Some will treat a universal generalization of the form 'All phlogiston is
. . .' as vacuously true if phlogiston does not exist. Second, if there is nothing for 'phlogiston' to refer to, one might alternatively treat sentences in which it occurs as failing to express propositions, in which case it is unclear that genuine understanding of phlogiston theory is possible. For the sake of the example, however, we may suppose that a core claim of phlogiston theory is of the form 'Phlo- giston plays role R,' that a necessary condition of understanding the term 'phlogiston' is assenting to that claim, and that the claim is untrue, because nothing plays role R. Suppositions of this kind will be questioned later.
We are sometimes advised to drop various ordinary terms, on the grounds that obsolete and false folk theories are built into them. Those who offer such advice may be assuming that understanding-truth links fail for some critical sentences of the folk theory in which those terms occur while the corresponding understandingassent links hold (if so, they presumably do not count themselves as fully understanding the folk theory). For if we can understand the critical sentences of the folk theory without assenting to them, in what sense is the theory built into the key terms? For example, we could use them to assert the negations of central principles of the theory.2
Some understanding-assent links might even be to logically inconsistent sentences or thoughts. For example, the ordinary notion of truth is sometimes held to be incoherent, on the grounds that a necessary condition for understanding 'true,' and so for understanding sentences in which it occurs, is assent to a disquotational principle for 'true' which the Liar paradox shows to be inconsistent. Tarski’s description of natural languages as 'inconsistent' in virtue of the paradox (1983a: 164–5) may involve such a view, for if we can understand 'true' in English without assenting to the troublesome instances of the disquotational principle, what prevents us from using
English consistently?3 Similarly, Prior’s connective 'tonk' has mismatched introduction and elimination rules; the introduction rule licenses the inference from 'P' to 'P tonk Q,' while the elimination rule licenses the inference from 'P tonk Q' to 'Q' (Prior 1960). By putting these rules together, one can derive any conclusion 'Q' from any premise 'P.' If assent to instances of those rules is necessary for understanding them, because necessary for understanding 'tonk,' it hardly follows that the rules are truth-preserving (in the context of someone who understands 'tonk'); they are so only if either every In effect, Horwich (1998: 131–53) allows understanding-belief links for which the understanding-truth links fail.
3
See Eklund (2002) for a defense of the idea of inconsistent languages. Epistemological Conceptions of Analyticity

sentence or no sentence of the language is true (including atomic sentences, in which 'tonk' does not occur).4
Such examples can be interpreted in diverse ways. Nevertheless, they show at least that to advance from understanding-assent links to understanding-truth links, let alone to understanding-knowledge links, is no trivial task.
One response to the examples is to stop trying to link understanding to knowledge and truth in this way, and try only to establish links to justification, conceived as non-factive. The hope would be to reach understanding-justification links like these:
(UJl) Necessarily, whoever understands the sentence 'Every vixen is a female fox' is justified in assenting to it.
(UJt) Necessarily, whoever grasps the thought Every vixen is a female fox is justified in assenting to it.
But this retreat from knowledge and truth to justification does less than full justice to the examples. Imagine a dogmatic proponent of phlogiston theory, who continues to accept it long after the accumulating negative evidence has made this unjustifiable. Suppose that 'phlogiston' does indeed provide a counterexample to the putative entailment from the understanding-assent link to the understandingtruth links. Thus although understanding a core of phlogiston theory necessitates assent to that core, because understanding the core necessitates understanding the term 'phlogiston' and understanding 'phlogiston' necessitates assent to the core of phlogiston theory, someone can understand the core despite its untruth. But if anyone can understand the core of phlogiston theory, its proponents can. Moreover, they do not stop understanding it when they unjustifiably refuse to take seriously the mounting negative evidence. Thus our last-ditch defender of phlogiston theory understands its core but is unjustified in assenting to it: the understanding-justification links fail too. For more blatantly defective concepts, the assent mandated by understandingassent links may be unjustifiable from the start, as with 'tonk.' In
4

An example in which understanding is more clearly possible: Dummett (1973: 397,
454) claims that the rules for pejorative terms such as 'Boche' suffer from a related kind of incoherence; Brandom (1994: 126; 2000: 69–70) and Boghossian (2003:
241–2), among others, have relied on his description of the practice of using such terms. I argue that it is mistaken in Williamson (2003a and 2008b), and suggest an alternative. such cases too, an understanding-assent link which lacks the understanding-truth link also lacks the understanding-justification link.
Could one defend versions of UJt and UJl by qualifying the justification as prima facie? Consider someone who is introduced to a long list of mutually inconsistent theories of combustion, including phlogiston theory. Their content is explained without any assurance that there was ever any serious evidence for any of them. Irrationally, this person plumps for phlogiston theory and assents to its principles
(unbeknownst to him, he is being influenced by happy associations from early childhood of the sound of the word 'phlogiston'). By ordinary standards, he is linguistically competent with the sentences of phlogiston theory and grasps the corresponding thoughts, but he is not even prima facie justified in assenting to them, since he has no evidence, even by testimony, of their truth.
The examples do not motivate a retreat from knowledge and truth to non-factive justification. Rather, if they work, they show that some understanding-assent links have no positive epistemological upshot at all.
A different response to the examples is that they do not work: either the understanding-assent link fails or the understanding-truth link holds.
Since the relevant sentences or thoughts in the examples are clearly untrue, the understanding-truth link can hold in them only vacuously.
That is, in such pathological cases, understanding is impossible: no meaning or concept is there to be grasped.5 This response seems plausible for 'tonk,' for any serious attempt to apply the 'tonk'
rules would lead to almost immediate disaster. The envisaged response also makes the links from understanding to truth and any positive epistemic status hold vacuously. Where there is no understanding, we can hardly expect much of a positive epistemological upshot from a constraint on understanding. A trickier question is whether such possibilities of an illusion of understanding have negative epistemological repercussions for cases of genuine understanding, since a skeptical doubt can arise for the subject in the latter cases too as to whether the understanding is not an illusion. If it could avoid such repercussions, this response might maintain a general entailment from understanding-assent links to understanding-knowledge links and the rest.
5 However, the response is less plausible for 'phlogiston' and some of the other examples than for 'tonk,' since communities used the rules for 'phlogiston' and 'true' for years before running into any trouble.6 There does seem to be some sort of difference between understanding the word 'phlogiston' and not understanding it.
Although speakers cannot know the reference of a term if it has none, they can attain some sort of ordinary linguistic competence with it, and in that attenuated sense understand it. If such understanding of theoretical terms requires understanding-assent links in general, it is unclear why it should fail to do so for the term 'phlogiston' in particular. Similarly, even if sentences with 'phlogiston' fail to express propositions, because 'phlogiston' fails to refer, there is still an attenuated sense in which some speakers have the empty concept phlogiston, an empty mental vehicle, while others do not. If such possession of theoretical concepts requires understanding-assent links in general, it is unclear why it should fail to do so for the concept phlogiston in particular.
Alternatively, someone might maintain that the understandingassent links in these examples fail, but that understanding-assent links for other sentences or thoughts hold; the examples involve genuine understanding. On this view, understanding-assent links may still be held to entail the corresponding understanding-knowledge links. It claims that the examples picked the wrong candidates for understanding-assent links. Either such links hold only for non-defective words or concepts or for those defective cases they hold only for cautiously circumscribed sentences or thoughts. For instance, rather than the core of phlogiston theory itself, we might have the conditional 'If phlogiston exists then . . .,' with that core filling in the dots. Arguably, however, since 'phlogiston' fails to refer, that conditional too fails to express a proposition, so even this more cautious sentence is not true, although it is also not false. A more general objection is that this response treats our practices as though they are bound to have anticipated from the start all problems that could subsequently arise for them. Presumably, if understanding-assent links hold, they do so because they are built into the linguistic or conceptual practices at issue. Consider, for instance, the
6

Boghossian (2003: 242–3), which represents a change of view from Boghossian
(2002). hypothesis that understanding 'true' necessitates assent to a disquotational principle carefully and ingeniously modified to avoid all the semantic paradoxes. Since they scarcely ever arise in ordinary life, why was our ordinary practice with the word 'true' tailored in advance to avoid them? Indeed, the puzzlement they cause suggests quite the opposite. That such precautions are part of every possible linguistic or conceptual practice is even less likely. If understandingassent links hold for some other reason than that they are built into the linguistic or conceptual practices at issue, what is that other reason? Even if one moderates the approach by substituting understanding-justification links for understanding-knowledge links, a version of the objection still applies. If our linguistic or conceptual practices can make assent to inference rules a precondition of understanding, nothing seems to stop bad practices from requiring assent to rules, like those for 'tonk,' that generate consequences not involving the original word or concept at issue. Such consequences may include arbitrary pernicious dogmas (such as racist ones) for which no justification is provided. More cautious fallbacks need not even implicitly have been provided; the practice simply breaks down once the dogma is abandoned. So this alternative way of maintaining a general entailment from understanding-assent links to understanding-justification links, let alone understanding-knowledge links, is unpromising. The objections tell equally against the putative understanding-knowledge or understanding-justification links, even if no attempt is made to derive them from understanding-assent links.
A more moderate response concedes that defective practices give rise to understanding-assent links without corresponding links to truth or any positive epistemological status, but maintains that understanding-assent links for non-defective practices do yield such links.
For instance, one might try to tell a story on which understandingassent links for non-defective practices constrain the reference of the relevant words or concepts so that the sentences or thoughts in the links come out true (for some defective practices, this constraint cannot be met). Under such conditions, understanding-assent links generate understanding-truth links. Thus assent to those sentences or thoughts (while understanding or grasping them) is, completely reliably, assent to truths. One might hope to squeeze understandingknowledge links out of such reliability considerations, perhaps when Epistemological Conceptions of Analyticity

enhanced by an argument that the reliability is not completely hidden from the subject. Clearly, much work would be needed to vindicate such a programme.7
A lazy alternative simply postulates understanding-knowledge or understanding-justification links for non-defective practices without attempting to derive them from understanding-assent links. But this has little explanatory value. I understand 'Every vixen is a female fox,' and it has some positive epistemic status for me. How does it get that status? How do I know 'Every vixen is a female fox'? Why am I justified in assenting to it? The lazy theorist may try to dismiss the question, saying that it is simply part of our linguistic practice that 'Every vixen is a female fox' has that positive epistemic status for whoever understands it. But the examples of defective practices show that it is not simply up to linguistic practices to distribute positive epistemic status as they please. That the practice is to treat a given sentence as having some positive epistemic status for competent speakers of the language does not imply that it really has that epistemic status for them. Their belief may be untrue and unjustified, however much the practice deems otherwise. Thus the only plausible way to make the relevant practice guarantee the putative link from understanding to the positive epistemic status is by making absence of the epistemic status constitute absence of understanding, just as absence of assent was supposed to do. On this account, whoever does not know 'Every vixen is a female fox' or is not justified in assenting to it thereby fails to understand it. But this direction of explanation does not trivialize the positive epistemic status, to which it assigns the role of constituter, not constituted. Thus the lazy theorist cannot simply dismiss the question: how does 'Every vixen is a female fox'
gets its positive epistemic for whoever understands it? Positing direct links from understanding to knowledge or justification does not remove the need for substantive epistemology here. Indeed, it makes the armchair nature of understanding problematic. Even when the relevant sentence or thought has the positive epistemic status at issue, the reason is not simply that the linguistic or conceptual practice deems it to be so – which of course is not to say that the practice is The treatment of the issue in Boghossian (2003) is of this general kind. For detailed criticism see Williamson (2003a). irrelevant to its epistemic status. In any case, if understanding-assent links fail, as is argued below, then a fortiori so do understandingknowledge links, and understanding-justification links turn out to fail for similar reasons.
Let us consider understanding-assent links in more depth. If they hold, with or without normative consequences, they should cast some light on the actual practice of philosophy. For if an understandingassent link holds for a philosophically significant sentence, and we do understand it, then we do assent to it, whether or not we are justified in doing so. But the next sections argue that understanding-assent links fail even for paradigms of 'analyticity.' The main focus will be on the simplest cases, since those are the ones for which understanding-assent links have the best chance: if they fail there, they fail everywhere. We will start by examining unqualified understandingassent links, beginning at the level of language. They fail. We then consider various ways of loosening them.

3
In their classic response to Quine’s critique of the analytic-synthetic distinction, Grice and Strawson give the sentence 'My neighbor’s three-year-old child is an adult' as an example of a sentence that we could not understand someone using with its ordinary literal meaning to make an assertion (1956: 150–1). That suggests an understandingassent link for the sentence 'No three-year-old child is an adult': necessarily, whoever understands it assents to it. But the link fails.
Someone may believe that normal human beings attain physical and psychological maturity at the age of three, explaining away all the evidence to the contrary by ad hoc hypotheses or conspiracy theories
(many three-year-olds pretend to be eighteen-year-olds in order to vote, the abnormally polluted local water slows development, and so on). However foolish those beliefs, they do not constitute linguistic incompetence. Friends of analyticity will reply that the example was badly chosen. It is therefore best to start with the most elementary examples possible.
Here is an elementary logical truth:
(1) Every vixen is a vixen. Epistemological Conceptions of Analyticity

Few quantified logical truths are simpler than (1), in either syntactic complexity or the number of steps needed to derive them in a standard system of natural deduction rules.8
One may be tempted to endorse understanding-assent links for
(1):
(UAl′)

Necessarily, whoever understands the sentence 'Every vixen is a vixen' assents to it.
(UAt′) Necessarily, whoever grasps the thought every vixen is a vixen assents to it.
Are UAl′ and UAt′ true? Consider two native speakers of English,
Peter and Stephen.
Peter’s first reaction to (1) is that it seems to presuppose:
(2) There is at least one vixen.
On reflection, Peter comes to the considered view that the presupposition is a logical entailment. He regards the truth of 'There is at least one F' as a necessary condition for the truth of 'Every F is a G'
quite generally, and the falsity of 'There is at least one F' as a sufficient condition for the falsity of 'Every F is a G'; he takes universal quantification to be existentially committing. More formally, he holds that 'Every F is a G' is true if and only if (i) there is a value of the variable 'x' for which 'x is an F' is true and (ii) there is no value of the variable 'x' for which 'x is an F' is true while 'x is a G' is not, and that 'Every F is a G' is false if and only if it is not true. Of course, Peter does not always think in such theoretical, metalinguistic terms, but he resorts to them in rationalizing and defending his
8

Parenthetical numerals such as '(1)' are taken throughout to refer to sentences rather than to thoughts. On a standard formalization of (1) as x(Vx → Vx), one proves it by starting from an instance of the rule of assumption, Vx Vx, applying the standard introduction rule for →, conditional proof, to discharge the premise, giving Vx → Vx, followed by the standard introduction rule for , universal generalization, to reach x(Vx → Vx) (no logical truth can be derived by the usual quantifier and structural rules alone, since none of them permits the discharge of all assumptions). A formalization of (1) closer to the English original uses a binary quantifier: (EVERYx(Vx; Vx)) is derivable from Vx Vx in a single step by an appropriate introduction rule for EVERY. pattern of assent and dissent to individual sentences. Peter also has the weird belief that (2) is false. For he spends far too much time surfing the Internet, and once came across a site devoted to propagating the view that there are no foxes, and therefore no vixens, and never have been: all the apparent evidence to the contrary has been planted by MI6, which even organizes widespread fox-hallucinations, so that people will protest about fox-hunting rather than the war in
Iraq. Being a sucker for conspiracy theories, Peter accepted this one.
Since he denies (2) and regards it as a logical consequence of (1), he also denies (1), and so does not assent to it.9
Stephen has no time for Peter’s pet theories. What worries him is vagueness. He believes that borderline cases for vague terms constitute truth-value gaps. Like many truth-value gap theorists (such as
Soames (1999)), he generalizes classical two-valued semantics by treating the gap as a third value ('indefinite') and using Kleene’s three-valued 'strong tables' (1952: 334), along the lines explained in Chapter 2. On Stephen’s view, for 'Every F is a G' to be true is for the conditional 'x is an F → x is a G' to be true for every value of the variable 'x'; for 'Every F is a G' to be false is for 'x is an F
→ x is a G' to be false for some value of 'x.' On his semantics, for a conditional sentence with '→' to be true is for either its antecedent to be false or its consequent to be true, and for it to be false is for its antecedent to be true and its consequent false. Stephen also believes that some clearly female evolutionary ancestors of foxes are borderline cases for 'fox' and therefore for 'vixen.' Consequently, for such an animal as the value of 'x,' 'x is a vixen' is neither true nor false, so the conditional 'x is a vixen → x is a vixen' is also neither true nor false, by the strong Kleene table for →. Hence 'Every vixen is a vixen' is not true; it is also not false, because the conditional is not false for any value of 'x.' Thus Stephen treats (1) as a truth-value gap. Of course, his initial reaction when presented with (1) is not to go through this explicit metalinguistic reasoning; he just says 'What
9 about borderline cases?' But his refusal to assent to (1) as true is firm.10
We may assume that Peter and Stephen are wrong about (1), at least on its standard reading: it is in fact a logical truth. It is true however we interpret its only non-logical syntactically atomic constituent, 'vixen,' given classical logic and two-valued semantics. If not, we can change the example, describing new characters who are deviant with respect to some sentence that really is an elementary logical truth. Peter and Stephen do not assent to (1). Thus, according to UAl′, Peter and Stephen do not understand (1) (with its standard
English meaning). If so, they presumably misunderstand at least one of its constituent words or modes of combination. Is that the impression one would have in conversing with them?
Both Peter and Stephen treat 'vixen' as synonymous with 'female fox.' Stephen’s popular but mistaken theory of vagueness does not prevent him from understanding 'vixen,' 'female,' 'fox' or their mode of combination. Even Peter’s conspiracy theory, however silly, involves no semantic deviation, just as religious fanatics who assert that there were never any dinosaurs do exactly that: they use the words 'There were never any dinosaurs' to assert that there were never any dinosaurs, thereby expressing their belief that there were never any dinosaurs. Their problem is not that they misunderstand the word 'dinosaur,' but that they have silly beliefs about evolution.
Peter, like Stephen, understands the word 'vixen.'
The best candidate for a word or mode of composition in (1) that
Peter and Stephen misunderstand is 'every.' Is it a good enough candidate? Peter’s not uncommon conception of the existential commitments of universal quantification makes little difference in practice, for when sentences of the form 'Every F is a G' occur in conversation, 'There is at least one F' tends to be common ground among the participants anyway. It is (usually, not always) a pragmatic presupposition in the sense of Stalnaker (1999). Pragmatically,
Peter adjusts his conversation to a society that obstinately retains its belief in the existence of foxes much as members of many other small
10

Note that while Peter assents to the conditional 'If there are vixens, then every vixen is a vixen,' Stephen does not, because it has a true antecedent and an indefinite consequent, and is therefore itself indefinite on the Kleene semantics. Given the qualifications in Boghossian (2003), this makes Stephen more problematic than Peter for
Boghossian’s program. sects with unpopular beliefs have learned to adjust to an unenlightened world. Stephen’s deviation is less localized than Peter’s, because his Kleene-inspired semantics turns many universal generalizations with empirical predicates into truth-value gaps. In practice, however, he often manages to ignore the problem by focusing on a small domain of contextually relevant objects among which there are no borderline cases for the noun or complex phrase which complements
'every.' Occasionally he cannot avoid the problem and sounds pedantic, as many academics too, but that hardly constitutes a failure to understand the words at issue. When Peter and Stephen are challenged on their logical deviations, they defend themselves fluently. In fact, both have published widely read articles on the issues in leading refereed journals of philosophy, in English. They seem like most philosophers, thoroughly competent in their native language, a bit odd in some of their views.
Someone might insist that Peter and Stephen appear to be using the word 'every' in its standard sense because they are really using it in senses very similar to, but not exactly the same as, the standard one.
Indeed, it may be argued, their non-standard senses were explained above, since in each case a truth-conditional semantics for the relevant fragment of English was sketched on which (1) is not true, whereas by hypothesis (1) is true on the standard semantics of English. But matters are not so simple. Peter and Stephen are emphatic that they intend their words to be understood as words of our common language, with their standard English senses. They are not making unilateral declarations of linguistic independence. They use 'every'
and the other words in (1) as words of the public language. Each of them believes that his semantic theory is correct for English as spoken by others, not just by himself, and that if it turned out to be (heaven forbid!) incorrect for English as spoken by others, it would equally turn out to be incorrect for English as spoken by himself. Giving an incorrect theory of the meaning of a word is not the same as using the word with an idiosyncratic sense – linguists who work on the semantics of natural languages often do the former without doing the latter. Peter and Stephen’s semantic beliefs about their own uses of
'every' may be false, even if they sometimes rely on those beliefs in conscious processes of truth-evaluation. Indeed, we may assume that
Peter and Stephen do not regard the elaborate articulations of truth-conditions and falsity-conditions for 'Every F is a G' above as Epistemological Conceptions of Analyticity

capturing the way in which they or other English speakers conceptualize the meaning of 'every,' which they regard as a semantically unstructured determiner for which a homophonic statement of meaning would be more faithful: even for us 'Every F is a G' is not strictly synonymous with 'There is no F that is not a G,' since the former does not contain negation. For Peter and Stephen, the more elaborate articulations are simply convenient records of important logical facts about 'every.' Only in tricky cases do they resort to their non-standard semantic theories in evaluating non-metalinguistic claims such as (1) expresses. Their non-metalinguistic unorthodoxy as to when every F is a G is not ultimately derived by semantic descent from metalinguistic unorthodoxy as to when 'Every F is a G' is true; rather, their metalinguistic unorthodoxy is ultimately derived by semantic ascent from their non-metalinguistic unorthodoxy.
Of course, the intention to use words with their normal public meanings does not guarantee success: it can fail in cases of sufficiently gross and extensive error. But that does not suggest that the intention is irrelevant to whether someone is using the words with those meanings. The intention is normally successful, in the absence of special defeating circumstances, just as the intention to use a proper name with the same reference as it has in the rest of the community is normally successful. The question is whether Peter and Stephen’s eccentricities are sufficiently gross and extensive to constitute defeating circumstances. By ordinary standards, they are not. Although they look gross enough when seen in isolation, they are compensated for by Peter and Stephen’s normality in other respects.
Peter and Stephen are native speakers who learned English in the normal way. They acquired their non-standard views as adults. At least before that, nothing in their use of English suggested semantic deviation. Surely they understood (1) and its constituent words and modes of construction with their ordinary meanings then. But the process by which they acquired their eccentricities did not involve forgetting their previous semantic understanding. For example, on their present understanding of (1), they have no difficulty in remembering why they used to assent to it. They were young and foolish then, with a tendency to accept claims on the basis of insufficient reflection. By ordinary standards, Peter and Stephen understand (1)
perfectly well. Although their rejection of (1) might on first acquaintance give an observer a defeasible reason to deny that they under- stood it, any such reason is defeated by closer observation of them.
They genuinely doubt that every vixen is a vixen. Nor are Peter and
Stephen marginal cases of understanding: their linguistic competence is far more secure than that of young children or native speakers of other languages who are in the process of learning English. They joined the club of 'every'-users; since they haven’t resigned or been expelled, they are still members.
If some participants in a debate have an imperfect linguistic understanding of one of the key words with which it is conducted, they need to have its meaning explained to them before the debate can properly continue. But to stop our logical debate with Peter and
Stephen in order to explain to them what the word 'every' means in English would be irrelevant and gratuitously patronizing. We cannot understand them better if we translate their word 'every' by some non-homophonic expression, or treat it as untranslatable. The understanding they lack is logical, is not semantic. Their attitudes to
(1) manifest only some deviant patterns of belief. Since there clearly could have been, and perhaps are, people such as Peter and Stephen, we have counterexamples to UAl′.
The argument that Peter and Stephen mean what we mean by their words exemplifies two interlocking themes: Quine’s epistemological holism, on which the epistemological status of a belief constitutively depends on its position in the believer’s whole system of beliefs, and
Putnam and Burge’s semantic externalism (discussed in more detail below), on which the content of a belief constitutively depends on the believer’s position in a society of believers. Epistemological holism explains how unorthodoxy on one point can be compensated for by orthodoxy on many others, so that overall Peter and Stephen’s usage of the key terms is not beyond the pale of social acceptability; since they remain participants in the relevant linguistic practice, semantic externalism then explains how they can still use the terms with their normal public senses. But neither epistemological holism nor semantic externalism figured as premises of the argument. Rather, the argument appealed to features of the relevant systems of belief that make epistemological holism plausible, and to features of our ascription of beliefs that make semantic externalism plausible.
To try to save UAl′ by restricting it to rational agents would be pointless. By ordinary standards, Peter and Stephen are rational agents. Although they fall short of some high standards of rationality, Epistemological Conceptions of Analyticity

so do most humans. Understanding-assent links that do not apply to most humans would be of limited epistemological interest. The picture was that those who appear to reject analytic sentences can be excluded from the discussion because they lack the linguistic competence to engage in it; but we cannot exclude humans who reject such sentences on those grounds if the connection between rejecting them and lacking competence holds only for super-humans, not for humans.
The problem for UAl′ is clearly not specific to sentences of the form
'Every F is an F' Let us see how it generalizes to rules of inference.
It is often claimed that assent to arguments by modus ponens of the form 'If A then B; A; therefore B' is a precondition for understanding the word 'if' (Boghossian 2003, for instance). Indeed, this is a standard example in the literature. However, Vann McGee, a distinguished logician, has published purported counterexamples to modus ponens for the indicative conditional in English. Here is one of them; the others are similar:
Opinion polls taken just before the 1980 election showed the Republican Ronald Reagan decisively ahead of the Democrat Jimmy Carter, with the other Republican in the race, John Anderson, a distant third.
Those apprised of the poll results believed, with good reason:
If a Republican wins the election, then if it’s not Reagan who wins it will be Anderson.
A Republican will win the race.
Yet they did not have reason to believe:
If it’s not Reagan who wins, it will be Anderson. (McGee 1985:
462)

With reasonable confidence, they combined assent to both premises of an argument by modus ponens with dissent from the conclusion, so they rejected the argument.11 If McGee’s examples are counterexamples to modus ponens, they are also counterexamples to the claim that assent to instances of modus ponens is necessary for understanding 'if.' But let us assume, with the majority, that modus ponens is
11

The formulation in the text is intended to distinguish the case from examples in which speakers’ confidence in each premise of a modus ponens argument is just above a probabilistic threshold which their confidence in the conclusion is just below. In
McGee’s case, speakers are sufficiently confident of the conjunction of the two premises. valid, so McGee’s examples are not in fact counterexamples.12 Perhaps the conclusion was true, because Reagan won; although the poll was not misleading, our usual methods for evaluating conditionals lead us astray in this case. A currently popular objection to the examples is that they depend on an illicit shift of context, perhaps in the treatment of 'If it’s not Reagan who wins, it will be Anderson' between the consequent of the first premise and the conclusion.13 But even if some such confusion causes the pattern of assent and dissent to the premises and conclusion, the effect is that McGee and his envisaged speakers end up accepting the premises and rejecting the conclusion in a single context, when they look back on all three sentences.14 They genuinely reject a genuine instance of modus ponens.15 Such reactions do not manifest the superimposition of a perverse semantic or logical theory on native speaker intuitions; they flow from native speaker intuitions themselves in a fairly natural way, despite being mistaken.
12

For early critical reactions to McGee’s examples see Sinnott-Armstrong, Moor, and Fogelin (1986), Lowe (1987) and Over (1987). But some authors have accepted the examples (Lycan 2001: 66–7).
13
Recent examples of context-shifting charges include Nolan (2003: 264) and
Gauker (2005: 86).
14
Contrast McGee’s example with instances of modus ponens such as 'I know that
I have hands; if I know that I have hands then I know that I’m not a brain in a vat; therefore, I know that I’m not a brain in a vat.' Many people accept the premises and reject the conclusion when they encounter them in that order. However, once they have rejected the conclusion, they are typically inclined to retract their acceptance of the first premise, not out of concern for modus ponens but because it no longer looks plausible to them in its own right, in the new context that arises once the skeptical possibility becomes relevant. For contextualists in epistemology, this is a paradigm case of context-shifting (Stine (1976), Cohen (1988), DeRose (1995), Lewis
(1996); see Hawthorne (2004), Stanley (2005) and Williamson (2005b) for some critical discussion and more references). By contrast, the premises of McGee’s argument continue to look plausible to those who reject the conclusion.
15
Edgington (2001: 408) suggests that McGee’s example is not a genuine instance of modus ponens on the grounds that the first premise has a misleading surface form; on her view, conditionals do not express propositions, so what look like conditionals with conditional antecedents or consequents must be reinterpreted. It is doubtful that such a view is consistent with a systematic account of the structure of English sentences, which permits a wide variety of such embeddings, for example, 'If it is the case that if it’s not Reagan who wins it will be Anderson, then a Republican will win the race.' Epistemological Conceptions of Analyticity

Does McGee not understand the English word 'if'? In conversation, he appears to understand it perfectly well. By ordinary standards, he does understand it. Before he had theoretical doubts about modus ponens, he understood the word 'if' if anyone has ever understood it. Surely his theoretical doubts did not make him cease to remember what it means. Moreover, his doubts derive from taking at face value a natural pattern of native speaker reactions to an ingeniously chosen case. If he counts as not understanding 'if,' so do millions of other native speakers of English.
Could we invoke the division of linguistic labor (Putnam 1975:
228), and say that making any given inference by modus ponens is a precondition only for full understanding of 'if,' the kind of understanding characteristic of the expert rather than the layman? The trouble is that McGee is an expert on conditionals. He publishes on them in the best journals. He does not defer in his use of 'if' to any higher authorities. He may lack some theoretical understanding of conditionals, just as experts on neutrinos may lack some theoretical understanding of neutrinos, but none of that amounts to any lack of linguistic competence with 'if' or 'neutrino' at all.
Are only some arguments by modus ponens such that assent to them is a precondition for understanding 'if'? Presumably, McGee will accept most arguments by modus ponens. However, any particular such argument might be rejected by another expert on conditionals, on the basis of a subtle theoretical argument. By hypothesis, the expert would be mistaken, but making a subtle theoretical error does not constitute linguistic incompetence.
The problem is not just the vagueness of natural languages. Similar problems arise for carefully constructed formal languages. Consider modus ponens for the material conditional →, explained by the standard truth-table. It is equivalent to disjunctive syllogism: from A and
A ∨ B derive B. Technically competent relevance logicians and dialetheists such as Graham Priest reject disjunctive syllogism (Priest
1995: 5). According to him, the best account of paradoxes such as the Liar is that in special circumstances a sentence can be both true and false; one can be on different lines of the truth-table simultaneously. When A is true and false while B is merely false, the premises of disjunctive syllogism are true (for A is true; since A is also false,
A is true, so A ∨ B is true), while its conclusion is straightforwardly false. Whatever the errors underlying the rejection of modus ponens for →, they do not arise from a lack of linguistic competence with → on the part of relevance logicians and dialetheists.
As a final example, consider the natural deduction rules for conjunction. Instances of the introduction rule are arguments of the form
'A; B; therefore A and B.' Instances of the elimination rule are arguments of the converse forms 'A and B; therefore A' and 'A and B; therefore B.' These are just about the simplest rules for a non-trivial binary connective. One must formulate what acceptance of the introduction rule requires with particular care, since the probability of a conjunction may be less than the probability of either conjunct. Iterations of the introduction rule yield the Lottery and Preface paradoxes.
Given a lottery known to have at most a million tickets and only one winner, each premise of the form 'Ticket i will lose' is overwhelmingly probable, even though their conjunction is known to be false.
The author of a book may endorse each individual statement in it, yet admit in the preface that, despite all her efforts, it is bound to contain errors, and on those grounds reject the conjunction of the individual premises. Of course, these paradoxes do not show that the introduction rule fails to preserve truth, although they might be used as grounds for rejecting the rule by a theorist who (mistakenly) used a probabilistic criterion for acceptance. The elimination rule does not suffer from these problems, since the probability of a conjunction is never higher than the probability of any given conjunct.
Let us therefore concentrate on the elimination rule for conjunction, as having the best chance of being non-discretionary for competent speakers.16 Consider Simon, whose view of vagueness resembles
Stephen’s, except that Simon’s practice conforms to a semantics with
Kleene’s weak three-valued tables rather than his strong ones. On these tables, a conjunction is indefinite (neither true nor false) if at least one conjunct is, irrespective of the value of the other conjunct; the same principle is applied to disjunction, the material conditional and negation (Kleene 1952: 334). Furthermore, Simon regards both
16

In discussion, Boghossian suggested conjunction elimination as a fallback example of a non-discretionary rule if modus ponens fails. Peacocke writes of the possession-condition for the concept of conjunction, 'On any theory, this possession-condition will entail that thinkers must find the transition from A and B to
A compelling, and must do so without relying on any background information'
(2004: 172). Epistemological Conceptions of Analyticity

truth and indefiniteness as designated (acceptable) semantic values for an assertion: what matters is to avoid falsity. In a borderline case, some speakers say 'Jack is bald,' others with equal vehemence say
'Jack is not bald'; they may persist even when they recognize that the dispute cannot be resolved. According to Simon, both assertions are acceptable. In answer to the question 'Is Jack bald?,' even the answer 'He is and he isn’t' is acceptable. Although Simon does not assign the value 'T' to 'Jack is bald,' that metalinguistic reservation is consistent with assenting to the sentence, that is, with believing that Jack is bald under the guise of that very sentence (similarly, supervaluationists about vagueness reject the disquotational inference from ' ‘Jack is bald’ is not true' to 'Jack is not bald'). The joint implication of Simon’s principles is that any complex sentence formed by the application of the specified operators to simpler sentences, at least one of which is borderline, has a designated value – of course, on Simon’s view, most such sentences should not be uttered, on the pragmatic grounds that they violate the conversational maxim of relevance (Grice 1989: 27). Suppose that 'A' is simply false while
'B' is borderline. Consequently, for Simon, 'B' is indefinite, so 'A
and B' is also indefinite. Thus the corresponding instance of conjunction elimination – 'A and B; therefore A' – has a designated premise and an undesignated conclusion. On these grounds, Simon rejects the conclusion of that instance while accepting its premise (although he points out that asserting the premise would be pragmatically misleading in most contexts, since 'B' is irrelevant to its status). In other cases, he treats the premise merely as a supposition, but still rejects the deduction from it to the conclusion. Once again, this need not reflect incompetence with the English language. Conjunction elimination is no exception to the general pattern. Arguably, violations of conjunction elimination are actual, not just possible, in the Conjunction Fallacy, a much-studied, widespread and robust psychological phenomenon in which subjects assign a higher probability to a conjunction than to one of its conjuncts.17
17

The seminal paper is Tversky and Kahneman (1983). See also Kahneman and
Frederick (2002), Sides, Osherson, Bonini, and Viale (2002) and Jönsson and Hampton
(2006).We can also imagine speakers who reject instances of conjunction elimination through muddling truth and conversational appropriateness. 'Did she take the money and give it back? Yes. Did she take the money? No, she took-the-moneyand-gave-it-back.' No given argument or statement is immune from rejection by a linguistically competent speaker. Quine’s epistemological holism in
'Two Dogmas' undermines his notorious later claim about the deviant logician’s predicament: 'when he tries to deny the doctrine he only changes the subject' (1970: 81).
Understanding words in a natural language has much to do with the ability to use them in ways that facilitate smooth and fruitful interaction with other members of the community. That ability can be realized in indefinitely various forms. Speakers can compensate for their deviance on one point by their orthodoxy on others, their ability to predict the reactions of non-deviant speakers, their willingness in the long run to have their utterances evaluated by public standards. As we have seen, such compensation is often possible when the deviance results from localized interference in the normal practice of using a word by high-level theoretical concerns. Thus there is no litmus test for understanding. Whatever local test is proposed, someone could fail it and still do well enough elsewhere with the word to count as understanding it. Could an inferentialist reply that such objections trade on a loose everyday sense of 'understanding' that must be replaced by something more precise for theoretical purposes? It is far from clear that a stricter sense would do a better job. The relevant features of the ordinary conception of understanding are not mere unreflective sloppiness. Rather, they are an appropriate response to an important constraint on a theory of linguistic meanings: that there is little point in talking about them unless they can be shared across significant differences in belief, between different individuals at the same time or the same individual at different times. They can survive factual learning and factual disagreement. Although inferentialist accounts respect the letter of that constraint, they violate its underlying spirit, by setting inflexible limits to the scope for genuine disagreement. The more holistic ordinary notion of understanding permits localized disagreement at virtually any point.
Cases of logical deviance hint at ways in which the failure of individualist accounts of meaning go deeper than the immediate lessons of the original anti-individualist arguments of Putnam (1975) and
Burge (1979). Their cases are often analyzed in terms of a distinction between experts with full understanding and lay-people with partial understanding who defer to the experts, in virtue of which one may Epistemological Conceptions of Analyticity

correctly ascribe to them attitudes to the contents that experts determine.18 Such asymmetries are postulated by Putnam’s Hypothesis of the Universality of the Division of Linguistic Labor:
Every linguistic community . . . possesses at least some terms whose associated 'criteria' are known only to a subset of the speakers who acquire the terms, and whose use by the other speakers depends upon a structured cooperation between them and the speakers in the relevant subsets. (Putnam 1975: 228)

But, as we have seen, experts themselves can make deviant applications of words as a result of theoretical errors and still count as fully understanding their words. Although they defer to nobody on the matters at issue, they are more than adequately integrated members of the speech community with respect to those very words. Their assignments of meaning to those words are not parasitic on the assignments that more privileged individuals make. Rather, each individual uses words as words of a public language; their meanings are constitutively determined not individually but socially, through the spectrum of linguistic activity across the community as a whole.
The social determination of meaning requires nothing like an exact match in use between different individuals; it requires only enough connection in use between them to form a social practice. Full participation in that practice constitutes full understanding. That is why there is no litmus test for understanding.19 An example is Peacocke’s discussion of deference-dependent propositional attitude ascriptions (1992: 29–33). Burge (1986) extends his earlier arguments in ways related to the arguments of this chapter, in his account of the understanding of words such as 'sofa,' and argues for such a deeper lesson. Goldberg (2000) replies on behalf of Burge to Bach (1988) and Elugardo (1993).
19
For a related conclusion concerning lexical competence in a shared language see
Marconi (1997: 56). For the relevance of the model of full understanding as full induction into a practice to the theory of vagueness see Williamson (1994a: 211–12).
It is not implied that no similar issue could arise for understanding on the part of a single isolated individual, for such an individual’s meanings and concepts are constitutively determined, at least in part, by their dispositions over a range of counterfactual circumstances; those dispositions and their bearings may be hard to survey from the limited standpoint of the actual circumstances.

Epistemological Conceptions of Analyticity 4
Peter and Stephen understand (1) without assenting to it; UAl′
fails. Someone sympathetic to the spirit of understanding-assent links might concede that much while arguing that its upshot is only a superficial loosening of those links. If the deviance results only from erroneous theorizing that overlays an ordinary understanding of the terms, may not the links still hold at the underlying level?
However, we have already seen reason to doubt that deviance can only arise from theorizing extrinsic to speakers’ ordinary understanding of the words. Vann McGee’s examples exert an intuitive pull on native speakers, irrespective of and even contrary to their theoretical predilections. We can also imagine untheoretical native speakers whose unreflective patterns of assent and dissent to non-metalinguistic sentences are those which Peter, Stephen, and Simon respectively recommend, although they lack the reflective capacity to rationalize those patterns by appeal to formal semantic theories. They too would be able to fit in well enough with the rest of the linguistic community, to engage smoothly in useful communication and adjust to their differences with other speakers in order not to attract too much attention. They too would use their words as words of the public language, rather than declaring unilateral linguistic independence. How do we know that there are not in fact many such native speakers of English around us? Once we concede that Peter, Stephen, and Simon are competent speakers, we can hardly refuse the same classification to other speakers merely on grounds of their unacquaintance with formal semantics.
What might be claimed, in the case of both theoretical and untheoretical deviant native speakers, is that the deviance is some kind of performance error which leaves their underlying competence intact: at some basic level they have the required dispositions, which they fail to manifest as a result of interfering factors, such as computational limitations, conflicting dispositions to take cheap and dirty intellectual short-cuts, and so on. On this view, Peter and Stephen still have a disposition to assent to (1), masked by their later theorizing; they use 'every' and other words and modes of construction with the same senses as the rest of us because they have the same underlying Epistemological Conceptions of Analyticity

inferential dispositions as the rest of us.20 At some deep level, they have a disposition to accept (1) as true. That disposition is prevented from manifesting itself by conscious reflection at an overlying level of theory-construction, just as someone’s pet views about grammar might interfere with their performance in speech while having no effect on the syntactic competence which they possess in virtue of their underlying linguistic competence. For untheoretical speakers, the interfering factors are unconscious, but the effect is similar. UAl′ and
UAt′ might therefore be watered down as follows:
(UDAl′)

Necessarily, whoever understands the sentence 'Every vixen is a vixen' has a disposition to assent to it.
(UDAt′) Necessarily, whoever grasps the thought every vixen is a vixen has a disposition to assent to it.
Having a disposition to assent does not entail assenting. Thus UDAl′
and UDAt′ are consistent with the denials of UAl′ and UAt′. Do Peter and Stephen have the disposition to assent to (1) despite happening not to assent to it? If understanding is linked to such dispositions to assent in these cases, one might even try to use that to explain how it is also linked to dispositions to know, along lines similar to those sketched in Section 2. But are UDAl′ and UDAt′ true?
There are two salient ways to fill out the dispositional story: at the personal level or the sub-personal level. At the personal level, the postulated dispositions require something like counterfactual conditionals to the effect that sufficient conscious reflection and exposure to further arguments would bring the person to assent. Thus Peter and Stephen would assent to (1) if only they thought about it more and talked to more experts. By contrast, at the sub-personal level, the postulated dispositions are grounded in something like an unconscious reasoning module, even if the personal-level counterfactual conditionals are false. Thus the default outcome of Peter and Stephen’s underlying competence is assent to (1), even if stable dispositions from other sources irreversibly override that default.
20

Eklund (2002: 262) defends such a view of logical deviance. See Martin (1994),
Lewis (1997), Martin and Heil (1998), Bird (1998), and Mumford (1998) for some basic issues about masked dispositions. Harman (1999: 213) relies on defeasible inferential dispositions in his conceptual role semantics. An analogous contrast arises for syntax. As a standard example, native speakers of English tend to reject (3) at first sight as ill-formed:
(3) The horse raced past the barn fell.
They want to insert 'and' between 'barn' and 'fell.' But they tend to change their minds about (3) when asked to consider the result of inserting 'that was' between 'horse' and 'raced' instead: they realize that the original string was well-formed after all; 'the horse'
is the object, not the subject, of 'raced.' Conversely, native speakers often unreflectively accept ill-formed strings as well-formed, for example when a plural verb is separated from its singular subject by a long intervening string that includes a plural noun, but can be brought to acknowledge their mistake, as when a draft is corrected.
On a personal level account, such conscious reflective judgments, actual or counterfactual, are constitutive of well-formedness. On the contrasting sub-personal level account, those judgments play a merely evidential role: what constitutes well-formedness is the structure of the syntactic component of the unconscious language module, even if the person’s conscious reflective judgment is irreversibly contrary as a result of extraneous factors, such as their dogmatic commitment to a pet theory of syntax.
The personal level account fails to shield UDAl′ and UDAt′ from the counterexamples of Peter and Stephen. For, by hypothesis, their refusal to assent to (1) is stable under conscious reflection, exposure to further arguments and so on. Like many people, not least philosophers, they are obstinate in defense of their favorite views, willing to make whatever ad hoc moves are needed to retain them. One knows in advance that the task of dissuading them is hopeless, however good one’s objections: a common experience in philosophy. As Peter and
Stephen became comfortable with their deviant theories they gradually ceased to feel even an initial temptation to assent to (1), we may assume, although they still remember what it was like to feel such a temptation. They assimilate the change to one in which education gradually eradicates the tendency to make a particular false assumption. Perhaps years of browbeating or social ostracism would cause them to change their minds, but that applies to almost any belief; it is poor evidence that an underlying disposition to assent was present all Epistemological Conceptions of Analyticity

along. Would Peter and Stephen assent to (1) if they lacked their conscious theoretical commitments? Perhaps not, but that counterfactual would show little. The possibility of untheoretical analogues of Peter and Stephen has already been raised. They lack the conscious theoretical commitments but still do not assent to (1). If it is objected that the untheoretical analogues, unlike Peter and Stephen, do not understand
(1) with its normal English sense because they lack the required unconscious cognitive structures, that is in effect to switch to the subpersonal version of the dispositional account. On the personal level account, Peter and Stephen are not disposed to assent to (1). If that makes them irrationally obstinate, they are no more so than many philosophers and non-philosophers in defense of a favorite view.
The sub-personal level story has more room for maneuver in defense of UDAl′ and UDAt′. It can insist that although Peter and
Stephen’s personal refusal to assent to (1) is stable under conscious reflection and exposure to further arguments, they retain a disposition to assent to (1) in virtue of features of their unconscious logic rules. This requires the postulated rules to be encased in some sort of psychological module, for if they consisted only in general habits of reasoning, Peter and Stephen’s earlier habits could eventually be erased by their later ones, and the disposition to assent to (1) would disappear. The module must include rules for deduction, since that is the kind of reasoning relevant to (1). This module may be a component of an overall semantic module (after all, we are considering
(1) as a candidate for analyticity). If the grounds for assent to (1)
were merely inductive – that we have never observed a vixen that was not a vixen – people who understood (1) could reasonably refuse to assent to it on the grounds that they had observed too few vixens to be in a position to judge. A prima facie attractive conjecture is that the deductive rules would include analogues for natural language connectives of the introduction and elimination rules in a Gentzenstyle system of natural deduction. But do humans have a module that includes unconscious logic rules of the required sort?
One might suppose the primary adaptive value of a cognitive module to be its capacity to perform a specific type of useful information processing quickly and reliably enough for the purposes of action in a changing environment. Its design can exploit special features of the type of task to which it is dedicated, in order to achieve efficiencies that would be impossible for a general purpose central processing unit. A diversion through higher mental processes, in particular through consciousness, would be slower and less reliable. Thus one might expect unconscious modular deductive reasoning to pay its way by the speed and reliability of its results, just as modules for vision and natural language processing seem to do. Naturally, performance would tail off as the complexity of problems increased, but there should be good performance over a worthwhile range of nontrivial problems. Is that prediction borne out?
Evidence from empirical psychology, amassed over several decades, suggests that most humans are strikingly bad at even elementary deductive reasoning, a finding which should not surprise those who have taught introductory logic. For example, in the combined results of over 65 large-scale experiments by different researchers on simple conditional reasoning, although 97 percent (not 100 percent!) of subjects endorsed modus ponens, only 72 percent endorsed modus tollens (if A then B; not B; therefore not A), while as many as 63
percent endorsed the fallacy of affirming the consequent (if A then
B; B; therefore A) and 55 percent endorsed the fallacy of denying the antecedent (if A then B; not A; therefore not B). When the antecedent is negative, affirming the consequent overtakes modus tollens in popularity.21 In some cases, when a further premise of the form 'If
C then B' is added to modus ponens only a minority endorses the inference (Byrne 1989).22 Similar phenomena arise for elementary syllogistic reasoning.
Performance greatly improves when the conditional premise in a reasoning task has a realistic deontic content, such as 'If you use a second class stamp, then you must leave the envelope unsealed'
(Manktelow and Over 1987, Wason and Shapiro 1971). In general, the real-life credibility or otherwise of premises and conclusion strongly influences judgments of validity and invalidity.
21

See Schroyens and Schaeken (2003); the percentages are as summarized by Oaksford (2005: 427).
22
Is it still modus ponens if there is an extra redundant premise? If not, then humans apply modus ponens only in the most artificial circumstances, since in practice we always have further information. Moreover, people without formal education tend to do worst in reasoning tasks with artificial premises from which all background information has been screened out (see Harris (2000: 94–117) for discussion). Such a restriction would make a disposition to assent to modus ponens a rather artificial test for understanding 'if.' Epistemological Conceptions of Analyticity

For simple problems in formal deductive reasoning, when the specific subject matter provides no helpful clues, success is significantly correlated with intelligence, in whatever sense it is measured by IQ
tests, SAT scores or the like (Stanovich and West 2000). For some simple tasks, success is rare except among those with the intelligence of able undergraduates (Newstead et al. 2004; the samples in the experimental literature tend to consist of university students, since they are the most easily available subjects). Contrast this with the efficient success which humans typically show in judging whether short strings of words constitute well-formed sentences of their native language, for example. There is little sign of anything modular that contains formal rules to subserve conscious deduction, whether conceived as part of a language module or as part of a reasoning module.
Of course, there may be sub-personal processes whose inner workings can conveniently be represented as employing deductive rules, just as there may be sub-personal processes whose inner workings can conveniently be represented as employing differential equations, for example to process perceptual input, in even the most mathematically ignorant subjects. But that is not quite the issue. We are questioning the existence of a sub-personal basis for an unmanifested disposition to assent, that is, to perform an action at the personal level. The problem is that the data of normal performance tell against the hypothesis of a set of deductive rules (semantic or not) unconsciously employed as the primary route to conscious assent in the relevant normal cases.
A widespread, although not universal, view among psychologists of reasoning is that humans have two reasoning systems. In the terminology of Stanovich and West, System 1 is associative, holistic, automatic, relatively undemanding of cognitive capacity, relatively fast, and acquired through biology, exposure, and personal experience; its construal of reasoning tasks is highly sensitive to personal, conversational, and social context. System 2 is rule-based, analytic, controlled, demanding of cognitive capacity, relatively slow, and acquired by cultural and formal tuition; its construal of reasoning tasks is rather insensitive to personal, conversational, and social context.23 System 1 lacks the formal rules that enable deductive rea23

See Stanovich and West (2000: 659), where a list is also provided of earlier authors who have proposed similar views. soning to succeed in the absence of helpful clues from the content of premises and conclusion. Although defeasible and only moderately reliable, it performs an important role in tasks of the kind for which it presumably evolved, such as integrating new information from perception or testimony with standing beliefs. System 1 is not a system for formal deductive reasoning. A suitably educated, highly intelligent person can achieve success in formal deductive reasoning by means of System 2, but it is not sealed off in an unconscious module.
How does this picture apply to Peter and Stephen? With respect to System 1, they fall within the normal range of human variation.
They are slightly unusual with respect to System 2, which is in any case much more sensitive than System 1 to specific features of the individual’s intelligence and education. But neither high intelligence nor a good education is needed to understand simple sentences like
(1). Any System 2 differences at issue between Peter or Stephen and average speakers of English are wholly consistent with Peter and
Stephen’s competence in their native language. If Peter and Stephen do have any underlying disposition to accept (1) as true, it concerns their System 1. But aversion to universal generalizations with empty subject terms or borderline cases seems to be within the normal range of System 1 reasoning among native speakers. On the two systems picture, there is no reason to assume that all linguistically competent speakers have an underlying disposition to assent to (1).
The two systems picture has not been conclusively established; it may turn out to need modification. Nevertheless, it throws into relief the empirical speculations on which the sub-personal understandingdisposition-to-assent links depend, and their clash with much current thinking in the psychology of reasoning. If the two systems picture is right to even a first approximation, the sub-personal links are in trouble.
How can System 1 or any other system evaluate deductive arguments without using formal rules for reasoning with logical constants in natural language, even if their effect is almost swamped by associations, heuristics, and other pragmatic factors?24 There are alternatives. For example, one of the main psychological theories of deductive
24

For such an approach see Braine and O’Brien (1991), criticized by Evans and
Over (2004: 56–9). Epistemological Conceptions of Analyticity

reasoning is currently the mental models approach. Two of its leading proponents write:
The evidence suggests that it [the reasoning mechanism] is not equipped with logical rules of inference, which it sometimes uses correctly and sometimes misuses, misapplies or forgets. This analogy with grammar, which has seduced so many theorists, is a mistake. The reasoning mechanism constructs a mental model of the premises, formulates a putative conclusion, and tests its validity by searching for alternative models in which it is false. The search is constrained by the metaprinciple that the conclusion is valid only if there are no such models, but it is not governed by any systematic or comprehensive principles.
(Johnson-Laird and Byrne 1993: 178)

Thus subjects may erroneously classify an invalid argument as valid, because the unrepresentative sample of models they have examined includes no counter-model, and they wrongly treat it as representative. They may erroneously classify a valid argument as invalid, because they leave the process of constructing a counter-model incomplete, under the misapprehension that there is no obstacle to completing it. Background beliefs about the specific subject matter of an argument influence its classification because they influence which mental models are constructed. Johnson-Laird and Byrne argue that their theory gives the best fit to the empirical data.
On the mental models approach, the nearest one normally comes to employing deductive rules of inference is in the procedures for evaluating sentences (premises or conclusions) with respect to a given model, itself conceived as a mental representation.25 But that process does not involve deductive reasoning in a natural language. Nor would natural deduction rules for the natural language connectives be very relevant; it is more like the construction of a truth-table. For example, in calculating the truth-value of a conditional in a model, one does not apply the rule of conditional proof to that very conditional if one already has the rules for constructing truth-tables.26
25

Mental models need not be visualized (Johnson-Laird and Byrne 1993: 182).
Johnson-Laird and Byrne also claim that human reasoning is a semantic rather than a syntactic process (ibid.: 180), but the significance of this claim is not entirely clear, since they treat reasoning as a manipulation of representations.
26
Standard proofs of formalizations of (1) use conditional proof. Evaluating a sentence in a model might involve something closer to an imaginative analogue of the processes that issue in complex perceptual judgments such as 'Everybody over there is wearing a hat.'
Not all such universally quantified conclusions are reached by deduction from further premises. One might employ this argument:
A is wearing a hat.
B is wearing a hat.
C is wearing a hat.
Everybody over there is A, B, or C.
Therefore:
Everybody over there is wearing a hat.
But of course the final premise 'Everybody over there is A, B, or C'
is itself a universally quantified perceptual judgment. To suppose that it too was reached as the conclusion of a deductive argument is to start a futile regress.
Although the mental models theory does not apply to all human reasoning – for example, to the System 2 kind some humans learn to carry out in logic classes – it may apply to a high proportion of it.
The theory is a salutary reminder that reasoning with logical constants need not be formal deductive reasoning, and that the empirical evidence suggests that in humans it usually is not.
One remaining concern is that logical skills must play some role in linguistic competence because logical features play a role in determining well-formedness. An example is the category of negative polarity items. Consider these sentences:
(4)
If she ate any of the cake, she was hungry.
(5)* If she was hungry, she ate any of the cake.
'Any' is a negative polarity item. To a first approximation, the reason why 'she ate any of the cake' is acceptable as the antecedent of the conditional but not as the consequent is that the antecedent is in a downward entailing (negative) context while the consequent is instead in an upward entailing (positive) context. A context C is upward entailing just in case whenever A entails B, C(A) entails C(B);
C is downward entailing just in case whenever A entails B, C(B)
entails C(A). Thus recognition of the logical features of contexts Epistemological Conceptions of Analyticity

seems to be needed in order to distinguish between well-formed and ill-formed sentences. But things are not so simple. Consider these sentences:
(6) Exactly four people in the room were of any help.
(7) Few people in the room were of any help.
Logically, 'few' creates a downward entailing context; 'exactly four' does not. However, (6) is acceptable provided that in the context it is taken to imply (7), but not generally otherwise. Thus the phenomenon involves a significant pragmatic element: which contexts are suitable for 'any' cannot be determined on purely logicolinguistic grounds. If we disagree with the speaker of (6) about how many people were in the room or what proportion of them could have been expected to help, we may find her use of 'any' inappropriate without regarding her as linguistically incompetent. Similarly, if a speaker has deviant views as to which contexts are downward entailing, but uses 'any' in just those contexts that she treats as downward entailing, we might find her deviant use of 'any' inappropriate without regarding her as linguistically incompetent, precisely because the deviation in use is explained by logical rather than linguistic unorthodoxy. Thus the role of logical knowledge in such cases does not make it part of purely linguistic competence. All our knowledge is potentially relevant to judging the appropriateness of a given use of 'any.'27
Suppose, nevertheless, that our classification of strings such as
(4)–(7) as well- or ill-formed does depend on some prior classification of contexts as downward entailing or not. The question remains: is that classification available for unconscious reasoning that would issue in conscious assent to supposedly analytic sentences? To identify
27
Ladusaw (1996: 325–37) surveys issues concerning negative polarity. Strictly speaking, the context of the antecedent of a counterfactual conditional is not downward entailing on standard logics of such conditionals, according to which strengthening of the antecedent fails; for example, although 'It rained hard' entails 'It rained,'
'If it had rained, it would not have rained hard' does not entail 'If it had rained hard, it would not have rained hard.' Nevertheless, negative polarity items are felicitous in the antecedent of counterfactual conditionals: 'If you had taken any of that arsenic, you would have died' (see van Rooij (2006) for discussion).

Epistemological Conceptions of Analyticity a context as downward entailing involves a more sophisticated logical insight than identifying a particular argument as valid, since it requires the validation of an abstract pattern of argument. For example, identifying negation as a downward entailing context requires checking this schema, for arbitrary sentences 'A' and 'B': If 'A' entails 'B'
then 'It is not the case that B' entails 'It is not the case that A.'
That is just the kind of abstract formal reasoning task on which humans perform worst. Contrast that with our high level of reliability in determining whether strings with negative polarity items are wellformed. Thus the evidence suggests that the unconscious logic in question is not at the service of the cognitive processes that normally produce conscious assent to sentences like (1). Such cases therefore fail to support a modification of the conclusions reached so far.
One special sort of case deserves separate discussion. Some metalinguistic sentences or thoughts look analytic for distinctive reasons.
As observed in Chapter 2, even when a philosophical question is not itself metalinguistic, metalinguistic considerations can still help us to answer it.
Consider theoretical terms. We can understand the word 'phlogiston' without believing phlogiston theory. Might we do so because we still believe that 'phlogiston' is generally associated with that theory, just as one can understand a natural kind such as 'gorilla'
without believing the associated stereotype ('Gorillas are ferocious')
because one still believes that 'gorilla' is generally associated with that stereotype (Putnam 1975)? However, such sociolinguistic beliefs are no more immune than logical beliefs from the challenge of theoretical unorthodoxy without change of meaning. If T is any version of phlogiston theory, someone can understand 'phlogiston' and associate it with T without believing that it is generally associated with T, in the belief that 'phlogiston' is and was generally associated not with T but with somewhat different versions of phlogiston theory.
This is clear if T is a strong version of the theory. Even if T is a weak version, they may believe that the word is generally associated with a stronger version, and deny that it is ipso facto associated with T.
On such grounds, they may even disbelieve that they themselves associate the word with T. Let such sociolinguistic beliefs be false; nevertheless, holding them is quite consistent with understanding
'phlogiston.' It is futile to multiply disjuncts and restrictive clauses Epistemological Conceptions of Analyticity

in the hope of formulating a sociolinguistic claim so anodyne that anyone who understands 'phlogiston' must accept it. The result will just be a complex theoretical claim that ordinary speakers can legitimately doubt, on the grounds that such matters are hard to determine.
A more minimalist line of argument for metalinguistic analyticities appeals to the connection between understanding and knowledge of reference. Suppose that someone understands this sentence:
(8) 'Tree' applies to all and only trees.
Then they understand its constituent words, in particular 'tree.' So they know what 'tree' means. For common nouns, knowledge of meaning requires knowledge of application conditions. Consequently, they know that 'tree' applies to all and only trees. Moreover, since knowledge entails belief, they also believe that 'tree' applies to all and only trees. Thus, it seems, they should knowledgeably assent to
(1). The argument generalizes to a large class of disquotational claims
(the identity of the expression mentioned on the left-hand side with the one used on the right-hand side is crucial, since if they were distinct understanding of the latter would not entail knowledge about the former).
Nevertheless, those who understand (8) may refuse assent to it.
Stephen is an example, since on his view a universally quantified biconditional with borderline cases for both sides is not definitely true. Indeed, some supervaluationists about vagueness even deny such disquotational principles for vague terms, such as 'tree'. However erroneous such theories of vagueness, holding them is consistent with ordinary linguistic understanding of (8). If understanding really does involve tacit propositional knowledge of meaning, that knowledge may contradict conscious beliefs.
Let us grant for the sake of argument that understanding (8) entails knowing both that 'tree' applies to all and only trees and that (8)
means that 'tree' applies to all and only trees. How then can one understand (8) without assenting to it? We lack direct conscious access to whatever tacit knowledge linguistic understanding is supposed to consist in, otherwise semantics as a branch of empirical linguistics would be much easier than it actually is. We consciously entertain the proposition that 'tree' applies to all and only trees as presented by sentence (8), or by the corresponding conscious thought
'tree' applies to all and only trees. In tacitly knowing that 'tree'
applies to all and only trees (if we do), we may tacitly entertain that proposition under a quite different unconscious mode of presentation. Thus understanding-assent links fail for sentences of natural language and conscious thoughts:
(UAl*)

Necessarily, whoever understands the sentence '‘Tree’
applies to all and only trees' assents to it.
(UAt*) Necessarily, whoever grasps the thought 'tree' applies to all and only trees assents to it.
For if linguistic understanding involves tacit propositional knowledge of meaning, it presumably involves tacit assent to the relevant propositions under modes of presentation of some sort. Any tacit assent to the proposition that 'tree' applies to all and only trees need not be to it under the modes of presentation that UAl* and UAt* require.
The same difficulty arises even if we require only a disposition to assent, as in UDAl′ and UDAt′.28
To determine in exactly what sense of 'tacit knowledge,' if any, understanding does involve tacit propositional knowledge of meaning lies beyond the scope of this book. According to Gareth Evans (1985:
338–9):
Tacit knowledge of the syntactic and semantic rules of the language are
[sic] not states of the same kinds as the states we identify in our ordinary use of the terms 'belief' and 'knowledge.' Possession of tacit knowledge is exclusively manifested in speaking and understanding a language; the information is not even potentially at the service of any other project of the agent, nor can it interact with any other beliefs of the agent (whether genuine beliefs or other tacit 'beliefs') to yield further beliefs. Such concepts as we use in specifying it are not concepts we need to suppose the subject to possess, for the state is inferentially insulated from the rest of the subject’s thoughts and beliefs.

Even if the contrast is less extreme than Evans argues, the lack of inferential integration is real, and crucial here. Of course, the
28 ordinary notions of knowledge and belief may well provide appropriate templates for the construction of new notions of 'tacit knowledge' and 'tacit belief' of value to cognitive psychology. It can be theoretically rewarding to exploit the similarities between tacit knowledge and ordinary knowledge, but for present purposes it is the differences that matter.
Whatever the nature of tacit assent and dissent, no reflective intellectual discipline operates at the level of such assent and dissent, even if such a tacit level is necessary for its operation. Thus linguists’ tacit knowledge of their native language does not already satisfy the goal of linguistics. Similarly, philosophy as a discipline operates at the level of conscious reflection and public discussion, whatever their unconscious underpinnings. For present purposes, we may therefore restrict assent to conscious assent and maintain the generalization that there are no necessary links from understanding to assent, or even to dispositions to assent.
To summarize: The case for treating lack of a disposition to assent to (1) as lack of linguistic competence depends on the status of (1)
as an elementary truth of deductive logic. But human deductive competence is far more sensitive than linguistic competence to high intelligence and advanced education. Deductive competence is a reflective skill, often painfully acquired and under one’s personal control. It is not insulated from one’s conscious theorizing. Thus deductive proficiency is not a precondition of linguistic competence.
Links from linguistic understanding to assent or to dispositions to assent fail.

5
The argument of the last two sections was at the level of language, not thought. It was directed primarily against UAl′ and UDAl′, not
UAt′ and UDAt′. Could a theorist of thought maintain UAt′ or UDAt′
while acknowledging Peter and Stephen as counterexamples to UAl′
and UDAl′?
For the sake of argument, thoughts are being individuated by a cognitive criterion fine enough to suit an epistemological conception of analyticity, so we may assume that when a speaker understands a sentence, they associate it with a unique thought, in the intimate way in which we associate the sentence 'Grass is green' with the thought grass is green. In particular, the speaker assents to the sentence if and only if they assent to the thought. Consider Stephen (the argument is parallel for Peter). Since Stephen understands 'Every vixen is a vixen,' he associates it with a unique thought t. Thus Stephen assents to 'Every vixen is a vixen' if and only if he assents to t. But Stephen is an acknowledged counterexample to UAl′; he does not assent to the sentence 'Every vixen is a vixen.' Therefore he does not assent to t. Consequently, if t is the thought every vixen is a vixen, Stephen does not assent to the thought every vixen is a vixen, in which case he is also a counterexample to UAt′. Thus if Stephen is not a counterexample to UAt′, the thought he associates with the sentence
'Every vixen is a vixen' is not the thought every vixen is a vixen.
There is a parallel argument for dispositions. Stephen is an acknowledged counterexample to UDAl′; he understands 'Every vixen is a vixen' while having no disposition to assent to it. We may therefore assume that he is relevantly stable; thus in all relevant situations t is the unique thought he associates with the sentence. Thus Stephen has a disposition to assent to 'Every vixen is a vixen' if and only if he has a disposition to assent to t. Therefore he has no disposition to assent to t. Consequently, if t is the thought every vixen is a vixen,
Stephen has no disposition to assent to the thought every vixen is a vixen, in which case he is also a counterexample to UDAt′. Thus if
Stephen is not a counterexample to UDAt′, the thought he associates with the sentence 'Every vixen is a vixen' is not the thought every vixen is a vixen.
The upshot is that theorists of thought can maintain links from understanding to assent or dispositions to assent at the level of thought while abandoning them at the level of language only if they deny that the thought Peter or Stephen associates with the sentence
'Every vixen is a vixen' is the thought every vixen is a vixen. They may either deny that Peter and Stephen grasp the thought every vixen is a vixen at all or assert that they grasp the thought by some means other than that sentence and assent to it, or at least have a disposition to assent.
The thought every vixen is a vixen is the thought we associate with (1). Thus the envisaged theorist of thought is claiming that the thought we associate with (1) differs from the thoughts Peter and
Stephen associate with it, even though all of us understand (1) with Epistemological Conceptions of Analyticity

its usual meaning in English.29 This need not imply that (1) is indexical, expressing different propositions in the contexts of different speakers, for thoughts are not being identified with propositions. You might use the sentence 'He is hungry' (pointing at me), which you associate with a demonstrative thought he is hungry to express the very proposition I express using the sentence 'I am hungry,' which
I associate with the distinct thought I am hungry; you associate the sentence 'I am hungry' with the same thought but use it to express a different proposition, that you are hungry. For all that has been said, Peter and Stephen use (1) to express the same proposition as we do. But on what basis are the thoughts Peter and Stephen associate with (1) being distinguished from the thought we associate with (1)?
One could simply use the word 'thought' subject to the stipulation that the inferential differences between Peter, Stephen, and us constitute differences between the thoughts we associate with (1). But what is the point of such a stipulation? As seen above, the linguistic understanding of (1) we share with Peter and Stephen already suffices for them and us to articulate our disagreements in rational discourse; we are not merely talking past one another. In its small way, (1)
determines a piece of the common intellectual heritage of mankind, something we share with Peter and Stephen in our very capacity to disagree over it. To insist that the thought we associate with (1)
nevertheless differs from the thoughts Peter and Stephen associate with (1) is to undermine Frege’s requirement of the publicity of senses, and in particular thoughts.
If Peter and Stephen associate (1) with different thoughts from ours, should we not understand them better by translating their idiolects non-homophonically into ours? Presumably we should seek sentences other than (1) that we associate with the very thoughts they associate with (1), or at least sentences we associate with thoughts
29
Neo-Fregeans such as Evans (1982: 40) sometimes claim that different speakers can achieve linguistic competence with the same proper name by associating it with different concepts (modes of presentation) of the same object. On the view envisaged in the text, phrases such as 'the thought every vixen is a vixen' or 'the concept every' presumably are indexical, since they refer to the thought or concept that the speaker associates with the italicized expression. Discussions of concept possession tend to use such phrases freely, without attention to such indexicality. On the envisaged view, they may require consequent revision. more similar to the thoughts they associate with (1) than is the thought we associate with (1), and translate the dissent from (1) in their mouths as dissent from those other sentences in our mouths.
But the use of such a translation scheme would be intellectually disreputable, just because it would involve a refusal to acknowledge the full challenge that Peter and Stephen have issued to (1) in our mouths, not just in theirs. However mistaken their challenge, it is real. They are quite explicit that they are challenging the thought we associate with (1), and that we should apply no non-homophonic translation scheme when interpreting their dissent from (1). To insist on applying such a non-homophonic translation scheme to them in the teeth of their protests would be to treat them less than fully seriously as human beings, like patients in need of old-fashioned psychiatric treatment, whose words are merely symptoms. The claim that Peter and
Stephen associate (1) with different thoughts from ours repackages our disagreement with them in a way that makes it sound less threatening than it really is. It misleadingly bundles together logical and semantic differences, without any genuine unification of the two categories. To call the logical disagreement a difference in associated
'thoughts' is an advertising trick. Since a homophonic reading of (1)
in the mouths of Peter and Stephen is more faithful to their intentions than is any non-homophonic reading, they associate (1) with the same thought as we do in any relevant sense of 'thought.'
Naturally, when Peter dissents from 'Every F is a G,' we may decide in the light of his logical unorthodoxy to store only the information that either not every F is a G or there are no Fs. But this is not a non-homophonic translation, any more than it is when someone notorious for exaggeration says 'At least six thousand people went on the march' and we decide to store only the information that at least one thousand people went on the march. By 'six thousand'
the speaker did not mean what we mean by 'one thousand.'
If exactly one thousand people went on the march he spoke falsely, not truly, for he was speaking English. Since we do not fully trust him, when he asserted one thing we stored only something weaker.
Similarly, since we do not fully trust Peter, we do not store exactly what he asserts. If there were no Fs, he spoke falsely, not truly, for he was speaking English. Our lack of trust in Peter and Stephen’s logic skills is quite consistent with reading their utterances homophonically. Epistemological Conceptions of Analyticity

Peter and Stephen are counterexamples to UAt′ and UDAt′. The links from understanding to assent, or even to dispositions to assent, fail for thought as they do for language.

6
How do the considerations of preceding sections apply to traditional paradigms of analyticity? Consider:
(9) Every vixen is a female fox.
Given that 'vixen' is synonymous with 'female fox,' (9) results from substituting synonyms for synonyms in the logical truth (9).
Hence (9) is synonymous with (1): it is Frege-analytic but not itself a logical truth. We can expect the arguments of previous sections against links from understanding to assent or dispositions to assent for examples like (1) to work at least as strongly for examples like
(9). Let us check this.
We may try to reduce discussion of (9) to discussion of (1), on the grounds that the concept vixen just is the concept female fox. Thus the thought every vixen is a female fox just is the thought every vixen is a vixen (since thoughts are composed of concepts). To grasp, assent to or know a thought is just to have a relation to that thought. Consequently, to grasp, assent, or know every vixen is a female fox just is to grasp, assent, or know every vixen is a vixen. At the level of thought, the previous discussion carries over automatically. For example, in being counterexamples to the understanding-assent link for the thought every vixen is a vixen, Peter and Stephen are ipso facto counterexamples to the understanding link for the thought every vixen is a female fox.
At the level of language, the reduction is slightly more complicated:
'vixen' and 'female fox' are distinct expressions even if they are associated with the same concept. Someone can understand 'female fox' without understanding 'vixen.' Conversely, someone can understand 'vixen' without understanding 'female fox': for instance, a native speaker of another language who is learning English understands 'vixen,' because she was taught it as a synonym for a word in her native language, but has not yet encountered 'female' and 'fox.' If she has mastered the construction 'Every . . . is a ,' she can understand (1) without being in a position to understand (9).
Someone who understands neither (1) nor (9) can assent to one of them without assenting to the other, on the testimony of someone else who tells him that the former is true without telling him that the latter is true. Nevertheless, we might try arguing that whoever understands (9) will take just the same attitudes to it as to (1).
The argument is this. Suppose that someone understands (9) (as always, with its normal English meaning). Thus she associates it with the thought every vixen is a female fox. Consequently, she takes an attitude Al (such as assent or knowledge) to (9) if and only if she takes the corresponding attitude At to the thought every vixen is a female fox at the level of thought (in preceding sections, Al and At were equated). Our speaker also understands (1), because it is composed entirely out of words ('vixen') and modes of construction ('every . . . is a –') which she understands in understanding (9). Thus she associates (1) with the thought every vixen is a vixen. Consequently, she takes Al to (9) if and only if she takes At to the thought every vixen is a vixen. For the reason already given, the thought every vixen is a vixen is the thought every vixen is a female fox. Therefore she takes
At to the thought every vixen is a vixen if and only if she takes At to the thought every vixen is a female fox. It follows that she takes Al to
(9) if and only if she takes Al to (1). Thus, with respect to speakers who understand (9), discussion of (9) reduces to discussion of (1).
Whether or not the concept vixen is the concept female fox, the reduction succeeds for Peter and Stephen, since they use the concepts interchangeably and do understand (9). They are counterexamples to epistemological analyticity for (9) just as much as they are for (1), at the levels of both thought and language.
The assumption that the concept vixen is the concept female fox is controversial. Burge (1978) has built on a point of Mates (1952)
to argue that synonyms cannot always be substituted for synonyms salva veritate in belief ascriptions. Thus someone under the misapprehension that the term 'vixen' also applies to immature male foxes may believe that every vixen is a vixen without believing that every vixen is a female fox. Burge argues powerfully against attempts to reconstrue such beliefs as metalinguistic. Does this speaker assent to the thought every vixen is a vixen without assenting to the thought every vixen is a female fox? If so, the thoughts are distinct (which is Epistemological Conceptions of Analyticity

compatible with the identity of the proposition that every vixen is a vixen with the proposition that every vixen is a female fox), and the concept vixen is not the concept female fox.
To make a case more like those of Peter and Stephen, we can imagine that our speaker is quite familiar with the dictionary definition of 'vixen' as 'female fox.' He also knows that dictionaries give a second definition of 'vixen' as 'quarrelsome woman.' However, unlike most of us, he does not believe that these are two senses of
'vixen.' Rather, he thinks that 'vixen' in its primary sense applies to both female foxes and quarrelsome women. He may defend his view with sophisticated arguments from the philosophy of language, although this is not essential. He denies (9), intending 'vixen' in the public sense in which it applies at least to female foxes.
Our imaginary speaker is not so different from actual natives speakers of English who deny that a man who has lived with a partner for several years without getting married is a bachelor, or assert that someone who underwent a sex-change operation after giving birth is a mother without being a female parent.30 Suppose that they are in fact mistaken; 'bachelor' has the same intension as 'unmarried man' and 'mother' has the same intension as 'female parent.' Thus they are mistaken about the meaning of the English words 'bachelor'
and 'unmarried.' Nevertheless, they fall well within the range of permissible variation for linguistically competent speakers. They are only giving more weight than others to an inclination that most speakers feel in some degree to classify the cases that way. Without regarding them as having spoken parrot-fashion, we report their beliefs using the words 'bachelor' and 'unmarried.' We classify them as believing that some unmarried men are not bachelors and that some mothers are not female parents because we interpret them as having used the words with their normal English meanings, despite their errors. That is how they intend to be interpreted, not as using the words with idiosyncratic senses.31 If we believe that all unmarried
30
Compare Harman (1999: 151) on problems in analyzing 'bachelor' as 'unmarried adult male' and Nozick (2001: 135–6) on the non-synonymy of 'mother' and
'female parent.'
31
One problem with interpreting speakers as all speaking their own idiolects is that it tends to undermine testimonial knowledge: if Y gets some knowledge from X and passes it on to Z in the same words, they do not mean in Y’s mouth what they meant in X’s.

Epistemological Conceptions of Analyticity men are bachelors and all mothers are female parents, we therefore classify their beliefs in question as untrue, for the belief that some unmarried men are not bachelors is true if and only if some unmarried men are not bachelors, and the belief that some mothers are not female parents is true if and only if some mothers are not female parents. Given that we correctly interpret them as using the words with their normal English meanings, they understand the words in the relevant sense of 'understand.' Although they are ignorant of some facts about the normal English meanings of the words, such ignorance is quite compatible with linguistic competence (which is why native speakers of English take university courses in the semantics of English). Arguably, their error is not primarily semantic: they have the semantic belief that the word 'bachelor' does not apply to all unmarried men because they have the non-semantic belief that some unmarried men are not bachelors and the semantic knowledge that 'bachelor' applies only to bachelors; they have the semantic belief that the word 'mother' does not apply only to female parents because they have the non-semantic belief that some mothers are not female parents and the semantic knowledge that the word 'mother'
applies to all mothers.
Such cases also help answer the objection to examples such as those in this chapter that the awkward subject who consciously denies that P also has unconscious, semantically derived knowledge
(or belief) that P. When a competent native speaker denies that every unmarried man is a bachelor, the postulation of unconscious knowledge (or belief) that every unmarried man is a bachelor serves no good explanatory purpose. The speaker tends to apply 'bachelor' to something once they have applied 'unmarried' and 'man' to it, but the tendency is defeasible. Such defeasible connections can be explained without postulation of unconscious belief in a universal generalization. In such cases, there need be no hint of the cognitive dissonance or tension that one might expect from a direct contradiction between conscious and unconscious beliefs. Given that there is no contradicted unconscious knowledge in these simple cases, it is not clear what better reason there is supposed to be in postulating it for more complex cases either.
Suppose, given the considerations above, that the concept vixen is not the concept female fox. Then the claim of epistemological analyticity is even worse off for (9) than it is for (1), at the levels of both Epistemological Conceptions of Analyticity

thought and language. Logically orthodox subjects can understand
(9) and grasp the thought every vixen is a female fox while refusing to assent. In that case, they will also reject the corresponding inference rule with instances of the form 'a is a vixen; therefore a is a female fox' (and conversely); likewise at the level of thought.32
The underlying style of argument against links from understanding to assent or dispositions to assent is quite general. For each candidate one must still find appropriate counterexamples: since they are most convincing when unorthodoxy on the point at issue is amply compensated by orthodoxy on related points, no one counterexample will suit all cases. Nevertheless, with a little ingenuity one always succeeds.33 Peter and Stephen assent to the conclusion of this inference rule whenever they assent to its premise. For some subtler problems it raises for them see Williamson
(2006b: 33–4).
33
Another application of the present style of reasoning is to claims that sorites paradoxes reveal incoherence in vague concepts. Thus Dummett (1975a) argues that observational predicates in natural language are governed by rules that infect the language with inconsistency: for example, to understand 'looks red' one must be willing to apply a tolerance principle by which one can infer from 'x is visually indiscriminable from y' and 'x looks red' to 'y looks red,' which generates sorites paradoxes because visual indiscriminability is non-transitive. More recently, Roy
Sorensen (2001) has argued that linguistic competence with vague terms involves willingness to make inferences such as that from 'n seconds after noon is noonish'
to 'n + 1 seconds after noon is noonish,' which commits us to inconsistent conclusions by sorites reasoning (given our other commitments, such as 'Noon is noonish'
and 'Midnight is not noonish'). Matti Eklund (2002) defends a similar account of both sorites and semantic paradoxes. There are no such requirements on linguistic competence and concept possession. An ordinary speaker of English who understands
'looks red' and 'noonish' and has the concepts looks red and noonish in the normal way but then rejects the relevant tolerance principles in the light of the sorites paradoxes does not thereby cease to understand those expressions or to have those concepts. She might treat the premises of the tolerance principles as providing good defeasible evidence for their conclusions, without even being disposed to expect long chains of such reasoning to preserve truth; this attitude seems to be less than Dummett,
Sorensen, and Eklund require for competence, since it is insufficient to render sorites paradoxes puzzling. In any case, even if a whole community of speakers is disposed to treat tolerance principles as obviously fallacious, it can still have terms like 'looks red' and 'noonish' that are just as vague as ours; speakers’ acceptance of tolerance principles is quite inessential to vagueness. In principle, we could also explore putative links from understanding of one sentence to (dispositions to) assent to another sentence or a thought, or from grasp of one thought to (dispositions to) assent to another thought. In practice, such candidates fall to objections very similar to those already raised. Details are therefore omitted.

7
Old theories tend to survive refutation in the absence of new theories to take their place. Despite all the evidence against the existence of links from understanding to assent or dispositions to assent, it can be hard to resist the idea that there must be such links, otherwise the distinction between understanding and not understanding would dissolve: speakers who all understood the same term might have nothing substantive in common to constitute its shared meaning. For example, in the case of moral vocabulary, which he treats as representative,
Frank Jackson (1998: 132) writes:
Genuine moral disagreement, as opposed to mere talking past one another, requires a background of shared moral opinion to fix a common, or near enough common, set of meanings for our moral terms. We can think of the rather general principles that we share as the commonplaces or platitudes or constitutive principles that make up the core we need to share in order to count as speaking a common moral language.34
34

Jackson’s application of the Ramsey-Carnap-Lewis method for defining theoretical terms to moral vocabulary (and more generally in his program of conceptual analysis) requires not merely some agreed role for moral terms but an agreed role specific enough to be uniquely instantiated: this further assumption is criticized at
Williamson (2001: 629–30). Jackson’s reply on this point (2001: 656) reiterates something like the assumption in the quoted passage. He also misunderstands the objection by falsely supposing that the claim that we can mean the same by a word and disagree radically about its application restricts the disagreement to what occupies the roles, rather than the roles themselves, however one imagines the latter as demarcated. For criticism of the application of the Ramsey-Carnap-Lewis method in
Boghossian (2003) see Williamson (2003a). In general, if the platitudes are weak, as we have every reason to expect, many different candidates will satisfy them. Call these the admissible candidates. For simplicity, think of them as properties (more accurately, they are n-place sequences of properties and relations, where n is the number Epistemological Conceptions of Analyticity

Jackson’s only argument for these claims is failure to see an alternative.
The notion of a shared language is vague (Jackson does not suggest otherwise). There can be sorites series of speakers in which each seems to be speaking the same language as the next but the first is clearly not speaking the same language as the last.35 One reaction is that there is no such thing as a shared language, a conclusion endorsed in some form by both Noam Chomsky and Donald Davidson. Similarly, Margaret Thatcher once claimed 'There is no such thing as society,' and one can certainly construct sorites series in her support. But almost everything looks vulnerable to sorites series; they are a poor way to establish non-existence. Whatever exactly shared languages are, they are no mere illusion. We can follow Jackson in asking how they are possible. But there is an alternative to his answer.

of primitive predicates to which the method is being applied). The conjunction or disjunction of these admissible candidates will often not itself be an admissible candidate. Schematic example: let the platitudes be 'All Fs are electrons,' 'Some electrons are Fs' and 'Some electrons are not Fs,' where the method is being applied to
'F'; the conjunction of the admissible candidates is the empty property, which does not satisfy the second platitude and so is inadmissible; their disjunction is the property of being an electron, which does not satisfy the third platitude and so is inadmissible.
The non-uniqueness problem for the Ramsey-Lewis-Carnap definiens, in effect 'the property that satisfies the platitudes,' is not that it is vague which property it denotes but that it definitely fails to denote any property at all, since many properties definitely satisfy the platitudes; neither supervaluationism nor any other theory of vagueness rescues the definition. A modified description such as 'the most natural property that satisfies the platitudes' may still not solve the problem – perhaps several admissible candidates are equally natural and more natural than any others, or for every admissible candidate there is a more natural one – and in any case raises the question why the Ramsey-Carnap-Lewis method is being applied to some terms but not to the highly theoretical term 'natural' itself (otherwise the problem simply recurs for
'natural'). It is a mistake to assume that such problems are really problems for the linguistic practice itself rather than for the appeal to platitudes, for that is to assume that the platitudes exhaust what the practice does to secure reference for the predicate.
Uses of the predicate to make controversial claims may also play a role in determining its reference, although not a naïvely descriptivist role (the account in Chapter 8 will permit this). The method of platitudes rashly throws such information away.
35
Williamson (1990: 137–41) discusses sorites series for languages. What binds together uses of a word by different agents or at different times into a common practice of using that word with a given meaning? This is an instance of a more general type of question: what binds together different events into the history of a single complex object, whether it be a stone, a tree, a table, a person, a society, a tradition, or a word? In brief, what makes a unity out of diversity?
Rarely is the answer to such questions the mutual similarity of the constituents. Almost never is it some invariant feature, shared by all the constituents and somehow prior to the complex whole itself – an indivisible soul or bare particular. Rather, it is the complex interrelations of the constituents, above all, their causal interrelations.
Although we should not expect a precise non-circular statement of necessary and sufficient conditions for the unity in terms of those complex interrelations, we have at least a rough idea of what it takes.
The similarity of the constituents is neither necessary nor sufficient; different constituents can play different but complementary roles in constituting the unity: both events in the head and events in the heart help constitute the life of a person. The idea that a shared understanding of a word requires a shared stock of platitudes depends on the assumption that uses of a word by different agents or at different times can be bound together into a common practice of using that word with a given meaning only by an invariant core of beliefs. But that assumption amounts to one of the crudest and least plausible answers to the question of what makes a unity out of diversity. In effect, it assumes that what animates a word is a soul of doctrine.36
As Kripke and Putnam argued, different speakers can make asymmetric contributions to binding together different uses of a word into a common practice of using it with a given meaning. The paradigm is their description of the role of scientific experts in fixing the reference of natural kind terms. Even if they oversimplified the relation between natural kind terms in natural language and scientific theory, a more refined account will still respect the division of linguistic labor, for distinctions between levels of expertise are observable even within the pre-scientific use of natural kind terms. Contrary to some of Putnam’s less careful formulations, no canonical list of 'criteria'
36 for the application of the term need be available even to the most expert members of the community. Speakers may simply differ from each other in various ways in their ability to distinguish between members and non-members of the relevant kind.
The underlying insight is relevant far beyond the class of natural kind terms, as Burge observed. Even where we cannot sensibly divide the linguistic community into experts and non-experts, the picture of a natural language as a cluster of causally interrelated but constitutively independent idiolects is still wrong, because it ignores the way in which individual speakers defer to the linguistic community as a whole. They use a word as a word of a public language, allowing its reference in their mouths to be fixed by its use over the whole community.37 No asymmetries in sociolinguistic status between individual speakers are required. For instance, if I classify a shade close to orange as 'red' but subsequently discover that it is classified as 'not red' by most native speakers of English whose eyesight is as good as mine, I may rationally admit that I was wrong without conceding that either I misunderstood the word 'red' or my visual system was abnormal or malfunctioning. One can know that 'red' means red without being infallible as to exactly which shades count as shades of red. Even if I obstinately insist that I am right and the rest are wrong in this particular case, my assumption that 'red' in my mouth is inconsistent with 'not red' in theirs shows that I intend my use of
'red' to be treated as the use of a word of a public language. That its reference is fixed by the pattern of use over the whole community does not entail that the majority must be right in any given case: reference can supervene on underlying facts in ways far from transparent to native speakers.
The unity of a linguistic practice, like the unity of other complex objects, has both synchronic and diachronic aspects. As usual, causal continuity is necessary but not sufficient for diachronic unity. Anaphoric pronouns constitute one paradigm of such unity: the reference of later tokens is parasitic on the reference of earlier tokens; the identity of reference results from collusion, not coincidence. Over a longer timescale, the historical chains that preserve the reference of names represent a similar form of diachronic unity. Written testi37

If the term is indexical, what is fixed by use over the whole community is not the content but the character in the sense of Kaplan (1989). For the bearing of this on communication in a vague language see Williamson (1999b: 512–14). mony and verbal testimony preserved in memory depend on such reference-preserving links. As usual, the intention to preserve reference is not guaranteed to succeed, but success is the default (Kripke
1980).
Such diachronic links can hold non-trivially even for the linguistic or conceptual practice of an isolated individual. Contrary to some readings of Wittgenstein’s private language argument, what seems right to the isolated individual need not be right, given their overall use dispositions: even at the individual level, reference can supervene on underlying facts in ways far from transparent to the subject. The point of the social determination of meaning is not that meaning can never be determined individually, but that, when an individual does use a shared language as such, individual meaning is parasitic on social meaning.
A complex web of interactions and dependences can hold a linguistic or conceptual practice together even in the absence of a common creed that all participants at all times are required to endorse.
This more tolerant form of unity arguably serves our purposes better than would the use of platitudes as entrance examinations for linguistic practices.
Evidently, much of the practical value of a language consists in its capacity to facilitate communication between agents in epistemically asymmetric positions, when the speaker or writer knows about things about which the hearer or reader is ignorant, perhaps mistaken.
Although disagreement is naturally easier to negotiate and usually more fruitful against a background of extensive agreement, it does not follow that any particular agreement is needed for disagreement to be expressed in given words. A practical constraint on useful communication should not be confused with a necessary condition for literal understanding. Moreover, the practical constraint is holistic; agreement on any given point can be traded for agreement on others.
The same applies to principles of charity as putatively constitutive conditions on correct interpretation: imputed disagreement on any given point can be compensated for by imputed agreement on others.38
38

Davidson famously endorses a holistic principle of charity while rejecting the analytic-synthetic distinction (2001: 144–9). See Chapter 8 for more discussion of charity. Of course, he takes the notion of a shared language less seriously than here
(Davidson 1986). Epistemological Conceptions of Analyticity

It is far easier and more rewarding to discuss the existence of true contradictions with a dialetheist such as Graham Priest than creationism with a Christian fundamentalist or Holocaust denial with a neoNazi.39 The difficulty of engaging in fruitful debate with fundamentalists or neo-Nazis is not plausibly attributed to some failure of linguistic understanding on their part (or ours); it arises from their willful disrespect for the evidence. Such difficulty as there is in engaging in fruitful debate with dialetheists provides no significant reason to attribute to them (or us) a failure of linguistic understanding. Competence with the English language no more requires acceptance of some law of non-contradiction or any other logical law than it requires acceptance of the theory of evolution or the historical reality of the Holocaust.
We cannot anticipate all our disagreements in advance. What strike us today as the best candidates for analytic or conceptual truth some innovative thinker may call into question tomorrow for intelligible reasons. Even when we hold fast to our original belief, we can usually find ways of engaging rationally with the doubter. If a language imposes conditions of understanding that exclude such a doubt in advance, as it were in ignorance of its grounds, it needlessly limits its speakers’ capacity to articulate and benefit from critical reflection on their ways of thinking. Such conditions are dysfunctional, and natural languages do not impose them.40 Similarly, conceptual practices do better not to restrict in advance their capacity for innovation.
There is, of course, a distinction between understanding a word and not understanding it. One can lack understanding of a word through lack of causal interaction with the social practice of using that word, or through interaction too superficial to permit sufficiently fluent engagement in the practice. But sufficiently fluent engagement in the practice can take many forms, which have no single core of agreement.41
39
For examples of rational debate for and against a law of non-contradiction see
Priest, Beall, and Armour-Garb (2004).
40
W. B. Gallie’s intriguing account of the positive function of 'essentially contested concepts' is relevant here; his examples are 'the concepts of a religion, of art, of science, of democracy and of social justice' (1964: 168).
41
Someone who understands a word without being disposed to utter it (perhaps because they find it obscene or unpronounceable) can still count as sufficiently If we picture speaking the same language in this way, how should we picture meaning the same thing? There is no quick generalization from the former to the latter. Different uses of the same word must be causally related, at least indirectly.42 Creatures who are causally unrelated to us cannot use our word 'not'; at best they can use a word exactly like our word in its general syntactic, semantic, and phonetic properties. But, on the usual view, their word can in principle be synonymous with ours. Synonymy does not entail causal relatedness.
Expressions are synonymous when they have exactly the same semantic properties. Fortunately, the tradition of truth-conditional semantics provides us with a rich store of such properties, if we take it seriously as a branch of linguistics and put aside Quinean reservations.
Two paradigms of a semantic property are the extension of a predicate, the set of things to which it applies, and its intension, the function that takes each circumstance of evaluation (say, an ordered pair of a world and a time) to the extension of the predicate with respect to that circumstance. For the purposes of compositional semantics, this approach can be generalized to expressions of other grammatical categories, so that they have intensions too. Thus synonymy entails at least sameness of intension. That is still a rather coarse-grained criterion, since it does not reflect internal compositional structure: '5 + 7' and '9 + 3' have the same intension. We can go more fine-grained by associating expressions with trees whose nodes correspond to their semantically significant constituents, each node being decorated with the content of the corresponding constituent; the branching structure of the tree encodes the constituency structure of the expression. Thus synonymy entails at least sameness of associated tree. This criterion is similar to Carnap’s notion of intensional isomorphism (1947: 56). In this sense not even 'vixen'
and 'female fox' are synonymous, since they differ in semantically significant structure, unless the account can be applied at a level of deep logical form at which they turn out to have the same constituents. Something like intensional isomorphism can serve as a criterion for sameness of content expressed in a given context of utterance.
engaged in the practice of using it. The account should also be read so as to allow for understanding of dead languages.
42
On the metaphysics of words see Kaplan (1990). Epistemological Conceptions of Analyticity

An expression brings its linguistic meaning to a context rather than having that meaning made up in the context. Thus 'I' as used by
TW does not have the same linguistic meaning as 'TW,' even though they have the same content (since they are unstructured rigid designators of the same object). Rather, 'I' as used by TW is identical in linguistic meaning with 'I' as used by any other competent speaker of English. Thus a better approximation to the linguistic meaning of an expression is its character in the sense of Kaplan (1989), the function taking each context of utterance to the content of the expression in that context.
We might go still further. For instance, so far 'and' and 'but'
come out synonymous, since they are simple expressions that make the same contribution to truth-conditions. We might distinguish their meanings by adding as further semantic properties conventional implicatures, themselves individuated like characters.
Even without conventional implicatures, once content is individuated by intensional isomorphism, the conception of linguistic meaning as character is already exquisitely fine-grained. Nevertheless, if semantic theory discovers a need to attribute still more semantic properties, or to revise the framework already sketched, sameness with respect to the newly identified semantic properties will be required for synonymy. In any case, we need not try to circumscribe in advance exactly what properties semantic theory will need to recognize.
The point is methodological. Whether an expression in one language is synonymous with an expression in another language is not a matter of whether the two speech communities associate similar beliefs with the expressions. Rather, the practices of each community
(including their beliefs) determine the semantic properties of its expressions. Synonymy is the identity of the properties so determined, irrespective of similarities in belief. It is consistent with large differences in belief (just as very different distributions can have the same mean), and non-synonymy is consistent with much smaller differences in belief (just as very similar distributions can have different means). In particular, synonymy is consistent with the total absence of shared platitudes.
The synonymy of two expressions does not entail that competent speakers treat them interchangeably, as noted in chapter 3. Someone can understand 'furze' and 'gorse' by learning them from ostension of different samples without appreciating their synonymy. In some

Epistemological Conceptions of Analyticity cases, even competent speakers who know two expressions to be synonymous will not treat them interchangeably. For example, the slang word 'gob' means the same as 'mouth,' but competent speakers are normally sensitive to whether the social context makes 'gob'
(but not 'mouth') inappropriate. Such differences in register are linguistic but not semantic. Consequently, knowing the meaning of an expression does not automatically qualify one for full participation in the practice of using it. Someone who acquires the word 'gob'
just by being reliably told that it is synonymous with 'mouth' knows what 'gob' means without being fully competent to use it. One does not achieve full competence with a sentence of a foreign language by learning its meaning from a phrasebook without knowing which constituent contributes what to that meaning. For a less obvious case, consider empty terms. Arguably, 'phlogiston' fails to refer with respect to any circumstance of evaluation (since it designates rigidly, if at all) and any context of utterance (since it is non-indexical); it is semantically atomic and has no conventional implicatures. Those facts may completely determine its semantics, strictly speaking. Nevertheless, knowing them alone does not qualify one to participate in the linguistic practice of using 'phlogiston,' since they do not distinguish it from empty terms associated with other failed theories.
Although no particular piece of knowledge is necessary for participation, such abject ignorance is not sufficient. We should resist the temptation to build all qualifications for participation in the practice of using a term into its meaning, on pain of turning semantic theory into a ragbag of miscellaneous considerations (even the inclusion of conventional implicature is marginal).
What of concepts? Presumably, thinkers causally unrelated to us could have the concept not. Hence sameness of concept does not entail causal relatedness; it is closer to sameness of meaning than it is to sameness of word. If so, the concept furze may well just be the concept gorse. If thoughts are composed of concepts in the obvious way, then the thought all furze is gorse just is the thought all furze is furze, and whoever assents to the latter ipso facto assents to the former. We may sometimes be unable to determine whether we are employing two concepts or one. That makes the individuation of thoughts and concepts less accessible to the thinker than many theorists of thought have wished. For the sake of greater (but still imperfect) accessibility, they might therefore switch to individuating Epistemological Conceptions of Analyticity

concepts more like words than like meanings. In any case, the argument against epistemological analyticity at the level of thought has already been explained, in Section 5.

8
At this point, a friend of epistemological analyticity may suspect that the mistake was to go for the idea that understanding is somehow psychologically sufficient for assent. Instead, the suggestion is, we should go for the idea that understanding is somehow epistemologically sufficient for assent.43 Externally, Peter and Stephen are in a position to know (or to assent with justification). They seem to be willfully and perversely turning their backs on knowledge that is available to them. It is there for the taking, but they are psychologically blocked from taking it.
We must be careful about the source of the blockage. Suppose that it is lack of logical insight. Although Peter and Stephen grasp the thought every vixen is a vixen, they lack the logical insight to know every vixen is a vixen. Other people just like Peter and Stephen except for having more logical insight do know every vixen is a vixen.
Anyone who grasps the thought every vixen is a vixen and has a modicum of logical insight can know every vixen is a vixen. That story assigns no special role to grasp of concepts, beyond the usual role that grasping any thought plays as a precondition for knowing it: the decisive role is assigned to logical competence, not conceptual competence. For conceptual competence to play the decisive role, something like this is needed:
(KUt′) (KUl′)

Whoever knows 'Every vixen is a vixen' in the normal way does so simply on the basis of their understanding of the sentence.

KUt′ and KUl′ may be plausible at first sight. They do not imply that whoever understands the sentence or grasps the thought has a disposition to assent to it, let alone to know it.
What do the definite descriptions 'their grasp of the thought' in
KUt′ and 'their understanding of the sentence' in KUl′ denote? There are thick and thin candidates. The thin candidates are the mere fact that they grasp the thought and the mere fact that they understand the sentence respectively. The thick candidates are the underlying facts that constitute the respective thin candidates, the facts that realize this particular subject’s understanding at this particular time.
The thin candidates are exactly similar for any two people who grasp the thought or understand the sentence, since they have the same property of grasping the thought or understanding the sentence. The thick candidates may differ between any two people who grasp the thought or understand the sentence, since different underlying facts can constitute their doing so. These characterizations are schematic, but will do for present purposes.
Suppose that the definite descriptions in KUt′ and KUl′ denote the thick candidates. KUt′ and KUl′ remain somewhat plausible on this reading. Then, given the holistic picture of concept possession and linguistic understanding in previous sections, KUt′ and KUl′ have much less epistemological significance than might have been hoped.
The facts that constitute your understanding of a given sentence include various cognitive capacities that are not in general necessary for understanding that sentence, but help to make up your particular competence with it. For example, the facts that constitute Peter’s understanding of (1) include his logical capacities; the facts that constitute Stephen’s understanding of (1) include his rather different logical capacities. The bases cited in KUl′ and KUt′ include cognitive capacities that are not in general necessary for understanding the sentence or grasping the thought. Thus the thick candidates are too thick to yield bases for analyticity; they involve cognitive capacities that are not semantic or conceptual in any relevant sense.
Suppose instead that the definite descriptions in KUt′ and KUl′
denote the thin candidates. But they are not the bases in any useful Epistemological Conceptions of Analyticity

sense for knowing every vixen is a vixen or 'Every vixen is a vixen'
in the normal way, although confusion with the thick candidates may suggest otherwise. The thin candidates imply no specific logical capacity at all, as Peter, Stephen and others show. It is not as though in such cases the subject’s understanding quietly tells them to assent but they override the advice; it is providing no such advice to be overridden. For the imagined overridden advice is a metaphor for the hypothesis of overridden dispositions to assent, dispositions necessary for understanding; that hypothesis was rejected in Section 4. By itself, thin understanding cannot guide our assent. Consequently, understanding in the thin sense provides no basis for assent to anyone. Of course, understanding is a precondition for knowing, and in that sense may be part of the basis for knowing, but that point is quite general; it is neutral between the analytic and the synthetic. Although the combination of understanding in the thin sense with the right bit of elementary but not universal logical competence is a basis for knowing (1), that point neither explains why logical knowledge is available in the armchair nor makes it distinctively conceptual or semantic. By themselves, the thin candidates are too thin to be bases for knowledge.
We could try eliminating the talk of bases, for instance in formulations like these:
(AJt′)
(AJl′)

Whoever grasps the thought every vixen is a vixen and assents to it does so with justification.
Whoever understands the sentence 'Every vixen is a vixen'
and assents to it does so with justification.44

But such principles are false, since someone who assents because his father told him not to does so without even defeasible justification.
The obvious way to avoid such counterexamples and make the connection with conceptual or semantic competence is to qualify 'assents to it' by 'on the basis of that grasp [understanding].' But that returns us to the difficulties of KUt′ and KUl′.
44

The intended differences between assenting with justification in AJt′ and AJl′ and being justified in assenting in UJt and UJl are that (i) the former but not the latter entails assent and (ii) the assent in the former must be appropriately sensitive to the justification. The problem is general. The idea that, in the cases at issue, understanding is epistemologically sufficient for assent is the idea that assent on the basis of understanding has the desired positive epistemic status. But once we disambiguate 'understanding' between thick and thin candidates, we can see that the thin candidates are too thin to be bases for assent while the thick candidates are not purely semantic or conceptual. The attempt to base the epistemology of obvious truths such as (1) and (9) on preconditions for understanding them rests on a false conception of understanding.
Linguistic competence plays the same role when we know 'Vixens are female foxes' as when we know 'There is a vixen in the garden.'
It does not gain a role just because perception loses one. The contribution of linguistic competence amounts to this: you won’t get very far if you conduct your inquiry in a language you don’t understand.
Of course, that goes for any inquiry.
The following chapters develop a quite different account of the nature of at least some philosophical knowledge, on which linguistic and conceptual competence play only this background role, and philosophical beliefs are much less distinctive in nature than many philosophers like to think. We start with knowledge of metaphysical possibility and necessity.

5
Knowledge of
Metaphysical Modality

1
Philosophers characteristically ask not just whether things are some way but whether they could have been otherwise. What could have been otherwise is metaphysically contingent; what could not is metaphysically necessary. We have some knowledge of such matters. We know that Henry VIII could have had more than six wives, but that three plus three could not have been more than six. So there should be an epistemology of metaphysical modality.
The differences between metaphysical necessity, contingency, and impossibility are not mind-dependent, in any useful sense of that frustrating phrase. Thus they are not differences in actual or potential psychological, social, linguistic, or even epistemic status (Kripke (1980)
made the crucial distinctions). One shortcut to this conclusion uses the plausible idea that mathematical truth is mind-independent. Since mathematics is not contingent, the difference between truth and falsity in mathematics is also the difference between necessity and impossibility; consequently, the difference between necessity and impossibility is mind-independent. The difference between contingency and non-contingency is equally mind-independent; for if C is a mindindependently true or false mathematical conjecture, then one of C
and its negation conjoined with the proposition that Henry VIII had six wives forms a contingently true conjunction while the other forms an impossible conjunction, but which is which is mind-independent.
To emphasize the point, think of the mind-independently truth-valued conjecture as evidence-transcendent, absolutely undecidable, neither provable nor refutable by any means. Thus the epistemology of metaphysical modality is one of mind-independent truths. Nevertheless, doubts begin to arise. Although philosophers attribute metaphysical necessity to mathematical theorems, what matters mathematically is just their truth, not their metaphysical necessity: mathematics does not need the concept of metaphysical necessity.
Does metaphysical modality really matter outside philosophy? Even if physicists care about the physical necessity of the laws they conjecture, does it matter to physics whether physically necessary laws are also metaphysically necessary? In ordinary life, we care whether someone could have done otherwise, whether disaster could have been averted, but the kind of possibility at issue there is far more narrowly circumscribed than metaphysical possibility, by not prescinding from metaphysically contingent initial conditions. He could not have done otherwise because he was in chains, even though it was metaphysically contingent that he was in chains. Does
'could have been' ever express metaphysical possibility when used non-philosophically?
If thought about metaphysical modality is the exclusive preserve of philosophers, so is knowledge of metaphysical modality. The epistemology of metaphysical modality tends to be treated as an isolated case. For instance, much of the discussion concerns how far, if at all, conceivability is a guide to possibility, and inconceivability to impossibility (Gendler and Hawthorne (2002) has a sample of recent contributions to this debate). The impression is that, outside philosophy, the primary cognitive role of conceiving is propaedeutic.
Conceiving a hypothesis is getting it onto the table, putting it up for serious consideration as a candidate for truth. The inconceivable never even gets that far. Conceivability is certainly no good evidence for the restricted kinds of possibility we mainly care about in natural science or ordinary life. We easily conceive particles violating what are in fact physical laws, or the man without his chains. On this view, conceiving, outside philosophy, is no faculty for distinguishing truth from falsity in some domain, but rather a preliminary to any such faculty. Although there are truths and falsehoods about conceivability and inconceivability, they concern our mental capacities, whereas metaphysical modalities are supposed to be mind-independent. They are not contingent on mental capacities, because not contingent on anything (at least if we accept the principles of the modal logic S5, that the necessary is necessarily necessary and the possible necessarily possible). When philosophers present conceiving as a faculty for Knowledge of Metaphysical Modality

distinguishing between truth and falsity in the domain of metaphysical modality, that looks suspiciously like some sort of illicit projection or unacknowledged fiction: at best, attributions of metaphysical modality would lack the cognitive status traditionally ascribed to them (compare Blackburn (1987), Craig (1985), Wright (1989), and
Rosen (1990)). The apparent cognitive isolation of metaphysically modal thought makes such suspicions hard to allay. Presenting it as sui generis suggests that it can be surgically removed from our conceptual scheme without collateral damage. If it can, what good does it do us? In general, the postulation by philosophers of a special cognitive capacity exclusive to philosophical or quasi-philosophical thinking looks like a scam.
Humans evolved under no pressure to do philosophy. Presumably, survival and reproduction in the Stone Age depended little on philosophical prowess, dialectical skill being no more effective then than now as a seduction technique and in any case dependent on a hearer already equipped to recognize it. Any cognitive capacity we have for philosophy is a more or less accidental byproduct of other developments. Nor are psychological dispositions that are non-cognitive outside philosophy likely suddenly to become cognitive within it. We should expect the cognitive capacities used in philosophy to be cases of general cognitive capacities used in ordinary life, perhaps trained, developed, and systematically applied in various special ways, just as the cognitive capacities that we use in mathematics and natural science are rooted in more primitive cognitive capacities to perceive, imagine, correlate, reason, discuss . . . In particular, a plausible nonskeptical epistemology of metaphysical modality should subsume our capacity to discriminate metaphysical possibilities from metaphysical impossibilities under more general cognitive capacities used in ordinary life.
I will argue that the ordinary cognitive capacity to handle counterfactual conditionals carries with it the cognitive capacity to handle metaphysical modality. Section 2 illustrates with examples our cognitive use of counterfactual conditionals. Section 3 sketches an epistemology for such conditionals. Section 4 explains how they subsume metaphysical modality. Section 5 assesses the consequences for the distinction between a priori and a posteriori knowledge.
Section 6 discusses some objections. Section 7 briefly raises the relation between metaphysical possibility and the restricted kinds of

Knowledge of Metaphysical Modality possibility that seem more relevant to ordinary life. Philosophers’
ascriptions of metaphysical modality are far more deeply rooted in our ordinary cognitive practices than most skeptics about it realize.

2
Our overall capacity for somewhat reliable thought about counterfactual possibilities is hardly surprising, for we cannot know in advance exactly which possibilities are or will be actual. We need to make contingency plans. In practice, the only way for us to be cognitively equipped to deal with the actual is by being cognitively equipped to deal with a wide variety of contingencies, most of them counterfactual. Our present task is to understand some of the more specific cognitive value to us of thinking with those conditional constructions labeled 'counterfactual.'
We can usefully start with a well-known example which proves the term 'counterfactual conditional' misleading. As Alan Ross
Anderson pointed out (1951: 37), a doctor might say:
(1)

If Jones had taken arsenic, he would have shown just exactly those symptoms which he does in fact show.

Clearly, (1) can provide abductive evidence by inference to the best explanation for its antecedent (see Edgington (2003: 23–7) for more discussion):
(2)

Jones took arsenic.

If further tests subsequently verify (2), they confirm the doctor’s statement rather than in any way falsifying it or making it inappropriate.
If we still call subjunctive conditionals like (1) 'counterfactuals,'
the reason is not that they imply or presuppose the falsity of their antecedents. In what follows, we shall be just as concerned with conditional sentences such as (1) as with those whose premises are false, or believed to be so.
Of course, what (2) explains is not the trivial necessary truth that
Jones shows whatever symptoms he shows. What is contingent is that
Jones shows exactly those symptoms which he does in fact show – he Knowledge of Metaphysical Modality

could have shown other symptoms, or none – and, given (1), (2)
explains that contingent truth.
While (1) provides valuable empirical evidence, the corresponding indicative conditional does not (Stalnaker 1999: 71):
(1I)

If Jones took arsenic, he shows just exactly those symptoms which he does in fact show.

We can safely assent to (1I) without knowing what symptoms Jones shows, since it holds whatever they are. Informally, (1) is non-trivial because it depends on a comparison between independently specified terms, the symptoms Jones would have shown if he had taken arsenic and the symptoms he does in fact show; by contrast, (1I) is trivial because it involves only a comparison of his symptoms with themselves. Thus the process of evaluating the 'counterfactual' conditional requires something like two files, one for the actual situation, the other for the counterfactual situation, even if these situations turn out to coincide. No such cross-comparison of files is needed to evaluate the indicative conditional. Of course, when one evaluates an indicative conditional while disbelieving its antecedent, one must not confuse one’s file of beliefs with one’s file of judgments on the supposition of the antecedent, but that does not mean that crossreferencing from the latter file to the former can play the role it did in the counterfactual case. One logical manifestation of this difference is that any indicative conditional A
@A is a logical truth, where
@ is the 'actually' operator (@A is true at any given world just in case A is true at the actual world), whereas the counterfactual con@A is false if A is contingently false. For instance, I
ditional A
can trivially assert 'If the coin landed heads, it actually landed heads,' without checking how it landed, but 'If the coin had landed heads, it would have actually landed heads' is false if the coin actually landed tails, because it implies that if the coin could have landed heads, it actually did so (Williamson (2006a) has more discussion).
The sentence (1I) works differently from the non-trivial habitual:
(1H)

If Jones takes arsenic, he shows just exactly those symptoms which he does in fact show.

Knowledge of Metaphysical Modality The latter can be false when both (1) and (1I) are true, for example because Jones’s symptoms are not those he would normally show on arsenic poisoning but those he would show given that he had, unusually, been fasting for the previous 72 hours, a fact the doctor took into account. Since habituals in some sense characterize 'normal'
cases while counterfactual conditionals can depend on abnormal features of the current case, habituals are not in general adequate substitutes for counterfactual conditionals. Of course, the truth conditions of habituals themselves involve counterfactual cases.
Since (1) constitutes empirical evidence, its truth was not guaranteed in advance. If Jones had looked suitably different, the doctor would have had to assert the opposite counterfactual conditional:
(3) If Jones had taken arsenic, he would not have shown just exactly those symptoms which he does in fact show.
From (3) we can deduce the falsity of its antecedent. For modus ponens is generally agreed to be valid for counterfactual conditionals.
Thus (2) and (3) entail:
(4) Jones does not show just exactly those symptoms which he does in fact show.
Since (4) is obviously false, we can deny (2) given (3).
The indicative conditional corresponding to (3) is:
(3I) If Jones took arsenic, he does not show just exactly those symptoms which he does in fact show.
To assert (3I) is like saying 'If Jones took arsenic, pigs can fly.'
Although a very confident doctor might assert (3I), on the grounds that Jones certainly did not take arsenic, that certainty may in turn be based on confidence in (3), and therefore on the comparison of actual and counterfactual situations.
Could a Bayesian account dispense with the counterfactual conditionals in favor of conditional probabilities? Consider the simple case in which we completely trust the doctor who asserts (1). Before the doctor speaks, we are certain what symptoms Jones shows but Knowledge of Metaphysical Modality

agnostic over the characteristic symptoms of arsenic poisoning. We want to update our probability for his having taken arsenic on evidence from the doctor, in Bayesian terms by conditionalizing on it. The doctor cannot simply tell us what probability to assign, because we may have further relevant evidence unavailable to the doctor, for example about Jones’s character. We need the doctor to say something that we can use as evidence; (1) exactly fits the bill (of course, our evidence also includes the fact that the doctor asserted
(1), but in the circumstances we can treat (1) itself as the relevant part of our evidence). It may even do better than a non-modal generalization such as 'Jones showed exactly those symptoms which everyone who takes arsenic shows': for the symptoms may vary with bodily characteristics of the victim, and through long experience the doctor may be able to judge what symptoms Jones would have shown if he had taken arsenic without being able to articulate a suitable generalization. If he were to say 'Jones showed exactly those symptoms which everyone relevantly like him who takes arsenic shows,'
he might easily have to do so without knowing of any instance of this contextually restricted generalization other than the one at hand; in such cases belief in the restricted generalization is epistemically based on the counterfactual conditional, not vice versa. Any Bayesian account depends on an adequately varied stock of propositions to act as bearers of probability, as evidence or hypotheses. Sometimes that range has to include counterfactual conditionals.
We also use the notional distinction between actual and counterfactual situations to make evaluative comparisons:
(5) If Jones had not taken arsenic, he would have been in better shape than he now is.
Such counterfactual reflections facilitate learning from experience; one may decide never to take arsenic oneself. Formulating counterfactuals about past experience is empirically correlated with improved future performance in various tasks.1
Evidently, counterfactual conditionals give clues to causal connections. This point does not commit one to the ambitious program of
1

The large empirical literature on the affective role of counterfactuals and its relation to learning from experience includes Kahneman and Tversky (1982), Roese and
Olson (1993, 1995) and Byrne (2005). analyzing causality in terms of counterfactual conditionals (Lewis
(1973b), Collins, Hall, and Paul (2004)), or counterfactual conditionals in terms of causality (Jackson 1977). If the former program succeeds, all causal thinking is counterfactual thinking; if the latter succeeds, all counterfactual thinking is causal thinking. Either way, the overlap is so large that we cannot have one without much of the other. It may well be over-optimistic to expect either necessary and sufficient conditions for causal statements in counterfactual terms or necessary and sufficient conditions for counterfactual statements in causal terms. Even so, counterfactuals surely play a crucial role in our causal thinking (see Harris (2000: 118–39) and Byrne (2005:
100–28) for some empirical discussion). Only extreme skeptics deny the cognitive value of causal thought.
At a more theoretical level, claims of nomic necessity support counterfactual conditionals. If it is a law that property P implies property Q, then typically if something were to have P, it would have
Q. If we can falsify the counterfactual in a specific case, perhaps by using better-established laws, we thereby falsify that claim of lawhood.
We sometimes have enough evidence to establish what the result of an experiment would be without actually doing the experiment: that matters in a world of limited resources.
Counterfactual thought is deeply integrated into our empirical thought in general. Although that consideration will not deter the most dogged skeptics about our knowledge of counterfactuals, it indicates the difficulty of preventing such skepticism from generalizing implausibly far, since our beliefs about counterfactuals are so well-integrated into our general knowledge of our environment. I
proceed on the assumption that we have non-trivial knowledge of counterfactuals.

3
In discussing the epistemology of counterfactuals, I assume no particular theory of their compositional semantics. Although I sometimes use the Stalnaker-Lewis approach for purposes of illustration and vividness, I do not assume its correctness or that of any other specific semantic account of counterfactuals, within or without the framework of possible worlds. That evasion of semantic theory might seem Knowledge of Metaphysical Modality

dubious, since it is the semantic facts which determine what has to be known. However, we can go some way on the basis of our pretheoretical understanding of such conditionals in our native language. Moreover, the best developed formal semantic theories of counterfactuals use an apparatus of possible worlds or situations at best distantly related to our actual cognitive processing. While that does not refute such theories, which concern the truth conditions of counterfactuals, not how subjects attempt to find out whether those truth conditions obtain, it shows how indirect the relation between the semantics and the epistemology may be. When we come to finetune our epistemology of counterfactuals, we may need an articulated semantic theory, but at a first pass we can make do with some sketchy remarks about their epistemology while remaining as far as possible neutral over their deep semantic analysis. Although I formalize the
, I do counterfactual conditional with the usual sentence operator not assume that that exactly reflects the structure of the corresponding natural language sentences.2 As for the psychological study of the processes underlying our assessment of counterfactual conditionals, it remains in a surprisingly undeveloped state, as recent authors have complained (Evans and Over 2004: 113–31).
Start with an example. You are in the mountains. As the sun melts the ice, rocks embedded in it are loosened and crash down the slope.
You notice one rock slide into a bush. You wonder where it would have ended if the bush had not been there. A natural way to answer the question is by visualizing the rock sliding without the bush there, then bouncing down the slope into the lake at the bottom. Under suitable background conditions, you thereby come to know this counterfactual:
(6) If the bush had not been there, the rock would have ended in the lake.
You could test that judgment by physically removing the bush and experimenting with similar rocks, but you know (6) even without performing such experiments. Logically, the counterfactual about the
2
Lewis (1975) treats 'if' in some occurrences as a restrictor on quantifiers rather than a sentential connective. This approach was generalized to all occurrences of 'if'
in Kratzer (1986). past is independent of claims about future experiments (for a start, the slope is undergoing continual small changes).
Somehow, you came to know the counterfactual by using your imagination. That sounds puzzling if one conceives the imagination as unconstrained. You can imagine the rock rising vertically into the air, or looping the loop, or sticking like a limpet to the slope. What constrains imagining it one way rather than another?
You do not imagine it those other ways because your imaginative exercise is radically informed and disciplined by your perception of the rock and the slope and your sense of how nature works. The default for the imagination in its primary function may be to proceed as 'realistically' as it can, subject to whatever deviations the thinker imposes by brute force: here, the absence of the bush. Thus the imagination can in principle exploit all our background knowledge in evaluating counterfactuals. Of course, how to separate background knowledge from what must be imagined away in imagining the antecedent is Goodman’s old, deep problem of cotenability (1954). For example, why don’t we bring to bear our background knowledge that the rock did not go far, and imagine another obstacle to its fall? Difficult though the problem is, it should not make us lose sight of our considerable knowledge of counterfactuals: our procedures for evaluating them cannot be too wildly misleading.
Can the imaginative exercise be regimented as a piece of reasoning?
We can undoubtedly assess some counterfactuals by straightforward reasoning. For instance:
(7) If twelve people had come to the party, more than eleven people would have come to the party.
We can deduce the consequent 'More than eleven people came to the party' from the antecedent 'Twelve people came to the party,'
and assert (7) on that basis. Similarly, it may be suggested, we can assert (6) on the basis of inferring its consequent 'The rock ended in the lake' from the premise 'The bush was not there,' given auxiliary premises about the rock, the mountainside and the laws of nature.
At the level of formal logic, we have the corresponding plausible and widely accepted closure principle that, given a derivation of C from
C from
B1, . . . , Bn, we can derive the counterfactual conditional A
Bn; in other the counterfactual conditionals A
B1, . . . , A Knowledge of Metaphysical Modality

words, the counterfactual consequences of a supposition A are closed under logical consequence (Lewis (1986: 132) calls this 'Deduction within Conditionals'). With the uncontroversial reflexivity principle
A, it follows that, given a derivation of C from A alone, we can
A
derive A
C from the null set of premises.
We cannot automatically extend the closure rule to the case of auxiliary premises, for since we can derive an arbitrary conclusion C
from an arbitrary premise A with C as auxiliary premise, we could
C from the auxiliary premise C alone: but that then derive A
implies the invalid principle that any truth is a counterfactual consequence of any supposition whatsoever. The truth of 'Napoleon lost at Waterloo' does not guarantee the truth of 'If Grouchy had marched towards the sounds of gunfire, Napoleon would have lost at Waterloo.' Auxiliary premises cannot always be copied into the scope of counterfactual suppositions (this is the problem of cotenability again). Even with this caution, the treatment of the process by which we reach counterfactual judgments as inferential is problematic in several ways.
First, a technical problem: not every inference licenses us to assert the corresponding counterfactual, even when the inference is deductive and the auxiliary premises are selected appropriately. For the consequent of (1) is a logical truth (count it vacuously true if Jones shows no symptoms):
(8) Jones shows just exactly those symptoms which he does in fact show.
Thus (8) follows from any premises, including (2), the antecedent of
(1); but we cannot assert (1) on the basis of that trivial deduction alone, independently of which symptoms Jones does in fact show. Formally,
(A ≡ @A) may be although A ≡ @A is always a logical truth, B
false. Similarly, although @A is always a logical consequence of A,
A
@A may be false. This is related to Kaplan’s (1989) point that the rule of necessitation fails in languages with terms such as 'actually.' The logical truth of (8) does not guarantee the logical truth, or even truth, of (9):
(9) It is necessary that Jones shows just exactly those symptoms which he does in fact show. For it is contingent that Jones shows just exactly those symptoms which he does in fact show.3 But let us assume that this technical problem can be solved by a restriction on the type of reasoning from antecedent to consequent that can license a counterfactual, and on the closure principle above, like the restriction on the type of reasoning that licenses the necessitation of its conclusion.
A more serious problem is that the putative reasoner may lack general-purpose cognitive access to the auxiliary premises of the putative reasoning. In particular, the folk physics needed to derive the consequents of counterfactuals such as (6) from their antecedents may be stored in the form of some analogue mechanism, perhaps embodied in a connectionist network, which the subject cannot articulate in propositional form. Normally, a subject who uses negation and derives a conclusion from some premises can at least entertain the negation of a given premise, whether or not they are willing to assert it, perhaps on the basis of the other premises and the negation of the conclusion. Our reliance on folk physics does not enable us to formulate its negation. More generally, the supposed premises may not be stored in a form that permits the normal range of inferential interactions with other beliefs, even at an unconscious level. This strains the analogy with explicit reasoning.
The third problem is epistemological. Normally, someone who believes a conclusion on the sole basis of inference from some premises knows the conclusion only if they know the premises. This principle must be applied with care, for often a thinker is aware of several inferential routes from different sets of premises to the same conclusion. For example, you believe that a and b are F; you deduce that something is F. If you know that a is F, you may thereby come to know that something is F, even if your belief that b is F is false, and so not knowledge. Similarly, you may believe more premises than you need to draw an inductive conclusion. The principle applies only to essential premises, those that figure in all the inferences on which the relevant belief in the conclusion is based. However, folk physics is an essential standing background premise of the supposed inferences The phrase 'does in fact show' is read throughout as inside the scope of the counterfactual conditional or modal operator, but as rigid, like 'actually shows.' See
Williamson (2006a) for discussion. Knowledge of Metaphysical Modality

from antecedents to consequents of counterfactuals like (6), as usually conceived, so the epistemological maxim applies. Folk physics in this sense is a theory whose content includes the general principles by which expectations of motion, constancy, and the like are formed online in real time; it is no mere collection of memories of particular past incidents. But then presumably it is strictly speaking false: although many of its predictions are useful approximations, they are inaccurate in some circumstances; knowledge of the true laws of motion is not already wired into our brains, otherwise physics could be reduced to psychology. Since folk physics is false, it is not known.
But the conclusion that no belief formed on the basis of folk physics constitutes knowledge is wildly skeptical. For folk physics is reliable enough in many circumstances to be used in the acquisition of knowledge, for example that the cricket ball will land in that field. Thus we should not conceive folk physics as a premise of that conclusion.
Nor should we conceive some local fragment of folk physics as the premise. For it would be quite unmotivated to take an inferential approach overall while refusing to treat this local fragment as itself derived from the general theory of folk physics. We should conceive folk physics as a locally but not globally reliable method of belief formation, not as a premise.
If folk theories are methods of belief formation rather than specific beliefs, can they be treated as patterns of inference, for example from beliefs about the present to beliefs about the future? Represented as a universal generalization, a non-deductive pattern of inference such as abduction is represented as a falsehood, for the relevantly best explanations are not always correct. Nevertheless, we can acquire knowledge abductively because we do not rely on every abduction in relying on one; we sometimes rely on a locally truth-preserving abduction, even though abduction is not globally truth-preserving. The trouble with replacing a pattern of inference by a universal generalization is that it has us rely on all instances of the pattern simultaneously, by relying on the generalization. Even if the universal generalization is replaced by a statement of general tendencies, what we are relying on in a particular case is still inappropriately globalized. Epistemologically, folk 'theories' seem to function more like patterns of inference than like general premises. That conception also solves the earlier problem about the inapplicability of logical operators to folk 'theories,' since patterns of inference cannot themselves be negated or made the antecedents of conditionals (although claims of their validity can).
Once such a liberal conception of patterns of inference is allowed, calling a process of belief formation 'inferential' is no longer very informative. Just about any process with a set of beliefs (or suppositions) as input and an expanded set of beliefs (or suppositions) as output counts as 'inferential.' Can we say something more informative about the imaginative exercises by which we judge counterfactuals like (6), whether or not we count them as inferential?
An attractive suggestion is that some kind of simulation is involved: the difficulty is to explain what that means. It is just a hint of an answer to say that in simulation cognitive faculties are run offline.
The cognitive faculties that would be run online to evaluate A and B
as free-standing sentences are run offline in the evaluation of the
B.4 This suggests that the cognition counterfactual conditional A
has a roughly compositional structure. Our capacity to handle
A
B embeds our capacities to handle A and B separately, and our capacity to handle the counterfactual conditional operator involves a general capacity to go from capacities to handle the antecedent and the consequent separately to a capacity to handle the whole conditional. Here the capacity to handle an expression comprises more than mere linguistic understanding of it, since it involves ways of assessing its application that are not built into its meaning. But it virtually never involves a decision procedure that enables us always to determine the truth-values of every sentence in which the expression principally occurs, since we lack such decision procedures. Of course, we can sometimes take shortcuts in evaluating counterfactual conditionals.
For instance, we can know that A
A is true even if we have no idea how to determine whether A is true. Nevertheless, the compositional structure just described seems more typical.
How do we advance from capacities to handle the antecedent and the consequent separately to a capacity to handle the whole conditional? 'Offline' suggests that the most direct links with perception have been cut, but that vague negative point does not take us far.
Matters become more complicated if A or B itself contains a counterfactual condition, as in 'If she had murdered the man who would have inherited her money if she had died, she would have been sentenced to life imprisonment if she had been convicted,' but the underlying principles are the same. Perceptual input is crucial to the evaluation of counterfactuals such as (1) and (6).
The best developed simulation theories concern our ability to simulate the mental processes of other agents (or ourselves in other circumstances), putting ourselves in their shoes, as if thinking and deciding on the basis of their beliefs and desires (see for example
Davies and Stone (1995), Nichols and Stich (2003)). Such cognitive processes may well be relevant to the evaluation of counterfactuals about agents. Moreover, they would involve just the sort of constrained use of the imagination indicated above. How would Mary react if you asked to borrow her car? You could imagine her immediately shooting you, or making you her heir; you could even imagine reacting like that from her point of view, by imagining having sufficiently bizarre beliefs and desires. But you do not. Doing so would not help you determine how she really would react. Presumably, what you do is to hold fixed her actual beliefs and desires (as you take them to be just before the request); you can then imagine the request from her point of view, and think through the scenario from there.
Just as with the falling rock, the imaginative exercise is richly informed and disciplined by your sense of what she is like.
How could mental simulation help us evaluate a counterfactual such as (6), which does not concern an agent? Even if you somehow put yourself in the rock’s shoes, imagining first-personally being that shape, size, and hardness and bouncing down that slope, you would not be simulating the rock’s reasoning and decision-making. Thinking of the rock as an agent is no help in determining its counterfactual trajectory. A more natural way to answer the question is by imagining third-personally the rock falling as it would visually appear from your actual present spatial position; you thereby avoid the complex process of adjusting your current visual perspective to the viewpoint of the rock. Is that to simulate the mental states of an observer watching the rock fall from your present position?5 By itself, that suggestion explains little. For how do we know what to simulate the observer seeing next?
That question is not unanswerable. For we have various propensities to form expectations about what happens next: for example, to
5

See Goldman (1992: 24), discussed by Nichols, Stich, Leslie, and Klein (1996:
53–9).

Knowledge of Metaphysical Modality project the trajectories of nearby moving bodies into the immediate future (otherwise we could not catch balls). Perhaps we simulate the initial movement of the rock in the absence of the bush, form an expectation as to where it goes next, feed the expected movement back into the simulation as seen by the observer, form a further expectation as to its subsequent movement, feed that back into the simulation, and so on. If our expectations in such matters are approximately correct in a range of ordinary cases, such a process is cognitively worthwhile. The very natural laws and causal tendencies our expectations roughly track also help to determine which counterfactual conditionals really hold. Thus some reliability in the assessment of counterfactuals is achieved.
However, talk of simulating the mental states of an observer may suggest that the presence of the observer is part of the content of the simulation. That does not fit our evaluation of counterfactuals.
Consider:
(10)

If there had been a tree on this spot a million years ago, nobody would have known.

Even if we visually imagine a tree on this spot a million years ago, we do not automatically reject (10) because we envisage an observer of the tree. We may imagine the tree as having a certain visual appearance from a certain viewpoint, but that is not to say that we imagine it as appearing to someone at that viewpoint. For example, if we imagine the sun as shining from behind that viewpoint, by imagining the tree’s shadow stretching back from the tree, we are not obliged to imagine either the observer’s shadow stretching towards the tree or the observer as perfectly transparent.6 Nor, when we consider (10),
6

The question is of course related to Berkeley’s claim that we cannot imagine an unseen object. For discussion see Williams (1966), Peacocke (1985) and Currie
(1995b: 36–7). Gaut (2006: 116–21) describes the role of art in facilitating the evaluation of counterfactuals by means of the imagination. He disavows commitment to the view, which he credits to Currie (1995a) (ch. 5), that 'imagination is a kind of
‘offline’ running of cognitive processes, and that this is a source of knowledge of psychological states,' appealing instead to the tradition of Vico and Weber, on which the relevant role of imagination is in verstehen, in understanding oneself and others
(Gaut 2006: 121). However, it is doubtful that this tradition can (or wants to) explain knowledge of counterfactuals that do not concern mental states. Knowledge of Metaphysical Modality

are we asking whether if we had believed that there was a tree on this spot a million years ago, we would have believed that nobody knew.7 It is better not to regard the content of the simulation as referring to anything specifically mental at all. It is just that visual imagining reuses offline some of the very same cognitive resources that visual perceiving uses online.
Of course, for many counterfactuals the relevant expectations are not hardwired into us in the way that those concerning the trajectories of fast-moving objects around us may need to be. Our knowledge that if a British general election had been called in 1948 the Communists would not have won may depend on an offline use of our capacity to predict political events. Still, where our more sophisticated capacities to predict the future are reliable, so should be corresponding counterfactual judgments. In these cases too, simulating the mental states of an imaginary observer seems unnecessary.
The offline use of expectation-forming capacities to judge counterfactuals corresponds to the widespread picture of the semantic evaluation of those conditionals as 'rolling back' history to shortly before the time of the antecedent, modifying its course by stipulating the truth of the antecedent and then rolling history forward again according to patterns of development as close as possible to the normal ones to test the truth of the consequent (compare Lewis (1979)).
The use of expectation-forming capacities may in effect impose a partial solution to Goodman’s problem of cotenability, since they do not operate on information about what happened after the time treated as present. In this respect indicative conditionals are evaluated differently: if I had climbed a mountain yesterday I would remember A similar problem arises for what is sometimes called the Ramsey Test for conditionals, on which one simulates belief in the antecedent and asks whether one then believes the consequent. Goldman (1992: 24) writes 'When considering the truth value of ‘If X were the case, then Y would obtain,’ a reasoner feigns a belief in X
and reasons about Y under that pretence.' What Ramsey himself says is that when people 'are fixing their degrees of belief in q given p' they 'are adding p hypothetically to their stock of knowledge and arguing on that basis about q' (1978: 143), but he specifically warns that 'the degree of belief in q given p' does not mean the degree of belief 'which the subject would have in q if he knew p, or that which he ought to have' (1978: 82; variables interchanged). Of course, conditional probabilities bear more directly on indicative than on subjunctive conditionals. it today, but if I did climb a mountain yesterday I do not remember it today. The known fact that I do not remember climbing a mountain yesterday is retained under the indicative but not the counterfactual supposition.
Our offline use of expectation-forming capacities to unroll a counterfactual history from the imagined initial conditions does not explain why we imagine the initial conditions in one way rather than another – for instance, why we do not imagine a wall in place of the bush. Very often, no alternative occurs to us, but that does not mean that the way we go adds nothing to the given antecedent. We seem to have a prereflective tendency to minimum alteration in imagining counterfactual alternatives to actuality, reminiscent of the role that similarity between possible worlds plays in the Lewis-Stalnaker semantics.
Of course, not all counterfactual conditionals can be evaluated by the rolling back method, since the antecedent need not concern a particular time: in evaluating the claim that space-time has ten dimensions, a scientist can sensibly ask whether if it were true the actually observed phenomena would have occurred. Explicit reasoning may play a much larger role in the evaluation of such conditionals.
Reasoning and prediction do not exhaust our capacity to evaluate counterfactuals. If twelve people had come to the party, would it have been a large party? To answer, one does not imagine a party of twelve people and then predict what would happen next. The question is whether twelve people would have constituted a large party, not whether they would have caused one. Nor is the process of answering best conceived as purely inferential, if one has no special antecedent beliefs as to how many people constitute a large party, any more than the judgment whether the party is large is purely inferential when made at the party. Rather, in both cases one must make a new judgment, even though it is informed by what one already believes or imagines about the party. To call the new judgment 'inferential'
simply because it is not made independently of all the thinker’s prior beliefs or suppositions is to stretch the term 'inferential' beyond its useful span. At any rate, the judgment cannot be derived from the prior beliefs or suppositions purely by the application of general rules of inference. For example, even if you have the prior belief that a party is large if and only if it is larger than the average size of a party, in order to apply it to the case at hand you also need to have a belief Knowledge of Metaphysical Modality

as to what the average size of a party is; if you have no prior belief as to that, and must form one by inference, an implausible regress threatens, for you do not have the statistics of parties in your head.
Similarly, if you try to judge whether this party is large by projecting inductively from previous judgments as to whether parties were large, that only pushes the question back to how those previous judgments were made.
In general, our capacity to evaluate counterfactuals recruits all our cognitive capacities to evaluate sentences. A quick argument for this uses the assumption that a counterfactual with a true antecedent has the same truth-value as its consequent, for then any sentence A is
A, where T is a trivial tautology; so any logically equivalent to T
non-logical cognitive work needed to evaluate A is also needed to evaluate the counterfactual T
A.8 For if we could evaluate that counterfactual without doing the non-logical work, we could also evaluate A without doing it, by first evaluating the counterfactual, then deriving its equivalence to A and finally extending the evaluation of the former to the latter. Any logical work needed to evaluate A
will also be needed to evaluate T
A when T is chosen to be irrelevant to A.
There is no uniform epistemology of counterfactual conditionals.
In particular, imaginative simulation is neither always necessary nor always sufficient for their evaluation, even when they can be evaluated. Nevertheless, it is the most distinctive cognitive feature of the process of evaluating them, because it is so much more useful for counterfactuals than for most non-counterfactual contents, whereas reasoning, perception, and testimony are not generally more useful for counterfactuals than for non-counterfactual contents.
We can still schematize a typical overall process of evaluating a counterfactual conditional thus: one supposes the antecedent and Lewis (1986: 26–31) defends the assumption; Nozick (1981: 176) rejects it to make the fourth condition in his analysis of knowledge non-trivial. Bennett (2003:
239–40) also rejects it. The point can be made independently of that assumption, using the rigidifying 'actually' operator @. For @A entails B
@A for any B and therefore T
@A in particular; conversely, T
@A entails @A by modus ponens.
Since A is logically equivalent to @A, it is logically equivalent to T
@A. Thus any cognitive capacities needed to assess A will also be needed to assess the more complex T
@A (modulo those needed to recognize the equivalence). develops the supposition, adding further judgments within the supposition by reasoning, offline predictive mechanisms, and other offline judgments. The imagining may but need not be perceptual imagining.
All of one’s background knowledge and beliefs are available from within the scope of the supposition as a description of one’s actual circumstances for the purposes of comparison with the counterfactual
@B for any A; in circumstances (if we know B, we can infer A
this respect the development differs from that of the antecedent of an indicative conditional). Some but not all of one’s background knowledge and beliefs are also available within the scope of the supposition as a description of the counterfactual circumstances, according to complex criteria (the problem of cotenability). To a first approximation: one asserts the counterfactual conditional if and only if the development eventually leads one to add the consequent.
An over-simplification in that account is that one develops the initial supposition only once. In fact, if one finds various different ways of imagining the antecedent equally good, one may try developing several of them, to test whether they all yield the consequent. For example, if in considering (10) one initially imagines a palm tree, one does not immediately judge that if there had been a tree on this spot a million years ago it would have been a palm tree, because one knows that one can equally easily imagine a fir tree. One repeats the thought experiment. Robustness in the result under such minor perturbations supports a higher degree of confidence.
What happens if the counterfactual development of the antecedent
A does not robustly yield the consequent C? We do not always deny
C, for several reasons. First, if C has not emerged after a given
A
period of development the question remains whether it will emerge in the course of further development, for lines of reasoning can be continued indefinitely from any given premise. To reach a negative conclusion, one must in effect judge that if the consequent were ever going to emerge it would have done so by now. For example, one may have been smoothly fleshing out a scenario incompatible with the consequent with no hint of difficulty. Second, even if one is confident that C will not robustly emerge from the development, one may suspect that the reason is one’s ignorance of relevant background conditions rather than the lack of a counterfactual connection between
A and C ('If I were to follow that path, it would lead me out of the forest'). Thus one may remain agnostic over A
C. Knowledge of Metaphysical Modality

The case for denying A
C is usually strongest when the counterfactual development of A yields C. Then one asserts the opposite counterfactual, A
C. The default is to deny a counterfactual if one asserts the opposite counterfactual, moving from A
C to
(A
C). The move is defeasible; sometimes one must accept opposite counterfactuals together. For example, deductive closure generates both (B & B)
B and (B & B)
B. Normally, if the counterfactual development of A robustly yields C and robustly
C, but even this connection fails to yield C then one denies A
is defeasible, since one may still suspect that C (as well as C)
would emerge given more complex reasoning or further background information.
Sometimes a counterfactual antecedent is manifestly neutral between contradictory consequents: consider 'If the coin had been tossed it would have come up heads' and 'If the coin had been tossed it would have come up tails.' In such cases one will clearly never be in a position to assert one conditional, and thus will never be in a position to use it as a basis for denying the opposite conditional.
Whether the symmetry permits one to deny both conditionals is controversial.9
The epistemological asymmetry between asserting and denying a counterfactual conditional resembles an epistemological asymmetry in practice between asserting and denying many existential claims. If
I find snakes in Iceland, without too much fuss I can assert that there are snakes in Iceland. If I fail to find snakes in Iceland, I cannot deny that there are snakes in Iceland without some implicit or explicit assessment of the thoroughness of my search: if there were snakes in
Iceland, would I have found some by now? But we are capable of making such assessments, and sometimes are in a position to deny such existential claims. Similarly, if I find a counterfactual connection
On the Lewis semantics, both A
C and A
C are false when there is a tie for the closest A worlds to the actual world and some but not all of the joint winners are C worlds. Thus we may truly assert both (A
C) and (A
C). On the
Stalnaker semantics, 'Conditional Excluded Middle' (A
C) ∨ (A
C) is a logical law, because a unique A world must be selected, but sometimes neither disjunct is determinately true, because it is indeterminate which A world is selected. In such cases, neither disjunct is determinately false, so we cannot truly assert either
(A
C) or (A
C); we must simply reject both A
C and A
C as not definitely true.
9 between A and C (my counterfactual development of A robustly
C. If I fail to find yields C) without too much fuss I can assert A
a counterfactual connection between A and C (my counterfactual development of A does not robustly yield C), I cannot deny A
C
without some implicit or explicit assessment of the thoroughness of my search: if there were a counterfactual connection, would I
have found it by now? But we are capable of making such assessments, and sometimes are in a position to deny counterfactual conditionals.
For both assertions and denials of counterfactuals, the reliability of our cognitive faculties in their online applications across a wide range of possible circumstances induces reliability in their offline applications too. Offline reliability is achieved even with respect to counterfactual circumstances in which we would not be around to apply those faculties ('If there had been no sentient beings . . .'), for online reliability is often best achieved by tracking robust underlying trends (in nature, in logic, . . .) that hold irrespective of the presence of an observer.
The preceding remarks are the merest sketch of an epistemology of counterfactuals. Nevertheless, they will serve for purposes of orientation in what follows.
Despite its discipline, our imaginative evaluation of counterfactual conditionals is manifestly fallible. We can easily misjudge their truthvalues, through background ignorance or error, and distortions of judgment. But such fallibility is the common lot of human cognition.
Our use of the imagination in evaluating counterfactuals is moderately reliable and practically indispensable. Rather than cave in to skepticism, we should admit that our methods sometimes yield knowledge of counterfactuals.

4
How does the epistemology of counterfactual conditionals bear on the epistemology of metaphysical modality? We can approach this question by formulating two plausible constraints on the relation between counterfactual conditionals and metaphysical modalities.
Henceforth, 'necessary' and 'possible' will be used for the metaphysical modalities unless otherwise stated. Knowledge of Metaphysical Modality

First, the conditional:

strict

NECESSITY

(A

conditional

implies

B)

B)

(A

the

counterfactual

Suppose that A could not have held without B holding too; then if
A had held, B would also have held. In terms of possible worlds semantics for these operators along the lines of Lewis (1973) or
Stalnaker (1968): if all A worlds are B worlds, then any closest A
worlds are B worlds. More precisely, if all A worlds are B worlds, then either there are no A worlds or there is an A world such that any
A world at least as close as it is to the actual world is a B world.
Second, the counterfactual conditional transmits possibility:
B)

(A

POSSIBILITY

( A

B)

Suppose that if A had held, B would also have held; then if A could have held, B could also have held. In terms of worlds: if any closest
A worlds are B worlds, and there are A worlds, then there are also
B worlds. More precisely, if either there are no A worlds or there is an A world such that any A world at least as close as it is to the actual world is a B world, then if there is an A world there is also a
B world.
Together, NECESSITY and POSSIBILITY sandwich the counterfactual conditional between two modal conditions. But they do not squeeze it very tight, for A
B is much weaker than (A
B): although the latter entails the former in any normal modal logic, the former is true and the latter false whenever B is possible without being a necessary consequence of A, for example when A and B are modally independent.
Although NECESSITY and POSSIBILITY determine no necessary and sufficient condition for the counterfactual conditional in terms of necessity and possibility, they yield necessary and sufficient conditions for necessity and possibility in terms of the counterfactual conditional.
We argue thus. Let be a contradiction. As a special case of
NECESSITY:
(11)

( A

)

( A

) By elementary modal logic (specifically, the weakest normal modal logic K, used throughout), since a truth-functional consequence of something necessary is itself necessary:
A

(12)

( A

)

From (11) and (12) by transitivity of the material conditional:
A

(13)

( A

)

Similarly, as a special case of POSSIBILITY:
(14)

( A

)

(

A

)

By elementary modal logic, since the possibility of a contradiction is itself inconsistent, and necessity is the dual of possibility (being necessary is equivalent to having an impossible negation):
(15)

(

A

A

)

From (14) and (15) by transitivity:
(16) ( A

)

A

Putting (13) and (16) together:
(17)

A≡( A

)

The necessary is that whose negation counterfactually implies a contradiction. Since possibility is the dual of necessity (being possible is equivalent to having an unnecessary negation), (17) yields a corresponding necessary and sufficient condition for possibility, once a double negation in the antecedent of the counterfactual has been eliminated.
(18)

A ≡ (A

) between necessity and possibility lies simply in the scope of negation.
Without assuming a specific framework for the semantics of counterfactuals (in particular, that of possible worlds), we can give a simple semantic rationale for (17) and (18), based on the idea of vacuous truth. That some true counterfactuals have impossible anteA would fail when A was imposcedents is clear, for otherwise A
sible. Make two widely accepted assumptions about the distinction
C is vacuously between vacuous and non-vacuous truth: (a) B
true if and only if B is impossible (this is almost a definition of 'vacuC is non-vacuously true only ously' for counterfactuals); (b) B
if C is possible. The truth of (17) and (18) follows, given normal modal reasoning. If A is true, then A is impossible, so by (a)
is vacuously true; conversely, if A
is true, then by
A
(b) it is vacuously true, so by (a) A is impossible, so A is true.
Similarly, if A is true, then A is not impossible, so by (a) A
is not vacuously true, and by (b) not non-vacuously true, so
) is true; if A is not true, then A is impossible, so by (a)
(A
is vacuously true, so (A
) is not true.
A
Given that the equivalences (17) and (18) and their necessitations are logically true, metaphysically modal thinking is logically equivalent to a special case of counterfactual thinking. Thus, modulo the implicit recognition of this equivalence, the epistemology of metaphysically modal thinking is tantamount to a special case of the epistemology of counterfactual thinking. Whoever has what it takes to understand the counterfactual conditional and the elementary logical auxiliaries and has what it takes to understand possibility and necessity operators.
The definability of necessity and possibility in terms of counterfactual conditionals was recognized long ago. It is easy to show from the in Section 3 that A
is closure and reflexivity principles for
A. Thus (17) and (18) generate two logically equivalent to A
new equivalences:
(19)
(20)

A≡ ( A
A ≡ (A

A)
A)

The necessary is that which is counterfactually implied by its own negation; the possible is that which does not counterfactually imply

Knowledge of Metaphysical Modality its own negation. Stalnaker (1968) used (19) and (20) to define necessity and possibility, although his reading of the conditional (with a different notation) was not exclusively counterfactual. Lewis (1973a:
25) used (17) and (18) themselves to define necessity and possibility in terms of the counterfactual conditional. However, such definitions seem to have been treated as convenient notational economies, their potential philosophical significance unnoticed (Hill (2006) is a recent exception).
If we permit ourselves to quantify into sentence position ('propositional quantification'), we can formulate another pair of variants on (17) and (18) that may improve our feel for what is going on.10
On elementary assumptions about the logic of such quantifiers and
A is provably equivalent of the counterfactual conditional, A
to ᭙p (p
A): something is counterfactually implied by its negation if and only if it is counterfactually implied by everything. Thus (19)
and (20) generate these equivalences too:
(21)
(22)

A ≡ ᭙p (p
A ≡ p (p

A)
A)

According to (21), something is necessary if and only if whatever were the case, it would still be the case (see also Lewis 1986: 23).
That is a natural way of explaining informally what metaphysically necessity is. According to (22), something is possible if and only if it is not such that it would fail in every eventuality.
We can plausibly treat NECESSITY and POSSIBILITY as axiom schemas of a joint logic of modality and counterfactuals, susceptible in the usual way to necessitation and the analogous closure principles for counterfactuals. Then (17)–(22) will be theorems, and susceptible to the same rules. Consequently, the result of substituting the lefthand for the right-hand side of any of these biconditionals or vice versa anywhere in any formula built up out of atomic sentences using
10

This quantification into sentence position need not be understood substitutionally.
In purely modal contexts it can be modeled as quantification over all sets of possible worlds, even if not all of them are intensions of sentences that form the supposed substitution class, although this modeling presumably fails for hyperintensional contexts such as epistemic ones. A more faithful semantics for it might use nonsubstitutional quantification into sentence position in the metalanguage. Such subtleties are inessential for present purposes. Knowledge of Metaphysical Modality

the modal operators, the counterfactual conditional, and truthfunctors will be logically equivalent to the original (see also Appendix
1; the restrictions on necessitation and the closure principles discussed there are not relevant here).
Since the right-hand sides of (17), (19), and (21) are not strictly synonymous with each other, given the differences in their semantic structure, they are not all strictly synonymous with A. Similarly, since the right-hand sides of (18), (20), and (22) are not strictly synonymous with each other, they are not all strictly synonymous with
A. Indeed, we have no sufficient reason to regard any of the equivalences as strict synonymies. That detracts little from their philosophical significance, for failure of strict synonymy does not imply failure of logical equivalence. The main philosophical concerns about possibility and necessity apply equally to anything logically equivalent to possibility or necessity. A non-modal analogy: A is logically equivalent to A
, but presumably they are not strictly synonymous; nevertheless, once we have established that a creature can handle and , we have established that it can handle something logically equivalent to negation, which answers the most interesting questions about its ability to handle negation. We should find the mutual equivalence of (17), (19), and (21), and of (18), (20), and (22)
reassuring, for it shows the robustness of the modal notions definable from the counterfactual conditional, somewhat as the equivalence of the various proposed definitions of 'computable function' showed the robustness of that notion.
If we treat (17) and (18) like definitions of and for logical purposes, and assume some elementary principles of the logic of counterfactuals, then we can establish the main principles of elementary modal logic for and . For example, we can show that what follows from necessary premises is itself necessary. Given that counterfactual conditionals obey modus ponens (or even weaker assumptions), we can show that what is necessary is the case. We can also check that the principles NECESSITY and POSSIBILITY, which we used to establish (17) and (18), do indeed hold under the latter characterizations of necessity and possibility. Under much stronger assumptions about the logic of the counterfactual conditional, we can also establish much stronger principles of modal logic, such as the S5
principle that what is possible is necessarily possible. Such connections extend to quantified modal logic. The logic of counterfactual conditionals smoothly generates the logic of the modal operators
(Appendix 1 gives technical details).
In particular, the proposed conception of modality makes quantification into the scope of modal operators tantamount to a special case of quantification into counterfactual contexts, as in (23)
and (24):
(23)
(24)

Everyone who would have benefited if the measure had passed voted for it.
Where would the rock have landed if the bush had not been there?

Thus challenges to the intelligibility of claims of de re necessity are tantamount to challenges to the intelligibility of counterfactuals such as (23) and (24). But (23) and (24) are evidently intelligible.
Other properties of metaphysical modality follow from corresponding properties of counterfactual conditionals. For instance, if this is identical with that then what would have been the case of this in given counterfactual circumstances is what would have been the case of that in those circumstances; thus x = y and the triviality x ≠ y yield x ≠ y x ≠ x; hence x = y entails x ≠ y and x≠ y x ≠ x; since x ≠ x entails , x = y entails x ≠ y x ≠ y, which is a form of the law of the necessity of therefore identity.11 Again, consider the Kripkean conception of the essentiality of origin, on which, very roughly, an object could not have originated otherwise than it actually did. It follows from the plausible assumption that if something in any circumstance had originated otherwise than a given object actually did, it would not have been that very object. By contrast, objects could easily have ended otherwise than they actually did. That temporal asymmetry seems to be related to more general temporal asymmetries in the evaluation of counterfactual conditionals by the 'rolling back' procedure mentioned above, which involves holding fixed an initial segment of the past but not a final segment of the future.
11

In his 1961 dissertation, Dagfin Føllesdal was already clear that problems of quantifying in and substitution of coreferential terms arise for counterfactual conditionals just as they do for modal operators, although the direct connection he envisaged was through an analysis of counterfactuals in terms of natural necessity (2004:
14, 99). Knowledge of Metaphysical Modality

Given (17) and (18), we should expect the epistemology of metaphysical modality to be a special case of the epistemology of counterfactuals. Despite the non-synonymy of the two sides, our cognitive capacity to evaluate the counterfactual conditionals gives us exactly what we need to evaluate the corresponding modal claims too. The idea that nevertheless we evaluate them by some quite different means is highly fanciful, since it indicates a bizarre lack of cognitive economy and has no plausible explanation of where the alternative cognitive resources might come from. Furthermore, as we shall see, characteristic features of the epistemology of modality are well explained by subsumption under corresponding features of the epistemology of counterfactuals. Far from being sui generis, the capacity to handle metaphysical modality is an 'accidental' byproduct of the cognitive mechanisms that provide our capacity to handle counterfactual conditionals. Since our capacity for modal thinking cannot be isolated from our capacity for ordinary thinking about the natural world, which involves counterfactual thinking, skeptics about metaphysical modality cannot excise it from our conceptual scheme without loss to ordinary thought about the natural world, for the former is implicit in the latter.
A useful comparison is with the relation between logical consequence and logical truth. Consider some agents who reason in simple ways about themselves and their environment, perhaps using rules of inference formalizable in a Gentzen-style natural deduction calculus, perhaps in some less sophisticated way. The practical value of their reasoning skill is that they can move from ordinary empirical premises to ordinary empirical conclusions in ways that always preserve truth, thereby extending their knowledge of mundane matters (see
Schechter 2006 for discussion). In doing so, they need never use logically true sentences. Nevertheless, the cognitive capacity that enables them to make these transitions between empirical sentences also enables them, as a special case, an 'accidental' byproduct, to deduce logical truths from the null set of premises. Highly artificial moves would be needed to block these bonus deductions; such ad hoc restrictions would come at the price of extra computational complexity for no practical gain. Likewise at the semantic level: the simplest compositional semantics that enables us to negate and conjoin empirical sentences also enables us to formulate logical truths and false- hoods, even if we have hitherto lacked any interest in doing so. By good fortune, everything is already in place for the logician to evaluate logical truths and falsehoods (at least in first-order logic, since it is complete). The philosopher’s position with respect to metaphysical modality is not utterly different.
Discussions of the epistemology of modality often focus on imaginability or conceivability as a test of possibility while ignoring the role of the imagination in the assessment of mundane counterfactuals.
In doing so, they omit the appropriate context for understanding the relation between modality and the imagination. For instance, scorn is easily poured on imagination as a test of possibility: it is imaginable but not possible that water does not contain oxygen, except in artificial senses of 'imaginable' that come apart from possibility in other ways, and so on. Imagination can be made to look cognitively worthless. Once we recall its fallible but vital role in evaluating counterfactual conditionals, we should be more open to the idea that it plays such a role in evaluating claims of possibility and necessity. At the very least, we cannot expect an adequate account of the role of imagination in the epistemology of modality if we lack an adequate account of its role in the epistemology of counterfactuals.
B when our
On the rough sketch in Section 3, we assert A
counterfactual development of the supposition A robustly yields B; we deny A
B when our counterfactual development of A does not robustly yield B (and we do not attribute the failure to a defect in our search). Correspondingly, by (17), we assert A when our counterfactual development of the supposition A robustly yields a contradiction; we deny A when our counterfactual development of
A does not robustly yield a contradiction (and we do not attribute the failure to a defect in our search). Similarly, by (18), we assert A
when our counterfactual development of the supposition A does not robustly yield a contradiction (and we do not attribute the failure to a defect in our search); we deny A when our counterfactual development of A robustly yields a contradiction. Thus our fallible imaginative evaluation of counterfactuals has a conceivability test for possibility and an inconceivability test for impossibility built in as fallible special cases.
Such conceivability and inconceivability will be subject to the same constraints, whatever they are, as counterfactual conditionals Knowledge of Metaphysical Modality

in general, concerning which parts of our background information are held fixed. If we know enough chemistry, our counterfactual development of the supposition that gold is not the element with atomic number 79 will generate a contradiction. The reason is not simply that we know that gold is the element with atomic number 79, for we can and must vary some items of our knowledge under counterfactual suppositions. Rather, part of the general way we develop counterfactual suppositions is to hold such constitutive facts fixed.
A nuanced account of our handling of counterfactuals is likely to predict that we are more reliable in evaluating some kinds than others. For example, we may well be more reliable in evaluating counterfactuals whose antecedents involve small departures from the actual world than in evaluating those whose antecedents involve much larger departures. We may be correspondingly more reliable in evaluating the possibility of everyday scenarios than of 'far-out'
ones, and extra caution may be called for in the latter case. At the limit, actuality is often the best argument for possibility. But current philosophical practice already shows some sensitivity to such considerations. Many philosophers are more confident in their judgments about more or less realistic thought experiments in epistemology and moral philosophy than about more radically strange ones in metaphysics. More explicit consideration of the link between modal thought and counterfactual thought may lead to further refinements of our practice.
The considerations of this chapter will not resolve every fraught dispute about metaphysical modality, such as whether zombies
(unconscious physical duplicates of us) are possible. For suppose that the source of such a dispute really is the failure of our usual methods for resolving modal issues to issue a clear verdict in the case at hand
– rather than, say, the unsolvability of a non-modal problem about the nature of consciousness. Then since the present account characterizes our usual method, rather than proposing an alternative, it cannot be expected to resolve the dispute. For all that has been argued here, we may in many cases be incapable of coming to know whether a given hypothesis is metaphysically possible. Philosophical controversy will naturally make the unclear cases salient. That should not blind us to the wide range of clear cases (talking donkeys are possible). General skepticism in the epistemology of metaphysical modality without general skepticism in the epistemology of counterfactuals is unmotivated. The use of imagination to evaluate philosophical claims of possibility and necessity is just as legitimate in principle, and sometimes just as effective in practice, as is its use to evaluate mundane counterfactuals.

5
What does the envisaged assimilation of modality to counterfactual conditionals imply for the status of modal judgments as knowable a priori or only a posteriori?
Some counterfactual conditionals look like paradigms of a priori knowability: for example (7), whose consequent is a straightforward deductive consequence of its antecedent. Others look like paradigms of what can be known only a posteriori: for example, that if I had searched in my pocket five minutes ago I would have found a coin.
But those are easy cases.
Standard discussions of the a priori distinguish between two roles that experience plays in cognition, one evidential, one enabling. Experience is held to play an evidential role in my visual knowledge that this shirt is green, but a merely enabling role in my knowledge that all green things are colored: I needed it only to acquire the concepts green and colored, without which I could not even raise the question whether all green things are colored. Knowing a priori is supposed to be incompatible with an evidential role for experience, or at least with an evidential role for sense experience, so my knowledge that this shirt is green is not a priori. By contrast, knowing a priori is supposed to be compatible with an enabling role for experience, so my knowledge that all green things are colored can still be a priori.
However, in our imagination-based knowledge of counterfactuals, sense experience can play a role that is neither strictly evidential nor purely enabling. For, even without surviving as part of our total evidence, it can mold our habits of imagination and judgment in ways that go far beyond a merely enabling role.
Here is an example. I acquire the words 'inch' and 'centimeter'
independently of each other. Through sense experience, I learn to make naked eye judgments of distances in inches or centimeters with moderate reliability. When things go well, such judgments amount Knowledge of Metaphysical Modality

to knowledge: a posteriori knowledge, of course. For example, I
know a posteriori that two marks in front of me are at most two inches apart. Now I deploy the same faculty offline to make a counterfactual judgment:
(25)

If two marks had been nine inches apart, they would have been at least nineteen centimeters apart.

In judging (25), I do not use a conversion ratio between inches and centimeters to make a calculation. In the example I know no such ratio. Rather, I visually imagine two marks nine inches apart, and use my ability to judge distances in centimeters visually offline to judge under the counterfactual supposition that they are at least nineteen centimeters apart. With this large margin for error, my judgment is reliable. Thus I know (25). Do I know it a priori or a posteriori? Sense experience plays no direct evidential role in my judgment.
I do not consciously or unconsciously recall memories of distances encountered in perception, nor do I deduce (25) from general premises I have inductively or abductively gathered from experience:
Section 3 noted obstacles to assimilating such patterns of counterfactual judgment to the use of general premises. Nevertheless, the causal role of past sense experience in my judgment of (25) far exceeds enabling me to grasp the concepts relevant to (25); the weakness of the conditions for concept possession was noted in the previous chapter. Someone could easily have enough sense experience to understand (25) without being reliable enough in their judgments of distance to know (25). Nor is the role of past experience in the judgment of (25) purely enabling in some other way, for example by acquainting me with a logical argument for (25). It is more directly implicated than that. Whether my belief in (25) constitutes knowledge is highly sensitive to the accuracy or otherwise of the empirical information about lengths (in each unit) on which I relied when calibrating my judgments of length (in each unit). I know (25) only if my offline application of the concepts of an inch and a centimeter was sufficiently skilful. Whether I am justified in believing (25) likewise depends on how skilful I am in making such judgments. My possession of the appropriate skills depends constitutively, not just causally, on past experience for the calibration of my judgments of length in those units. If the calibration is correct by a lucky accident, despite massive errors in the relevant past beliefs about length, I lack the required skill.12
If we knew counterfactual conditionals by purely a priori inference from the antecedent and background premises to the conclusion, our knowledge might count as a priori if we knew all the background premises a priori, and otherwise as a posteriori. However, it was argued above that if the process is inferential at all, the relevant inferences are themselves of just the kind for which past experience plays a role that is neither purely enabling nor strictly evidential, so the inferential picture does not resolve the issue.
Suppose that we classify my knowledge of (25) in the envisaged circumstances as a priori, because sense experience plays no strictly evidential role; perhaps we insist on counting the role of such experience in knowledge of (25) as enabling. Then the danger is that far too much will count as a priori. Long-forgotten experience can mold my judgment in many ways without playing a direct evidential role, for example by calibrating my skilful application of concepts and conditioning me into patterns of expectation which are called on in my assessment of ordinary counterfactual conditionals. How we know (25) may turn out to be quite similar to how many of us know (26):
(26) If two marks had been nine inches apart, they would have been further apart than the front and back legs of an ant.
Sense experience need play no direct evidential role in knowledge of (26). One can know (26) without remembering any occasion on which one perceived an ant, and without having received any testimony about the size of ants. The ability to imagine accurately what an ant would look like next to two marks nine inches apart suffices.
Doubtless (25) is necessary and (26) contingent. But that metaphysical difference does not imply any epistemological difference between how we know (25) and how we know (26). It does not justify the claim that (25) is known a priori and (26) a posteriori. Yet (26) is not usually supposed to be known or even knowable a priori.
Suppose, on the other hand, that we classify my knowledge of (25)
as a posteriori, because experience plays more than a purely enabling
12 role; perhaps we insist on counting the role of sense experience in knowledge of (26) as evidential. Then the danger is that the same verdict will apply to many philosophically significant modal judgments too. The assumption that they are known or even knowable a priori will be undercut. Of course, Kripke has argued strongly for a category of necessary truths knowable only a posteriori, such as
'Gold is the element with atomic number 79'; 'It is necessary that gold is the element with atomic number 79' would then be knowable only a posteriori too. The present suggestion is intended far more widely than that. For example:
(27) It is necessary that whoever knows something believes it.
(28) If Mary knew that it was raining, she would believe that it was raining.
(29) Whoever knew something believed it.
Although (28) is not general and (29) is not modal, our way of knowing them is similar to our way of knowing (27); we do not learn
(28) by analysis of Mary’s individual psychology or (29) by enumerative induction. Knowledge of truths such as (27)–(29) is usually regarded as a priori, even by those who accept the category of the necessary a posteriori. The experiences through which we learned to distinguish in practice between belief and non-belief and between knowledge and ignorance play no strictly evidential role in our knowledge of (27)–(29). Nevertheless, their role may be more than purely enabling. Many philosophers, native speakers of English, have denied
(27) (Shope (1983: 171–92) has a critical survey). They are not usually or plausibly accused of failing to understand the words 'know' and
'believe.' Why should not subtle differences between two courses of experience, each of which sufficed for coming to understand 'know'
and 'believe,' make for differences in how test cases are processed, just large enough to tip honest judgments in opposite directions?
Whether knowledge of (27)–(29) is available to one may thus be highly sensitive to personal circumstances. Such individual differences in the skill with which concepts are applied depend constitutively, not just causally, on past experience, for the skillfulness of a performance depends constitutively on its causal origins.
In a similar way, past experience of spatial and temporal properties may play a role in skilful mathematical 'intuition' that is not directly evidential but far exceeds what is needed to acquire the relevant

Knowledge of Metaphysical Modality mathematical concepts. The role may be more than heuristic, concerning the context of justification as well as the context of discovery.
Even the combinatorial skills required for competent assessment of standard set-theoretic axioms may involve offline applications of perceptual and motor skills, whose capacity to generate knowledge constitutively depends on their honing through past experience that plays no evidential role in the assessment of the axioms.
If the preceding picture is on the right lines, should we conclude that modal knowledge is a posteriori? Not if that suggests that (27)–
(29) are inductive or abductive conclusions from perceptual data. In such cases, the question 'A priori or a posteriori?' is too crude to be of much epistemological use. The point is not that we cannot draw a line somewhere with traditional paradigms of the a priori on one side and traditional paradigms of the a posteriori on the other. Surely we can; the point is that doing so yields little insight. The distinction is handy enough for a rough initial description of epistemic phenomena; it is out of place in a deeper theoretical analysis, because it obscures more significant epistemic patterns. We may acknowledge an extensive category of armchair knowledge, in the sense of knowledge in which experience plays no strictly evidential role, while remembering that such knowledge may not fit the stereotype of the a priori, because the contribution of experience was far more than enabling. For example, it should be no surprise if we turn out to have armchair knowledge of truths about the external environment.13

6
It is time to consider objections to the preceding account.
Objection: Knowledge of counterfactuals cannot explain modal knowledge, because the former depends on the latter. More specifically, in developing a counterfactual supposition, we make free use

13 of what we take to be necessary truths, but not of what we take to be contingent truths. Thus we rely on a prior or at least independent stock of modal knowledge or belief. The principle NECESSITY above illustrates how we do this.
Reply: Once we take something to be a necessary truth, of course we can use it in developing further counterfactual suppositions. But that does nothing to show that we have any special cognitive capacity to handle modality independent of our general cognitive capacity to handle counterfactual conditionals. If we start only with the latter, just as envisaged above, it will generate knowledge of various modal truths, which can in turn be used to develop further counterfactual suppositions, in a recursive process. For example, we need not judge that it is metaphysically necessary that gold is the element with atomic number 79 before invoking the proposition that gold is the element with atomic number 79 in the development of a counterfactual supposition. Rather, projecting constitutive matters such as atomic numbers into counterfactual suppositions is part of our general way of assessing counterfactuals. The judgment of metaphysical necessity originates as the output of a procedure of that kind; it is not an independently generated input.
What if our general cognitive capacity to handle counterfactuals has as a separate constituent a special cognitive capacity to handle metaphysical modality? Consider the cognitive resources sketched in Section 3 for the evaluation of counterfactual conditionals: most distinctively, imaginative simulation; less distinctively, reasoning, memory, testimony, perception. The question is whether they require supplementation by an additional capacity for the evaluation
. They do not. Although of counterfactuals of the special form A
we often cannot perceptually imagine the truth of A, not all imagining is perceptual imagining. 'Imagine that there is a barber who shaves all and only those who do not shave themselves' is not radically different from the instruction 'Suppose that there is a barber who shaves all and only those who do not shave themselves.' In imaginatively and inferentially developing a counterfactual supposition, one may or may not run into a contradiction. Of course, we often find claims of metaphysical possibility or necessity hard to evaluate. But that is not the point. There is no evidence whatsoever that we are better at evaluating claims of metaphysical modality than we would be if we had just the sorts of cognitive capacity listed above for evaluating counterfactual conditionals, with no additional separate capacity for evaluating claims of metaphysical modality. Therefore the postulation of such an additional capacity is unwarranted.
Objection: The account associates metaphysical modality with counterfactual conditionals of a very peculiar kind: in the case of
(17) and (18), those with an explicit contradiction as their consequent. Why should a capacity to handle ordinary counterfactuals confer a capacity to handle such peculiar ones too?
Reply: That is like asking why a capacity to handle inferences between complex empirical sentences should confer a capacity to handle inferences involving logical truths and falsehoods too. There is no easy way to have the former without the latter. More specifically, developing a counterfactual supposition includes reasoning from it, and we cannot always tell in advance when such reasoning will yield a contradiction (there are surprises in logic). The undecidability of logical truth for first-order logic implies that there is no total mechanical test for the consistency even of first-order sentences.
Thus the inconsistent ones cannot be sieved out in advance (consider
'In the next village there is a barber who shaves all and only those in that village who do not shave themselves'). Consequently, a general capacity to develop counterfactual suppositions must confer in particular the capacity to develop those which subsequently turn out inconsistent. Although the capacity may not be of uniform reliability, as already noted, the variation is primarily with the antecedent of the counterfactual (the supposition under development), not with its consequent (which is what is exceptional in (17) and (18)). In deductive inference, our reasoning to contradictions (as in proof by reductio ad absurdum) is not strikingly more or less reliable than the rest of our deductive reasoning. We can reach many conclusions about metaphysical modality without overstretching our imaginative resources. For instance, whenever we can deny a counterfactual
B, we can assert A, because A
entails A
B. Again,
A
the argument in Section 4 for a version of the necessity of identity employed only straightforward reasoning in the logic of counterfactuals. It is not an objection to the present account that our use of the imagination in evaluating counterfactuals may be unreliable for some with far-out antecedents.
Objection: The assumption about vacuous truth on which the account relies is wrong (Nolan 1997). For some counterpossibles Knowledge of Metaphysical Modality

(counterfactuals with metaphysically impossible antecedents) are false, such as (30), uttered by someone who mistakenly believes that he answered '13' to 'What is 5 + 7?'; in fact he answered '11':
(30)

If 5 + 7 were 13 I would have got that sum right.

Thus, contrary to (17), A may be true while A
is false. In the argument for (17) in Section 3, the objectionable premise is
NECESSITY. If some worlds are metaphysically impossible, and A is true at some of them but false at all metaphysically possible worlds, then every metaphysically possible A world is a B world, even if the closest A worlds are not B worlds.14 Similar objections apply to the other purported equivalences (18)–(22).
Reply: Suppose that all counterpossibles are false. Then A is
A, for the latter will still be true whenever A is equivalent to A
A)
possible; correspondingly, A is equivalent to the dual ( A
and one can carry out the program of Section 3 using the new equivalences. But that is presumably not what the objector has in mind.
Rather, the idea is that the truth-value of a counterpossible can depend on its consequent, so that (30) is false while (31) is true:
(31)

If 5 + 7 were 13 I would have got that sum wrong.

However, such examples are quite unpersuasive.
First, they tend to fall apart when thought through. For example, if 5 + 7 were 13 then 5 + 6 would be 12, and so (by another eleven steps) 0 would be 1, so if the number of right answers I gave were
0, the number of right answers I gave would be 1. We prefer (31) to
(30) because the argument for (31) is more obvious, but the argument for (30) is equally strong.
14

Technically, NECESSITY fails on a semantics with similarity spheres for that include some impossible worlds (inaccessible with respect to ). Conversely, POSSIBILITY fails on a semantics with some possible worlds excluded from all similarity spheres (see Lewis (1986: 16) on universality). Inaccessible worlds seem not to threaten POSSIBILITY. For suppose that an A world w but no B world is accessible from a world v. Then if A
B holds at v on the usual semantics, there is an A
world x such that every A world as close as x is to v is a B world. It follows that w is not as close as x is to v and that x is inaccessible from v, which contradicts the plausible assumption that any accessible world is at least as close as any inaccessible world. Second, there are general reasons to doubt the supposed intuitions on which such examples rely. We are used to working with possible antecedents, and given the possibility of A, the incompatibility of B
B and A
C cannot both be and C normally implies that A
true. Thus by over-projecting from familiar cases we may take the uncontentious (31) to be incompatible with (30). The logically unsophisticated make analogous errors in quantificational reasoning.
Given the evident truth of 'Every golden mountain is a mountain,'
they think that 'Every golden mountain is a valley' is false, neglecting the case of vacuous truth. Since the logic and semantics of counterfactual conditionals is much less well understood, even the logically sophisticated may find similar errors tempting. Such errors may be compounded by a tendency to confuse negating a counterfactual conditional with negating its consequent, given the artificiality of the constructions needed to negate the whole conditional unambiguously
B (with A
('it is not the case that if . . .'). Thus the truth of A
B) and thereimpossible) may be mistaken for the truth of (A
fore the falsity of A
B. If we must choose between (30) and (31), it is clear which we should choose; but the impression that we must choose is an illusion.
Some objectors try to bolster their case by giving examples of mathematicians reasoning from an impossible supposition A ('There are only finitely many prime numbers') in order to reduce it to absurdity. Such arguments can be formulated using a counterfactual conditional, although they need not be. Certainly there will be points in
C (in particular, the argument at which it is legitimate to assert A
C (in particular,
A
A) but illegitimate to assert A
A is false.
A
A). But of course that does not show that A
At any point in a mathematical argument there are infinitely many truths that it is not legitimate to assert, because they have not yet been proved (Lewis (1986: 24–6) pragmatically explains away some purported examples of false counterfactuals with impossible antecedents). Similarly, this reply could just as well have begun 'If all counterpossibles were false, A would be equivalent to A
A.'
Read 'the antecedent' in such a way that it is impossible. Then it would have been equally true to say 'If all counterpossibles were false, A would not be equivalent to A
A.' But that would not have mattered, for only the former counterfactual is assertable in a context in which for dialectical purposes the possibility of Knowledge of Metaphysical Modality

the antecedent is not excluded, and that is what the argument requires.
We may also wonder what logic of counterfactuals the objectors envisage. If they reject elementary principles of the pure logic of counterfactual conditionals, that is an unattractive feature of their position. If they accept all those principles, then they are committed to operators characterized as in (17) and (18) that exhibit all the logical behavior standardly expected of necessity and possibility.
What is that modality, if not metaphysical modality?
A final problem for the objection is this. Here is a paradigm of the kind of counterpossible the objector regards as false:
(32)

If Hesperus had not been Phosphorus, Phosphorus would not have been Phosphorus.

Since Hesperus is Phosphorus, it is metaphysically impossible that
Hesperus is not Phosphorus, by the necessity of identity. Nevertheless, the objectors are likely to insist that in imaginatively developing the counterfactual supposition that Hesperus is not Phosphorus, we are committed to the explicit denial of no logical truth, as in the consequent of (32). According to them, if we do our best for the antecedent, we can develop it into a logically coherent though metaphysically impossible scenario: it will exclude 'Phosphorus is not
Phosphorus.' But they will presumably accept this trivial instance of reflexivity:
(33)

If Hesperus had not been Phosphorus, Hesperus would not have been Phosphorus.

In general, however, coreferential proper names are intersubstitutable in counterfactual contexts. For example, the argument from (34) and
(35) to (36) is unproblematically valid:
(34)

If the rocket had continued on that course, it would have hit
Hesperus.
(35) Hesperus = Phosphorus.
(36) If the rocket had continued on that course, it would have hit
Phosphorus. Similarly, the argument from (33) and (35) to (32) should be valid.
But (33) and (35) are uncontentiously true. If the objector concedes that (32) is true after all, then there should be an explanation of the felt resistance to it, compatible with its truth, and we may reasonably expect that explanation to generalize to other purported examples of false counterpossibles. On the other hand, if the objector rejects (32), they must deny the validity of the argument from (33) and (35) to
(32). Thus they are committed to the claim that counterfactual conditionals create opaque contexts for proper names (the same argument could be given for other singular terms, such as demonstratives).
But that is highly implausible. (34) and (36) are materially equivalent because their antecedents and consequents concern the same objects, properties, and relations: it matters not that different names are used, because the counterfactuals are not about such representational features (if the substitution of coreferential names in propositional attitude ascriptions does not preserve truth value, the reason is that such ascriptions are about representational features). But then exactly the same applies to (32) and (33). Their antecedents and consequents too concern the same objects, properties, and relations. That the antecedent of (32) and (33) is in fact metaphysically impossible does not radically alter their subject matter. The transparency of the counterfactual conditional construction concerns its general semantic structure, not the specific content of the antecedent.
Under scrutiny, the case for false counterpossibles looks feeble.
The logic of quantifiers was confused and retarded for centuries by unwillingness to recognize vacuously true universal generalizations; we should not allow the logic of counterfactuals to be similarly confused by unwillingness to recognize vacuously true counterpossibles.15
Objection: Counterfactuals are desperately vague and contextand , sensitive; equivalences such as (17) and (18) will infect interpreted as metaphysical modalities, with all that vagueness and context-sensitivity.
Reply: Infection is not automatic. For instance, within a LewisStalnaker framework, different readings or sharpenings of may
15 differ on the similarity ordering of worlds while still agreeing on what worlds there are, so that the differences cancel out in the right-hand sides of (17) and (18). Whether a given supposition counterfactually implies a contradiction may be unclear to us; that does not imply that there is no right answer.
On some dynamic accounts, the semantics of counterfactuals involves a more systematic interaction with context, because one normal effect of the antecedent is to update the context to one in which the horizon of contextually relevant worlds includes some in which the antecedent is true; the truth of the sentence is then equivalent to the truth of the consequent in all the relevant worlds in the updated context (von Fintel 2001). The present account can be adapted to such an account, if it is allowed that updating can fail to provide a world in which the antecedent is true when there is no such world, for then the counterfactual is vacuously true: its consequent is true in every relevant world in which its antecedent is true. Even if, less plausibly, the counterfactual is 'undefined' in such cases (a view with awkward consequences for many informal mathematical proofs by reductio ad absurdum involving counterfactuals), metaphysical impossibility and the other modalities can still be recovered from the counterfactual, since ' A' will be equivalent to 'It is
A).'
defined whether (A
Objection: It has been argued that counterfactual conditionals lack truth-values (Edgington 2003, Bennett 2003: 252–6). If so, the assimilation of claims of metaphysical possibility and necessity to counterfactuals will deprive such claims of truth-values.
Reply: The issues are too complex to discuss properly here, but the readily intelligible occurrence of counterfactual conditionals embedded in the scope of other operators as in (23) and (24) is hard to make sense of without attributing truth-values to the embedded occurrences. Here is another example:
(37)

Every field that would have been flooded if the dam had burst was ploughed.

(37) can itself be intelligibly embedded in more complex sentences in all the usual ways; for example, it can be negated or made the antecedent of another conditional. In order to understand how such embeddings work, we must assign truth conditions to (37); ad hoc treatments of a few particular embeddings are not enough. For (37)
to have truth conditions, 'field that would have been flooded if the dam had burst' must have application-conditions. Thus there must be a distinction between the fields to which 'would have been flooded if the dam had burst' applies and those to which it does not. But that is just to say that there must be a distinction between the values of 'x' for which 'If the dam had burst, x would have been flooded'
is true and those for which it is false. That it is somewhat obscure what the truth conditions of counterfactual conditionals are, and that we sometimes make conflicting judgments about them, hardly shows that they do not exist. The requirement that counterfactual conditionals have truth conditions is one way in which the preceding discussion has not been perfectly neutral on their semantics.

7
The counterfactual conditional is of course not the only construction in ordinary use that is closely related to metaphysical modality. Consider comments after a swiftly extinguished fire in an explosives factory:
(38) There could have been a huge explosion.
(39) There could easily have been a huge explosion.
The truth-value of both (38) (on a natural reading) and (39) depends on the location of the fire, the precautions in place, and so on. The mere metaphysical possibility of a huge explosion is insufficient to verify either (38) (so interpreted) or (39). The restricted nature of the possibility is explicit in (39) with the word 'easily'; it is implicit in the context of (38).16 To discover the truth-value of (38) or (39), we need background information. We may also need our imagination, in attempting to develop a feasible scenario in which there is a huge explosion. We use the same general cognitive faculties as we do in evaluating related counterfactual conditionals, such as (40):
16

On easy possibility see Sainsbury (1997), Peacocke (1999: 310–28) and
Williamson (2000a: 123–30). On the idea that natural language modals such as 'can'
and 'must' advert to contextually restricted ranges of possibilities see Kratzer
(1977). Knowledge of Metaphysical Modality

(40)

If the fire engine had arrived a minute later, there would have been a huge explosion.

Judgments of limited possibility such as (38) (interpreted as above)
and (39) have a cognitive value for us similar to that of counterfactual conditionals such as (40). Both (38) and (39) entail (41), although not vice versa:
(41)

It is metaphysically possible that there was a huge explosion.

This is another way in which our ordinary cognitive capacities enable us to recognize that something non-actual is nevertheless metaphysically possible. But we cannot reason from the negation of (37) or of
(38) to the negation of (41).
Can metaphysical possibility be understood as the limiting case of such more restricted forms of possibility? Perhaps, but we would need some account of what demarcates the relevant forms of possibility from irrelevant ones, such as epistemic possibility. It also needs to be explained how, from the starting-point of ordinary thought, we manage to single out the limiting case, metaphysical modality. The advantage of counterfactual conditionals is that they allow us to single out the limiting case simply by putting a contradiction in the consequent; contradictions can be formed in any language with conjunction and negation. Anyway, the connections with restricted possibility and with counterfactual conditionals are not mutually exclusive, for they are not being interpreted as rival semantic analyses, but rather as different cases in which the cognitive mechanisms needed for one already provide for the other.
The epistemology of metaphysical modality requires no dedicated faculty of intuition. It is simply a special case of the epistemology of counterfactual thinking, a kind of thinking tightly integrated with our thinking about the spatio-temporal world. To deny that such thinking ever yields knowledge is to fall into an extravagant skepticism. Here as elsewhere, we can do philosophy on the basis of general cognitive capacities that are in no deep way peculiarly philosophical.

6
Thought Experiments

1
Of all the armchair methods of philosophy, one of the most conspicuous is the thought experiment. Much of the philosophical community allows that a judicious act of the imagination can refute a previously well-supported theory. In natural science, one might expect, to imagine obtaining a negative outcome to a crucial experiment may be to imagine refuting the theory at issue, but imagining refuting a theory no more actually refutes it than imagining killing a tyrant actually kills him. Why should philosophy be any different? If the idea of a crucial experiment is too crude to describe the workings of real science, that merely reinforces skepticism about crucial thought experiments in philosophy.
Such an objection to thought experiments is facile, as their seminal role in physics immediately suggests, most famously in the work of
Galileo and Einstein. Of course, philosophy-hating philosophers (a common breed) claim that philosophical thought experiments are profoundly unlike those in natural science, in ways which make the former bad and the latter good, but we should be suspicious of such claims of philosophical exceptionalism. We have already seen the imagination play a mundane but vital role in the evaluation of counterfactual conditionals, from the most ordinary empirical ones to those equivalent to statements about metaphysical modality. We shall see it play a corresponding role in thought experiments.
The canonical example in the literature on philosophical thought experiments is Edmund Gettier’s use of them to refute the traditional analysis of knowledge as justified true belief (Gettier 1963). The background working hypothesis is that his thought experiments are Thought Experiments

paradigmatic, in the sense that if any thought experiments can succeed in philosophy, his do: thus to determine whether Gettier’s thought experiments succeed is in effect to determine whether there can be successful thought experiments in philosophy. Even if we do not afford them quite that status, they provide a convenient focus for discussion. Moreover, they demonstrate the cognitive weight analytic philosophers rest on thought experiments. Sociologically, the phenomenon is remarkable. Gettier had no previous publications and was unknown to most of the philosophical profession; he did not write as an established authority. For the theory he was attacking, a neat and at the time widely accepted analysis of the central concept of epistemology, he cited well-known books by two leading philosophers of his time (Ayer 1956, Chisholm 1957) and, more tentatively,
Plato (Theaetetus 201, Meno 98).1 His three-page article turns on two imaginary examples.2 Yet his refutation of the justified true belief analysis was accepted almost overnight by the community of analytic epistemologists. His thought experiments were found intrinsically compelling.
This chapter analyzes the logical structure of Gettier-style thought experiments. The discussion can be generalized to many imaginary counterexamples that have been deployed against philosophical analyses and theories in ways more or less similar to Gettier’s. Far more extensive investigation would be needed to warrant the claim that all philosophical thought experiments work in that way, but one must start somewhere. The main overall aim is to subsume the epistemology of thought experiments under the epistemology of counterfactual conditionals and metaphysical modality developed in the previous chapter, and thereby to reveal it as an application of quite ordinary ways of thinking, not as something peculiarly philosophical. A related subsidiary aim is to achieve a finer-grained understanding of the structure of the arguments that underlie thought experiments, both

1
Shope (1983: 12–19) discusses whether Plato endorsed the justified true belief analysis of knowledge and argues that Kant did in the Critique of Pure Reason at
A822, B850.
2
Russell (1912) gave examples with a structure very similar to Gettier’s, but used them only to draw the conclusion that 'a true belief is not knowledge when it is deduced from a false belief' (in the chapter on 'Knowledge, error and probable opinion'). for its own sake and in order to test the overall account by developing it in detail.

2
We can extract from Gettier’s paper an argument that makes no obvious appeal to thought experiments. According to the target analysis, a necessary and sufficient condition for knowing something is that it is true, one believes it and one is justified in believing it; for short, one has justified true belief.3 Now in the sense of 'justified'
in which being justified in believing something is necessary for knowing it, Gettier argues, one can be justified in believing what is in fact false (the truth component of the justified true belief analysis is not redundant). But if one is justified in believing something, and correctly deduces from it something else, one is justified in believing the latter proposition on that basis (deduction is a way of transmitting justification from the premises to the conclusion of an argument).
Since any truth is deductively entailed by various falsehoods, one can believe a truth on the basis of having correctly deduced it from a falsehood one is justified in believing, and thereby be justified in believing the deduced truth too; thus one has justified true belief in the latter. Nevertheless, one does not know, for one’s belief in the truth, no matter how justified, is essentially based on a false lemma; one’s conclusion cannot be epistemically better off than one’s premises. Therefore, justified true belief is insufficient for knowledge.
One disadvantage of the abstract argument is that it rests on several very general claims for which we might find adequate support hard to provide. In particular, it assumes that a belief essentially based on a false belief does not constitute knowledge. Can we take that for granted? How do we know that a belief essentially based on a false belief never constitutes knowledge even in recherché cases?
Fortunately, the universal generalization is more than Gettier needs in order to refute the target analysis. He needs only some particular instance in which the belief essentially based on a false lemma clearly
3 fails to constitute knowledge, whether or not all other cases go the same way. As Gettier proceeds, the verdict that the subject lacks knowledge in the particular case has epistemic priority over the general diagnosis that a true belief essentially based on a false one never constitutes knowledge. In this account, the primary direction of support is abductive, from particular verdict to general principle
(by inference to the best explanation), rather than deductive, from general principle to particular verdict (by universal instantiation).
Gettier’s own focus is on the particular verdicts, and that is how his counterexamples have usually been understood as working. In any event, his examples can be used in that way, and methodologically it is best to start with the simplest case, in which the particular verdict has priority. A similar point applies to Gettier’s explicit assumption that justification is closed under deduction: what matters for his immediate purposes is just that the assumption clearly holds in his chosen cases, whether or not it holds in all more recherché ones. The need for examples is also implicit in Gettier’s claim that one can be justified in believing a falsehood, for how could he adequately support the claim without appeal to examples? In effect, he provides a general recipe for developing any example of justified false belief into a counterexample to the justified true belief analysis.
Gettier’s assumption that there can be justified false belief is not unquestionable, for any belief which does not constitute knowledge is ipso facto defective, and so in some sense not fully justified, even if it is fully excusable. That objection clearly does not invoke a standard of justification on which it is unnecessary for knowledge, nor does it give any succor to skepticism. However, it does invoke a concept of justification which is not prior to the concept of knowledge, and so risks making the analysis of knowledge as justified true belief circular (Williamson 2000a: 184–5, Sutton 2007). The analysis of knowledge as justified true belief loses much of its intended explanatory power if justification has to be understood by reference to knowledge. It is dialectically legitimate for critics of the analysis to work, as Gettier does, with the view of justification on which its proponents rely. On such a view, my justification for believing that
I have hands is equally good whether I am an ordinary human with hands or a brain in a vat which merely seems to itself to be an ordinary human with hands: since my belief is justified in the former case, on pain of skepticism, it is equally justified in the latter case, when it is false. In what follows, we assume a sense of 'justified' in which one can be justified in believing falsehoods.
Gettier presents his specific counterexamples to the target analysis through short fictional narratives, in the present tense indicative, with fictional uses of proper names ('Smith' and 'Jones'), all introduced by 'suppose that.' Beyond their conformity to the abstract pattern just explained, their details do not concern us. Let us construct another example to the same pattern. A clever bookseller fakes evidence which appears to show conclusively that a particular book once belonged to Virginia Woolf; convinced, Orlando pays a considerable sum for the book. He has a justified false belief that this book of his once belonged to Virginia Woolf. On that basis alone, he forms the existential belief that he owns a book which once belonged to Virginia Woolf. The latter belief is in fact true, because another of his books in fact once belonged to her, although he does not associate that one with her in any way. Thus Orlando has a justified true belief that he owns a book which once belonged to Virginia Woolf, but he does not know that he owns a book which once belonged to Virginia
Woolf. What we need to understand is how such fictional narratives can present counterexamples to philosophical analyses.
On Gettier’s account, the target analysis is a claim of necessary and sufficient conditions for knowing. Let us formalize this as the claim that, necessarily, for any subject x and proposition p, x knows p if and only if x has a justified true belief in p.4 Symbolically:
(1)

᭙x᭙p (K(x, p)

JTB(x, p))

This does not say that knowledge is identical with justified true belief, nor does it entail that the word 'knowledge' is synonymous with the phrase 'justified true belief' or that the concept knowledge is identical with the concept justified true belief. But if any of those further claims is true, so too is (1). Thus a refutation of (1) automatically refutes each of those further claims too, although not conversely.
For present purposes, in formalizing Gettier’s argument against
(1), we can ignore most of the structure specific to his cases, and
4 concentrate on the logical structure they share with most other imaginary counterexamples to philosophical analyses. Suppose that we fix on a particular Gettier-style story (the one about Orlando would do), henceforth 'the Gettier case,' told in neutral terms, without prejudice to the target analysis. For instance, it is not explicitly part of the story that Orlando does not know that he owns a book which once belonged to Virginia Woolf. Since the story contains fictional singular terms, such as 'Orlando' and 'this book,' it is arguably just a pretence that its constituent sentences express propositions. However, we can treat such fictional singular terms as picturesque substitutes for variables. Replacing them by variables, we can represent the
Gettier-style story by an open sentence GC(x, p), where the variables
'x' and 'p' occupy the positions for, respectively, the believer and the content of the justified true belief. Although one could attempt an analysis of thought experiments that took their fictional aspect more seriously, their relevance to fictional claims such as (1) is most easily understood in this more literal-minded way.
If the Gettier case were impossible, it would pose no obvious threat to the claim of necessity (1). We therefore make the putative possibility of the case explicit:
(2)

x p GC(x, p)

Someone could stand in the relation described in the Gettier story to some proposition. In order to complete the argument against (1), we need the verdict that the subject in the Gettier case has justified true belief without knowledge. To a first approximation, we can formalize that as the claim that, necessarily, anyone who stands in the Gettier relation to a proposition has justified true belief in that proposition without knowledge:
(3)

᭙x᭙p (GC(x, p)

(JTB(x, p) &

K(x, p)))

By elementary modal reasoning, a necessary consequence of something possible is itself possible. Therefore, as a logical consequence of (2) and (3), someone could have justified true belief in a proposition without knowledge:
(4)

x p (JTB(x, p) &

K(x, p)) But (4) is straightforwardly inconsistent with (1), in particular with its right-to-left direction. Justified true belief is insufficient for knowledge. Consequently, (2) and (3) suffice as premises for a deductive argument against the target analysis.
This objection to (1) relies essentially on its modal content. If (1)
were replaced by a non-modal universally quantified biconditional, thought experiments would not refute it, for an imaginary case in which two things fail to coincide is quite compatible with their coincidence over all actual cases. The function of the thought experiment is to show that a certain case could arise, and that if it did, the two things would come apart, from which it follows that the two things could come apart. That refutes the modal claim that they could not come apart, but not the non-modal claim that they never in fact come apart.
That (3) is the best representation of the verdict on the Gettier case is doubtful. In philosophy, examples can almost never be described in complete detail. An extensive background must be taken for granted; it cannot all be explicitly stipulated. Although many of the missing details are irrelevant to whatever philosophical issues are in play, not all of them are. This applies not just to highly schematic descriptions of examples, such as the initial abstract Gettier schema, but even to the much richer stories Gettier and other philosophers like to tell. For example, in the Gettier case, if the subject’s inference to the true belief p from the false belief q bizarrely happens to trigger awkward memories or apparent memories that cast doubt on q, the effect may be to lose justification for q rather than to gain it for p.
Without specifically addressing the question, we do not envisage the
Gettier case like that. Nor do we worry about whether our verdicts would hold even if mad scientists were interfering with the subject’s brain processes in various ways; those possibilities do not normally occur to us when we assess Gettier examples. Similarly, when moral philosophers assess imaginary examples, one can almost always fill out the case with unintended but morally relevant additions that would reverse the verdict. Any humanly compiled list of such interfering factors is likely to be incomplete.
Instead of asking whether justified true belief without knowledge is a necessary consequence of the Gettier case, one might more naturally ask whether, if there were an instance of the Gettier case, it would be an instance of justified true belief without knowledge. The Thought Experiments

verdict that it would constitutes a counterfactual conditional, which is much weaker than the strict conditional (3).5 In very rough terms, it requires justified true belief without knowledge only in the closest realizations of the Gettier case, not in all possible realizations. By using the counterfactual conditional, we in effect leave the world to fill in the details of the story, rather than trying to do it all ourselves.
For present purposes the counterfactual can be symbolized thus (its formalization will be discussed in detail later):
(3*)

x p GC(x, p)

᭙x᭙p (GC(x, p)

(JTB(x, p) & K(x, p)))

The counterfactual conditional in (3*) takes widest possible scope. If there were an instance of the Gettier case, it would be an instance of justified true belief without knowledge. For the time being, let us simply assume that (3*) correctly formalizes Gettier’s major premise.
That assumption will be evaluated in later sections.
Let us reconstruct the logic of the argument against (1). Informally, why do (2) and (3*) entail (4)? Given (2), (3*) cannot hold vacuously.
Thus, given (2) and (3*), (3*) holds non-vacuously. Therefore its antecedent and consequent hold together in some possible world.
That must be a possible world in which someone has justified true belief without knowledge. Thus (4) is true, so (1) is false.
We can make the reasoning rigorous without reliance on possible worlds. First, consider the logical relations between the nonmodal constituents of the argument. Let A be x p GC(x, p)
('Someone stands in the Gettier relation to something'), B be
᭙x᭙p (GC(x, p)
(JTB(x, p) & K(x, p))) ('Whoever stands in the
Gettier relation to something has justified true belief in it without knowledge') and C be x p (JTB(x, p) & K(x, p)) ('Someone has justified true belief in something without knowledge'). Thus (2) is
A, (3*) is A
B and (4) is C. Obviously, C is a logical conse5

Similarly, in describing one of his famous examples to motivate the causal theory of perception, Grice writes 'if, unknown to me, there were a mirror interposed between myself and the pillar, it would certainly be incorrect to say that I saw the first pillar, and correct to say that I saw the second' (1961, section 5); the counterfactual conditional here reads completely naturally (although one might object to his dressing up a fact about perception as, in his words, a 'linguistic fact'). Sorensen
(1992) formalizes the arguments underlying thought experiments using counterfactual conditionals; for discussion of his proposal see Häggqvist (1996: 92–103). quence of A and B: in symbols, A, B
C. By the principle that the counterfactual consequences of a given supposition are closed under logical consequence (CLOSURE), we therefore have A
A,
C.6 Since everything counterfactually implies itself
A
B A
A. Thus
(REFLEXIVITY), the first premise is a logical truth: A
C. By the principle POSSIBILITY
we can simplify to A
B A
from the previous chapter, a counterfactual consequence of a possiC. Combining bility is itself a possibility, which yields A, A
C
B
C, in other words, (2), (3*)
these two results gives A, A
(4), as required. Thus weakening the major premise from a strict to a counterfactual implication leaves the validity of the argument intact. The extra strength of strict implication was an unnecessary commitment.
This account of the use of imaginary counterexamples in refuting philosophical analyses extends far beyond Gettier cases. It also generalizes to their use in refuting philosophical claims of necessity which lack the form of an analysis, such as one-way strict implications.
Preview: Section 3 makes some observations about the epistemology of the argument just analyzed. Section 4 assesses (3*) as a formalization of the counterfactual (Appendix 2 considers another alternative). Section 5 asks whether the right counterfactual was selected for formalization. The final section considers whether Gettier’s argument concerns counterfactual possibility at all. The foregoing account survives all these tests, at least as an adequate approximation.

3
On our account, a thought experiment such as Gettier’s embodies a straightforward valid modal argument for a modal conclusion. The role of the imagination is in verifying the premises.7
6

As noted in the previous chapter, CLOSURE cannot be applied to cases when the original argument preserves truth at the actual world of every model but not at counterfactual worlds. Since C is an ordinary first-order logical consequence of A and
B, this problem does not arise here.
7
There is a debate as to whether thought experiments in science reduce to arguments
(Norton 1991, 2004) or contain an irreducible imaginative element (Gendler Thought Experiments

The major premise (3*) is a counterfactual conditional; the imagination is used in verifying it just as it is used in verifying many everyday counterfactuals, such as 'If the bush had not been there, the rock would have landed in the lake.' There is nothing peculiarly philosophical about the way in which the counterfactual is assessed. The antecedent and consequent express empirical conditions. Is the connection between them endorsed on distinctively 'conceptual' grounds?
The epistemological idea of conceptual connections turned out in earlier chapters to be a myth. Here, two points are enough. First, if what warranted the counterfactual conditional (3*) was that its antecedent conceptually entailed its conclusion, then that would also warrant the strict implication (3); but we have seen that the strict implication is not warranted. Second, native English speakers sometimes dispute the Gettier verdict, and so by implication reject the counterfactual. In doing so, they show poor epistemological judgment but not linguistic incompetence: they are not usually accused of failing to understand the relevant words of English; it would be inappropriate to send them off to language school for retraining. Some of them have had no exposure to philosophy; others are professional epistemologists.8 We assent to (3*) on the basis of an offline application of our ability to classify people around us as knowing various truths or as ignorant of them, and as having or as lacking other epistemologically relevant properties. That classificatory ability goes far beyond mere linguistic understanding of 'know' and other words.
The minor premise (2) is a claim of possibility. For standard
Gettier cases it is quite uncontentious. They constitute mundane practical possibilities; nobody doubts that they could arise: (2) is not where the philosophical action is. What skeptics about Gettier’s thought experiments doubt is not (2) but (3*). They call into question
'the Gettier intuition,' that the case is one of justified true belief without knowledge: it corresponds to (3*), not (2), for the English original of (2) does not even contain 'know' or cognate terms. In
1998, 2004). The present account of thought experiments in philosophy goes some way towards reconciling the two sides: thought experiments do constitute arguments, but the imagination plays an irreducible role in warranting the premises.
8
Shope (1983: 26–33) discusses some attempts by professional epistemologists to argue that the Gettier problem is not genuine. See Weinberg, Stich, and Nichols
(2001) for lay denials.

Thought Experiments any case, the previous chapter showed how the ordinary epistemology of counterfactual conditionals applies to possibility claims such as (2).
For other philosophical thought experiments, the possibility premise corresponding to (2) may be far more contentious: a bizarre science fiction possibility, perhaps involving a brain swap or even a disembodied mind. Whether the possibility premise is warranted depends on the details of the case, but there is no reason in principle why it should not be. In general, we have a trade-off between the uncontentiousness of the major premise and the uncontentiousness of the minor premise. The more we pack into the description of the case (such as GC(x, p)), the more firmly we can secure the major premise, the desired verdict, but the less obvious we make the minor premise, the possibility claim. By packing less into the description, we can make the possibility claim more obvious, but risk loosening our grip on the desired verdict. However, such trade-offs are a commonplace of abstract argument; they do not mean that we cannot make both premises simultaneously plausible enough for our purposes.
Do we know the premises (2) and (3*) a priori? Presumably, we do so if and only if we also know the conclusion (4) a priori, given that we believe it just on the basis of this logically valid deduction.
However, in the previous chapter we saw reason to doubt the significance of the distinction between a priori and a posteriori knowledge.
The considerations there apply to the present case too. We accept (2)
and (3*) on the basis of a capacity for applying epistemological concepts that goes far beyond what it takes to possess the concepts in the first place, since someone with a distorted epistemological outlook may reject (3*), yet still possess the relevant concepts: they genuinely believe that the subject of the Gettier case would not have justified true belief without knowledge. Past experience contributed to the acquisition of those classificatory epistemological skills that go far beyond possession of the relevant concepts. That experience included sense experience. For example, we learn to recognize perceptually conditions of observation under which observers can gain perceptual knowledge of various features of their environment. Again, our skill in discriminating justification from its absence is developed in observation of other thinkers. In our acceptance of (3*), sense experience is not confined to a purely enabling role, for example by providing Thought Experiments

the opportunity to acquire those concepts or to encounter philosophical arguments about them. It is more directly implicated than that.
It plays a positive role in helping to tip judgment one way rather than the other when one imagines the Gettier case instantiated as such that the subject’s inference extends justification from the false premise to the true conclusion, rather than as such that the inference undermines justification for the premise. Which way one goes depends on what one finds normal or natural, which partly depends on the past course of one’s sense experience. Thus knowledge of (3*) does not conform to the usual stereotype of a priori knowledge. Typically, however, past experience plays no strictly evidential role in knowledge of (3*): for example, we need not invoke past instances of lack of knowledge as inductive evidence for lack of knowledge in the
Gettier case. The experience of performing the thought experiment itself is not sense experience as usually understood. Thus knowledge of (3*) fails equally to conform to the usual stereotype of a posteriori knowledge. Although we might try to resolve the issue by stipulation, doing so would yield little insight into the nature of knowledge such as we have of (3*). To gain such insight, we must focus on the ways in which that knowledge differs both from the stereotype of a priori knowledge and from the stereotype of a posteriori knowledge.
One manifestation of the influence of past experience on epistemological judgments may be cross-cultural variation in verdicts on thought experiments, including the Gettier case.9 Such variation, if it occurs, may result from cross-cultural variation in the meaning of
'know' or other epistemological terms, but it need not. It may occur between sub-communities of English speakers who all use the words as part of a single common vocabulary, but disagree in their applications of them, just as different communities may disagree in their applications of the word 'justice' while still using it with a single shared meaning. Cross-cultural disagreement over the theory of evolution is compatible with a common meaning of the word 'evolution' between the cultures. In the present cases, the variation between individuals within a single group is just as striking as the statistical
9

For some evidence see Weinberg, Stich, and Nichols (2001), critically discussed by
Sosa (2005). The rationale for the use of thought experiments in philosophy which
Weinberg, Stich and Nichols attack is very different from that defended in this book. variation between groups: the data do not suggest a clash of monolithic cultures, but rather some variation in the proportion of the population who respond in a given way.
Much of the evidence for cross-cultural variation in judgments on thought experiments concerns verdicts by people without philosophical training. Yet philosophy students have to learn how to apply general concepts to specific examples with careful attention to the relevant subtleties, just as law students have to learn how to analyze hypothetical cases. Levels of disagreement over thought experiments seem to be significantly lower among fully trained philosophers than among novices. That is another manifestation of the influence of past experience on epistemological judgments about thought experiments.
We should not regard philosophical training as an illegitimate contamination of the data, any more than training natural scientists how to perform experiments properly is a contamination of their data. Although the philosophically innocent may be free of various forms of theoretical bias, just as the scientifically innocent are, that is not enough to confer special authority on innocent judgment, given its characteristic sloppiness. Training in any intellectual discipline whatsoever has some tendency to instill unquestioning conformity to current basic assumptions in that discipline, and a consequent slowness to recognize errors in those assumptions. That is inevitable, for no progress is made when everything is put simultaneously into question. Fully trained practitioners can still obtain experimental results that undermine currently accepted theories. That can happen with philosophical thought experiments too, as the example of Gettier shows.10
The residual levels of disagreement in judgments between trained philosophers do not warrant wholesale skepticism about the method of thought experiments. Naturally, philosophical debates focus on points of disagreement, not on points of agreement. Most intellectual disciplines have learned to live with significant levels of disagreement between trained practitioners, concerning both theory and observation: philosophy is not as exceptional in this respect as some pretend.
10 Notoriously, eye-witnesses often disagree fundamentally in their descriptions of recent events, but it would be foolish to conclude that perception is not a source of knowledge, or to dismiss all eye-witness reports. To ignore the evidence of thought experiments would be a mistake of the same kind, if not of the same degree. Disagreement can provide a reason to be somewhat more cautious than we might otherwise have been, in our handling both of eye-witness reports and of thought experiments; such caution is commonplace in philosophy.
There is no need to be panicked into more extreme reactions.
This account has emphasized the epistemological continuity between verdicts on philosophical thought experiments and other judgments. That emphasis is supported by cases in which observations of real life do the same epistemological work as philosophical thought experiments. For instance, not all Gettier counterexamples are imaginary: sometimes a stopped watch really does show the right time. To make the point vivid, I have occasionally created Gettier cases for lecture audiences. For example, I have begun a lecture by apologizing for not giving a power-point presentation; I explained that the only time I gave a power-point presentation it was a complete disaster. Since my listeners had no reason to distrust me on a claim so much to my discredit, they acquired through my testimony the justified belief that the only time I gave a power-point presentation it was a complete disaster. They competently deduced that I had never given a successful power-point presentation. Thus they acquired the justified belief that I had never given a successful power-point presentation. That belief was true, but the reason was that I had never given a power-point presentation at all (and still do not intend to).
My assertion that the only time I had given a power-point presentation it was a complete disaster was a bare-faced lie.11 Thus they were basing their justified true belief that I had never given a successful power-point presentation on their justified false belief that the only time I had given a power-point presentation it was a complete disaster. Consequently, they did not know that I had never given a successful power-point presentation. The original audience encountered the case by living through it, others do so by reading my testimony, which is more similar to encountering a case by reading a fictional narrative. Either way, this actual Gettier case is a counterexample to
11

Someone commented 'You can’t believe the first thing he says.' the non-modal principle that knowledge coincides with justified true
A), belief in all actual cases; since actuality entails possibility (A
it is also a counterexample to the modal principle (1) that knowledge coincides with justified true belief in all possible cases.
What is striking about real life Gettier cases is how little difference they make. They are not markedly more or less effective as counterexamples to the target analysis than imaginary Gettier cases are.
Those who found the imaginary counterexamples convincing find the real life ones more or less equally convincing. Unless one is a skeptic about the external world, the reliance on empirical methods is no reason for serious doubt.12 Conversely, those who were suspicious of the imaginary counterexamples are more or less equally suspicious of the real life ones.
It might be replied that the process of classifying a real life instance of the Gettier case as an instance of justified true belief without knowledge involves a modal judgment, because it can be factorized into a deduction from the non-modal premise that this is an instance of the Gettier case and the modal premise that if something were an instance of the Gettier case it would be an instance of justified true belief without knowledge. However, such factorization is deeply problematic. Note first that the modal element in it is quite gratuitous; the deduction works just as well with the non-modal second premise that every (actual) instance of the Gettier case is an instance of justified true belief without knowledge. Furthermore, we have no good reason to insist on factorization here but not for utterly ordinary ascriptions of epistemological predicates, as when someone says that John does not know that the meeting has been cancelled. Nor have we any good reason to insist on it for ascriptions of epistemological predicates and not for ascriptions of other empirical predicates. But if factorization is ubiquitous, an infinite regress occurs. The process of classifying this as an instance of the Gettier case is itself factorized into a deduction from the non-modal premise that this is an instance of F and the modal premise that if something were an instance of F it would be an instance of the Gettier case. The process of classifying this as an instance of F would in turn be factorized into
12 a deduction from the non-modal premise that this is an instance of
E and the modal premise that if something were an instance of E it would be an instance of F, and so on. Plainly, no such infinite regress of inferences occurs in us. At some point, we simply apply our concepts to what confronts us, without relying on an inference from further premises. Why should that not happen with the original epistemological classification of the real life instance of the Gettier case?
No doubt epistemological facts supervene on non-epistemological facts (so that the non-epistemological facts in a suitable instance of the Gettier case determine that it is an instance of justified true belief without knowledge), but of course that does not entail that our epistemological beliefs are derived from non-epistemological beliefs. Our epistemological beliefs are certainly not inferred from our beliefs about microphysics, even if epistemological facts supervene on microphysical facts. Why should our epistemological beliefs be inferred from some other putative supervenience base? Most people have scarcely any idea how to formulate even approximately sufficient conditions in informative non-epistemological terms for epistemological conclusions. Even if they do happen to speculate along such lines, their speculations are far less secure epistemically than are their ordinary applications of epistemological concepts, so the latter do not depend on the former. The factorization hypothesis has little independent plausibility. Moreover, even if the factorization hypothesis were true, it would apply equally to non-philosophical applications of epistemological predicates in ordinary life and natural science, and so would indicate nothing distinctive about their applications in real-life instances of Gettier cases.
Removing the tricky apparatus of thought experiments and modal judgments does not reassure those who doubted that the subjects of
Gettier’s original examples lacked knowledge: whatever their rhetoric, their doubts did not really concern the method of thought experiments. Rather, they concerned the reliability of our epistemological judgments, whether modal or non-modal, in particular of our applications of the concepts of knowledge and justification.13 The switch
13

Objection: Nozick (1981: 172–96) analyzes knowledge in counterfactual terms; on his view, any judgment about knowledge implicitly involves judgments concerning counterfactual conditionals. Reply: First, the objection does not fully generalize, since it depends on a specific analysis of knowledge. Second, Nozick’s analysis does not make philosophers’ ascriptions of knowledge or of its absence any more modal than from an 'a priori' to an 'a posteriori' method here makes very little practical difference. We manifest recognition of this underlying cognitive similarity when we refuse to treat real life and fictional Gettier cases as mutually independent evidence against the justified true belief account of knowledge to a much greater extent than we treat two fictional Gettier cases as mutually independent evidence.

4
Let us now consider more carefully the fine structure of the major premises of the arguments which underlie philosophical thought experiments.
What is sometimes called 'the Gettier intuition' has been expressed by a counterfactual conditional in English, roughly:
(5) If a thinker were Gettier-related to a proposition, he/she would have justified true belief in it without knowledge.14
This was in turn symbolized by the formula (3*). Later, we will assess some alternative expressions of the Gettier intuition in English. For the time being, let us treat (5) as faithfully expressing the Gettier intuition, and ask whether (3*) faithfully enough formalizes (5).
We might query (3*) as a formalization of (5) on grounds of syntactic structure. Where (5) has the anaphoric pronouns 'he/she' and
'it,' (3*) repeats the material GC(x, p) and applies universal quantification. In fact, (5) is a case of 'donkey anaphora.' It is similar to (6):
(6) If a farmer owned a donkey, he would beat it.
non-philosophers’ ascriptions are. Third, skeptics about epistemological thought experiments typically make no appeal to counterfactual analyses of knowledge. After all, the way in which Nozick reaches his conclusions exemplifies the very methodology about which they are skeptical. Nor would they regard their skepticism as undermined by growing evidence that counterfactual analyses of knowledge are incorrect (Williamson 2000a: 147–63). Their skepticism is intended to get its grip irrespective of whether ascriptions of knowledge as such involve modal thinking.
14
To be Gettier-related here is to be related as specified in the given Gettier scenario, not merely to be related as in some Gettier scenario or other. Thought Experiments

This is just the 'subjunctive' analogue of the classic indicative donkey sentence (7):
(7) If a farmer owns a donkey, he beats it.
The standard first-order formalization of (7) is (8):
(8) ᭙x᭙y ((Farmer(x) & Donkey(y) & Owns(x, y))

Beats(x, y))

The main challenge is to explain how (7) can have the truth conditions of (8) in terms of a compositional semantics for (7), given the mismatch in syntactic structure between (7) and (8).15 For present purposes, however, what matters most is just getting the right truth conditions, up to logical equivalence. We might expect that if (7) has the same truth conditions as (8), then (6) will have the same truth conditions as the result of replacing the material conditional in (8)
by a counterfactual conditional:
(9) ᭙x᭙y ((Farmer(x) & Donkey(y) & Owns(x, y))

Beats(x, y))

The analogous formalization of (5) is not (3*) but (10):
(10)

᭙x᭙p (GC(x, p)

(JTB(x, p) &

K(x, p)))

In the indicative case, (8) is logically equivalent to the donkey analogue of (3*):
(11)

x y (Farmer(x) & Donkey(y) & Owns(x, y))
᭙x᭙y ((Farmer(x) & Donkey(y) & Owns(x, y))

Beats(x, y))

15
Elbourne (2005) is a recent discussion of the topic with further references. Some will judge 'If John had a dime, he would put it in the meter' true if in the relevant counterfactual circumstances John has two dimes and puts one in the meter. They may also have to judge 'If John had a dime, he would put it in his piggybank'
simultaneously true by parity of reasoning. There is no corresponding true reading of 'If John had a dime, he would put it in the meter and put it in his piggybank.'
All that is clearly true in the envisaged case is 'If John had a dime, he would put one in the meter.' For since (8) is the consequent of (11), (8) obviously entails (11), and conversely, if the antecedent of (11) is false then (8) is vacuously true, so (11) entails (8). However, the corresponding equivalence fails in the counterfactual case: (9) is not equivalent to (12).
(12)

x y (Farmer(x) & Donkey(y) & Owns(x, y))
᭙x᭙y ((Farmer(x) & Donkey(y) & Owns(x, y))

Beats(x, y))

For (12) is true and (9) false in the following circumstances. In the actual world (and, if you like, in all close ones) some farmer owns some donkey and every farmer who owns a donkey beats it. Farmer
Giles could have owned this donkey, although he does not own it in the actual world (or in any close one). If he owned it, he would not beat it. Similarly, (10) is not equivalent to (3*). For (3*) is true and
(10) false in the following circumstances. In the actual world (and, if you like, in all close worlds) someone is Gettier-related to some proposition and everyone who is Gettier-related to a proposition has justified true belief in it without knowledge. That woman could have been Gettier-related to that proposition, although she is not Gettierrelated to it in the actual world (or in any close world). If she had been Gettier-related to it, she would have lacked justified belief in it
(perhaps because making the relevant inference would have caused her to lose justification for the premise rather than gain it for the conclusion). Thus if (5) and (6) respectively have the same truth conditions as (10) and (9), then they have different truth conditions from (3*) and (12). One might therefore conclude that (3*) does not capture the truth conditions of (5).
However, there is reason to doubt that (5) and (6) respectively do have the same truth conditions as (10) and (9). Consider another sentence of the same form:
(13)

If an animal escaped from the zoo, it would be a monkey.

The formalization of (13) corresponding to (9) and (10) is (14):
(14)

᭙x ((Animal(x) & Escapedzoo(x))

Monkey(x)) (13) is not trivially false; it may well be true. Thus (13) does not have the same truth conditions as (14). For similar reasons, (5) and (6)
respectively seem to differ in truth conditions from (10) and (9).
Indeed, the very examples used to establish that (3*) and (12) respectively differ in truth conditions from (10) and (9) tell in favor of (3*)
and (12) rather than (10) and (9) as formalizations of (5) and (6), on at least one reading. Suppose that in the actual world (and, if you like, in all close ones) some farmer owns some donkey and every farmer who owns a donkey beats it; Farmer Giles could have owned this donkey, although he does not own it in the actual world (or in any close one); if he owned it, he would not beat it. In these circumstances, (6) seems to be true on at least one reading, and thereby to have the same truth-value as (12) rather than (9). Similarly, suppose that in the actual world (and, if you like, in all close worlds) someone is Gettier-related to some proposition and everyone who is Gettierrelated to a proposition has justified true belief in it without knowledge; that woman could have been Gettier-related to that proposition, although she is not Gettier-related to it in the actual world (or in any close world); if she had been Gettier-related to it, she would have lacked justified belief in it. In these circumstances, (5) seems to be true on at least one reading, and thereby to have the same truth-value as (3*) rather than (10).16
We can formalize (13) along the lines of (3*) and (12):
(15)

x (Animal(x) & Escapedzoo(x))
᭙x ((Animal(x) & Escapedzoo(x))

Monkey(x))

This deals with the elephant problem. For (15) is true if, had some animal escaped, only monkeys would have escaped; it does not entail that if the elephant had escaped, it would have been a monkey.
The example of (13) also supports the use of universal quantification in the consequents of (3*) and (12). For suppose that, if some animal had escaped, both a monkey and an elephant would have escaped: then (13) is not true. It is not the case both that if an animal escaped it would be a monkey and that if an animal escaped it would
As can easily be checked, placing Farmer(x) & Donkey(x) in (9) and Animal(x)
in (14) outside the scope of makes no serious difference to the argument.
16

Thought Experiments be an elephant. Thus (13) is not equivalent to the result of replacing universal quantification in the consequent of (15) by existential quantification:
(16)

x (Animal(x) & Escapedzoo(x))
x (Animal(x) & Escapedzoo(x) & Monkey(x))

In sloppy terms, what is wrong with (16) as a formalization of (13)
is that it does not require the escaping animal with which we started to be a monkey; it is satisfied if some other escaping animal is a monkey. That is not enough to vindicate (13). Analogous points apply to (5) and (6). For purposes of deriving (4), we could have used
(17) in place of (3*):
(17)

x p GC(x, p)

x p (GC(x, p) & JTB(x, p) & K(x, p))

But (17) does not entail (5). In sloppy terms, what is wrong with (17)
as a formalization of (5) is that it does not require the instance of the
Gettier case with which we started to be an instance of justified true belief without knowledge; it is satisfied if some other instance of the
Gettier case is an instance of justified true belief without knowledge.
That is not enough to vindicate (5). Formalizing (5) as (3*) avoids this problem.17
Henceforth, we assume that (3*) adequately formalizes the English counterfactual sentence (5).18 But does (5) adequately express 'the
Gettier intuition'? Such truth conditions emerge naturally from accounts that analyze anaphoric pronouns in terms of (not obligatorily singular) definite descriptions (Davies 1981:
166–76, Neale 1990: 180–91); Elbourne (2005) develops a related approach within a framework of situation semantics. It may be less straightforward for alternative approaches to donkey anaphora (such as those based on discourse representation theory or dynamic semantics, for example van Rooij (2006)) to deliver appropriate truth conditions for the relevant sentences: but perhaps it can be done.
18
For an alternative approach to formalizing the Gettier argument, see
Appendix 2. Thought Experiments

5
One might worry that the counterfactual claim (5) overstates the
Gettier intuition, just as the claim of strict implication (3) turned out to do. If the actual world happens to contain an abnormal instance of the Gettier case that is not an instance of justified true belief, however many normal instances it also contains that are instances of justified true belief without knowledge, the counterfactual (5) is still false. It is false too if, although the actual world contains no instance of the Gettier case, it happens to be such that if there had been instances, they would have included an abnormal one which was not an instance of justified belief. If it is still possible to have normal instances of the Gettier case which are instances of justified true belief without knowledge, the Gettier intuition might be regarded as still correct, and therefore as not adequately formalized by the false counterfactual (5). Why make the premise of the Gettier argument unnecessarily strong?
We might alleviate the problem by understanding the quantifiers in the formalization (3*) of (5) as restricted by the conversational context. For example, it might sometimes exclude instances of the
Gettier case on Alpha Centauri. However, such restrictions are unlikely to provide a complete solution. For even the contextually relevant domain may happen to betray our expectations.
Here is a simple example. Hank is better at logic than at geography. He wants to refute someone’s claim that it is impossible validly to deduce a true conclusion from a false premise. Since he falsely believes that Glasgow is in England, he presents a thought experiment in which 'Glasgow is in England or Glasgow is in France' is deduced from 'Glasgow is in France.' Contextual restrictions do not save
Hank. What should we say about this case?
As it stands, Hank’s counterexample does not work, and his belief that it works is mistaken. But when the mistake is pointed out, he has no difficulty in repairing it. The easiest repair is simply to substitute 'Scotland' for 'England.' Alternatively, he might stipulate that in his thought experiment Glasgow is in England. One mild disadvantage of the latter stipulation is that it makes the thought experiment depend on an assumption about the contingency of national boundaries which is irrelevant to the logical point at issue. What would be childish on Hank’s part would be to insist that his original thought experiment already constituted a correct counterexample, before he made the stipulation, because he believed that Glasgow was in England, and it could have been, so the thought experiment could have been realized in line with his beliefs and, if it had been, it would have been a case of a valid deduction from a false premise to a true conclusion. Although Hank may insist that Glasgow was in England in the case which he had in mind, that was just not the 'counterexample' which he actually presented. He spoke falsely when he first said 'Someone who infers 'Glasgow is in England or Glasgow is in
France' from 'Glasgow is in France' has validly deduced a true conclusion from a false premise.' Similarly, suppose that someone says 'Every man in the room is wearing a tie'; I look around, see a man not wearing a tie, misidentify him as Dave (who is in fact wearing a tie), and say 'Dave isn’t.' When it is pointed out to me that Dave is wearing a tie, I deceive myself if I insist that my original reply was correct because the man whom I had in mind was not wearing a tie; that was just not the 'counterexample' I actually presented. I spoke falsely when I said 'Dave isn’t.' Even if the audience shares the speaker’s false belief that Glasgow is in England or that the man over there is Dave, a third party overhearing the conversation can know that the 'counterexample' as it stands is incorrect.
For a thought experiment to constitute a counterexample, it is not sufficient that some counterfactual filling out of it, no matter how far-fetched, constitutes a counterexample.
Many philosophers have the common human characteristic of reluctance to admit to having been wrong. We should not distort our account of thought experiments in order to indulge that tendency.
Often purported counterexamples fail for accidental reasons and can easily be repaired. To attempt to build into the counterexample in advance all repairs which might conceivably be needed is a futile exercise. It loads the purported counterexample with complexity and in the process weakens it in other respects. The repairs need not articulate qualifications that were in some obscure sense implicit in the thought experiment from the beginning. Rather, they genuinely modify the thought experiment, but the similarity of the new thought experiment to the old one is evidence that the old one was not far wrong.
An example is this. If one is working in the modal system S5, one can weaken the counterfactual premise (3*) to its mere possibility: Thought Experiments

(3**)

( x p GC(x, p)
᭙x᭙p (GC(x, p)

(JTB(x, p) &

K(x, p))))

The reason is that in S5, given the necessity of the POSSIBILITY
principle, one can reason from A and (A
B) to B. For
B to A
B, it since POSSIBILITY allows the move from A
B) to ( A
B). But in S5 the also allows the move from (A
B
application of and to fully modalized formulas such as A
is redundant (modal matters are not themselves contingent), so
( A
B) entails A
B. Consequently, (A
B) entails
A
B. In particular, we can deduce (4) from (2) and (3**). Thus one might be tempted to weaken the counterfactual premise to (3**).
But that move has its costs too. For it makes thought experiments depend on the soundness of the characteristic principles of S5, whereas the original analysis in terms of (3*) rather than (3**) involved no such commitment.19 Moreover, it is strained to attribute the commitment to S5 to people who have never considered the matter when their reasoning can readily be rationalized without it, as before.
Another watering down of the counterfactual premise is to its dual, the negation of the opposite counterfactual:
(3***)

( x p GC(x, p)
᭙x᭙p (GC(x, p)

(JTB(x, p) &

K(x, p))))

Indeed, from (3***) one can reason to (4) without invoking (2) as a separate premise.20 Roughly speaking, (3***) says that if the Gettier case had an instance, it might be an instance of justified true belief without knowledge, rather than that it would be. But (3***) falls
Strictly speaking, one must check that that the inference schema from (A
B)
to A
B requires the characteristic S5 schema, A
A. But substituting A
for A and the contradiction for B in the inference schema gives the inference from
( A
) to
A
. Since A
is just the counterfactual equivalent of
A from the previous chapter and
A
is equivalent to A by normal modal logic, that is tantamount to the inference from A to A, which is equivalent to the
S5 schema, as required.
20
From the negation of (4) one infers ᭙x᭙p (JTB(x, p)
K(x, p)) and thence
( x p GC(x, p)
᭙x᭙p (GC(x, p)
(JTB(x, p) & K(x, p)))) by standard quantified modal logic; the negation of (3***) follows by the NECESSITY principle in the previous chapter. Similarly, the negation of (3***) follows from the negation of (2). Thus both (2) and (4) follow from (3***).
19 short of normal standards of adequacy for thought experiments.
Suppose that a slow-witted philosopher wants to test the hypothesis that the objective probability of a false belief cannot be greater than
99 percent. He imagines himself having bought one ticket in a fair lottery of a thousand tickets with only one winner, believing before the draw that his ticket will lose. He notes that the objective probability of his belief would be greater than 99 percent. However, he has not yet considered whether the scenario is to be one in which his ticket wins. By normal standards, he has not yet determined a counterexample to the hypothesis, although he will have done so once he specifies that in the scenario his ticket wins.21 Yet presumably the analogue of (3***) already holds for his unspecific scenario. It is not true that if the unspecific scenario were realized, his ticket would lose
– it might win. Normal standards of adequacy for thought experiments require something much more like (3*) than like (3***). A
similar objection applies to (3**) too.
At the limit, it may be suggested that the role of the Gettier thought experiments is to supply not premises for the conclusion (4) but instead something more like a causal basis for assenting to (4).
However, such an undifferentiated account fails to capture what is rational about our rejection of the target analysis. It does not articulate the evidential role of the Gettier case. In most valid deductions, the premises are collectively stronger than the conclusion: that is, the conclusion does not entail every premise. Therefore, they are unnecessarily strong in a purely logical sense. But that sense is not the one that matters. Epistemically and dialectically, the 'unnecessarily strong' premises may be exactly what we need. Although their extra strength sometimes leads to trouble, and revision is required, we should not try to cross all such bridges right now, before we come to them; many of them we shall never need to cross.
In any field, arguments are subject to inessential problems of various kinds. Once such problems are identified, they can be fixed without too much difficulty or damage to the original purpose of the argument. We may well be warranted in continuing to attribute the
'essential insight' for the argument to its originator, despite his or her minor slips, as we might for the proof of a mathematical theorem.
Where reasoning is most explicit, in logic and mathematics, the
21 history of mistakes and corrections is often easily documented. Where reasoning is less explicit, as in philosophy, there is more scope for cover-ups. Nevertheless, we should expect that the same process of fine-tuning occurs for philosophical thought experiments as elsewhere. We should not confuse subsequent fallbacks with the original claims. Unnatural formulations such as (3**) and (3***) are far more likely to be the fallbacks than to be the original claims. But even when lacunae are identified in a thought experiment, the most likely response in practice is just to add further stipulations to the specification of the case, as it were simply to replace GC(x, p) by GC (x, p), so as to preserve the original structure of argument.22 We resort to the likes of (3**) and (3***) only in exceptional circumstances.
One may even wonder whether the move to the counterfactual conditional (3*) from the strict conditional (3) represents another such fallback. Perhaps: but the question 'If there had been an instance of this case, would it have been an instance of justified true belief without knowledge?' seems quite a natural way of articulating what is at stake with a Gettier counterexample. The corresponding questions for (3**) and (3***) seem less natural. Moreover, counterfactual questions arise continually in everyday thought, whereas questions of metaphysical necessity rarely arise outside philosophy, so the burden of proof is on those who claim that our initial questions about a hypothetical case are metaphysically modal rather than simply counterfactual in nature. We may, therefore, treat a counterfactual analysis of the arguments underlying philosophical thought experiments as the default. In particular, we may continue to view the Gettier argument as something like the argument from (2) and
(3*) to (4).

6
In the original paper, Gettier presents his cases as indicative suppositions. He uses no 'subjunctive' conditionals. Although he describes
Merely adding the stipulation that x and p constitute a normal instance of the
Gettier case is unlikely to solve the problem, for the relevant notion of normality is an epistemological one that violates the supposed neutrality of the initial description of the case. Thought Experiments 207

his target as an attempt 'to state necessary and sufficient conditions for someone’s knowing a given proposition' (1963: 121), not as an attempt to analyze the concept of knowledge, we cannot take it for granted that his concern was the metaphysical possibility of justified true belief without knowledge rather than its possibility in some other senses. He wrote before Kripke made the relevant distinctions salient.
Gettier’s intentions aside, why should we not interpret his examples in terms of some non-metaphysical notion of possibility? For instance, we might read the target analysis as the claim that it is conceptually necessary that knowledge coincides with justified true belief. We should then read premise (2) and the conclusion (4) as saying respectively that the Gettier case and justified true belief without knowledge are conceptually possible. If we read (3) as saying that it is conceptually necessary that every instance of the Gettier case is an instance of justified true belief without knowledge, the argument from (2) and (3) to (4) should be valid.
Unfortunately for this reading, the claim that every instance of the
Gettier case is an instance of justified true belief without knowledge is unlikely to be conceptually necessary in any useful sense, even if we bracket the general doubts in previous chapters about conceptual modalities. The reason is very similar to that for which we weakened the strict implication premise (3) to the counterfactual conditional premise (3*). On any reasonable understanding of the phrase 'conceptually possible,' it is conceptually possible that some abnormal instance of the Gettier case is not an instance of justified true belief.
However, we cannot simply replace the claim of conceptual necessity by the counterfactual premise (3*). For the argument from (2) and
(3*) to (4) is invalid if the possibility operator in (2) and (4) is understood as conceptual. The POSSIBILITY principle that a counterfactual conditional transmits possibility from its antecedent to its consequent holds for metaphysical but not for conceptual possibility.
For instance, friends of conceptual possibility typically think that it is conceptually possible that Hesperus is not Phosphorus but not conceptually possible that Phosphorus is not Phosphorus. But we saw in the previous chapter that the counterfactual conditional 'If Hesperus was not Phosphorus, Phosphorus would not be Phosphorus'
follows by the logic of identity and counterfactuals from the true identity statement 'Hesperus is Phosphorus.' Thought Experiments

If the argument from (2) and (3*) to (4) is to be reworked in terms of conceptual possibility, we need a conditional for (3*) that stands to conceptual possibility as the counterfactual conditional stands to metaphysical possibility. It is doubtful that the ordinary indicative conditional will do, for 'If Hesperus is not Phosphorus, Phosphorus is not Phosphorus' also seems to follow by the logic of identity from
'Hesperus is Phosphorus' and the triviality 'If Hesperus is not Phosphorus, Hesperus is not Phosphorus.'
Even if we succeeded in cooking up a suitable conditional for (3*)
in respect of conceptual possibility, the reinterpreted argument would show little of philosophical interest. The conclusion would be that it is conceptually possible to have justified true belief without knowledge. That does not refute the hypothesis that knowledge just is justified true belief, of metaphysical necessity, any more than the conceptual possibility of something with atomic number 79 that is not gold refutes the hypothesis that gold just is the element with atomic number 79, of metaphysical necessity. The primary concern of epistemology is with the nature of knowledge, not with the nature of the concept of knowledge. If knowledge were in fact identical with justified true belief, that would be what mattered epistemologically, irrespective of the conceptual possibility of their non-identity. Presumably, if the concept of knowledge were the concept of justified true belief, that identity of concepts would entail the identity of natures, but the converse fails: the non-identity of concepts does not entail the non-identity of natures.
The result of a Gettier thought experiment, interpreted in terms of mere conceptual possibility, would be of significance primarily to theorists of concepts, not to epistemologists. Similarly, the result of a thought experiment in moral philosophy, interpreted in terms of mere conceptual possibility, would be of significance primarily to theorists of concepts, not to moral philosophers. The same would apply to thought experiments in other branches of philosophy. But the use of thought experiments is not confined to the theory of concepts; it flourishes in most branches of philosophy. Consequently, we need an interpretation of them where the possibility at issue is not merely conceptual. The sort of possibility most relevant to the nature of the phenomena under investigation is metaphysical. That fits the approach of this chapter. Nor should we forget how badly the idea of conceptual modality fared under examination in earlier chapters. The present reflections reinforce the earlier conclusion that it is not a fit instrument for understanding philosophical inquiry.
Related criticisms would apply to the interpretation of philosophical thought experiments in terms of epistemic modalities other than conceptual possibility and necessity. The upshot of a thought experiment in the philosophy of X would be the epistemic possibility (in some sense) of some state of affairs concerning X, not the metaphysical possibility of that state of affairs. That would teach us about the epistemology of beliefs about X, not directly about the nature of X
itself. Of course, the epistemology of beliefs about X may indirectly teach us something about the nature of X itself. Indeed, for X =
knowledge, the epistemology of beliefs about knowledge is a special case of the philosophy of knowledge, although hardly a representative one. But philosophy does not in general take the diversion of studying X through studying the epistemology of beliefs about X. A
more direct approach is feasible. Thus the interpretation of philosophical thought experiments in terms of epistemic possibility is typically inappropriate. Although we may occasionally wish to use them to learn about the epistemology of the object of our study, often we wish to learn more directly about the object of our study itself, in which case a different interpretation of thought experiments is required. The possibility we need then is metaphysical, not epistemic.
Thus the non-epistemic approach of this chapter is more widely applicable. Paradigm thought experiments in philosophy are simply valid arguments about counterfactual possibilities.

7
Evidence in Philosophy

1
In most intellectual disciplines, assertions are supposed to be backed by evidence. Mathematicians have proofs, biochemists have experiments, historians have documents. You cannot just say whatever you happen to believe. Is philosophy an exception? That hardly fits the emphasis many philosophers place on arguing for one’s claims. When they cannot provide a deductive argument, they still offer supporting considerations. Often they cite phenomena which, they suggest, their theory best explains: they provide abductive arguments. Indeed, in the last three sentences I gave evidence that philosophers give evidence; so philosophers do sometimes give evidence. Of course, philosophers who give evidence that evidence is relevant in philosophy can be accused of begging the question. But let us proceed on the working hypothesis that evidence plays a role in philosophy not radically different from its role in all other intellectual disciplines. Without such a role, what would entitle philosophy to be regarded as a discipline at all?
To describe mathematics, biochemistry, and history as evidencebased disciplines is obviously not to subscribe to any extreme foundationalism. Particular appeals to proofs, experiments, and documents can all be questioned. The same goes for philosophy.
In any evidence-based discipline, it is good for an assertion to be consistent with the evidence. The alternative is inconsistency with the evidence, which is bad. Since consistency and inconsistency are relations among truth-evaluable items, evidence will be treated as consisting of such items, in particular, of propositions. In this sense, the historical evidence is not the physical document itself but various propositions about it, for example that it is signed 'John.' The biochemical evidence is not the experiment as an event but, for example, the proposition that it was carried out with such-and-such results.
The mathematical evidence is not the proof as a sequence of steps but, for example, the proposition that the sequence is a correct proof of this claim. This propositional conception of evidence fits the discursive nature of philosophy. When philosophers produce evidence, they produce something truth-evaluable.1
Why is it bad for an assertion to be inconsistent with the evidence?
A natural answer is: because then it is false. That answer assumes that evidence consists only of true propositions. For if an untrue proposition p is evidence, the proposition that p is untrue is true but inconsistent with the evidence. Using 'fact' for 'true proposition,'
we may say that evidence consists only of facts. That helps explain the point of conforming one’s beliefs to the evidence.
Although all evidence is true, not all truths are evidence. Some sort of epistemic accessibility is required. Internalists about evidence require the accessibility to be independent of the environment external to the thinker; externalists about evidence reject that requirement.
This difference generates a further difference as to what sorts of facts are capable of being evidence. These issues will be considered later.
Since all evidence is true, whatever the evidence entails is also true.
The evidence can still support a false proposition non-deductively. If you have not yet heard the result of the lottery, your evidence strongly supports the proposition that your ticket lost, even if in fact it won.
Your evidence consists of truths about the lottery available to you at the time.
How can all evidence be true when sometimes the evidence offered turns out to be false? The document was mistranscribed; it was signed
'Joan,' not 'John.' But the claim that it was signed 'Joan' was not really inconsistent with the evidence before the mistranscription was recognized. It was only inconsistent with what was then taken to be the evidence. It was consistent with the fact that the document was transcribed as signed 'John.' No evidence was lost when the mistranscription was recognized, and the claim that the document was
1

Williamson (2000a: 194–200) argues in more detail that propositionality is essential to the functional role of evidence (for the purposes of this chapter, little turns on the choice between sentences and propositions). signed 'Joan' is consistent with the present evidence, so it was consistent with the past evidence. Similarly, biochemists who rely on the misreported results of an experiment are mistaken in saying that part of their evidence for a theory is that the experiment was performed with such-and-such results. Mathematicians who overlook a fallacy in a proof are mistaken in saying that their evidence for the purported theorem is that this sequence of steps is a correct proof of it. Practitioners of any discipline sometimes mistake the extent of their evidence. What is offered as evidence is not always evidence.
Since we can mistake the extent of our evidence, it can be controversial whether a given proposition is evidence. When evidence is not recognized as such, it cannot play its proper role in inquiry. If its status as evidence is controversial, it is not part of the common ground in debate. Relying on a premise one’s opponents have already refused to accept tends to be dialectically useless. They will probably deny that it constitutes evidence; one’s argument will make no headway. As far as possible, we want evidence to play the role of a neutral arbiter between rival theories. Although the complete elimination of accidental mistakes and confusions is virtually impossible, we might hope that whether a proposition constitutes evidence is in principle uncontentiously decidable, in the sense that a community of inquirers can always in principle achieve common knowledge as to whether any given proposition constitutes evidence for the inquiry.
Call that idea Evidence Neutrality. Thus in a debate over a hypothesis h, proponents and opponents of h should be able to agree whether some claim p constitutes evidence without first having to settle their differences over h itself. Moreover, that agreement should not be erroneous: here as elsewhere, 'decidable' means correctly decidable.
Barring accidents, if they agree that p constitutes evidence, it does; if they agree that p does not constitute evidence, it does not.
One problem for Evidence Neutrality is that the nature of evidence is itself philosophically controversial, as may already be obvious. For example, suppose that a philosophical theory T entails that every mathematical theorem is evidence, while another philosophical theory
T* entails that no mathematical theorem is evidence. When proponents of T debate with proponents of T*, whether a given mathematical theorem is evidence is in principle uncontentiously decidable neither positively (since proponents of T* are committed to saying that it is not) nor negatively (since proponents of T are committed to saying that it is). This objection has the faint air of a self-reflexive paradox, however; perhaps it is an isolated singularity. We turn to more general problems for Evidence Neutrality.
Arguing from the Gettier proposition that the subject in a Gettier case lacks knowledge, I conclude that knowledge is not equivalent to justified true belief. Now I meet someone who thinks the Gettier proposition a mere cultural prejudice, not itself evidence. In this context, it is not in principle uncontentiously decidable that the Gettier proposition is evidence. Thus the only way to satisfy Evidence Neutrality is by ruling that the Gettier proposition does not constitute evidence. To argue that knowledge is not equivalent to justified true belief, I must go back a step to less contentious premises. What can they be? My opponent allows that I believe the Gettier proposition, and may even admit to feeling an inclination to believe it too (I am not merely idiosyncratic), while overriding it on theoretical grounds. Thus Evidence Neutrality tempts one to retreat into identifying evidence with uncontentious propositions about psychological states, that I believe the Gettier proposition and that both of us are inclined to believe it.
How much that helps is questionable. For now I face the challenge of arguing from a psychological premise, that I believe or we are inclined to believe the Gettier proposition, to an epistemological conclusion, the Gettier proposition itself. That gap is not easily bridged.
The example depends on no special feature of the Gettier proposition. Any such premise can be questioned and usually is, by skeptics of one sort or another. The dialectical nature of philosophical inquiry exerts general pressure to psychologize evidence, and so distance it from the non-psychological subject matter of the inquiry.
Attempts have been made to close the gap by psychologizing the subject matter of philosophy. If we are investigating our own concepts, our applications of them must be relevant evidence. But this proposal makes large sacrifices for small gains. As seen in earlier chapters, the subject matter of much philosophy is not conceptual in any distinctive sense. Many epistemologists study knowledge, not just the ordinary concept of knowledge. Metaphysicians who study the nature of identity over time ask how things persist, not how we think or say they persist. In such inquiry, the gap between belief and truth is of the same kind as in most non-philosophical inquiry, and the proposal offers little help. Even when one of our own concepts is our subject matter, our inclination to apply it in a given case by no means guarantees that the application is correct. Cultural prejudices really do sometimes wear the mask of self-evident truth. More generally, the problem with attempts to defend the philosophies of mind and language on the grounds that beliefs about mind and language have a special epistemic status, because they help to constitute their own subject matter, is not just that to extend the argument to other branches of philosophy is to succumb to the usual idealist fallacies.
The argument is weak even for the philosophies of mind and language, since our beliefs about our own mind and language can be false for any number of reasons.2 The gap between belief and truth never completely disappears.
Evidence Neutrality has no more force in philosophy than in other intellectual disciplines: philosophers are lucky if they achieve as much certainty as the natural sciences, without quixotic aspirations for more. If Evidence Neutrality psychologizes evidence in philosophy, it psychologizes it in the natural sciences too. But it is fanciful to regard evidence in the natural sciences as consisting of psychological facts rather than, for example, facts about the results of experiments and measurements. When scientists state their evidence in their publications, they state mainly non-psychological facts (unless they are psychologists); are they not best placed to know what their evidence is?
The psychologization of evidence by Evidence Neutrality should be resisted in the natural sciences; it should be resisted in philosophy too. Moreover, not even psychologizing evidence suffices to meet the demands of Evidence Neutrality. For ascriptions of beliefs or inclinations to belief are contestable too, in ways sketched later in this chapter.
Evidence Neutrality is false. Having good evidence for a belief does not require being able to persuade all comers, however strange their views, that you have such good evidence. No human beliefs pass that test. Even in principle, we cannot always decide which propositions constitute evidence prior to deciding the main philosophical issue; sometimes the latter is properly implicated in the former. Elsewhere,
I have argued on more general grounds that we are not always in a position to know whether a proposition constitutes evidence
(Williamson 2000a: 93–113, 147–83; 2008a). That argument implies
2

Hintikka (1999) argues that philosophical appeals to 'intuitions' were inspired by the paradigm of Chomsky’s linguistics. the same conclusion, for when it cannot be known whether p constitutes evidence, it is not in principle uncontentiously decid-able whether p constitutes evidence. Of course, we can often decide whether a proposition constitutes evidence prior to deciding the main issue, otherwise the notion of evidence would be useless. But the two sorts of question cannot be kept in strict isolation from each other.
In this respect, philosophy is no different in principle from inquiry in other areas. Since comprehensive physical theories have implications for the reliability of various forms of observation and measurement, they are not neutral as to which reports of such processes constitute evidence. Which axioms of set theory are legitimately assumed in mathematical proofs is itself a mathematical question.
Most of the evidence historians cite can be disputed on the basis of perverse conspiracy theories, which are themselves historical theories, however bad. Although philosophy is unusually tolerant of challenges to evidence, no discipline can afford to exclude them altogether, on pain of fatal gullibility.
How much do failures of Evidence Neutrality threaten the conduct of philosophy? From an internal perspective, they make consensus harder. Each of many conflicting theories may be the one best supported by the evidence by its own lights. The role of evidence as a neutral arbiter is undermined. From an external perspective, both the good fortune of being right and the misfortune of being wrong are magnified. If your theory is true, so are its consequences for which propositions constitute evidence; it will be a reliable methodological guide in your further theorizing. If your theory is false, it may have false consequences for which propositions constitute evidence and be an unreliable guide in your further theorizing (if you are very lucky, its falsity is confined to other areas). Although both internal and external effects are damaging, neither is fatal if the failures of Evidence Neutrality are limited enough. The predicament is not special to philosophy, although it may be worse there than elsewhere. It is not in practice fatal to other disciplines; it is not in principle fatal to philosophy.
Unfortunately, the difficulties consequent on failures of Evidence Neutrality are compounded by unawareness of them in much philosophical writing. That unawareness does more than distort philosophers’ descriptions of philosophy. It alters their first-order philosophizing, because the regulation of philosophical debate must be informed by a conception of its nature. For example, the popular but unclear accusation of 'question-begging' is leveled on the basis of assumptions about the scope and purpose of philosophical argument.3 Philosophers under the influence of Evidence Neutrality tend to reject evidence which is not in principle uncontentiously recognizable as such.
These questions are explored below in more detail. They arise with particular urgency from talk of 'intuitions.' When contemporary analytic philosophers run out of arguments, they appeal to intuitions.
It can seem, and is sometimes said, that any philosophical dispute, when pushed back far enough, turns into a conflict of intuitions about ultimate premises: 'In the end, all we have to go on is our intuitions.'
Thus intuitions are presented as our evidence in philosophy.
I have heard a professional philosopher argue that persons are not their brains by saying that he had an intuition that he weighed more than three pounds. Surely there are better ways of weighing oneself than by intuition. But such inapposite appeals to intuition should not be dismissed as mere idiosyncratic misjudgments. They are clues to the role of the term 'intuition' in contemporary analytic philosophy.
Its use may reflect the tacit influence of Evidence Neutrality.
That philosopher knew that if he had simply said that he weighed more than three pounds, rather than that he had an intuition that he weighed more than three pounds, he would have been accused of naïvely begging the question against those who identify persons with their brains. Their theory of personal identity may commit them to denying that he weighed more than three pounds, but not to denying the psychological claim that he had the intuition that he weighed more than three pounds. Thus he used the term 'intuition' in an attempt to formulate a psychological premise, not directly about the subject matter of the dispute, which his opponents would concede.
Had he been more artful, he might have said that his body weighed more than three pounds, and that he had the intuition that he weighed the same as his body, since they might have conceded both those premises too, and the latter 'intuition' has a less empirical flavor.
3

See Sinnott-Armstrong (1999) for some of the complexities. Naïve attempts to define 'begging the question' typically count all deductively valid arguments as question-begging (if you reject the conclusion, you cannot consistently accept the premises). The point of such maneuvers is primarily dialectical, to find common ground on which to argue with the opponent at hand. The rest of us can be still more confident that he weighed more than three pounds than that he had an intuition that he weighed more than three pounds – he had more chance of deceiving himself or others on the latter point than on the former. But even the dialectical value of such maneuvers is dubious. For if his opponents concede that he has the intuition, they will challenge him to argue from the occurrence of the intuition to its truth: how is he to do that? The simple premise that he weighs more than three pounds at least has the merit of bearing directly on the subject matter of the dispute. Nor need his opponents even concede that he has an intuition that he weighs more than three pounds. They may argue that he is reporting an intuition with some other content, or something other than an intuition.
'Intuition' plays a major role in contemporary analytic philosophy’s self-understanding. Yet there is no agreed or even popular account of how intuition works, no accepted explanation of the hoped-for correlation between our having an intuition that P and its being true that P. Since analytic philosophy prides itself on its rigor, this blank space in its foundations looks like a methodological scandal. Why should intuitions have any authority over the philosophical domain?

2
What are intuitions supposed to be, anyway? Let us start by considering a minimalist answer. For David Lewis, 'Our ‘intuitions’ are simply opinions' (1983a: x). For Peter van Inwagen, 'Our ‘intuitions’ are simply our beliefs – or perhaps, in some cases, the tendencies that make certain beliefs attractive to us, that ‘move’ us in the direction of accepting certain propositions without taking us all the way to acceptance' (1997: 309; he adds parenthetically 'Philosophers call their philosophical beliefs intuitions because ‘intuition’
sounds more authoritative than ‘belief’'). If all beliefs or tendencies to belief count as intuitions, then reliance on intuitions is in no way distinctive of philosophy. No scientific progress can be made without reliance on some beliefs and tendencies to belief: simultaneous universal doubt is a dead-end. In the metaphilosophical debate, that the subject in a Gettier case lacks knowledge is standardly taken as the content of a paradigmatic philosophical intuition. The account of this example in the previous chapter fits indiscriminate characterizations of intuition like Lewis’s and van Inwagen’s. Our belief in the Gettier proposition (3*) depends on our capacity to apply epistemological concepts online to encountered instances, our general capacity to apply concepts we can apply online offline too, in the imagination, and our capacity to use such imaginative exercises to evaluate counterfactual conditionals. Far from the brute simplicity which the term 'intuition' may suggest, that basis involves complexities absent from the basis of the corresponding judgment about a perceptually encountered Gettier case.
For most philosophical purposes, however, the differences between fictional and real-life instances of the Gettier case turned out to be unimportant; what matter are the relevant applications of epistemological concepts, whether offline or online. Nor were those applications especially intimately connected to grasp of the relevant concepts, as some rationalists suggest (Bealer 1998, 2002). Many people grasp the concepts in question without feeling inclined to assent to the Gettier proposition. What they lack is a skill in applying those concepts which goes beyond mere possession. Those who respond correctly to the Gettier case, presented in imagination or perception, do so on the basis of skill in applying the concepts; possessing them is insufficient. None of this encourages the use of the
Gettier 'intuition' as an exemplar to pick out a special psychological or epistemological kind to which the term 'intuition' could helpfully applied.
Epistemologically, the most significant feature of the example may be that many of us know the truth of the Gettier proposition. But those trying to demarcate a distinctive category of intuition usually insist that there are false intuitions as well as true ones; they do not project truth from the Gettier example to other cases (for example,
Sosa 2006).
George Bealer conceives (rational) intuitions as intellectual seemings (1998: 207; 2002: 73). Background information can defeat our inclination to take perceptual or intellectual seemings at face value.
Although we are tempted to believe that one line is longer than the other in the Müller-Lyer illusion, we resist the temptation when we know better. Similarly, the Naïve Comprehension principle for sets, by which any predicate has a set as its extension, seems true, although we know it to be false, since it is inconsistent by Russell’s paradox.
But intellectual seemings typically lack the rich phenomenology of perceptual seemings. In its perceptually appearing that something is so, normally in the same event much else perceptually appears too: that various things have various specific shapes and sizes, colors, sounds, tastes, textures, smells . . . Even very primitive sensations have a specific quality of their own. By contrast, in the moment of its intellectually appearing that something is so, often nothing much else intellectually appears. Although mathematical intuition can have a rich phenomenology, even a quasi-perceptual one, for instance in geometry, the intellectual appearance of the Gettier proposition is not like that. Any accompanying imagery is irrelevant. For myself, I am aware of no intellectual seeming beyond my conscious inclination to believe the Gettier proposition. Similarly, I am aware of no intellectual seeming beyond my conscious inclination to believe Naïve Comprehension, which I resist because I know better. I can feel such an inclination even if it is quite stably overridden, and I am not in the least danger of giving way to temptation (just as one can feel the inclination to kick someone without being in the least danger of giving way). Of course, dwelling introspectively for long on any belief or inclination to believe has its characteristic phenomenology, but that is the phenomenology of the dwelling, not of what is dwelt upon.
These paradigms provide no evidence of intellectual seemings, if the phrase is supposed to mean anything more than intuitions in Lewis’s or van Inwagen’s sense.
Can we at least restrict intuitions to non-inferential beliefs or inclinations to believe? The belief that one weighs more than three pounds is inferential. So is the belief that there either was or wasn’t a cat on this spot exactly five hundred years ago. Yet philosophers often count such beliefs as intuitive, and rejection of them as counterintuitive. If there is a narrower sense of 'intuitive,' it is often not the operative one when appeal is made in practice to the intuitiveness of some theories as a virtue and the counterintuitiveness of others as a vice.
Does a belief or inclination to believe with an inappropriate causal origin, such as wishful thinking, count as an intuition? We do not want such beliefs or inclinations to believe to carry weight in philosophy. But that is explicable quite independently of whether we classify them as intuitions. Wishful thinking is as relevant to the epistemology of intuition as misperception is to the epistemology of perception.
Should we restrict philosophical intuitions to those whose basis is grasp of the relevant thought? That is just a variant on the epistemological conceptions of analyticity that were seen to fail in the final section of Chapter 4. The thin grasp of the thought is no basis for assent. The thick grasp of the thought is a basis for assent, but it involves cognitive capacities that are not exclusively conceptual, because they are not necessary for the thin grasp; on such a criterion, intuitions again lose their distinctiveness.
Although we could decide to restrict the term 'intuition' to states with some list of psychological or epistemological features, such a stipulation would not explain the more promiscuous role the term plays in the practice of philosophy. This emerges more clearly in appeals to intuition in disputes over actual cases.
Some revisionary metaphysicians deny that, strictly and literally, there are mountains.4 They deny a proposition of the sort for which
G. E. Moore stood up in his defense of common sense (1925). For example, they may argue that although, if there were such a thing as a mountain, it would be a vague object, it is logically impossible for an object to be vague, so there is no such thing as a mountain. Alternatively, they may appeal to ontological economy, and argue that since all the appearances can be explained in terms of the microscopic objects, postulating macroscopic ones in addition is unnecessary and unjustifiable. And so on. The revisionists may concede that microscopic events occur in the joint presence of which it is usual to believe that a mountain is present, but they count that belief false. They hold that although the ordinary use of the word 'mountain' has utility, because it registers genuine discriminations between different cases in which different actions are appropriate, it also embodies a mistaken metaphysical theory as to what the difference between those cases consists in (skeptics who doubt that there are mountains may
4

Van Inwagen (1995) and Horgan (1995) defend related views. They allow that the sentence 'There are mountains' may express a truth in some loose or non-literal way, for example when the quantifier is not taken at face value, but in this book
'There are mountains' is to be understood strictly and literally. The text presents a metaphysical view of a familiar general type without attempting to follow any one metaphysician in detail. also be committed to doubting that there are words or beliefs; for the sake of argument we ignore such complications, just as the skeptics tend to do). The claim that there are no mountains is usually regarded as counterintuitive. Even its proponents may concede that it is counterintuitive, arguing that the cost to intuition is worth paying for the overall gain in simplicity, strength, logical coherence, and consonance with science they attribute to their total metaphysical system, which entails the claim. If their system also entails that there could not have been mountains, it contradicts the modal 'intuition'
that there could have been mountains. But even without the claim of necessity, the non-modal claim that there are no mountains is already counterintuitive as many philosophers use the term, because it contradicts the common sense judgment that there are mountains, for example in Switzerland. Thus the term 'intuition' may even be applied to the inferential belief that there are mountains, when based on the belief that there are mountains in Switzerland and elsewhere.
Whether or not they agree that there are no mountains, many contemporary metaphysicians would find it philosophically naïve to dismiss a revisionary metaphysical system by appeal to our elementary geographical knowledge that there are mountains in Switzerland.
Thus doubts about 'intuition' arise for straightforward empirical judgments, even for perceptual judgments: (pointing in the Alps)
'Those are mountains.'
Someone could of course stipulate that the only 'intuition' in their sense around here is conditional in form: if matter is arranged mountain-wise, then there is a mountain. They would then need to explain what they mean by 'mountain-wise.' If they mean so that it constitutes a mountain, the purported intuition is an obvious quasilogical truth: trivially, if matter is arranged so that it constitutes a mountain, then there is a mountain. Perhaps the content of the intuition is supposed to be more like this: if matter is so arranged that according to the mountain-story it constitutes a mountain, then there is a mountain. But what exactly is the mountain story? Hard theoretical work is needed to clarify the content of the purported conditional intuition. Once that is done, if it can be, perhaps common sense will be brought to accept the conditional, although it feels more like the conclusion of a plausible argument than the premise. In any case, it lacks the immediate attraction of whatever makes us describe the denial that there are mountains as counterintuitive. The application of 'intuition' and cognate terms in philosophical practice is scarcely more restricted than Lewis and van Inwagen suggest. In general, the objection 'That’s only an intuition' is ill-posed in the same way as the objection 'That’s only a judgment.' Some judgments are indeed objectionable, but the mere fact that a proposition is judged is not even a prima facie reason for doubting it.
Philosophers might be better off not using the word 'intuition'
and its cognates. Their main current function is not to answer questions about the nature of the evidence on offer but to fudge them, by appearing to provide answers without really doing so. If so, what is really at issue in disputes over the legitimacy of intuitions in philosophy?

3
Perhaps skepticism about intuition consists not in skepticism about a special kind of judgment but in a special kind of skepticism about any judgment. That skepticism does not target the distinctive features of perception, memory, testimony, or inference. Rather, it targets our practices of applying concepts in judgment. Call it judgment skepticism. For example, it does not question the existence of an external world to which we are causally related in the ways appropriate to perception – at least, not until the concepts of causation and perception themselves come under scrutiny. Indeed, many judgment skeptics are naturalists, their rhetoric scientistic. They present themselves as identifying ways in which our conceptual practices need, or may need, revision in the light of scientific advances those practices failed to anticipate. They doubt that we should go on in the same way.
Few judgment skeptics advocate skepticism about all judgments.
Total judgment skepticism would result in total intellectual paralysis.
Call 'judgment skeptics' those skeptical in the way just sketched about some contextually relevant judgments. For example, in a context that concerns folk psychological ascriptions of belief and desire, Paul Churchland and other eliminativists about such mental states are judgment skeptics. In a context that concerns ordinary geographical judgments, Terry Horgan and other eliminativists about mountains are judgment skeptics. Such skeptics question our standards for applying ordinary concepts both in experience and in thought: the concept of a mountain, the concept of belief, the concept of knowledge, the concept of possibility, the concept of the counterfactual conditional, and so on. Philosophers tend to call judgments
'intuitive' when they are considered as the primary targets of judgment skepticism. Thus the term is applied even to the perceptual demonstrative judgment 'Those are mountains' or the inferential judgment 'There are mountains,' derived by existential generalization – although, for obvious reasons, the primary targets of judgment skepticism are more usually the premises rather than the conclusion of an inference.
Like other skeptics, judgment skeptics construct scenarios to explain how we might make the judgments in question even if they were false. The debunking explanation aims to make massive error a genuine possibility. Scenarios for judgment skepticism are often distinctive in attempting to verify the scientific image of the world while falsifying the manifest image, common sense, or what passes for it in our culture. Sometimes they allow that the ability to apply the key terms of ordinary language (such as 'mountain') in the ordinary way confers an evolutionary advantage, because it helps us communicate to each other genuine but misarticulated differences.
The disposition to apply such terms immediately on the basis of casual observation contributes to practical efficiency. Such unreflective discriminations have survival value in harsh environments, where quick decisions are needed. We are here because our ancestors could make them before discovering the true theory of reality. Although the physical theory embedded in our intuitions has to be approximately correct in its predictions over a limited range of practically important cases, we do not expect it to match or even resemble the true physics in representation of the underlying reality. Why should we expect other parts of folk theory to do much better? The cheapest, fastest, and easiest conceptual route for us to making useful discriminations may run through intellectually dirty shortcuts that presuppose false but convenient metaphysics.
In other cases, skeptics may regard a conceptual practice as of merely local value, or even as doing more harm than good. Thus if standards for applying the term 'know' vary radically with cultural background, an evolutionary-biological explanation of my current standard is less plausible.5 The skeptic may tell a different, more sociological story about the cultural role of knowledge ascriptions, detaching them from their truth conditions. The story might imply that such ascriptions nevertheless fulfill a positive social function to which their cultural variability adapts them. But we can also envisage more sinister stories, on which they serve as instruments of intellectual repression.
Like other skeptics, judgments skeptics ask for independent evidence that favors the piece of common sense at issue over their skeptical hypothesis. The 'scientific' flavor of their alternative scenario disguises the resemblance to more traditional forms of skepticism.
However, there is one significant difference.
Traditional skeptics argue that we do not know that we are not in a skeptical scenario. They do not positively argue that we are in such a scenario; their point is that we cannot know what our situation really is. For them, the claim that we are in the common sense scenario is no better in epistemic status, but also no worse, than the claim that we are in the skeptical scenario. By contrast, judgment skeptics often argue that we actually are in their skeptical scenario, for example in which there are no mountains, or no beliefs.6 If they hold that we can recognize that their argument is sound, they must also hold that we can deduce that we are actually in their skeptical scenario. That involves them in no immediate inconsistency, for their skepticism is intended to be partial; they might compare it to skepticism about superstition. Some present their views as superior to
'common sense' judgments in compatibility with the results of the natural sciences. They take for granted that those results have some positive epistemic status. Indeed, they often treat them as scientific knowledge. They feel a crisis of confidence in common sense, not in scientific method. For others, it is metaphysical reasoning rather than natural science that trumps common sense.
Despite this more positive aspect of judgment skepticism, judgment skeptics often fall back on traditional skeptical strategies. For instance, they try to put defenders of a piece of common sense into the position Kornblith (2002) treats knowledge as a natural kind.
Of course, once we stop believing that there are mountains we can no longer be in the full skeptical scenario in which one falsely believes that there are mountains. Evidence in Philosophy 225

of arguing for it over the judgment skeptical scenario from a starting point neutral between the two alternatives, just as skeptics about the external world do.
Judgment skeptics need not puritanically insist that nobody should ever say things like 'There are mountains in Switzerland.' Some of their debunking explanations imply that in everyday contexts those are good, useful things to say: outside the metaphysics seminar, utterances of 'There are mountains in Switzerland' have more desirable effects than utterances of 'There are no mountains in Switzerland.'
Discovering the true theory of metaphysics will not change that. Even revisionary metaphysicians can continue to say such things, just as they can continue to say 'The sun will rise at 6 a.m. tomorrow.'
But, they hold, those things are not strictly and literally true: the sun will not strictly and literally rise at 6 a.m. tomorrow; there are not strictly and literally any mountains in Switzerland. If we want to think what is really true, we must think with the learned; for many purposes it is enough to say what is to all appearances true, and speak with the vulgar. We can live most of our lives on the basis of a fiction; only when we take a more scientific attitude are we forced to recognize the fiction for what it is.
For judgment skeptics, appeals to intuition are nothing more than the last resort of dogmatic conservativism, in its desperate attempt to hold back the forward march of scientific and metaphysical progress. But how can such skeptics prevent their arguments for skepticism from applying as far as the sciences themselves?
Judgment skeptical arguments apply to standard perceptual judgments, on which the natural sciences systematically depend: microscopes, telescopes, and other scientific instruments enhance ordinary perception but do not replace it, for we need ordinary perception to use the instruments. If the contents of those perceptual judgments concern ordinary macroscopic objects, they are vulnerable to judgment skepticism about common sense ontology. If so, the empirical evidence for scientific theories is threatened. To assume that the evidence can be reformulated without relevant loss in ontologically neutral terms, in the absence of any actual such reformulation, would be optimistic to the point of naïvety.
Even if that problem could be solved, a more pressing one would remain. Given judgment skeptical arguments, what is the status of scientists’ evidential judgments? For example, suppose that they judge that a given complex body of evidence of various kinds supports one theory against another, because the former theory explains the evidence better than the latter does. The concept of a better explanation is an informal one, rooted in ordinary ways of thinking, even if scientists’ particular applications of it are informed by their background knowledge. A question typical of judgment skepticism arises: what evidence is there that our rankings of explanations are reliable? If the evidence for the hypothesis that our rankings of explanations are reliable is that it provides the best explanation of something else (such as the survival of our species), the charge of question-begging can hardly be ignored. Thus when scientists apply standard concepts of epistemic appraisal, they are not immune to judgment skeptics’ styles of argument. In particular, judgment skeptics who judge that our empirical evidence tells against the reliability of some folk theory are vulnerable to judgment skepticism about the elements of folk epistemology on which they are relying.
Although in practice judgment skeptics are often skeptical about only a few judgments or concepts at a time, the underlying forms of argument are far more general. We may suspect that judgment skepticism is a bomb which, if it detonates properly, will blow up the bombers and those whom they hope to promote together with everyone else. But it does not follow that we can dismiss judgment skepticism as self-defeating. That the revolutionary movement would be incapable of establishing a stable new government of its own does not show that it cannot bring the old government down. At worst, judgment skeptics are troublemakers who put on the table arguments we find powerful and in need of a proper response, irrespective of their dubious motives for putting them there.7
The similarity between some arguments for judgment skepticism and traditional arguments for traditional forms of skepticism already gives us grounds for suspicion of the arguments for judgment skepticism. If the skeptic about the external world wears the traditional garb of the philosopher while the judgment skeptic dresses up in a scientist’s white coat, that should not blind us to the underlying structural similarity of their arguments. A judgment skeptic argues that our evidence is neutral between the ordinary hypothesis that there are mountains and the skeptical hypothesis that there are no
7

Compare Feyerabend (1978: 143). mountains, but instead only complex microphysical events the human brain usefully but untruthfully classifies as mountains, and concludes that we cannot know and are not justified in believing that there are mountains. A skeptic about the external world argues that our evidence is neutral between the ordinary hypothesis that there are mountains and the skeptical hypothesis that there are no mountains, but instead only mental states indiscriminable from the inside from perceptions of mountains, and concludes that we cannot know and are not justified in believing that there are mountains. Most people are confident that an argument like the latter for skepticism about the external world is unsound, much less confident as to where exactly it goes wrong. That position is quite reasonable. Similarly, it is fallacious to assume that if one cannot put one’s finger on the mistake in an argument for judgment skepticism, one must accept the conclusion, however implausible.
Still, we do want to identify the mistake. Let us therefore consider the epistemological position in more detail, while remembering that the diagnosis of the error in a skeptic’s argument may be far less obvious than the fact that it contains an error somewhere.

4
Different kinds of skepticism distinguish themselves from each other by questioning some things while leaving others unquestioned. The skeptic about induction grants that all emeralds observed so far were green, in order to question the distinctively inductive step to the conclusion that all emeralds will always be green. The skeptic about deduction grants the premises that if P then Q and that P of an inference by modus ponens, in order to question the distinctively deductive step to its conclusion that Q. The skeptic about testimony grants that someone has said that it was raining, but questions whether she spoke the truth. The skeptic about memory grants that my experience is as of remembering that it was raining, but questions whether I
really remember that it was raining. The skeptic about perception grants that my experience is as of seeing that it is raining, so that it visually appears to me that it is raining, but questions whether the experience is veridical. In each case, the skeptic concedes an evidential base, in order to accuse us of going illegitimately beyond it. For the judgment skeptic, sometimes the only evidential base to hand short of the disputed proposition itself is the conscious inclination to assent to that proposition, to make the judgment.
If judgment skepticism is treated by analogy with skepticism about perception, its evidential base will be described as intellectual seemings, somehow analogous to perceptual seemings. As we saw, Bealer has defended just such an account of intuitions as intellectual seemings. Its intellectually or perceptually seeming to one that P is a psychological state one can be in whether or not P, even if the default outcome of being in the state is judging that P. Whether intellectual seemings are more than conscious inclinations to believe we found reason to doubt.
Skepticism about perception typically narrows one’s evidential base to one’s present internal mental state. When I can see and hear and feel that it is raining, I suppose my total evidence to include the fact that it is raining, available for assessing hypotheses, for example the hypothesis that the grass will grow. By contrast, the skeptic about perception insists that I have as evidence only the fact that it perceptually appears to me that it is raining, for sometimes what perceptually appears to me is not so. From the fact about my present mental state I am challenged to reason legitimately outwards to the conclusion about my external environment that it really is raining. The skeptic about perception asks by what right I treat the fact that it perceptually appears to me that it is raining as good evidence that it is raining. Judgment skepticism narrows and internalizes our evidential base in a similar way without going as far as skepticism about perception, since typically it treats other people on a par with oneself, and other times on a par with the present. After reading Gettier’s article, I suppose my total evidence to include the fact that the subject in a Gettier case lacks knowledge. But the judgment skeptic insists that I have as evidence at most the fact that it non-perceptually appears to me and others that the subject in a Gettier case lacks knowledge, for sometimes what non-perceptually appears to me is not so. From the fact about our mental states we are challenged to reason legitimately outwards to the conclusion that the subject in a Gettier case really does lack knowledge. The judgment skeptic asks by what right we treat the fact that it non-perceptually appears to us that the subject in a Gettier case lacks knowledge as good evidence that the subject in a Gettier case does lack knowledge. Behind the skeptic about perception’s rhetorical question lies an assumption like this: one should be confident that P (on the basis of perception) only if its (perceptually) appearing that P is good evidence that P. Similarly, behind the judgment skeptic’s rhetorical question lies an assumption like this: one should be confident that P (on the basis of common sense) only if its appearing (by the standards of common sense) that P is good evidence that P. Call such principles appearance principles. They have some initial plausibility. For example, suppose that although whenever I am about to toss a coin either it appears to me that it will come up heads or it appears to me that it will come up tails, such appearances turn out to be correlated no better than chance with the actual results. Its appearing to me that the coin will come up heads is no evidence that it will come up heads.
Then I should not take those appearances at face value. Although it appears to me that the coin will come up heads, I should not be confident that it will come up heads.
To discipline the assessment of appearance principles, let us think probabilistically. Say that q would be evidence for p just if q raises the probability of p, that is, the conditional probability of p on q is higher than the unconditional probability of p, Prob(p) < Prob(p | q).8
That it appears to me that the coin will come up heads does not raise the probability that the coin will come up heads, so the former proposition would not be evidence for the latter, and I should not be confident that the coin will come up heads on the basis of that appearance, by the relevant appearance principle. More generally, the appearance of p is truth-indicative just if it would be evidence for p (Prob(p) < Prob(p | Ap)), and falsity-indicative just if it would be evidence against p (Prob( p) < Prob( p | Ap), equivalently
Prob(p) > Prob(p | Ap)). An appearance principle implies that one should be confident in p only if the appearance of p is truth-indicative
The conditional probability Prob(p | q) is usually defined as the ratio of unconditional probabilities Prob(p & q)/Prob(q) for Prob(q) > 0. The reason for the 'would be' is that, in the sense defined, it may happen that q would be evidence for p even though q is itself unknown or even false: the relation between p and q is purely conditional. Compare Williamson (2000a: 187). In order to keep the conditional probabilities that are relevant to this chapter uncontentiously well-defined, we allow some metaphysical impossibilities to have non-zero probabilities (for example, according to some judgment skeptics, it may well be metaphysically impossible that there are mountains).
8 (for specified types of sentence and appearance). A weaker principle says that one should be confident in p only if the appearance of p is not falsity-indicative. Note that appearance principles merely purport to give necessary conditions for when one should be confident, not sufficient conditions.
On some views, if the prior probability of p is high enough, we should be confident of p even if its probability is somewhat lowered by Ap. The judgment skeptic regards such a defence of disputed philosophical propositions as unacceptably dogmatic, having the advantages of theft over honest toil. Let us concentrate on the unrestricted appearance principles.
What kind of probability should we use to interpret 'Prob'? The appearance of p must not be certain, for if Prob(Ap) = 1 then automatically Prob(p | Ap) = Prob(p), making truth-indicativeness and falsity-indicativeness uselessly indiscriminate as tests: trivially, the appearance of p is neither truth-indicative nor falsity-indicative. Thus purely subjective probabilities (credences, degrees of belief) are unsuitable, for the subject may always have been subjectively certain of the appearance of p. Purely objective probabilities (chances) are also unsuitable, for in a deterministic world with the appearance of p the appearance of p is objectively certain. A kind of evidential epistemic probability intermediate between subjective and objective extremes is most relevant.9 Assume, for the sake of argument, that we have fixed on such probabilities: the discussion below is neutral on their exact nature.
It appears that there are mountains in Switzerland, in a liberal sense of 'appears' correlative with the liberal sense of 'counterintuitive' in which the claim that there are no mountains in Switzerland is counterintuitive. Presumably, this appearance is truth-indicative, even if significant epistemic probability is assigned to the suggestion of a judgment skeptic that mountains are metaphysically impossible.
For there is still a nonzero epistemic probability that mountains are metaphysically possible; conditional on that non-skeptical hypothesis, the appearance that there are mountains in Switzerland surely raises the epistemic probability that there are mountains in Switzerland (for Switzerland might have been a plain), whereas, conditional
9

Williamson (2000a: 209–37) describes such an intermediate kind of epistemic probability. on the skeptical hypothesis, the appearance merely leaves the probability unchanged rather than lowering it. Overall, therefore, the appearance that there are mountains in Switzerland raises the epistemic probability that there are mountains in Switzerland.10
Some philosophically contested 'intuitive' propositions are truth-indicative.
However, let SS be the judgment skeptic’s scenario in which it falsely appears that there are mountains in Switzerland, because folk geography misinterprets joint microscopic events as the presence of mountains in Switzerland when in fact mountains are metaphysically impossible. Add to the specification of SS that each trivially necessary condition of there being mountains in Switzerland appears (in the liberal sense) to hold. Since SS is set up as a scenario in which there are no mountains in Switzerland, a trivially necessary condition of there being mountains in Switzerland is that SS does not obtain.
Consequently, in SS, it appears that SS does not obtain. Since that is built into the background logic, it is certain, conditional on its not appearing that SS does not obtain, that SS does not obtain. Thus
Prob( s | A s) = 1, where s says that SS obtains. It can be shown to follow that Prob( s | A s) ≤ Prob( s), that is, that the appearance that SS does not obtain is not truth-indicative.11 It is not evidence that SS does not obtain. By the stronger appearance principle, one should not be confident that SS does not obtain.
The judgment skeptic can go further. As already noted, the appearance in question must not be certain, otherwise truth-indicativeness and falsity-indicativeness are trivialized. Thus we may assume
Prob(A s) < 1. Moreover, those with even the slightest sympathy for judgment skepticism will allow that it is not certain that we are not in SS: Prob(s) > 0. These two further assumptions entail that the appearance that SS does not obtain is falsity-indicative: it actually
Formally, where m says that there are mountains in Switzerland and s that mountains are metaphysically impossible, if all the probabilities are well-defined as ratios and Prob(m | s) < Prob(m | s & Am) and Prob(m | s) = Prob(m | s & Am) = 0 then
Prob(m) < Prob(m | Am). Although there are cases of s & Am & m, they are outweighed by cases of s & Am & m.
11
Proof: If Prob( s | A s) = 1
then Prob( s | A s) = Prob(A s).Prob( s | A s) + (1 − Prob(A s)).Prob( s | A s)
≤ Prob(A s).Prob( s | A s) + Prob( A s).Prob( s | A s) = Prob( s).
The weaker assumption Prob( s | A s) ≤ Prob( s | A s) also suffices.
10 lowers the probability that SS does not obtain.12 Its appearing that
SS does not obtain is evidence that SS does obtain. Therefore, even by the weaker appearance principle, one should not be confident that
SS does not obtain.
That there are mountains in Switzerland obviously entails that SS
does not obtain. Consequently, one’s confidence that there are mountains in Switzerland should be no higher than one’s confidence that
SS does not obtain: if p entails q and subjective probabilities obey the standard probability axioms then the subjective probability of p is no higher than the subjective probability of q. By the appearance principle, one’s confidence that SS does not obtain should be low. So one’s confidence that there are mountains in Switzerland should also be low, even though the appearance that there are mountains in
Switzerland is truth-indicative. We therefore face an argument for a sweeping form of judgment skepticism.
The form of argument is not specific to judgment skepticism. It applies equally to skepticism about the external world. We need only replace SS by a skeptical scenario of a more traditional kind. Let p be a description of the external world acceptable to the judgment skeptic, perhaps in terms of particle physics. Let SS* be a scenario in which p is false but an evil demon makes each trivially necessary condition for the truth of p, including the truth of p itself, appear to hold. By the same reasoning as before, it is certain, conditional on its not appearing that SS* does not obtain, that SS* does not obtain.
Thus Prob( s* | A s*) = 1, where s* says that SS* obtains. It follows that the appearance that SS* does not obtain is not truthindicative; it is not evidence that SS* does not obtain. By the relevant appearance principle, one should not be confident that SS* does not obtain. The skeptic will further argue that the appearance that SS*
does not obtain is falsity-indicative; it is evidence that SS* does obtain. Since p obviously entails that SS* does not obtain, one’s confidence in p should be no higher than one’s confidence that SS*
does not obtain. By the appearance principle, one’s confidence that
SS* does not obtain should be low. So one’s confidence in p should
Proof: 0 < Prob(s) = Prob(A s).Prob(s | A s) + Prob( A s).Prob(s | A s) =
Prob(A s).Prob(s | A s) because Prob(s | A s) = 0. Therefore 0 < Prob(s | A s), so Prob( s | A s) < 1 = Prob( s |
A s). Since 0 < Prob( A s),
Prob( A s).Prob( s | A s) < Prob( A s).Prob( s | A s), so the inequality in the previous footnote is strict.
12 also be low, even if its appearance is truth-indicative. We therefore face an argument for a sweeping form of skepticism about the external world, more specifically, the external world as described in terms the judgment skeptic would accept.
Few judgment skeptics would be consoled by the idea that one’s confidence in p need only be low in contexts in which, since SS* has been considered, one must fix a level of confidence in the proposition that SS* does not obtain. For they would be unimpressed by a defense of common sense based on the idea that confidence in it is legitimate provided that one refuses to consider their skeptical scenarios. They will insist that head-in-the-sand strategies are futile. They are asking how confident we can be that SS* does not obtain, not whether we are capable of ignoring the proposition altogether.
It is unsurprising that if an argument for traditional skepticism works, so does an argument for judgment skepticism. But that is not the kind of success most judgment skeptics seek. They want a more selective skepticism, which for example does not undermine the results of fundamental physics, even though the latter are in the target area for skepticism about the external world. Consequently, they should not use appearance principles as premises in their reasoning, since such principles generate traditional skepticism as well as judgment skepticism. At least in some cases, one can be legitimately confident in a proposition even though its apparent truth is no evidence for its truth, and is even evidence for its falsity.
An observation reinforces that moral. Let t be any ordinary tautology. The standard probability axioms entail that t has probability 1, conditional on anything. Then no appearance of t in any sense is truth-indicative, for Prob(t | At) = 1 = Prob(t). Since t is also not falsity-indicative, this observation might be met by weakening the requirement of the corresponding appearance principle from truth-indicativeness to lack of falsity-indicativeness. But that misses the intended point of appearance principles. After all, the appearance to me that the coin will come up heads is not falsity-indicative.
It does as well as chance, but no better. A different kind of epistemological diagnosis is needed; truth-indicativeness and falsityindicativeness are just not the relevant criteria.
The problem is not that the definitions of truth-indicativeness and falsity-indicativeness mention only one aspect of appearances, the apparent truth of the proposition p directly at issue. The arguments work just the same if we ask whether the totality of appearances (in the relevant sense) would be evidence for p, given a skeptical scenario
SS** in which p is false but the totality of appearances matches the actual totality of appearances and all the trivially necessary conditions for the truth of p appear to hold. For it is certain, conditional on the absence of that totality of appearances, that SS* does not obtain. By the same reasoning as before, the totality of appearances is not evidence that SS** does not obtain, and is even evidence that
SS** does obtain.
Nor is the problem that the arguments were framed in terms of appearances rather than psychological states such as beliefs or dispositions to belief. They work equally well in the latter terms (just substitute B for A).
Rather, the problem concerns a more abstract issue about the structure of confirmation. Let e be a body of evidence that raises the probability of a hypothesis h to a value close to 1 without quite making h certain, so Prob(h) < Prob(h | e) < 1. The material conditional e h is a logical consequence of h, and therefore at least as probable as h; in fact, Prob(e h | e) = Prob(h | e). However, e is evidence against e h, for Prob(e h) > Prob(e h | e), simply because e h is true in all those possibilities which e eliminates
(e h is a logical consequence of e).13 Clearly, all of this is compatible with a high degree of legitimate confidence in both h and e h.
Whenever evidence makes some hypothesis more probable than before without making it certain, that evidence makes some logical consequence of that hypothesis less probable than before. Similarly, whenever a hypothesis is certain on some evidence, that evidence makes some logical consequence of that hypothesis no more probable than before (of course, it does not make any such consequence less probable than before, since they all become or remain certain). What this reveals is a fallacy in the tactic of criticizing confidence in a theory by identifying a logical consequence of the theory (not itself a logical

Proof: Prob(e h) = 1 − Prob(e & h) = 1 − (Prob(e).Prob(e & h | e) +
Prob( e).Prob(e & h | e) = 1 − Prob(e).Prob(e & h | e) > 1 − Prob(e & h | e) =
Prob(e h | e). The assumption here that Prob(e).Prob(e & h | e) < Prob(e & h | e)
holds because Prob(e) < 1 (otherwise Prob(h | e) = Prob(h), contrary to hypothesis) and
Prob(e & h | e) > 0 (otherwise Prob(h | e) = 1, contrary to hypothesis).
13 truth) whose probability is not raised by the evidence. Call that the consequence fallacy.
Consider the deductively valid argument from (1) and (2) to (3):
(1) Physical events occur that folk geography takes to constitute the presence of mountains in Switzerland.
(2) If physical events occur that folk geography takes to constitute the presence of mountains in Switzerland, then there are mountains in Switzerland.
(3) There are mountains in Switzerland.
We may assume that the defender of folk geography is committed to both the premises and the conclusion. In particular, premise (2) is a logical consequence of the common sense conclusion (3) (read the conditional as material). A judgment skeptic may hold that our evidence raises the probability of (1) but not of (2). However, to argue on that basis that, given our evidence, we are not entitled to high degrees of confidence in (2) and (3) is to commit the consequence fallacy.
Similarly, consider the valid argument from (1*) and (2*)
to (3*):
(1*) The Gettier case has features that folk epistemology takes to constitute the subject’s lack of knowledge.
(2*) If the Gettier case has features that folk epistemology takes to constitute the subject’s lack of knowledge, then the subject in the Gettier case lacks knowledge.
(3*) The subject in the Gettier case lacks knowledge.
We may assume that the defender of folk epistemology is committed to both the premises and the conclusion. In particular, premise (2*)
is a logical consequence of the common sense conclusion (3*). A
judgment skeptic may hold that our evidence raises the probability of (1*) but not of (2*). However, to argue on that basis that, given our evidence, we are not entitled to high degrees of confidence in (2*)
and (3*) is again to commit the consequence fallacy.
Finally, consider the valid argument from (1**) and (2**) to
(3**): (1**) It appears to me that I have hands.
(2**) If it appears to me that I have hands, then I have hands.
(3**) I have hands.
As before, the defender of common sense is committed to both the premises and the conclusion. A skeptic about the external world may hold that our evidence raises the probability of (1**) but not of (2**).
However, to argue on that basis that, given our evidence, we are not entitled to high degrees of confidence in (2**) and (3**) is once again to commit the consequence fallacy.
The point is doubtless connected to the role of the assumption in some skeptical arguments that knowledge is closed under competent deduction: if I cannot know that I am not a handless brain in a vat that appears to itself to have hands, how can I know that I have hands?14 However, the arguments in this section have been framed in terms not of knowledge but of legitimate degrees of confidence, conceived as answerable to the standard axioms of probability. In this setting, closure is much less contentious.15

5
Although judgment skepticism, like other forms of skepticism, easily falls into the consequence fallacy, it would be complacent to assume that it loses all its force once the consequence fallacy has been identified and abjured. We saw in Section 1 the temptation, under the influence of Evidence Neutrality, to conceive the evidence in philosophy as consisting of psychological facts, such as the fact that we believe that there are mountains in Switzerland, not the fact that there are mountains in Switzerland. Since psychological evidence has no obvious bearing on many philosophical issues, judgment skepticism is also encouraged in ways that do not depend on the consequence fallacy. For now the issue is not whether our evidence is evidence for some devious consequence of our theory but whether it is evidence
14
Seminal works are Dretske (1970), Stine (1976) and Nozick (1981). More recent discussions of closure include DeRose (1995) and Hawthorne (2004); see the latter for more references.
15
See Williamson 2005c for more discussion of skepticism in relation to truthindicativeness, and Williamson 2000a: 164-83 for more on traditional skepticism. for our theory as a whole. And even if our evidence does raise the probability of the whole theory somewhat, is it raised high enough for confidence, in particular, to a higher level than its skeptical alternatives?
Traditional skepticism exploits Evidence Neutrality to achieve a similar psychologization of evidence: only the fact that it appears to me that I have hands is evidence, not the fact that I have hands. How does that happen? Since evidence is true, the false proposition that I
have hands is not evidence in a skeptical scenario in which it falsely appears to me that I have hands. Thus the proposition that I have hands is evidence only if I am not in the skeptical scenario. But in the presence of a real or notional skeptic it is contentious that I am not in the skeptical scenario. So it is contentious that the proposition that I have hands is evidence, hence not in principle uncontentiously decidable that it is evidence. Therefore, by Evidence Neutrality, that
I have hands is not evidence, even if I am in fact in the common sense scenario in which I have hands and all my perceptual faculties are working properly. Only the proposition that it appears to me that I
have hands is evidence. Since both the common sense scenario and the skeptical scenario are consistent with all my evidence, so conceived, the question arises: with what right do I regard the former scenario as more probable than the latter?
Both traditional skepticism and judgment skepticism reflect the tendency of Evidence Neutrality to narrow our evidence base. One result is the uneasy conception many contemporary analytic philosophers have of their own methodology. They think that, in philosophy, ultimately our evidence consists only of intuitions (to use their term for the sake of argument). Under pressure, they take that to mean not that our evidence consists of the mainly non-psychological putative facts which are the contents of those intuitions, but that it consists of the psychological facts to the effect that we have intuitions with those contents, true or false.16 On such a view, our evidence in philosophy amounts only to psychological facts about ourselves.
16

A recent example is Brian Weatherson (2003: 27), who, despite showing far more sophistication in these matters than most philosophers do, still assumes that the argument from Gettier cases against the traditional analysis has the premise 'Intuition says that Gettier cases are not cases of knowledge' rather than the simpler 'Gettier cases are not cases of knowledge.' His considered view may not be the one described in the text. Nevertheless, they do not want the psychological fact that we have an intuition that P to be perfectly neutral with respect to the nonpsychological question whether P, for that leads to skepticism about philosophy. If we merely seek the best explanation of our having the intuitions, without any presumption in favor of their truth, we may find a psychological theory to explain them, but how are we to answer the questions about a mainly non-psychological universe that grip many metaphysicians and other philosophers? In explaining why we have intuitions, analytic philosophy has a preference for explanations that make those intuitions true over explanations that make them untrue, but the justification for that preference remains unclear.
Even if we have an intuition that the former sort of explanation is better than the latter, why should we give that intuition a special privilege over others by adopting a methodology that assumes its truth? That our evidence in philosophy consists of facts about intuitions and that explanations of those facts on which the intuitions come out true are better (ceteris paribus) than explanations on which they do not are themselves epistemological rather than psychological claims. Taken far enough, the psychologization of philosophical method becomes self-defeating. Psychologism is no more a psychological theory than the Pythagorean doctrine that everything consists of numbers is a mathematical theory.17
Not even psychological facts really meet the demands of Evidence
Neutrality. Whatever Descartes thought, facts about one’s own present consciousness are not always cognitively accessible to one.
For example, on any reasonable view, intuitions vary in strength. An adequately fine-grained theory of intuitions would have to distinguish weaker ones from stronger ones in evidential impact. If the strength of intuitions is taken into account, the evidence will be recorded in something like the form 'I have an intuition of strength s that P.'
The strength parameter s will have to be specified according to some common scale, in order to permit the comparisons between the strengths of sometimes conflicting intuitions which the theory of evidence will need to make. But that will give plenty of scope both for
17
Pust (2001) argues carefully that the following principle is self-defeating: 'Aside from propositions describing the occurrence of her judgements, S is justified in believing only those propositions which are part of the best explanation of S’s making the judgements that she makes.' Contrast Goldman and Pust (1998). misjudging the strength of one’s intuitions and for being accused by others of having done so. After all, philosophers have a powerful vested interest in persuading themselves and others that the intuitions which directly or indirectly favor their position are stronger than they really are. The stronger those intuitions, the more those who appeal to them gain, psychologically and professionally. Given what is known of human psychology, it would be astonishing if such vested interests did not manifest themselves in some degree of wishful thinking, some tendency to overestimate the strength of convenient intuitions and underestimate the strength of inconvenient ones. In trying to compensate for such bias, one may undercompensate or overcompensate; the standpoint of consciousness gives one no privileged access to whether one has succeeded, for bias does not work by purely conscious processes. Its effects are much easier to observe in others than in oneself. A further obstacle to classifying one’s intuitions is that some philosophers with a tin ear for natural language seem to misarticulate their own strong intuitions, using forms of words that do not express what they really want. There is sometimes controversy as to whether this has happened. It would be naïve to suppose that all these obstacles can be overcome just by 'trying harder.' Restricting evidence to psychological facts, even to those about present conscious intuitions, does not satisfy Evidence Neutrality. It is often not in principle uncontentiously decidable whether someone has an intuition of a given degree of strength that P.
Radical eliminativists about the mind are another source of contentiousness. They say 'Research in neurophysiology has shown that folk psychology is a false theory; its ascriptions of mental states and acts are never strictly and literally true, however convenient they may have been' (even if they do not believe what they say). At least some of them will classify 'S has the intuition that P' and 'S has the belief that P' together as ascriptions of folk psychological mental states
(perhaps not the same one). On their view (itself a form of judgment skepticism), humans never have the intuition that P. In particular, consistent radical eliminativists will not even concede that their theory is counterintuitive, or that we have the intuition that we have beliefs and desires. To find common ground with radical eliminativists, one must rigorously depsychologize one’s evidence. I am better off showing them my brain scans than describing my intuitions. For other philosophers, brain scans no more exist than mountains do. Does a more pragmatic attitude to evidence finesse these difficulties? On a pragmatic view, what permits a fact to serve as evidence in a given context is that it happens to be uncontroversial in that context, not that it is uncontroversial in all contexts, or foundational in any deeper sense. The dialectical standard does not favor the use of psychological facts as evidence in contexts in which such facts are controversial. Currently undisputed non-psychological truths can be used as evidence too. We get by with agreement on particular pieces of evidence without any context-independent standard for evidence.
This dialectical conception of evidence makes sense even for a single thinker: in isolation one can still play rival theories against each other in one’s head; virtual opponents suffice for much philosophical thinking.
We should not assume too readily that a dialectical standard of evidence is always appropriate. It works well when both sides show moderation and restraint. But the adversarial system of inquiry has limits. By accepting the dialectical standard unconditionally, we lay ourselves open to exploitation by ruthless opponents – such as skeptics. It allows them to rule our best evidence out of court simply by issuing a peremptory challenge to that evidence. A debate conducted in that spirit is unlikely to converge on the truth. The common ground is too narrow to form an adequate evidence base. Testing one’s beliefs that way is a dangerous game; we should expect unreliable results. For example, if one uses only premises and forms of inference that a skeptic about perception will allow one, and therefore only premises that are true and forms of inference that are valid even if one is a brain in a vat, one has little prospect of reaching the conclusion that one has hands. But that does not show that we should not be confident that we have hands. To be warranted, confidence need not be recoverable from an impoverished skeptical startingpoint. After all, if one uses only premises and forms of inference that skeptics about reason will allow one, one cannot reach the conclusion that there are good reasons. For since such skeptics doubt that there are good reasons, they allow one neither the premise that there are good reasons nor any form of reasoning with which to reach that conclusion from some other starting-point. It would be frivolous to conclude, from that trivial point, that we do not know that there are good reasons. Indeed, even skeptics about reason must deny that conclusion to follow, since they deny that anything follows from anything. Sometimes, in self-defense, one must abandon skeptics to their fate.
Some skepticism, like skepticism about reason, is so radical that it leaves too little unchallenged for what remains as shared evidence to be an appropriate basis for evaluating the claims under challenge.
When one is warranted in refusing to play the skeptic’s dialectical game, the dialectical standard of evidence becomes irrelevant. In refusing, one does not abandon one’s claims to knowledge and reason, for the appropriate standard of evidence is non-dialectical. By that standard, the skeptic’s peremptory challenge fails to disqualify the challenged fact as evidence. To neglect such evidence would be to violate the requirement of total evidence.18 One continues to assert propositions of the disputed kind on the basis of evidence, without expecting to find arguments for them that use only premises and forms of inference acceptable to the skeptic. Since escape from the radical skeptical predicament is impossible, one must take good care not to get into it in the first place.
Is this attitude a legitimate response to judgment skepticism? For instance, may one take the fact that the subject in a Gettier case lacks knowledge or the fact that there are mountains in Switzerland as evidence, even though the judgment skeptic challenges one’s right to such evidence? In reaching one’s views, one does not restrict oneself to premises and forms of inference acceptable to judgment skeptics, for one regards their restricted evidence base as too willfully impoverished to constitute a reasonable starting-point for inquiry. Such skeptics have not shown that the facts they allow as evidence are really more certain than the facts they disallow. In particular, it is quite insufficient for them to point out that it is possible to judge that there are mountains in Switzerland even if there are no mountains in
Switzerland, for a parallel objection can be made to any evidence worth having in the sciences.
Even if (let us pretend) facts about our intuitions were in some sense more certain for us than all other facts, it would not follow that we should restrict our evidence to facts about our intuitions. For the extra information in a wider evidence base may be worth a cost in reliability. If logical truths were more certain than all other facts,
18

'[I]n the application of inductive logic to a given knowledge situation, the total evidence available must be taken as a basis for determining the degree of confirmation' (Carnap 1950: 211; compare Hempel 1965: 63–7). See also Williamson (2000a:
189–90). it would not follow that we should restrict our evidence to logical truths: that would eliminate most of our knowledge. It would be skepticism about everything except reason. Similarly, if facts of some other special kind were more certain than all other facts, it would not follow that we should restrict our evidence to facts of that special kind.
Isn’t this short way with the judgment skeptic contrary to the open spirit of philosophical discussion? The skeptic has thoughtful, recognizably philosophical concerns: don’t they deserve a fair hearing?
How can they be given such a hearing if the very propositions the skeptic challenges are taken as evidence? Skeptics of any principled kind can indeed expect more tolerance in philosophy than in other disciplines. One can discuss their skepticism with them without stepping outside the bounds of philosophy. In talking to them, it is futile to offer for their acceptance arguments with premises they have already refused to accept. In particular, it seems unphilosophical to refuse to discuss judgment skepticism with its proponents. In conversation with them, it is dialectically pointless, rude, to offer as evidence propositions one knows they do not accept. But the issue remains: what implications, if any, does the outcome of such a conversation have for the epistemic status of belief in the propositions the skeptic questions? Faced with a skeptic about reason, or everything except reason, many philosophers would be willing to start a conversation, out of politeness, curiosity, competitiveness, or the desire to save a soul. But their inability to achieve a dialectical triumph over such a resourceful opponent does not oblige them to become skeptics about reason, or everything except reason, themselves. There is no bad faith in continuing to claim (and have) knowledge of the contested truths.
For the anti-skeptic is not obliged to treat dialectic as the measure of all things. Indeed, the claim that dialectic is the measure of all things faces self-defeat, for it cannot triumph dialectically over its denial; even if it appeared to be getting the better of the argument, would not taking that to establish its truth beg the question? Similarly, even if one cannot establish dialectically, in dispute with a judgment skeptic, that the subject in a Gettier case lacks knowledge or that there are mountains in Switzerland, without bad faith one can still claim to know that the subject in a Gettier case lacks knowledge or that there are mountains in Switzerland, and use those facts as evidence. What prevents astrologers from using this approach to defend astrology by arguing that the fact that astrological predictions have an excellent track record constitutes good evidence for astrological theory? Nothing prevents astrologers from saying such things, although they will presumably be speaking falsely, since astrological predictions have no such excellent track record. Similarly, nothing prevents astrologers from saying that astrology meets the strictest methodological standards of natural science, although again they will be speaking falsely. In both cases, there will be excellent evidence that they are speaking falsely, which they will not accept as evidence of that. There is a persistent temptation to assume that a good account of methodology should silence astrologers and other cranks, by leaving them in a position where they can find nothing more to say. That assumption is naïve. They always find more to say. Of course an account of methodology should specify respects in which good intellectual practices are better than bad ones. But that does not mean that if devotees of a bad intellectual practice endorse the account, they will abandon the practice; more likely they will convince themselves that their practice triumphantly conforms to its precepts. No methodology is proof against misapplication by those with sufficiently poor judgment.
None of the foregoing arguments provides any guarantee that judgment skepticism is not correct for some types of judgment;
'common sense' is sometimes wrong. But if it is accepted in such cases, that should be on the basis of evidence specific to those types of judgment, not on the basis of general skeptical fallacies.

6
Our evidence in philosophy consists of facts, most of them nonpsychological, to which we have appropriate epistemic access.
Consequently, there is a one-sided incompleteness to descriptions of philosophical methodology, and attempts to justify or criticize it on that basis, if formulated in terms neutral over the extent of that evidence. For instance, in describing some philosophers as believing or having the intuition that P, one fails to specify whether their evidence includes the fact that P.
A simple attempt to justify common sense as a starting point for philosophy on the basis of such a neutral description appeals to the principle of Epistemic Conservativism: one has a defeasible right to one’s beliefs, which may be defeated by positive reasons for doubt, but not by the mere absence of independent justification.19 Thus one’s belief that there are mountains in Switzerland gives one the defeasible right to rest arguments on the premise that there are mountains in
Switzerland. Whether or not the belief constitutes knowledge, it confers the right.
Our beliefs are what we start from, the boat we find ourselves in.
Even if we can progressively replace them, we cannot distance ourselves from all of them at once, for we have nowhere else to stand.
Epistemic Conservativism elevates the practical necessity of starting from where one is, wherever that is, to normative status, subject to the proviso on defeaters. Although the principle is not perfectly neutral on the epistemic status of the belief, since the notion of a defeater is epistemologically normative, it is neutral on how much evidence, if any, the subject has. Justifying a philosophical method by appeal only to Epistemic Conservativism ignores crucial epistemological distinctions concerning the relevant beliefs: it is like justifying scientific methodology without giving any information as to what evidence is required in its application. Even if Epistemic Conservativism is true, it is radically incomplete as a basis for an account of the epistemic status of philosophical beliefs.
If philosophical 'intuitions' are simply beliefs, they fall within the domain of Epistemic Conservativism. That is less clear if 'intuitions'
include inclinations to belief. Someone inclined to believe p may nevertheless not believe p; inclinations conflict. This difference matters for Epistemic Conservativism.
Justin has been brought up to believe that knowledge is equivalent to justified true belief. He is confronted for the first time with a
Gettier case. He might have immediately and confidently judged that the subject has justified true belief without knowledge, and abandoned his old belief that knowledge is equivalent to justified true belief. Presumably, Epistemic Conservativism would then have switched sides and started supporting the new belief that knowledge is not equivalent to justified true belief. Instead, Justin is more cau19
See Harman (1986: 29–42) for a defense of epistemic conservativism, and Vahid
(2004) for a recent critical survey of its varieties. For simplicity and generality, subtleties in the formulation of the principle have been glossed over. tious, not wanting to assent too readily to anything tricky. Although he is consciously inclined to judge that the subject has justified true belief without knowledge, he does not immediately give in to that inclination or abandon his ingrained belief that knowledge is equivalent to justified true belief. Does Epistemic Conservativism counsel abandoning his ingrained belief in this situation? If Justin is asked
'What reason have you to doubt your analysis?,' he cannot answer
'The subject in this possible case has justified true belief without knowledge,' since he does not yet believe that. He must say something else. The answer 'I am inclined to believe that the subject in this possible case has justified true belief without knowledge' would be relevant if the function of the prefix 'I am inclined to believe that'
were to signal tentative assent to what follows, but Justin’s commitment to his analysis inclines him to resist even tentative assent to a putative counterexample. If the function of the prefix 'I am inclined to believe that' is instead to report his psychological state of being inclined to believe the proposition expressed by the embedded sentence, as its literal compositional semantics suggests, the relevance of that answer to the original question is far from obvious, for he has not yet assented even tentatively to a counterexample.
Can Epistemic Conservativism be extended to the claim that one has a defeasible right to believe whatever one is inclined to believe?
Such an extension is less clearly motivated than the original principle by the idea that, since one must start from where one is, one has at least a defeasible right to be there. A right to be where I am is a right to have the beliefs and inclinations I have. That does not obviously include a right to follow those inclinations to new places, especially when the beliefs I already have imply that those are bad destinations, for example, when the inclinations are to believe things inconsistent with what I currently believe. As Gettier counterexamples show, intuition can be revolutionary as well as conservative. If I currently believe p, I am currently committed to the belief that any inclination to believe something inconsistent with p is an inclination to believe something false. I am not committed to the beliefs I am merely inclined to have in the way I am committed to my current beliefs. I
am merely inclined to commit myself to them in that way. After all, a right to be where I am is of limited practical use unless it involves a right to stay where I am, to continue believing, at least for a while, what I currently believe. 7
Many philosophers recognize their philosophical activity in the more dynamic notion of reflective equilibrium, described by Nelson
Goodman and John Rawls.20 Our initial set of general theories and particular intuitions is inconsistent; each side is revised in the light of the other, by an iterative process, until they are brought into harmony. There is a debate whether the beliefs that emerge from this process are thereby justified. But a prior question is whether such descriptions of the process yield an adequate conception of a philosophical method, good or bad. The question is not whether philosophers engage in the mutual adjustment of general theory and judgments about specific cases – they manifestly do – but whether such descriptions of it are sufficiently informative for epistemological purposes.
A process generally acknowledged as at least superficially analogous to the attainment of reflective equilibrium in philosophy is the mutual adjustment of theory and observation in natural science.21
Imagine a description of it in which the word 'observation' is used simply as a label for judgments with non-general content, irrespective of origin; it ignores the perceptual process. Such a description misses the point of the natural scientific enterprise. It provides no basis for an epistemological assessment. The nature of scientists’ evidence has been left unspecified. Similarly, one has no basis for an epistemological assessment of the method of reflective equilibrium in philosophy without more information about the epistemological status of the
'intuitions.' In particular, it matters what kind of evidence 'intuitions' provide. The previous account of thought experiments is consistent with the idea that the Gettier proposition and its like are evidence. Indeed, since real life counterexamples will sometimes do in place of imaginary ones, observed facts are sometimes relevant evidence. Talk of reflective equilibrium fails to address such issues.
20

See Goodman (1955: 65–8) and Rawls (1951, 1971: 20). David Lewis (1983a: x) describes philosophers’ task as the identification of such equilibria. Two recent critiques of the method are Cummins (1998) and Stich (1998); a recent defense is
DePaul (1998).
21
For such an analogy see Rawls (1951). One factor obscuring the descriptive inadequacy of standard accounts of reflective equilibrium is the already noted tendency to conceive evidence in philosophy as the mere having of 'intuitions': it is easy to slip into the illusion that our epistemic access to such psychological facts is unproblematic. Thus attention is distracted away from the epistemic status of the 'intuitions' themselves. Even if we revise an 'intuition,' our evidence may still include the fact that we had it. But the epistemic status of the original 'intuition,'
however much the model ignores it, must be relevant to the epistemic value of revising general theories in line with its content.
The reflective equilibrium account, as usually understood, already assigns a proto-evidential role to at least one kind of non-psychological fact. For it treats philosophers as relying on logical relations between theories and intuitions, in particular their consistency and inconsistency. Can one retell the story in purely psychological terms, with beliefs about logical relations in place of actual logical relations?
That move is doubly problematic. It reduces explanatory power unless the assumption is added that beliefs about logical relations are reliable, for otherwise the account no longer explains any tendency to bring theory and intuition into mutual consistency, but at best a tendency to believe that one has done so. Moreover, the beliefs about logical relations are explanatorily redundant. Consider the theory (4)
and the 'intuition' (5):
(4) Every F is a G.
(5) This F is no G.
In order to explain, without appeal to the inconsistency of (4) with
(5), why philosophers do not simply retain both, we merely say that they believe (6):
(6) (4) and (5) are jointly inconsistent.
Philosophers do not in fact fix belief in all of (4), (5), and (6). But the envisaged strategy does not understand that in terms of a protoevidential role for (7):
(7) (4), (5), and (6) are jointly inconsistent. It no more assumes that (7) is evidence than it assumes that (6) is.
To invoke the fact of belief in (7) as evidence is merely to take another backwards step on an infinite regress. But if the strategy relies on a brute unwillingness to believe all three of (4), (5), and (6), it might as well have relied on a brute unwillingness to believe both of (4) and
(5) in the first place; they are already inconsistent. Without protoevidential backing from the inconsistency of (4) and (5), the unwillingness to believe both of (4) and (5) looks irrational.
If the reflective equilibrium story assigns a proto-evidential role to some logical facts even though all logical facts are philosophically contestable, as we saw in earlier chapters, why not allow a similar role to other philosophically contestable facts? If no other philosophically contestable facts can play such a role that is something we need to know, and have not yet been given any good reason to believe. If other philosophically contestable facts can play a proto-evidential role, that too is something we need to know and which the reflective equilibrium story leaves unacknowledged.
To say that mathematicians or biochemists or historians strive to bring their opinions into equilibrium would be sadly inadequate as even a summary description of their method of research. It omits the constraining evidence that makes their opinions worth listening to, their research worth funding. Is philosophy so different that in its case such a description will suffice? If so, it should give up any claim to be an evidence-based discipline. Such pessimism is unwarranted once we accept the contestability of evidence. Thought experiments do provide evidence, in the shape of mainly non-psychological facts.
That philosophers sometimes disagree as to what evidence they provide is only to be expected.

8
Knowledge Maximization

1
In philosophy, as elsewhere, one can easily experience conflict between one’s role as a believer and one’s role as an appraiser of oneself as a believer. I cannot simply regard my belief in p as a psychological phenomenon. For p implies that p is true, and therefore that whoever believes p does so truly. In believing p, I am committed by that implication to the belief that a belief in p is true, and that to continue believing truly on the matter I must continue believing p (if the truthvalue of p is atemporal). Similarly, p implies that its negation p is false, and therefore that whoever believes p has a false belief in p.
In believing p, I am committed by that implication to the belief that a belief in p is false.1 Neutrality is not an option for believers. One is bound to think any given belief of one’s own superior in truth-value to the contrary beliefs of others. But sometimes we step back from our beliefs and regard them as psychological phenomena on a par with the beliefs of others, in equal need of both psychological explanation and epistemological criticism. I may see my beliefs as the product of my social and cultural background, your beliefs as the product of your social and cultural background, and wonder what objective reason there is to prefer mine to yours. As argued in the previous chapter, that third-person stance can involve a refusal to take crucial knowledge seriously, just because someone disputes it; sometimes we must take a first-person present tense stance. But
1

The exact status of the implications depends on delicate issues about disquotational principles for truth and falsity, but whatever their outcome the point in the text will hold in some form. sometimes the third-person stance is the right one to take. This chapter explores some general aspects of the tension between one’s role as a believer and one’s role as an appraiser of oneself as a believer in philosophy.
Some anti-skeptical commitment is built into the role of believer.
If I believe p, I am thereby committed to the belief that I do not falsely believe p. This commitment can be generalized in two ways. First, the content of the hypothetical commitment can be generalized. If I
believe p, I am thereby committed to the belief that no one falsely believes p. Similarly, given that propositional truth is atemporal, if
I believe p, I am thereby committed to the belief that I shall never falsely believe p (since propositional truth is not amodal, there is no corresponding modal generalization: if I believe p, my commitments may allow that p could have been false and still believed). Second, the whole conditional can be generalized, on personal, temporal, and modal dimensions. Necessarily, anyone who ever believes p is thereby committed to the belief that they do not falsely believe p. All these generalizations can be combined: necessarily, anyone who ever believes p is thereby committed to the belief that no one ever falsely believes p.
Nevertheless, this anti-skeptical commitment is very limited. For if I believe p, my commitments may allow that just about everyone else falsely believes p at all times in all circumstances, that I falsely believe p at just about all other times in all circumstances, and that
I would now have falsely believed p in just about all counterfactual circumstances: true belief with respect to p in the current case contrasts with error on the same question in just about all other cases.
I might take skeptical scenarios to prevail almost everywhere while insisting that I happen not to be currently in one. Such a response to skepticism would be unimpressive, perhaps unstable. The admitted frequency of skeptical scenarios in nearby situations constitutes an urgent reason for doubting one’s own beliefs. One should beware of regarding oneself as too happy an exception to sadly general trends.
Sometimes the tension between one’s role as a believer and one’s role as an appraiser of oneself as a believer becomes unbearable, and the belief in question is abandoned.
Few of us regard ourselves as highly exceptional in having currently escaped the worst scenarios for skepticism about perception.
We think them rare in worlds like ours. We find the brain in a vat

Knowledge Maximization scenario far-fetched; while dreams are common, dreams with the sustained coherence of waking life are very rare. The environment as we perceive it is full of creatures in regular perceptual contact with it. No special luck or skill is needed to avoid envatment: it has never been a big danger for humans. Of course, skeptics will say that such claims about our environment merely beg the question; their truth is part of what is at stake. But the claims were not addressed to skeptics, in a futile attempt to persuade them out of skepticism. Instead, they figure in our appraisal of skeptical arguments, from our current non-skeptical point of view.2 Not yet having suspended our ordinary beliefs, we must decide whether the acknowledged bare metaphysical possibility of skeptical scenarios gives us good reason to suspend those beliefs – not just momentarily in an epistemology seminar, but for the rest of our lives. Most of us find the reason inadequate. Bare possibilities of error, however picturesque, constitute no imminent threat; the threat is not nearly urgent enough to warrant the drastic and costly precautions skeptics recommend. For most purposes, we do not take the skeptical possibilities seriously.
Our tendency to ignore skeptical possibilities is not explained by their making no practical difference; many of them make such a difference. If you are a brain in a vat, not really interacting with other people, much of your altruistic behavior is futile. Again, in some skeptical scenarios you feel unremitting horrible pain for years, starting tomorrow, unless you immediately do what appears to you exactly like going out and buying ten copies of the same newspaper: I bet you do not take even that elementary precaution. Of course, in other skeptical scenarios you feel unremitting horrible pain for years, starting tomorrow, if you immediately do what appears to you exactly like going out and buying ten copies of the same newspaper. If one takes all possibilities equally seriously, they tend to cancel each other out for practical purposes. But that does not imply that we are left back where we were before skeptical possibilities occurred to us. If everything except present consciousness is utterly unknown, why not simply indulge in sweet dreams?
For the thorough skeptic, that you have hands is no more probable
(epistemically) than that you are in a skeptical scenario in which you merely appear to have hands: will you therefore reject a bet on which
2

Compare Nozick (1981: 167). you win 10 euros if you have hands and lose 100 euros otherwise on the grounds that its expected utility is negative, since 10/2 − 100/2 =
−45? If skepticism makes you doubt the enforceability of the bet, that is no reason to accept it. Surely it is a good bet, even when you happen to be in an epistemology seminar. We ignore radical skeptical possibilities in practice, even when they are drawn to our attention, because we do not rate them as epistemically serious possibilities. We make that epistemic assessment from our non-skeptical perspective.
When we judge that in our world radical skeptical scenarios present no imminent danger to anyone, we do so on the basis of our own beliefs, but that judgment depends on the specific content of those beliefs; it is not automatic. We have a rich conception of ourselves and our environment on which brains in vats are very far-out physical possibilities, and even long-term coherent dreams are highly unlikely.
That conception also enables us to give specific answers to the question 'How do you know?' as it arises on specific occasions, for example by indicating relevant processes of perception, memory, testimony, and inference, although of course the conception need not figure among premises from which the more specific knowledge was inferred, since the latter need not have been inferred at all. None of this amounts to a detailed dissection of the flaws in particular skeptical arguments. Rather, it provides the appropriate background to our confidence that such flaws must be there.
How imminent a threat do scenarios for judgment skepticism pose? Skepticism about perception starts with actual perceptual errors and imaginatively radicalizes them until it reaches brains in vats.
Similarly, judgment skepticism starts with actual errors about witchcraft, oracles, and magic and imaginatively radicalizes them until it reaches the nonexistence of mountains. In both cases, there is a tradeoff between how remote the skeptical scenarios are (judged from our current perspective) and how far-reaching a skepticism they motivate.
The set of very close possibilities motivates only a very limited skepticism; a wider range of possibilities motivates a more general skepticism. The closer the possibility, the more seriously it deserves to be taken. For skepticism about perception, we know at least roughly what makes the more radical scenarios remote, the enormous practical obstacles to setting up all the requisite causal mechanisms, not to mention the shortage of motivation for doing so. For judgment skepticism, what corresponds to those obstacles? Do we even believe

Knowledge Maximization that the actual world is not full of apt scenarios for judgment skepticism?
Suppose that most ordinary beliefs in most other cultures are false, because somehow laden with false theories.3 Then the possibility that, for similar reasons, most ordinary beliefs in our own culture are also false is too close to home to be dismissed as fanciful or far-fetched.
Judgment skepticism gets a grip. A satisfying response would put such skeptical scenarios far from other cultures, not just far from one’s own.
Given empirical evidence for the approximate intertranslatability of all human languages and a universal innate basis of human cognition, we may wonder how 'other' any human culture really is. If we believe p and believe that others believe p too, then we are committed to the belief that the others’ belief in p is true. But if human beliefs tend to be true merely as an accidental by-product of our DNA, and other galaxies are rife with nonhuman persons most of whose beliefs are false, because laden with false theories, then scenarios for judgment skepticism are still dangerously close to home. Even if such scenarios are rare or absent in the actual universe, but only by good luck, it remains uncomfortable for opponents of judgment skepticism. If we are to refuse in good conscience to take seriously the radical scenarios for judgment skepticism, we must do so from a perspective on which there is a quite general tendency for beliefs to be true. Anything less than that will look like special pleading on our own behalf. But why should there be any such tendency? What we believe is one question, what is true another.

2
Some naturalists argue on evolutionary grounds that beliefs tend to be true, for creatures with too many false beliefs are unfit to survive.
True beliefs tend to cause one to get what one wants in a way in which false beliefs do not. Truth conduces to success. That is not to deny that some false beliefs have survival value; the suggestion is only that on the whole truth is more conducive than falsity to survival.
Since we are arguing from our current perspective, on which our
3

For present purposes, how finely cultures are individuated matters little. world is governed by regularities extending over past, present, and future, we need not worry overmuch about scenarios for inductive skepticism on which generalizations with only true instances up to some future time t have false instances thereafter (in any case, judgment skepticism is not skepticism about induction). We can take past success as some guide to future success.
How do true beliefs tend to cause success in action? This principle seems central to the nature of belief and desire:
(1) If an agent desires that P, and believes that if it does A then P, then ceteris paribus it does A.
The 'ceteris paribus' clause in (1) covers possibilities of irrationality, alternative means to the same end, countervailing desires, and so on.
If an agent desires that P, believes that if it does A then P, and does
A, then P if the belief is true, so its desire is realized. If its belief is not true, then it may well not happen that P. Of course, that P may not help the agent if it is not good for the agent that P. The argument might therefore be taken to support a stronger conclusion: that evolution favors creatures who both believe what is true and desire what is good for them. 'Good for them' here means good for them collectively, since evolution sometimes favors altruistic behavior which benefits one’s relatives to one’s individual disadvantage; for simplicity, this qualification is left tacit in what follows.4
An agent has some idea of the act A in believing that if it does A
then P. If it does A without believing itself to be doing so, then the natural link between antecedent and consequent in (1) is broken. For example, if you go north while believing that you are going south,
4

If for them to desire that P were for them to believe that it is good for them that
P, the tendency to desire what is good for them might be subsumed under the tendency to believe what is true. However, in whatever sense of 'good for them' evolution can be assumed to favor creatures that get what is good for them, for them to believe that it is good for them that P seems to be neither necessary nor sufficient for them to desire that P. For example, they may believe that it is good for them in that sense that there be a cull of the unfit without desiring one, and they may desire that cigarettes be more readily available without believing that it is good for them in that sense that cigarettes be more readily available. But if in some relevant sense desiring that
P can be equated with believing that it is good that P, so much the better for the argument in the text. your action is not explained just by your desire to reach the oasis and belief that if you go north then you will reach the oasis, (1) notwithstanding. Perhaps the explanation is that, in addition, you desire even more strongly to avoid your enemy and believe that he is at the oasis.
Although such examples do not refute (1), since the 'ceteris paribus'
clause absorbs their shock, they indicate that the rationale for (1)
takes for granted that beliefs about what one is doing tend to be true, which is a special case of the very phenomenon that we are trying to understand. Therefore, in order not to assume what needs to be explained, let us revise (1) thus:
(2) If an agent desires that P, and believes that if it does A then P, then ceteris paribus it acts so that it believes that it does A.
A natural variant of (2) would have 'on the intention to do A' in place of 'so that it believes that it does A.' The argument below could be reformulated in terms of this variant, but for simplicity let us stick with (2), to minimize the number of types of propositional attitude under consideration.
Given that you want to avoid your enemy, and believe that if you go south then you will avoid him, (2) helps explain why you act so that you believe that you go south, even though in fact you go north.
But the reason for taking (2) rather than (1) as basic for present purposes is not that anything is wrong with (1) as a ceteris paribus generalization in its own right. Rather, the point is just that (1) is too close to what we are trying to explain to be an appropriate starting point for an illuminating explanation.
Starting from (2) rather than (1), one can still explain why it is good for an agent to have true beliefs and desires for what is good for it. For if it desires that P, believes that if it does A then P, and acts so that it believes that it does A, then P if both beliefs are true, which is good for it if its desire is for what is good for it. Unfortunately, such a derivation explains much less than it appears to. For, given (2), one can show in the same way for infinitely many deviant properties true* and good* that the combination of true* beliefs and desires for what is good* for one yields (ceteris paribus) what is good
(not just good*) for one.
To see this, consider an arbitrary mapping on propositions, taking the proposition that P to the proposition that P, subject to the constraint that it commutes with logical operations, in the sense that the proposition that (not P) is the proposition that not P, the proposition that (if P then Q) is the proposition that if P then Q, and so on. In other respects, the mapping is arbitrary: for example, the proposition that (I am going north) can be the proposition that you are eating slowly.
If a proposition is just the set of possible worlds in which it is true, then we can construct such a mapping for any permutation π of possible worlds (a one-one mapping of the possible worlds onto the possible worlds) by stipulating that each world w belongs to the proposition that P if and only if π(w) belongs to the proposition that P. The mapping commutes with negation, for example, because, for any world w, the following are equivalent: w belongs to the proposition that (not P); π(w) belongs to the proposition that not P;
π(w) does not belong to the proposition that P; w does not belong to the proposition that P; w belongs to the proposition that not P.
For similar reasons the mapping commutes with other logical operations, such as the truth-functional conditional.
Alternatively, if propositions have quasi-syntactic structure, we can take an arbitrary permutation of their atomic constituents and extend it recursively to complex propositions in the natural way. The mapping automatically commutes with logical operations because the commutativity clauses are built into its inductive definition.
Now define 'true*' and 'good*' by these equivalences:
(3) That P is true* if and only if that P is true.
(4) That P is good* for an agent if and only if that P is good for it.
Suppose that an agent desires that P, believes that if it does A then
P, and acts so that it believes that it does A. Suppose further that both beliefs are true*. By (3), since the proposition that if it does A
then P is true*, the proposition that (if it does A then P) is true. Since the mapping commutes with logical operations, in particular with the truth-functional conditional employed (by stipulation) in (1) and (2), the proposition that (if it does A then P) is the proposition that if
(it does A) then P. Thus the proposition that if (it does A) then P
is true. By (3) again, since the proposition that it does A is true*, the proposition that (it does A) is true. Since truth is closed under modus ponens, the proposition that P is true. Suppose finally that what the agent desires is good* for it. So that P is good* for it; therefore, by
(4), that P is good for it. In other words, something (that P) good for the agent obtains: together, true* belief and desire for what is good* for one yield (ceteris paribus) what is good (not just good*)
for one.
From (2), we cannot conclude that the combination of true belief and desire for what is good for one is any better for one than the combination of true* belief and desire for what is good* for one.
Yet, despite all the evolutionary pressures, we have no special tendency to believe what is true* or to desire what is good* for us.
For example, that I am going north may be true* if and only if you are eating slowly, and that I reach the oasis may be good* for me if and only if it is good for me that you read your book. I have no special tendency to believe that I am going north only if you are in fact eating slowly or to desire that I reach the oasis only if it is in fact good for me that you read your book. If we start theorizing without any reason to expect a correlation between belief and truth, considerations of survival will not make the connection for us.
We can envisage schemes for interpreting creatures under which they tend to believe the true* and desire the good* for them, rather than to believe the true and desire the good for them. Suppose that we are trying to understand some aliens. We already have an extremely plausible interpretation Int of their beliefs and desires, under which they tend to believe the true and desire the good for them. We define a new interpretation Int* by specifying that, under Int*, an alien believes that P if and only if, under Int, it believes that P, and, under
Int*, it desires that P if and only if, under Int, it desires that P.5 Thus
Int* ascribes a true belief just where Int ascribes a true* belief; Int*
ascribes a desire for what is in fact good for one just where Int ascribes a desire for what is in fact good* for one. Int* attributes bizarre contents to the aliens: under Int*, their beliefs about their environment have no tendency to be true, their bodily movements no tendency to bring about the satisfaction of their desires. For example,
5

The definition of Int* assumes that the proposition that P is the proposition that
Q if and only if the proposition that P is the proposition that Q; this condition is easily met. Int* is also stipulated to ascribe to the aliens only beliefs and desires of the form that P. under Int, an alien desires that it will be cool and believes that if it jumps into the lake then it will be cool; it jumps into the lake and will be cool. Under Int*, it desires that (it will be cool) and believes that (if it jumps into the lake then it will be cool), in other words, that if (it jumps into the lake) then (it will be cool); it jumps into the lake and will be cool. For definiteness, let that (it will be cool) and that (it jumps into the lake) be that you were tall and that you went to bed respectively. Thus, under Int*, the alien desires that you were tall and believes that if you went to bed then you were tall; it jumps into the lake and will be cool. Under Int, when it jumps into the lake it also believes that it jumps into the lake and that it will be cool. Thus, under Int*, when it jumps into the lake it believes that you went to bed and that you were tall. Int* make the aliens’ mental lives formally as rational and coherent in propositional content as Int does; but Int* radically disconnects their mental lives from what is happening around them and from what they are physically doing, whereas Int connects them in the normal way.
Moreover, Int* postulates no special mechanism to help explain the strange disconnection. Surely Int* misinterprets the aliens. Even if such radical disconnection is not metaphysically impossible, it would occur only under highly abnormal circumstances. The nature of mental content seems to favor Int over Int* in some constitutive way.
We could try to rule out Int* by proposing more specific constraints on the internal interconnections of propositional attitudes for Int* to fail. But that approach is unpromising; it misses the point of the problem. The deviant interpretation Int* can meet even more specific constraints on the internal structure of the agent’s system of propositional attitudes while still attributing mental lives radically disconnected from the environment and bodily behavior. For the mapping preserves the main structural features of propositions, and could be tailored to preserve even finer-grained structure.
It may be objected that truth* and goodness* are less natural properties than truth and goodness, just as grue and bleen are less natural than green and blue (Lewis 1983b). Although green will coincide with grue until some future moment, we have evolved a tendency to react differentially to green rather than to grue (even when they diverge) because green is a more natural property than grue, so a mechanism sensitive to green can develop far more easily than a mechanism sensitive to grue. Evolutionary selection does not have a completely free hand; it is constrained by the available material and its causal powers. Why not explain the tendency to believe the true and desire the good for one through the combination of constraints of internal coherence such as (2) with considerations of naturalness?
A difficulty for the proposal is that truth* and goodness* need not be much more unnatural than truth and goodness. For we can define the mapping of propositions in quite natural ways, while still preserving constraints of internal coherence. For example, suppose that propositions are sets of possible worlds. Then the permutation
π of possible worlds used to define might be a rotation of the similarity spheres of worlds about some counterfactual world. Thus each proposition that P would have the same shape in similarity space as the proposition that P, and their locations would be systematically related. Alternatively, if propositions have quasi-syntactic structure, we could replace all atomic predicative constituents of the proposition that P by their negations in constructing the proposition that P.
Although such mappings may involve some loss of naturalness, it is comparatively slight. Indeed, we may even gain naturalness by selecting more natural entities than the 'right' ones out of which to construct the 'wrong' propositions. Yet the proposition that P will differ in truth-value from the proposition that P in very many cases; truth* is very poorly correlated with truth, and goodness* with goodness. Thus some wildly deviant interpretations Int* are approximately as natural as or even more natural than the non-deviant interpretation Int. Moreover, the propositions we ordinarily entertain do not concern only very natural objects, properties and relations, for we do not ordinarily think in terms that figure in the fundamental laws of the universe. The proposition that this car is green does not cut nature at its most fundamental joints; this car is not a very natural object and greenness is not a very natural property. Nor are the properties of believing truly and desiring what is good for one very natural. At best, propositional attitude ascriptions proceed at a level of moderate naturalness. Thus the combination of constraints of internal coherence with considerations of naturalness is quite insufficient to explain why Int* is a hopeless interpretation.
Of course, evolution does to some extent favor believing what is true and desiring what is good for one. But one cannot understand why it does so simply by appeal to internal constraints and considerations of naturalness. For that understanding, one must start with a richer conception of belief and desire. More specifically, we need external constraints on the relation between mental life and the non-mental world. Much contemporary philosophy consists of attempts to provide such constraints.
Attempts to impose external constraints on the relation between mental life and the non-mental world may be roughly divided into the molecular and the holistic.6 Molecularists analyze mental contents into constituents, and try to specify conditions for employing each constituent in thought. For example, a simple theory of possession conditions for concepts says that to possess the concept mountain one must, under optimal conditions specified without ascription of that very concept, be willing to judge here is a mountain if and only if a mountain is present. A simple verificationist theory of meaning states necessary and sufficient conditions for the sentence 'Here is a mountain' to be canonically verified (or assertable). A simple causal theory of reference says that a thought token refers to mountains if and only if it is causally related in a specified way to mountains. And so on. More complex and sophisticated accounts can be developed in the same spirit.
If a molecularist account could be made to work, it might support many of the conclusions of this chapter. However, molecularist accounts face major obstacles. For instance, it is hard for an account that is intended to provide non-circular necessary conditions for concept possession to say anything non-trivial about what the agent does in non-optimal conditions, where ignorance and error are rife even among those who possess the concepts at issue; yet it is hard for an account to provide non-circular sufficient conditions for concept possession if it says nothing non-trivial about what the subject does in non-optimal conditions.
The terminology of 'holism' and 'molecularism' is hijacked from Dummett
(1975b) to make a slightly different distinction.
It is also hard to screen out the effects of the subject’s background theory without circularity. As seen in earlier chapters, radical unorthodoxy is compatible with concept possession and linguistic understanding. For example, if the optimal conditions are specified without ascription of the concept mountain, then they can presumably be met when a revisionary metaphysician, a native English speaker with good eyesight and open eyes, dissents in good visibility from the sentence 'Here is a mountain' in the middle of the Alps. The danger is that a molecularist possession condition would count her as lacking the concept mountain, a highly implausible result. By any reasonable standard she had the concept mountain before she developed her revisionary metaphysics; since she fully understood the English word
'mountain,' she knew that it meant mountain. Developing her revisionary metaphysics did not make her cease to understand the word 'mountain'; she understands the word in the normal way as used by other speakers, and therefore knows that it means mountain; she still has the concept mountain. When she denies that there are mountains, she is consciously disagreeing with common sense, not talking past it. Similar problems plague verificationist theories of meaning. Not even causal theories of reference are free of such problems. Mountains may cease to cause tokenings of 'mountain' in speakers with unorthodox background beliefs who continue to understand the word 'mountain.' Nor are causal connections always needed. Even for mountains, a community might think about them without ever having had any causal contact with them, by having causal contact with hills and envisaging mountains like hills, only bigger. As usual, attempts to preserve the necessity of the alleged condition for concept possession or linguistic understanding tend to undermine its non-circular sufficiency.
The history of molecularist programs gives little ground for optimism that such obstacles will eventually be overcome. That is not to imply that all molecularist claims are hopelessly false. Many of them seem to be true 'for the most part.' What is doubtful is that they can be replaced by strictly true claims within the spirit of a molecularist program.
The alternative to molecularism is holism. Although holism need not deny that thoughts have constituent structure, its constraints on thinking given thoughts apply at the level of the subject’s total system of thoughts, not at the level of individual constituents; they are global rather than local. The most salient holistic proposal is Donald
Davidson’s principle of charity. According to Davidson (1974: 197):
'Charity is forced on us; whether we like it or not, if we want to understand others, we must count them right in most matters.' He argues that methodologically good interpretation imputes agreement in the main between interpreter and interpreted; there is no obstacle in principle to a methodologically good omniscient interpreter, agreement with whom guarantees truth; since the omniscient interpreter’s interpretation is by hypothesis correct, correct interpretation imputes truth in the main (1977: 200–1). Thus, by Davidson’s lights, revisionary metaphysicians are bad interpreters if they interpret ordinary people as in massive error, for example over the existence of mountains. Of course, a revisionary metaphysician might claim that ordinary people do not really believe that there are mountains, but that seems to be an even worse misinterpretation. Davidson’s account directly implies a tendency for beliefs to be true.
Davidson’s principle of charity evokes massive disagreement.
However, it is not wholly to blame for the contentious conclusions that Davidson uses it to draw. It figures in his notorious argument against the very idea of mutually incommensurable conceptual schemes, alien ways of thought or untranslatable languages (1974).
But that argument also makes both the verificationist assumption that other creatures have beliefs only if we can have good evidence that they have beliefs and the constructivist assumption that we can have good evidence that they have beliefs only if we can have good evidence as to which beliefs they have. Neither assumption follows from the principle that beliefs tend to be true. Neither assumption is warranted, for we are far from omniscient interpreters (compare
Nagel 1986: 93–9). The aliens may be able to interpret each other even if we cannot interpret them. More generally, Davidson’s application of the methodology of radical interpretation to the philosophy of language embodies a kind of ideal verificationism, on which agents have just the intentional states that a methodologically good interpreter with unlimited access to non-intentional data would ascribe to them. However, we could, as David Lewis (1974: 110–11) recommends, treat the predicament of the radical interpreter as merely a literary device for dramatizing the question: how do the intentional states of agents supervene on the non-intentional states of the world?
The sense in which that question concerns the determination of content is metaphysical, not epistemological. In this spirit, we could consistently accept a principle of charity while allowing that alternative conceptual schemes are possible.7
If the role of the radical interpreter is inessential, so too is that of agreement between interpreter and interpreted. Truth is prior to agreement: the metaphysical version of Davidson’s principle of charity requires that agents have mostly true beliefs. Other things equal, interpretation should maximize the ascribed proportion of true beliefs. That is in effect a constraint on reference for the constituents of beliefs or of the sentences that express them. Agreement is secondary; two agents with mostly true beliefs do not mostly disagree with each other, although they may have few beliefs in common, if they have different concerns, and may even tend to disagree over their limited common concerns.
Davidson’s principle of charity is too loose to figure in an algorithm for reducing the intentional to the non-intentional. But present purposes do not force us to engage in the heroically ambitious quest for such a reduction. What we need are correct non-trivial principles about propositional attitudes that somehow link belief and truth, metaphysically rather than epistemologically. Such principles can fall far short of reducing the intentional to the non-intentional, even of fixing the supervenience of the former on the latter.
Even in its de-epistemologized, non-reductive version, Davidson’s principle of charity remains highly contentious. Massive error seems genuinely possible for a brain envatted only months ago.8 Some have responded by formulating revised principles that allow one to interpret another as in massive error when one would have been in massive error oneself in her circumstances. For example, Richard
Grandy (1973: 443) proposes 'as a pragmatic constraint on translation' a principle of humanity: 'the condition that the imputed pattern of relations among beliefs, desires, and the world be as similar to our own as possible.' Even if we treat the principle of humanity as a metaphysical constraint on what makes an ascription of content
7

By contrast, McGinn (1986) treats radical interpretation as an epistemological problem. He explicitly allows for uninterpretable believers (367). For a recent discussion of Davidson on radical interpretation see McCulloch (2003: 94–108).
8
Klein (1986) discusses of Davidson’s treatment of skeptical scenarios. McCulloch
(2003: 126–40) is a recent discussion of the difficulty of interpreting brains in vats. correct, rather than an epistemological guide to plausible translation, it says nothing directly about any tendency for beliefs to be true.
However, since each of our beliefs commits us to regarding it as true, and therefore as having that relation to the world, one could argue that the principle of humanity requires the beliefs of others to tend to have the same relation to the world, and therefore to be true too.
Perhaps humanity implies at least a limited version of charity, although the vagueness of 'similarity' between patterns of relations makes it hard to tell. But the anthropocentrism of the metaphysical principle of humanity is suspect. After all, humans are prone to peculiar logical and statistical fallacies: once we recognize a quirky design fault in ourselves, it would be perverse to prefer, on metaphysical principle, interpretations of non-human aliens that attribute the same design fault to them. Although humans are the clearest examples of rational agents with which we are familiar, we are also clear that there could be far more rational agents than we are. On their metaphysical reading, anthropocentric principles of charity implausibly imply that the very nature of content militates against the possibility of superhuman rationality.
Other principles of charity put a premium on rationality or coherence, conceived as conditions internal to the agent. But they do not explain the superiority of the sensible interpretation Int over the silly
Int* above. Even those which enjoin the minimization of inexplicable error or ignorance rely on there being further principles, so far unspecified, for explaining error and ignorance when they are legitimately attributed: whatever those further principles are, they will do much of the work in specifying the relations between mind and world. We need to make a new start.

4
Suppose that Emanuel has an ill-founded faith in his ability to discern character and life-history in a face. On that basis he forms elaborate beliefs about passers-by, in which he is confident enough to bet large sums when the opportunity offers, which it rarely does. By sheer luck he has won such bets so far, which has increased his confidence in his powers, although many other beliefs he has formed in this way are in fact false. Now Emanuel sees a stranger, Celia, standing some distance away. Looking at her face, he judges 'She is F, G, H, . . .'; he ascribes a character and life-history in considerable detail. In fact, none of it fits Celia. By pure coincidence, all of it fits someone else,
Elsie, whom Emanuel has never seen or heard of. Does the pronoun
'she' as used by Emanuel in this context refer to Celia or to Elsie?
Which of them does he use it to express beliefs about? He accepts
'She is standing in front of me,' which is true if 'she' refers to Celia but false if it refers to Elsie. However, he also accepts 'She is F,'
'She is G,' 'She is H, . . . ,' all of which are false if 'she' refers to
Celia but true if it refers to Elsie. We may assume that the latter group far outweighs the former. A principle of charity that crudely maximizes true belief or minimizes error therefore favors Elsie over Celia as the referent of the pronoun in that context. But that is a descriptive theory of reference gone mad. Emanuel has no beliefs about Elsie.
He has many beliefs about Celia, most of them false. In virtue of what is Emanuel thinking about Celia rather than Elsie?
A causal theorist of reference will point out that Emanuel’s use of
'she' in this context is causally related to Celia. Of course, it may be causally related to Elsie too – she may have saved Celia’s life by performing the plastic surgery on Celia’s face that helped cause
Emanuel’s beliefs – but not in the right way for reference, whatever that is. In this case, the specific link is that Emanuel is perceptually attending to Celia and using 'she' as a perceptual demonstrative.
But to say that he is using 'she' as a perceptual demonstrative is to say little more than that he is using it so as to refer to what he is perceptually attending to, and we may hope to say something more useful about what sets up this link between perception and reference.
If the notion of perceptual attention is purely causal, and does not involve the notion of thinking about, in virtue of what is Emanuel thinking about that to which he has this causal relation? If, on the other hand, the notion of perceptual attention is not purely causal, and does already involve the notion of thinking about, in virtue of what is Emanuel perceptually attending to Celia? Although it is somewhat obscure just what such 'in virtue of' questions are demanding, we do not simply want to meet them with silence.
A natural idea is this. The perceptual link from Celia to Emanuel matters because it is a channel for knowledge. If 'she' refers to Celia, then, in the circumstances, Emanuel expresses knowledge when he says 'She is standing in front of me,' although of course not when he says 'She is F,' 'She is G,' 'She is H, . . . ,' since they are false.
If 'she' refers to Elsie, then of course Emanuel does not express knowledge when he says 'She is standing in front of me,' since it is false, but he also fails to express knowledge when he says 'She is F,'
'She is G,' 'She is H, . . . ,' even though they are true. Emanuel is in a position to know of Celia that she is standing in front of him; he is not in a position to know of Elsie that she is F, G, H, . . . The same contrast holds, more fundamentally, at the level of thought. The assignment of Elsie as the referent in Emanuel’s beliefs gains no credit from making them true because it does not make them knowledge.
The assignment of Celia wins because it does better with respect to knowledge, even though it does worse with respect to true belief.
Such examples are of course just the analogue for demonstrative pronouns of examples Kripke and Putnam used to refute descriptive cluster theories of reference for proper names and natural kind terms.
In effect, such theories are special cases of a truth-maximizing principle of charity. One fundamental error in descriptive theories of reference is to try to make true belief do the work of knowledge.
As for causal theories of reference, the postulated link between knowledge and reference suggests a schematic explanation of both their successes and their failures. Roughly: a causal connection to an object (property, relation, . . .) is a channel for reference to it if and only if it is a channel for the acquisition of knowledge about the object (property, relation, . . .). Often, a causal connection is a channel for both. Equally, a non-causal connection, such as a definite description, to an object (property, relation, . . .) is a channel for reference to it if and only if it is a channel for the acquisition of knowledge about the object (property, relation, . . .). Sometimes, a non-causal connection is a channel for both. It was in any case clear that causal theories of reference and causal theories of knowledge were closely linked in their successes and failures. Both faced the problem of deviant causal chains, of specifying which causal chains carry the relevant intentional link. Both faced the problem of mathematics, which appears to exhibit both non-causal reference to abstract objects and non-causal knowledge about them.
The proposal is to replace true belief by knowledge in a principle of charity constitutive of content. But how can doing so help with the objection that massive error is possible? Presumably knowledge implies true belief. Unless the agent is inconsistent, any case of massive error is also a case of massive ignorance. At first sight, the objection only makes the problem worse. However, it is independently obvious that our knowledge is dwarfed by our ignorance. The right charitable injunction for an assignment of reference is to maximize knowledge, not to minimize ignorance (which is always infinite).9
Suppose that under some assignment of reference a brain in a vat has mainly true beliefs about electrical impulses in the computer that controls it. If we are still disinclined to accept the assignment, a natural reason to give is that the brain is not in a position to know about the electrical impulses. If we are inclined to accept the assignment, we probably think that the brain is in a position to know about them.
Here is a simpler case. A fair coin was tossed and landed heads.
The agent cannot see or otherwise know which way up it landed, but is easily convinced by what are really just his own guesses. He sincerely asserts 'Toda.' Is a point in favor of interpreting 'Toda'
to mean 'It landed heads' rather than 'It landed tails' that it has him speaking and believing truly rather than falsely? Surely not. The true belief would no more be knowledge than the false belief would be. Although Davidson’s principle of charity does not imply that
'Toda' cannot mean 'It landed tails,' since data from other cases might outweigh the current data, it does imply that this case provides a defeasible consideration in favor of interpreting 'Toda' as 'It landed heads' rather than 'It landed tails,' which it does not. The point extends to less irrational beliefs. If we interpret someone as judging on purely probabilistic grounds that ticket n did not win the lottery, our interpretation gains or loses no credit dependent on whether ticket n did in fact win, since either way the agent in the circumstances could not have known that it did not win.10
Is knowledge maximization in danger of absurdly imputing knowledge of quantum mechanics to Stone Age people? They were in no

9
The substitution of knowledge for truth in a principle of charity is proposed in connection with a knowledge-based account of assertion by Williamson (2000a:
267).
10
An interpretation on which the agent believes that ticket n did not win might do better than one on which the agent believes that ticket n won, even though neither constitutes knowledge, if the former attributes more knowledge of chances to the agent than the latter does. position to know about quantum mechanics, so even on an interpretation on which they referred to quantum mechanical properties and relations they would not know about those properties and relations.
Objective limits on what subjects are in a position to know appropriately constrain the maximization of knowledge by the assignment of reference. Unless it is raining, one does not know that it is raining.
Even if it is raining, one may lack the kind of causal contact with the rain one needs in order to know that it is raining. The compositional structure of sentences and thoughts further constrains the ascription of knowledge, because the inferential processes in which subjects engage are sensitive to that structure: to interpret those processes as yielding knowledge, one must interpret them as valid inferences.
Knowledge maximization need not make the ascription of knowledge come too cheap. By contrast, Davidson’s principle of charity gives good marks to an interpretation for having Stone Age people assent to many truths of quantum mechanics, if it happens to fit the compositional structure of their language.
One might still fear that the knowledge maximization principle is over-charitable. Suppose, for example, that I can see only a small part of a ball, the rest of which is hidden by some obstacle. I judge of the ball 'It is red.' Unknown to me, the rest of the ball is green, so that the ball as a whole does not qualify as red. I falsely believe, and do not know, that the ball is red; at best I know that the visible part of the ball is red. Does knowledge maximization imply, falsely, that the visual demonstrative 'it' refers to just the presently visible part of the ball rather than to the whole ball? Ask first why the visual demonstrative does not refer to the ball part. One answer is that since the ball is a more natural object than the ball part, it is a more eligible referent; I refer to the ball by default because I have done nothing special to divert reference to the ball part. Equally, then, I
have failed to do the individuative work required to know anything about the ball part. By contrast, I can express some knowledge about the ball, for example, by 'It is there,' if 'it' refers to the ball.
An alternative answer is that I have positively individuated the ball, for example because my basic judgment was 'That thing is red,'
in a thick sense of 'thing' applicable to the ball but not to the ball part, from which in effect I derived 'It is red' using the identity
'It is that thing.' But then 'It is red' expresses knowledge only if
'That thing is red' and 'It is that thing' express knowledge and the inference is valid, so 'it' and 'that thing' remain constant in reference across premises and conclusion. But if 'it' refers to the ball part on both occurrences, then both premises are false, since 'that thing' refers to the ball, so the conclusion fails to express knowledge.
By contrast, if 'it' refers anaphorically on 'that thing' to the ball, 'It is that thing' expresses knowledge, even though the other premise and the conclusion are false. Of course, there are further possibilities. But it is already appreciable that the holistic character of the considerations gives plenty of scope for the knowledge maximization principle to get the right answer, arguably for the right reasons.
Another doubt about knowledge maximization concerns variants of the Celia/Elsie case above in which Emanuel knows independently that Elsie is F, G, H, . . . However, he can still use 'she' as a visual demonstrative to refer to Celia in judging 'She is F,' 'She is G,'
'She is H, . . . ,' thereby expressing false beliefs about Celia rather than knowledge about Elsie, because those judgments are not causally based on his independent knowledge of Elsie, and therefore fail to express that knowledge. Of course, in a further variant of the case,
Emanuel makes the identity judgment 'She is Elsie,' and then judges
'She is F,' 'She is G,' 'She is H, . . . ,' on the basis of inference from the identity judgment and the premises 'Elsie is F,' 'Elsie is
G,' 'Elsie is H, . . . ,' so that his independent knowledge of Elsie is causally active in his reaching the conclusions. Even in that case, knowledge maximization still does not warrant assigning Elsie as the referent of the visual demonstrative 'she.' If knowledge is sensitive to differences in mode of presentation, and 'she' is associated with a visual mode of presentation, then the judgment 'She is Elsie' does not constitute knowledge; consequently, the further judgments derived from it also fail to constitute knowledge. On the other hand, if knowledge is not sensitive to differences in mode of presentation, then assigning Elsie as the referent of 'she' merely makes the judgments
'She is F,' 'She is G,' 'She is H, . . . ,' express the same knowledge as 'Elsie is F,' 'Elsie is G,' 'Elsie is H, . . . ,' already express; no knowledge is gained. Moreover, that assignment also makes judgments such as 'She is standing in front of me' fail to constitute knowledge, whereas they do constitute knowledge on the assignment of Celia as the referent of 'she.' Hence the correct assignment (Celia)
involves the ascription of more knowledge than the incorrect one (Elsie) does. Thus knowledge maximization is consistent with a correct interpretation of such cases.
Perhaps the underlying worries about knowledge maximization can be captured in a more abstract form. Knowing is itself an intentional state. As already emphasized, the present aim is not to reduce the intentional to the non-intentional. But to explain reference by appeal to the intentional features of knowledge states – which objects, properties, and relations they are about – is in effect to explain reference in terms of itself. In order to avoid such trivialization, we must avoid helping ourselves to those intentional features, and instead concentrate on the imputed reliability of the subject (in some appropriate sense) under various assignments of reference
(where such assignments assign reference across many possible worlds). But if that is what we have to maximize, surely the winner is likely to be some artificial cooked-up assignment quite different from what is pretheoretically correct. For example, a highly contextsensitive assignment may make the Stone Age people reliable about matters of quantum mechanics. Similarly, some assignment will make the victim of a skeptical scenario come out thinking reliably about their own brain states rather than unreliably about the wider world.
And so on. How can knowledge maximization avoid such false consequences without collapsing into triviality?
We take such assignments of reference to be incorrect because we take them to be gerrymandered, unnatural, insensitive to the underlying similarities and differences, not cutting at the joints. The corresponding ascriptions of knowledge make it an equally artificial attitude. In response to such examples, we should therefore insist that the relation to be maximized is a natural one: doubtless not a perfectly natural one, for the most basic structure of the world is not mental, but natural by the standards of mentality. Such a bias towards naturalness in the objects of reference has independent support (Lewis
1983b, Weatherson 2003, Hawthorne 2006: 53–69). Here it is extended to the relation of reference itself, by inheritance from the relation of knowledge. It holds the anti-skeptical effect of knowledge maximization within reasonable limits.
The more abundant ontology is, the more objects, properties, and relations there are, the more scope there is for an assignment of reference under which we know. Conversely, the sparser ontology is, the fewer objects, properties, and relations there are, the greater the

Knowledge Maximization danger that we do not know under any assignment. But the correlation is imperfect, for a sparse ontology sometimes facilitates knowledge by reducing the number of wrong answers clustered around the right one and hard to distinguish from it. Knowledge maximization tilts the playing field in our favor without guaranteeing us victory.
Is it surprising that reference maximizes knowledge? Reference concerns what mental states and acts are about. Knowledge is one mental state among many. Why should it play a privileged role in determining what all of them are about? One answer is that knowledge is not just one mental state among many. A creature that is not aware of anything at all has no mental life. It lacks genuine intelligence. Although intelligent life does not consist solely of awareness, it is intelligent only because appropriately related to awareness of something. But to be aware is to know: one is aware that P if and only if one knows that P, and one could hardly be aware of anything without some capacity to know that something is the case. Intelligent life is life appropriately related to intelligent action, and intelligent action is action appropriately related to knowledge. In a paradigm of intelligent action, given a desire that P, one knowingly does A, knowing that if one does A then P. One can believe that one does A
and that if one does A then P, even truly, without knowing, but the action is defective in such cases; they are to be understood in relation to non-defective cases. The function of intelligent action involves the application of knowledge to realize the agent’s ends. In unfavorable circumstances, only mere beliefs are available, and intentional action does not function properly, although with good luck it may still achieve the desired end, just as other defective processes sometimes issue in the intended product.11
11

Williamson (2000a) has more on the associated conception of mind and knowledge. The idea that all thinking qualifies as such by being appropriately related to knowing was advocated by another Wykeham Professor of Logic, John Cook Wilson
(1926, vol. I: 35–40, also for the view that knowledge is indefinable). He defends a neo-Aristotelian version of common sense realism on which ordinary language has a central role in metaphysics. Of the 'examination of the meaning of grammatical forms' and the consideration of 'certain distinctions of the kind called metaphysical'
he says 'The two investigations are necessarily connected with one another; for since the sentence or statement describes the nature of objects and not any attitude of ours to the objects described, in the way of apprehension or opinion, its meaning is wholly objective, in the sense that we have already given to objective. That is, it is about When conditions are unfavorable, the agent is in no position to know anything much, just as a victim of total paralysis may be in no position to do anything much. Intentional action may be limited to pursuing a line of thought. For a brain in a vat, both knowledge and action may shrink to the internal: but that pathological case does not reveal their underlying nature, for it does not show them to be equally shrunken in more normal cases. Rather, the pathological cases are parasitic on the normal ones.
Given the central role of knowledge in intelligent life, the intimate relation between knowledge and reference is hardly surprising. Reference maximizes knowledge because its role is to serve knowledge, not to impose any independent limitation on it. Although maximizing knowledge is not equivalent to maximizing true belief, the nature of reference grounds a general, highly defeasible tendency for beliefs to constitute knowledge, and therefore to be true.

5
On a more internalist proposal, the nature of reference is to maximize justified belief rather than knowledge, where justified beliefs can be false; charity is often presented as a principle of rationality maximization. But such internalism makes the bearing of reference on justification obscure. Suppose that I have a few factual memories of a brief acquaintance, which I express using the pronoun 'he.' The assignment of one reference rather than another to 'he' seems to make no difference to the internalist justification of my memory beliefs; it makes an obvious difference to whether they constitute knowledge.
Similarly, internalist considerations of justified belief are much less likely than externalist considerations of knowledge to explain why the silly interpretation Int* in Section 2 is worse than the sensible something apprehended, in the case of knowledge for instance, and not about our apprehension of it' (1926, vol. I: 149). In respect of the fundamental role assigned to knowing, both Williamson (2000a) and the present book belong to a tradition that runs from Cook Wilson to Prichard and others, then to J.L. Austin and later to John
McDowell; see Marion (2000). That there are also very significant differences between these philosophers hardly needs saying. connection Int, for the permutation of contents preserves internal coherence but not knowledge.
On an uneasy compromise, what matters for reference is neither knowledge nor internalist justification but an intermediate standard of non-factive externalist justification. That still gets it wrong, because the failure of a brain in a vat to refer to a new object in its external environment is far better explained by its incapacity for knowledge of it than by its incapacity for justified (and perhaps true) beliefs about it, for on the supposition that it has beliefs about the object there need be no further obstacle to classifying them as justified in the relevant sense By contrast, the full-blooded external involvement of knowledge exactly suits it to constrain reference.
Can the semantic significance of knowledge be understood within
Davidson’s framework? He tries to recover a plausible epistemology by extracting epistemological consequences from his principle of charity by appeal to the immunity from massive error that it is supposed to grant. That immunity is holistic: it is consistent with the falsity of almost any given one of our beliefs, given enough compensating truth elsewhere in the system. For example, my belief that I
have hands enjoys no immunity from error. The supposed general immunity from massive error does not explain how I know that I
have hands: likewise for most of what we ordinarily take ourselves to know. Davidson adds an appeal to causal constraints on reference in simple cases, but formulates the constraints too crudely to permit any straightforward connection with knowledge (Davidson 1991:
196–7). Even if my belief that P is caused by what it is about, I may fail to know that P because the causal chain is somehow deviant.
When Davidson tries to explain how his principle of charity yields knowledge, he appears to rely on something like the pre-Gettier assumption that justified true belief is knowledge.12
12

'There is at least a presumption that we are right about the contents of our own minds; so in the cases where we are right, we have knowledge' (Davidson 1991: 194);
'Anyone who accepts perceptual externalism knows he cannot be systematically deceived about whether there are such things as cows, people, water, stars, and chewing gum. Knowing why this is the case, he must recognize situations in which he is justified in believing he is seeing water or a cow. In those cases where he is right, he knows he is seeing water or a cow' (Davidson 1991: 201). See also Davidson
(1983). A subtler attempt to extract knowledge from Davidson’s principle of charity exploits beliefs that one knows. Very often, when one believes that P, one also believes that one knows that P.13 If one believes truly that one knows that P, then one does know that P. Does maximizing true belief therefore indirectly maximize knowledge too?
The detour through second-order belief is unpromising. First, it depends on the assumption that the relevant agents are to be interpreted as believing that they know. Of course, we often believe that we know; for that matter, we often know. But the aim was to derive the conclusion that agents in general often know from a truthmaximizing principle of charity; that agents in general often believe that they know has not been derived from such a principle. Second, even granted that agents believe that they know, Davidson’s principle attributes no special status to beliefs of that form; an interpretation might sacrifice them all as false and still maximize true belief overall by making enough other beliefs true. Third, the account does not generate attributions of knowledge to simple creatures who lack the concept of knowledge and therefore cannot believe that they know; surely they can have knowledge without having the concept of knowledge.14 Truth maximization lacks most of the epistemological rewards of knowledge maximization.
Quine endorses as a canon of translation the epistemologicalsounding maxim 'Save the obvious' (1970: 82; compare 1960: 59): do not interpret the natives as dissenting from obvious truths. On that
13

The principle cannot be exceptionless, otherwise having any belief involves having infinitely many beliefs of increasing complexity.
14
Davidson might have denied that one can have knowledge without the concept of knowledge, for he denies that one can have beliefs without the concept of belief:
'Someone cannot have a belief unless he understands the possibility of being mistaken, and this requires grasping the contrast between truth and error – true belief and false belief' (1975: 170). Whether or not he would extend it to knowledge,
Davidson’s argument is unconvincing, for it conflates de re and de dicto readings.
Grant for the sake of argument that, to believe that P, one must grasp the contrast between the state of affairs that P, which is in fact the condition for the belief to be true, and the state of affairs that not P, which is in fact the condition for the belief to be false (the de re reading). Even so, Davidson does not explain why one must grasp it as the contrast between the condition for the belief to be true and the condition for it to be false (the de dicto reading), which is what he needs. Thus he leaves it obscure why a creature with the concept of negation could not have a belief without the concept of belief. basis he argues that apparent deviations in logic are mere artifacts of bad translation. Although this appears to invoke a knowledge-related standard of charity, like the principle of knowledge maximization,
Quine insists on interpreting 'obvious' behavioristically rather than epistemologically.15 His intended maxim is that translation should preserve general assent. Without further argument, we cannot conclude that sentences that enjoy general assent are true, for we can assume neither that every sentence to which speakers of another language assent can be translated into English nor that every sentence to which speakers of English assent is true – naturally, it is harder for us, as speakers of English, to produce a counterexample. Like
Grandy’s principle of humanity, Quine’s maxim on its behavioral reading tends to project our design faults onto others. For example, it discourages us from translating a sentence to which the natives universally assent by a simple logical truth from which many speakers of English dissent through intellectual confusion. On an epistemological reading of 'obvious,' the maxim is not vulnerable to that criticism, for confused speakers can dissent from what is obvious.
We do better to start with the notion of knowledge in the explanatory order.

6
A picture of the mind has been sketched, with the broadest strokes, on which the nature of reference nudges belief towards the status of knowledge, and therefore of truth. That helps put the burden of proof on judgment skeptics to argue that their radical scenarios deserve to be taken more seriously than do the radical scenarios for skepticism about perception. Although we can allow that scenarios of both sorts are metaphysically possible, much more than that is needed to justify serious doubt. The burden of proof on the judgment skeptic is particu- 'I must stress that I am using the word ‘obvious’ in an ordinary behavioral sense, with no epistemological overtones. When I call ‘1 + 1 = 2’ obvious to a community
I mean only that everyone, nearly enough, will unhesitatingly assent to it, for whatever reason; and when I call ‘It is raining’ obvious in particular circumstances I mean that everyone will assent to it in those circumstances' (Quine 1970: 82). larly heavy when the proposed scenarios make vast ranges of common beliefs false or at least not knowledge, as many of them do.16
A judgment skeptic might respond: 'Granted, when we believe p, we often – but not always – know p. That we believe p should therefore be treated as good but defeasible evidence for p. It is just one more part of the total body of evidence on which philosophical theories should be evaluated.' This response depends on the fallacy, diagnosed in the previous chapter, of psychologizing evidence. It perversely ignores the evidential role of p itself, as opposed to that of the fact that we believe p. After all, if we do know p, would it not be negligent not to use that knowledge in evaluating a philosophical theory to which it is relevant? Philosophy is hard enough already: why make it even more difficult by forbidding ourselves to bring some of our knowledge to bear? You are not obliged to fight with one arm tied behind your back.17
The judgment skeptic might reply that, if we know p without knowing that we know p, the knowledge does not really help. But that response is doubly inadequate. First, it gives no more reason to deny that we know that we know p than to deny that we know p in the relevant cases. Although we cannot expect to have infinitely many iterations of knowledge, for more than computational reasons
(Williamson 2000a: 114–34), that general point merely shows that we must sometimes simply apply our knowledge, without first checking whether we know, for otherwise we get stuck in an infinite regress of checks. That is the second problem for the judgment skeptic’s envisaged reply. It gave us no evidence that we are entitled to rely on the premise p in philosophical discussion only if we know that we know p.
When we know, there is something non-trivial to be said about how we know. But we may know p, and even know that we know p, without knowing how we know p. For instance, we may know that we know the truth of some logical or mathematical axioms without knowing how we know their truth. Similarly, the epistemic role of elegance and simplicity in theoretical physics seems as indis16

The case of folk physics does not constitute a straightforward skeptical scenario, for folk physics plays a role in generating much knowledge of particular facts about our environment.
17
See Williamson (2000a: 184–208) for defense and development of the conception of our total evidence as everything that we know. pensable as it is hard to explain. But for many philosophically contentious facts, the question 'How do you know?' is not unusually puzzling. There is no distinctive mystery as to how we know that there are mountains in Switzerland. We can explain how we know, typically by describing the process by which we acquired the knowledge, without having to convince the skeptic who doubts that we know.
Even those who know p can sometimes be too dogmatic about p in this sense: their summary dismissal of objections to p manifests general cognitive dispositions whose overall tendency is to limit their knowledge and increase their error, by preventing them from learning from experience or criticism.18 But that does not show that they acted wrongly in treating p as evidence in this particular case. There will always be cases in which bad dispositions produce right actions and good dispositions produce wrong ones; since philosophers question fundamental assumptions, they are particularly liable to get themselves into such cases.
The knowledge maximization principle is not itself intended as an answer to the question 'How do you know?' The knowledge maximized may have been acquired by quite familiar means of perception, memory, testimony, inference, and imagination. The proper response to judgment skepticism is not to postulate a separate means to knowledge to underpin all the others but rather to challenge the skeptical idea that they need such underpinning. The supposed function of the underpinning would be to rule out the scenarios that motivate judgment skepticism. But a good answer to the question 'How do you know p?' need not specifically address far-fetched skeptical scenarios for p, since knowing p does not require specifically addressing them. Knowledge maximization is a factor, typically unnoticed by judgment skeptics, that makes their scenarios more far-fetched than they realize.
More naturalistically inclined judgment skeptics try to induce a crisis of confidence in present common sense by pointing towards a present or future scientific outlook that stands to present common sense as the latter stands to a Stone Age outlook. But the analogy rebounds against judgment skepticism. For although it is plausible
One can know p and acquire counter-evidence to p that is significant, but not significant enough to make one cease to know p. 278 Knowledge Maximization

that Stone Age people had many false beliefs about the general nature of the world, it is at least as plausible that they had significant knowledge of their local environment. Knowledge maximization implies that our ancestors had some primitive knowledge as soon as they had some primitive beliefs; it is not as though archaeology suggests otherwise. Again, if it is plausible that some non-human animals have primitive beliefs, it is equally plausible that they have some primitive knowledge.
Consider this analogue for observational evidence of the judgment skeptic’s response to knowledge maximization: 'Granted, when we have a perceptual belief in p, we often – but not always – know p.
That we have a perceptual belief in p should therefore be treated as good but defeasible evidence for p. It is just one more part of the total body of evidence on which scientific theories should be evaluated.' What this response perversely ignores is the evidential role of p itself, as opposed to that of the fact that we have a perceptual belief in p. After all, if we do know p, would it not be negligent not to use that knowledge in evaluating a scientific theory to which it is relevant? It would not advance science to insist that scientists’ evidence cannot include the fact that 19 out of 20 rats fed the substance died within 24 hours, but only the fact that the scientist had the perceptual belief that 19 out of 20 rats fed the substance died (only the former fact leads itself to statistical analysis). Such claims about past beliefs are not peculiarly foundational. Indeed, they are less amenable to public checking by the scientific community than are claims about the actual outcomes of experiments. Of course, it may later turn out that a disgruntled lab technician fed the rats the wrong substance, but the proper response to such remote possibilities is to backtrack if one of them is found to obtain, not to make a futile attempt in advance to identify evidence for which backtracking will never be required in even the remotest eventualities.
In philosophy as in natural science, our evidence consists of ordinary human knowledge. We have no general guarantee that we know everything we think we know. Our evidence is more contested in philosophy than in natural science. The philosopher’s predicament is somewhat like that which would face natural scientists if accusations of falsified evidence were vastly more common in science than they currently are. Whatever the discipline, when someone disputes the evidence, it is often better to look for common ground on which to pursue the argument than to ride roughshod over the objections.
For that temporary purpose, we may refrain from treating the disputed evidence as evidence; that does not entail that it should never have been treated as evidence in the first place. Moreover, as we have seen, the search for common ground can be taken too far, especially with a reckless opponent who does not scruple to challenge any inconvenient evidence. An indiscriminate skeptic can challenge whatever we offer as evidence, by always demanding a proof; that should not drive us to suspend all our evidence. At some point we are entitled to hold on to what we know, and apply it.
Our evidence in philosophy consists of a miscellaneous mass of knowledge, expressed in terms of all kinds, some from ordinary language, some from the theoretical vocabulary of various disciplines.
Some of it consists of knowledge about our own mental states; most of it does not. Whatever we know is legitimate evidence. Inevitably, we make mistakes, treating as known what is unknown, or as unknown what is known. The principle of knowledge maximization helps our practice survive our critical reflection, by reassuring us that knowing is a natural state for believers, not an anomalous achievement. In general, our practice makes sense, which of course does not excuse us from meeting particular challenges on their merits. This messy epistemological predicament in which philosophers find themselves is not deeply different from the messy epistemological predicament of all human inquiry.

Afterword
Must Do Better

Imagine a philosophy conference in Presocratic Greece. The hot question is: what are things made of? Followers of Thales say that everything is made of water, followers of Anaximenes that everything is made of air, and followers of Heraclitus that everything is made of fire. Nobody is quite clear what these claims mean; some question whether the founders of the respective schools ever made them.
But among the groupies there is a buzz about all the recent exciting progress. The mockers and doubters make plenty of noise too. They point out that no resolution of the dispute between the schools is in sight. They diagnose Thales, Anaximenes, and Heraclitus as suffering from a tendency to over-generalize. We can intelligibly ask what bread is made of, or what houses are made of, but to ask what things in general are made of is senseless, some suggest, because the question is posed without any conception of how to verify an answer; language has gone on holiday. Paleo-pragmatists invite everyone to relax, forget their futile pseudo-inquiries, and do something useful instead.
The mockers and doubters had it easy, but we know now that in at least one important respect they were wrong. With however much confusion, Thales and the rest were asking one of the best questions ever to have been asked, a question that has painfully led to much of modern science. To have abandoned it two and a half thousand years ago on grounds of its conceptual incoherence or whatever would have been a feeble and unnecessary surrender to despair, philistinism, cowardice, or indolence. Nevertheless, it is equally clear that the methods of investigation used by the Presocratics were utterly inadequate to their ambitions. If an intellectual tradition applied just those methods to those questions for two and a half millennia, which

Afterword: Must Do Better is far from unimaginable, it might well be very little the wiser at the end. Much of the progress made since the Presocratics consists in the development of good methods for bringing evidence to bear on questions that, when first asked, appear hopelessly elusive or naïve. Typically, of course, making progress also involves refining and clarifying the initial question: but the relevant refinements and clarifications cannot all be foreseen at the beginning. They emerge in the process of attempting to answer the original rough question, and would not emerge otherwise.
The Presocratics were forerunners of both modern philosophy and modern natural science; they did not distinguish natural science from philosophy. For positivists, the moral of the story is that natural science had to be separated from philosophy, and marked out as the field for observation, measurement, and experiment, before it could make serious progress. There is doubtless something right about that moral, although as it stands it hardly does justice to the significance of armchair methods in natural science, such as the use of mathematics and of thought experiments, for example by Galileo and Einstein.
Moreover, the positivist moral misses a deeper methodological point.
The case of the Presocratics shows that one cannot always tell in advance which questions will be fruitful to pursue. Even if a community starts with no remotely adequate idea of how to go about answering a question, it does not follow that the question is meaningless or not worth addressing. That goes for the questions we now classify as philosophical as much as it does for those we now classify as empirical or natural-scientific.
The opponents of systematic philosophical theorizing might reply that they are not judging philosophical questions in advance; they are judging them after two and a half millennia of futile attempts to answer them. Of course, it is an important issue how similar our philosophical questions are to those of ancient Greece, or even to those of Enlightenment Europe. Nevertheless, philosophy has been going too long as an intellectual tradition separate from natural science (although sometimes interacting with it) for the question
'How much progress has it made?' to be simply dismissed as premature.
We should not be too pessimistic about the answer, at least concerning the broad, heterogeneous intellectual tradition we conveniently label 'analytic philosophy.' In many areas of philosophy, we know much more in 2007 than was known in 1957; much more was known in 1957 than in 1907; much more was known in 1907
than was known in 1857. As in natural science, something can be collectively known in a community even if it is occasionally denied by eccentric members of that community. Although fundamental disagreement is conspicuous in most areas of philosophy, the best theories in a given area are in most cases far better developed in 2007
than the best theories in that area were in 1957, and so on. Much of the knowledge is fairly specific in content. For example, we know far more about possibility and necessity than was known before the development of modern modal logic and associated work in philosophy. It is widely known in 2007 and was not widely known in 1957
that contingency is not equivalent to a posteriority, and that claims of contingent or temporary identity involve the rejection of standard logical laws. The principle that every truth is possibly necessary can now be shown to entail that every truth is necessary by a chain of elementary inferences in a perspicuous notation unavailable to Hegel
A is derivable from instances of
(every instance of the schema A
the schema A
A in the weak modal system T). We know much about the costs and benefits of analyzing possibility and necessity in terms of possible worlds, even if we do not yet know whether such an analysis is correct.1
Another example: Far more is known in 2007 about truth than was known in 1957, as a result of technical work by philosophical and mathematical logicians such as Saul Kripke, Solomon Feferman,
Anil Gupta, Vann McGee, Volker Halbach, and many others on how close a predicate in a language can come to satisfying a full disquotational schema for that very language without incurring semantic
1

This guarded optimism about philosophical progress is consistent with the pessimism in Williamson (2000a) about the prospects for the post-Gettier program of analyzing the concept of knowledge and similar programs of analyzing other philosophically significant concepts. Such programs did make progress in clarifying the relations between the concepts under study (and between the things to which those concepts refer). What they failed to make plausible was that the eventual outcome of such progress would be anything like an analysis in the intended sense (necessary and sufficient conditions stated in non-circular terms, perhaps meeting further conditions).
Take any concept that is indefinable in the relevant sense: the vain program of analyzing it in terms of more basic concepts, if conducted by able and honest people over several decades, would lead to some progress of this kind. paradoxes. Their results have significant and complex implications, not yet fully absorbed, for current debates concerning deflationism and minimalism about truth (see Halbach (2001) for a recent example). One clear lesson is that claims about truth need to be formulated with extreme precision, not out of knee-jerk pedantry but because in practice correct general claims about truth often turn out to differ so subtly from provably incorrect claims that arguing in impressionistic terms is a hopelessly unreliable method. Unfortunately, much philosophical discussion of truth is still conducted in a programmatic, vague, and technically uninformed spirit whose products inspire little confidence.
In 1957, Michael Dummett was about to open his campaign to put the debate between realism and anti-realism, as he conceived it, at the centre of philosophy. The campaign had a strong methodological component. Intractable metaphysical disputes (for example, about time) were to be resolved by being reduced to questions in the philosophy of language about the proper form for a semantic theory of the relevant expressions (for example, tense markers). The realist’s semantic theory would identify the meaning of an expression with its contribution to the truth conditions of declarative sentences in which it occurred. The anti-realist’s semantic theory would identify the meaning with the expression’s contribution to the assertability conditions of those sentences. Instead of shouting slogans at each other,
Dummett’s realist and anti-realist would busy themselves in developing systematic compositional semantic theories of the appropriate type, which could then be judged and compared by something like scientific standards. But that is not what happened.
True, over recent decades truth-conditional semantics for natural languages has developed out of philosophical logic and the philosophy of language into a flourishing branch of empirical linguistics.
Frege already had the fundamental conception of compositional truth-conditional semantics, in which expressions refer to items in the mostly non-linguistic world, the reference of a complex expression is a function of the reference of its constituents, and the reference of a sentence determines its truth value. But Frege was more concerned to apply that conception to ideally precise and perspicuous artificial languages than to messy natural ones. The systematic application of compositional truth-conditional semantics to natural languages goes back to Richard Montague (under the influence of Carnap) in its intensional form and has been mediated in linguistics by Barbara Partee and others. In its extensional form, it goes back to Donald Davidson (under the influence of Tarski) and has been mediated in linguistics by Jim Higginbotham and others. Needless to say, that crude schema does no justice to the richness of recent work and the variety of contributors to it (in both departments of philosophy and departments of linguistics), which one can check by looking at any decent handbook of contemporary semantic theory as a branch of linguistics. Surprisingly, however, most participants in the
Dummett-inspired debates between realism and anti-realism have shown little interest in the success of truth-conditional semantics, judged as a branch of empirical linguistics. Instead, they have tended to concentrate on Dummett’s demand for 'non-circular' explanations of what understanding a sentence with a given truth condition
'consists in,' when the speaker cannot verify or falsify that condition. That demand is motivated more by preconceived philosophical reductionism than by the actual needs of empirical linguistics. Thus the construction and assessment of specific truth-conditional semantic theories has almost disappeared from sight in the debate on realism and anti-realism.
As for assertability-conditional semantics, it began with one more or less working paradigm: Heyting’s intuitionistic account of the compositional semantics of mathematical language in terms of the condition for something to be a proof of a given sentence. The obvious and crucial challenge was to generalize that account to empirical language: as a first step, to develop a working assertabilityconditional semantics for a toy model of some small fragment of empirical language. But that challenge was shirked. Anti-realists preferred to polish their formulations of the grand program rather than getting down to the hard and perhaps disappointing task of trying to carry it out in practice. The suggestion that the program’s almost total lack of empirical success in the semantics of natural languages might constitute some evidence that it is mistaken in principle would be dismissed as crass.
Some participants in the debate denied any need for anti-realists to develop their own semantic theories of a distinctive form. For, it was proposed, anti-realists could take over truth-conditional semantic theories by interpreting 'true' to mean assertable or verifiable at the limit of inquiry, or some such epistemic account of truth (Wright 1993: 403–25). But that proposal is quite contrary to Dummett’s original arguments. For they require the key semantic concept in the anti-realistic semantics, the concept in terms of which the recursive compositional clauses for atomic expressions are stated, to be decidable, in the sense that the speaker is always in a position to know whether it applies in a given case. That is what allows anti-realists to claim that, unlike realists, they can give a non-circular account of what understanding a sentence consists in: a disposition to assert it when and only when its assertability condition obtains. But it is supposed to be common ground between realists and anti-realists that truth is not always decidable. A speaker may understand a sentence without being in a position either to recognize it as true or to recognize it as not true. I can understand the sentence 'There was once life on Mars,' even though I have neither warrant to assert 'There was once life on Mars' nor warrant to assert 'There was never life on Mars.' The point is particularly clear in the intuitionistic semantics for mathematical language. The key concept in the compositional semantics is the concept p is a proof of s, which is decidable on the intuitionistic view because to understand a sentence is to associate it with an effective procedure for recognizing whether any given putative proof is a proof (in some canonical sense) of it. By contrast, what serves as the intuitionistic concept of truth is not the dyadic concept p is a proof of s nor even the monadic concept s has been proved but the monadic concept s has a proof or s is provable.
According to intuitionists, we understand many mathematical sentences (such as 'There are seven consecutive 7s in the decimal expansion of π') without having a procedure for recognizing whether they are provable. We understand them because we can recognize of any given putative proof, once presented to us, whether it is indeed a proof of them. Nor can we replace 'true' in a truth-conditional semantics by 'has been proved' (treated as decidable), because that would reduce the semantic clause for negation (that the negation of a sentence s is true if and only if s is not true) to the claim that the negation of s has been proved if and only if s has not been proved, which is uncontroversially false whenever s has not yet been decided.
Dummett’s requirement that assertability be decidable forces assertability-conditional semantics to take a radically different form from that of truth-conditional semantics. Within this tradition, anti- realists have simply failed to develop natural language semantics in that form, or even to provide serious evidence that they could so develop it if they wanted to.2 They proceed as if Imre Lakatos had never promulgated the concept of a degenerating research program.
Dummett’s posing of the issue between realism and anti-realism provides a case study of an occasion when the philosophical community was offered a new way of gaining theoretical control over notoriously elusive issues, through the development of systematic semantic theories. The community spurned the opportunity, if that is what it was. Those who discussed realism and anti-realism on
Dummett’s terms tended to concentrate on the most programmatic issues, which they debated with no more clarity or conclusiveness than was to be found in the traditional metaphysical reasoning that
Dummett intended to supersede. The actual success or lack of it in applying the rival semantic programs to specific fragments of natural language was largely ignored. Far from serving as a beacon for a new methodology, the debate between realism and anti-realism has become notorious in the rest of philosophy for its obscurity, convolution, and lack of progress.
Of course, one may reject Dummett’s attempted reduction of issues in metaphysics to issues in the philosophy of language. As seen in earlier chapters, not all philosophical questions are really questions about language or thought. However, as we also saw, that a question is non-semantic does not imply that semantics imposes no useful constraints on the process of answering it. To reach philosophical conclusions one must reason, usually in areas where it is very hard to distinguish valid from invalid reasoning. To make that distinction reliably, one must often attend carefully to the semantic form of the premises, the conclusion, and the intermediate steps. That requires implicit semantic beliefs about the crucial words and constructions.
Sometimes, those beliefs must be tested by explicit semantic theorizing. Philosophers who refuse to bother about semantics, on the grounds that they want to study the non-linguistic world, not our
2

Perhaps some work in contemporary formal semantics can be interpreted as assertability conditional rather than truth conditional in spirit: for instance, probability semantics for conditionals and other constructions, some forms of speech act theory, some theories of dynamic semantics. It is doubtful that much of this work conforms to Dummett’s anti-realist constraints, or even makes a serious attempt to do so. talk about that world, resemble scientists who refuse to bother about the theory of their instruments, on the grounds that they want to study the world, not our observation of it. Such an attitude may be good enough for amateurs; applied to more advanced inquiries, it produces crude errors. Those metaphysicians who ignore language in order not to project it onto the world are the very ones most likely to fall into just that fallacy, because their carelessness of the structure of the language in which they reason makes them insensitive to subtle differences between valid and invalid reasoning.
Explicit compositional semantic theories for reasonable fragments of particular natural languages also have the great methodological advantage of being comparatively easy to test in comparatively uncontentious ways, because they make specific predictions about the truth conditions (or assertability conditions) of infinitely many ordinary unphilosophical sentences. The attempt to provide a semantic theory that coheres with a given metaphysical claim can therefore constitute a searching test of the latter claim, even though semantics and metaphysics have different objects.
Discipline from semantics is only one kind of philosophical discipline. It is insufficient by itself for the conduct of a philosophical inquiry, and may sometimes fail to be useful, when the semantic forms of the relevant linguistic constructions are simple and obvious.
But when philosophy is not disciplined by semantics, it must be disciplined by something else: syntax, logic, common sense, imaginary examples, the findings of other disciplines (mathematics, physics, biology, psychology, history, . . .) or the aesthetic evaluation of theories (elegance, simplicity, . . .). Indeed, philosophy subject to only one of those disciplines is liable to become severely distorted: several are needed simultaneously. To be 'disciplined' by X here is not simply to pay lip-service to X; it is to make a systematic conscious effort to conform to the deliverances of X, where such conformity is at least somewhat easier to recognize than is the answer to the original philosophical question. Of course, each form of philosophical discipline is itself contested by some philosophers. But that is no reason to produce work that is not properly disciplined by anything. It may be a reason to welcome methodological diversity in philosophy: if different groups in philosophy give different relative weights to various sources of discipline, we can compare the long-run results of the rival ways of working. Tightly constrained work has the merit that even those who reject the constraints can agree that it demonstrates their consequences.
Much contemporary analytic philosophy seems to be written in the tacit hope of discursively muddling through, uncontrolled by any clear methodological constraints. That may be enough for easy questions, if there are any in philosophy; it is manifestly inadequate for resolving the hard questions with which most philosophers like to engage. All too often it produces only eddies in academic fashion, without any advance in our understanding of the subject matter.
Although we can make progress in philosophy, we cannot expect to do so when we are not working at the highest available level of intellectual discipline. That level is not achieved by effortless superiority.
It requires a conscious collective effort.
We who classify ourselves as 'analytic' philosophers tend to fall into the assumption that our allegiance automatically grants us methodological virtue. According to the crude stereotypes, analytic philosophers use arguments while 'continental' philosophers do not.
But within the analytic tradition many philosophers use arguments only to the extent that most 'continental' philosophers do: some kind of inferential movement is observable, but it lacks the clear articulation into premises and conclusion and the explicitness about the form of the inference that much good philosophy achieves. Again according to the stereotypes, analytic philosophers write clearly while
'continental' philosophers do not. But much work within the analytic tradition is obscure even when it is written in everyday words, short sentences and a relaxed, open-air spirit, because the structure of its claims is fudged where it really matters.
If the high standards that make philosophy worth doing are often absent even in analytic philosophy, that is not because they are a natural endowment found only in a brilliant elite. Even if Frege’s exceptional clarity and rigor required innate genius – although they undoubtedly also owed something to the German mathematical tradition within which he was educated – after his example they can now be effectively taught. Some graduate schools communicate something like his standards, others notably fail to do so.
Of course, we are often unable to answer an important philosophical question by rigorous argument, or even to formulate the question clearly. High standards then demand not that we should ignore the question, otherwise little progress would be made, but that we should be open and explicit about the unclarity of the question and the inconclusiveness of our attempts to answer it, and our dissatisfaction with both should motivate attempts to improve our methods. Moreover, it must be sensible for the bulk of our research effort to be concentrated in areas where our current methods make progress more likely.
We may hope that in the long term philosophy will develop new and more decisive methods to answer its questions, as unimaginable to us as our methods were to the Presocratics. Indeed, the development of such methods is one of the central challenges facing systematic philosophy. Paul Grice once wrote 'By and large the greatest philosophers have been the greatest, and the most self-conscious, methodologists; indeed, I am tempted to regard this fact as primarily accounting for their greatness as philosophers' (Grice 1986: 66).
Nevertheless, we must assume, in the short term philosophy will have to make do with something like currently available methods. But that is no reason to continue doing it in a methodologically unreflective way. A profession of very variable standards can help the higher to spread at the expense of the lower, by conscious collective attention to best practice.
One might think that methodological consciousness-raising is unnecessary, because on any particular issue good arguments will tend to drive out bad in the long run, by a reverse analogue of
Gresham’s Law. But that is over-optimistic. Very often – not least in debates between realists and anti-realists – a philosopher profoundly wants one answer rather than another to a philosophical question to be right, and is therefore predisposed to accept arguments that go in the preferred direction and reject contrary ones. Where the level of obscurity is high, wishful thinking may be more powerful than the ability to distinguish good arguments from bad, to the point that convergence in the evaluation of arguments never occurs.
Consider a dispute between rival theories in natural science. Each theory has its committed defenders, who have invested much time, energy, and emotion in its survival. The theories are not empirically equivalent, but making an empirical determination between them requires experimental skills of a high order. We may predict that if the standards of accuracy and conscientiousness in the community are high enough, truth will eventually triumph. But if the community is slightly more tolerant of sloppiness and rhetorical obfuscation, then each school may be able to survive indefinitely, claiming empirical vindication and still verbally acknowledging the value of rigor, by protecting samples from impurities a little less adequately, describing experimental results a little more tendentiously, giving a little more credit to ad hoc hypotheses, dismissing opposing arguments as question-begging a little more quickly, and so on. Each tradition maintains recruitment by its dominance and prestige in some departments or regions. A small difference in how carefully standards are applied can make the large difference between eventual convergence and ultimate divergence.
It seems likely that some parts of contemporary analytic philosophy just pass the methodological threshold for some cumulative progress to occur, however slowly, while others fall short of the threshold. For example, a reasonable fear is that debates over realism and anti-realism fall short. That is not to condemn every piece of work in such areas individually – which would surely be unfair – but to say that collectively the community of participants has not held itself responsible to high enough methodological standards. Perhaps these debates raise even more difficult issues than are encountered elsewhere in philosophy: if so, all the more reason to apply the very highest standards available. As already noted, that appears not to have happened.
How can we do better? We can make a useful start by getting the simple things right. Much even of analytic philosophy moves too fast in its haste to reach the sexy bits. Details are not given the care they deserve: crucial claims are vaguely stated, significantly different formulations are treated as though they were equivalent, examples are under-described, arguments are gestured at rather than properly made, their form is left unexplained, and so on. A few resultant errors easily multiply to send inquiry in completely the wrong direction.
Shoddy work is sometimes masked by pretentiousness, allusiveness, gnomic concision, or winning informality. But often there is no special disguise: producers and consumers have simply not taken enough trouble to check the details. We need the unglamorous virtue of patience to read and write philosophy that is as perspicuously structured as the difficulty of the subject requires, and the austerity to be dissatisfied with appealing prose that does not meet those standards. The fear of boring oneself or one’s readers is a great enemy of truth. Pedantry is a fault on the right side.

Afterword: Must Do Better Precision is often regarded as a hyper-cautious characteristic. It is importantly the opposite. Vague statements are the hardest to convict of error. Obscurity is the oracle’s self-defense. To be precise is to make it as easy as possible for others to prove one wrong. That is what requires courage. But the community can lower the cost of precision by keeping in mind that precise errors often do more than vague truths for scientific progress.
Would it be a good bargain to sacrifice depth for rigor? That bargain is not on offer in philosophy, any more than it is in mathematics. No doubt, if we aim to be rigorous, we cannot expect to sound like Heraclitus, or even Kant: we have to sacrifice the stereotype of depth. Still, it is rigor, not its absence, that prevents one from sliding over the deepest difficulties, in an agonized rhetoric of profundity. Rigor and depth both matter: but while the continual deliberate pursuit of rigor is a good way of achieving it, the continual deliberate pursuit of depth (as of happiness) is far more likely to be self-defeating. Better to concentrate on trying to say something true and leave depth to look after itself.
Nor are rigor and precision enemies of the imagination, any more than they are in mathematics. Rather, they increase the demands on the imagination, not least by forcing one to imagine examples with exactly the right structure to challenge a generalization; cloudiness will not suffice. They make imagination consequential in a way in which it is not in their absence. The most rigorous and precise discussion often involves the most playfulness and laughter: toying with subtly different combinations of ideas yields surprising scenarios.
Humorless solemnity masks sloppiness and confusion.
Beyond rigor and precision, mathematics has less obvious values to teach. In particular, a mathematical training makes one appreciate the importance of the aesthetics of definitions. Experience shows that a mathematician or logician with no ability to discriminate between fruitful and unfruitful definitions is unlikely to achieve much in research. Such discriminations involve a sort of aesthetic judgment.
The ugly, convoluted, ramshackle definitions of concepts and theses that philosophers seem to feel no shame in producing are of just the kind to strike a mathematician as pointless and sterile. Of course, it is notoriously hard to explain why aesthetic criteria are a good methodological guide, but it would be dangerously naïve to abandon them for that reason. In addition to the humdrum methodological virtues, we need far more reflectiveness about how philosophical debates are to be subjected to enough constraints to be worth conducting. For example,
Dummettian anti-realism about the past involved, remarkably, the abandonment of two of the main constraints on much philosophical activity. In rejecting instances of the law of excluded middle concerning past times, such as 'Either a mammoth stood on this spot a hundred thousand years ago or no mammoth stood on this spot a hundred thousand years ago,' the anti-realist rejected both common sense and classical logic. Those constraints are simultaneously abandoned in many contemporary philosophical debates too, for example over vagueness. Neither constraint is methodologically sacrosanct; both can intelligibly be challenged, even together. But when participants in a debate are allowed to throw out both simultaneously, methodological alarm bells should ring: it is at least not obvious that enough constraints are left to frame a fruitful discussion. Yet such qualms surface remarkably little (although Dummett himself did not ignore the methodological issues).
Part of the problem is that it is often left unclear just how extensively a constraint is being challenged. A philosopher treats the law of excluded middle as if it carried no authority whatsoever but implicitly relies on other logical principles (perhaps in the metalanguage): exactly which principles of logic are supposed to carry authority? A
philosopher treats some common sense judgment as if it carried no authority whatsoever but implicitly relies on other judgments that are found pre-philosophically obvious: exactly which such judgments are supposed to carry authority?
When law and order break down, the result is not freedom or anarchy but the capricious tyranny of petty feuding warlords. Similarly, the unclarity of constraints in philosophy leads to authoritarianism. Whether an argument is widely accepted depends not on publicly accessible criteria that we can all apply for ourselves but on the say-so of charismatic authority figures. Pupils cannot become autonomous from their teachers because they cannot securely learn the standards by which their teachers judge. A modicum of willful unpredictability in the application of standards is a good policy for a professor who does not want his students to gain too much independence. Although intellectual deference is not always a bad thing, some debates have seen far too much of it. We can reduce it by articulating and clarifying the constraints.
Philosophy can never be reduced to mathematics. But we can often produce mathematical models of fragments of philosophy and, when we can, we should. No doubt the models usually involve wild idealizations. It is still progress if we can agree what consequences an idea has in one very simple case. Many ideas in philosophy do not withstand even that very elementary scrutiny, because the attempt to construct a non-trivial model reveals a hidden structural incoherence in the idea itself. By the same token, an idea that does not collapse in a toy model has at least something going for it. Once we have an unrealistic model, we can start worrying how to construct less unrealistic models.
Philosophers who reject the constraints mentioned above can say what constraints they would regard as appropriate. Of course, those who deny that philosophy is a theoretical discipline at all may reject the very idea of such constraints. But surely the best way to test the theoretical ambitions of philosophy is to go ahead and try to realize them in as disciplined a way as possible. If the anti-theorists can argue convincingly that the long-run results do not constitute progress, that is a far stronger case than is a preconceived argument that no such activity could constitute progress. On the other hand, if they cannot argue convincingly that the long-run results do not constitute progress, how is their opposition to philosophical theory any better than obscurantism?
Unless names are invidiously named, sermons like this one tend to cause less offence than they should, because everyone imagines that they are aimed at other people. Those who applaud a methodological platitude usually assume that they comply with it. I intend no such comfortable reading. To one degree or another, we all fall short not just of the ideal but of the desirable and quite easily possible. Certainly this afterword exhibits hardly any of the virtues that it recommends, although with luck it may still help a bit to propagate those virtues
(do as I say, not as I do). Philosophy has never been done for an extended period according to standards as high as those that are now already available, if only the profession will take them seriously to heart. None of us knows how far we can get by applying them systematically enough for long enough. We can find out only by trying. In making these comments, it is hard not to feel like the headmaster of a minor public school at speech day, telling everyone to pull their socks up after a particularly bad term. It is therefore appropriate to end with a misquotation from Winston Churchill. This is not the end of philosophy. It is not even the beginning of the end. But it is, perhaps, the end of the beginning.

Appendix 1
Modal Logic within
Counterfactual Logic

This appendix sketches the development of logics of possibility and necessity as subsystems of logics of the counterfactual conditional, on suitable definitions of the former in terms of the latter. No particular formal semantic account of the counterfactual conditional is assumed, although various sorts of model theory are occasionally used in auxiliary roles. The emphasis is on questions of deducibility from principles plausible on an informal reading of the counterfactual conditional.
For most purposes our object language is L, which has countably many propositional variables p, q, r, . . . , the propositional constant
(a logical falsehood) and two binary connectives,
(the material
(the counterfactual conditional). Other truthconditional) and functional operators are introduced as metalinguistic abbreviations in the usual way; for example, A is A
. The metalinguistic variables 'A,' 'B,' 'C,' . . . range over all formulas.
Except when otherwise specified, we work in the following axiomatic system ( means theoremhood):
If A is a truth-functional tautology then A
A
A
A)
(B
A)
( A
B and A then B
If A
C then
If (B1 & . . . & Bn)
((A
B1) & . . . & (A
Bn))
(A
C)
B) (A*
B)
EQUIVALENCE If A A* then (A

PC
REFLEXIVITY
VACUITY
MP
CLOSURE

These axiom schemas and inference rules constitute a weak subsystem of David Lewis’s 'official' logic of counterfactuals, VC (1986: 132). PC, REFLEXIVITY, and VACUITY are his axiom schemas (1),
(3), and (4) respectively, and MP is his rule of Modus Ponens (for
). CLOSURE is his rule of Deduction within Conditionals (unlike
Lewis, we allow n = 0, interpreting this case as the rule that if C
then A
C; but that special case is anyway derivable from
CLOSURE for n = 1 and REFLEXIVITY). EQUIVALENCE is a special case of Lewis’s rule of Interchange of Logical Equivalents
(incorrectly omitted from the original 1973 edition (1986: ix)); Interchange of Logical Equivalents in its full generality for all sentential contexts in L is derivable from EQUIVALENCE, CLOSURE, PC, and
MP (proof: by induction on the construction of formulas).
PC and MP simply encapsulate the background classical logic.
REFLEXIVITY reflects the triviality that in developing a counterfactual supposition we can start with that supposition itself. The point of VACUITY is that A is the 'worst' antecedent for A as consequent; if A is forthcoming even in that case, it is forthcoming in every
A can be true only by being case. To think of it another way, A
vacuously true, in which case A is true in every eventuality. CLOSURE
means that in developing a counterfactual supposition, we can include any logical consequence of the results obtained so far. EQUIVALENCE goes with the idea that differences between logically equivalent counterfactual suppositions are in effect differences only in the mode of presentation of the way things are being supposed to be.
One way in which the present subsystem of Lewis’s system is weak is that it lacks his irredundant 'centering' axiom schema (7)
(A & B)
(A
B), for, unlike the principles above, it is invalid when is reinterpreted as strict implication in S5. It also lacks
B)
(A
B), the his 'weak centering' axiom schema (6) (A
addition of which will be considered later. Finally, our subsystem lacks the axiom schema (5) for whose length and obscurity Lewis apologizes:
(A

B)

(((A & B)

C)

(A

(B

C)))

(Lewis 1986: 133). Unlike (6) and (7), (5) is part of Lewis’s core system
V. We can check that (5) is irredundant in Lewis’s axiomatization by considering an unintended semantics on which it is invalid but all his other axiom schemas are valid and his rules preserve validity. Specifically, suppose that each model supplies a set of worlds and a func- tion f from formulas A and worlds w to sets of worlds f(A, w) satisfying the constraints (i) A is true at every world in f(A, w); (ii) f(A, w) is empty only if A is true at no world; (iii) if A is true at w then f(A, w) = {w};
(iv) if A and B are true at exactly the same worlds then f(A, w) =
is then that A
B is true at w if f(B, w). The semantic clause for and only B is true at every world in f(A, w). One easily checks by induction on the length of proofs that all Lewis’s other axiom schemas are true at every world in every model under this semantics, and that his rules preserve this property. However, schema (5) fails. Consider a set of four worlds {0, 1, 2, 3}, let the atomic formula p be true at 1, 2 and
3 only, q be true at 1 and 2 only, r be true at 1 only; if A is true at w let f(A, w) be {w}; if A is false at w let f(A, w) be the set of all worlds at which A is true, except when w is 0 and A is true at 1 and 2 only, in which case f(A, w) is {1}. These stipulations obviously satisfy (i)–(iv).
Now p q is false at 0, because f(p, 0) is {1, 2, 3} and q is false at
(q r) is false at 0 because q r is false at 2, but
1 and 2, and p
(p & q)
r is true at 0, because f(p & q, 0) is {1} and r is true at 1.
r) (p
(q r))) is false
Consequently, (p q) (((p & q)
at 0. In this setting, we therefore cannot apply most of Lewis’s results about derived modal logics within counterfactual logics (1986: 137–
42), because they depend on completeness theorems for his counterfactual logics with respect to classes of models with respect to which the present systems are incomplete. Not that any reason has been provided to regard Lewis’s extra schemas as informally invalid on their intended natural language readings (if we do not already assume the correctness of Lewis’s semantic theory); the point is just that their informal validity on those readings is hard to assess, so it is better to derive modal logic from counterfactual logic without them.
CLOSURE and EQUIVALENCE are not quite as straightforward as they look. In a language with a rigidifying 'actually' operator @, p @p is arguably a logical truth. But if it is a theorem, each of
CLOSURE and EQUIVALENCE separately (when combined with
REFLEXIVITY) yields the theorem p
@p, which is false on many interpretations: 'If it had rained, it would have actually rained' is false if it did not rain. In the terminology of Davies and Humberstone
(1980), CLOSURE and EQUIVALENCE preserve general validity
(truth at every world of every model) but not real world validity
(truth at the actual world of every model). Thus CLOSURE and
EQUIVALENCE must be restricted to theorems derived solely by appeal to axioms and rules that preserve general validity. A similar restriction is needed on the standard Rule of Necessitation (RN) in
@p is modal logic, that if A is a theorem so is A, for even if p logically true, (p
@p) may be false. For present purposes we can ignore this complication, since the languages under consideration lack operators such as 'actually' (see Williamson (2006a) for further discussion).
For our immediate purposes, we expand L to the language L+ by adding propositional quantifiers. That is, if p is a propositional variable and A is a formula of L+, ᭙p A is also a formula of L+. We extend the axiomatization by a corresponding axiom schema and rule
(where A[B/p] is the result of substituting the formula B for all free occurrences of p in A, on the assumption that no variable free in B
thereby becomes bound):
UINST If p is any propositional variable then ᭙p A
A[B/p]
UGEN If p is any propositional variable not free in A, and
A
B then A
᭙p B
This system, like that for L, satisfies the rule of substitution of proved material equivalents, in the sense that if
B
B* then
A[B/p] A[B*/p] for any formula A and propositional variable p
(proof: by induction on the complexity of A). Thus proved material equivalents are interchangeable in all relevant contexts. In the setting of possible worlds semantics, UINST and UGEN are sound when the propositional quantifiers are interpreted as ranging over all subsets of the set of possible worlds associated with the given model, but they will not yield a complete system, since they do not guarantee the existence of maximally specific possible propositions, true in exactly one world (for example, one cannot derive p (p & ᭙q (q
(p q))).1
For present purposes, those stronger assumptions are unnecessary. See the pioneering works of Fine (1970) and Kaplan (1970) for more technical detail on propositional quantification in modal logic. Williamson (1999a) discusses its interpretation: interpreting it by means of quantification into name position in the metalanguage, over sets of possible worlds or anything else, is arguably only a rough approximation to its philosophically most significant interpretation, which involves ineliminable quantification into sentence position. Our first task is to show that three candidate definitions of A in
L+ are mutually equivalent: (i) ᭙ p (p
A) (where p is not free in
A; (iii) A
. First we establish the equivalence
A); (ii) A
of (i) and (ii):
(1)
(2)
(3)
(4)

᭙ p (p
( A
( A
᭙ p (p

A)
( A
A)
A)
(p
A)
A)
᭙ p (p
A)
A) ( A
A)

UINST
VACUITY
2, UGEN
1, 3, PC, MP

Now we establish the equivalence of (ii) and (iii):
(1)
(2)
(3)
(4)
(5)
(6)
(7)

(A & A)
A) & ( A
(( A
A
A
( A
A)
( A
A
)
( A
( A
A) ( A
( A

A))

( A

)

)
A)
)

PC
1, CLOSURE
REFLEXIVITY
2, 3, PC, MP
PC
5, CLOSURE
4, 6, PC, MP

Thus (i), (ii), and (iii) are mutually interchangeable in all relevant contexts. It matters little which of them we use to define A. However, the complexities of propositional quantification are best avoided when not needed, and (iii) is marginally simpler than (ii), so we treat
A as a metalinguistic abbreviation for A
. We therefore return to the propositional language L, and omit the quantifier rules.
As usual in modal logic we treat A as a metalinguistic abbreviation
), which is equivalent for
A, which in our case is ( A
).
by EQUIVALENCE to (A
The next task is to check the status on our definitions of two principles used in the main text:
NECESSITY
POSSIBILITY

(A
(A

B)
B)

(A
( A

B)
B)

We prove them in our system as follows. First, NECESSITY:
(1)
(2)

(A
( (A

B)
B)

( (A
)

B)
( (A

)
B)

(A

B))

DEF , PC
PC, CLOSURE Modal Logic within Counterfactual Logic

( (A
B)
(A
B))
(A
B))
(A
(A
B))
(4)
(A
B)
(A
(5) ((A
(A
B)) & (A
A))
B)
(A
B)
(6) (A
(A
B))
(A

(3)

VACUITY

(7)

1, 2, 3, PC, MP
PC,
CLOSURE
5, REFLEXIVITY, PC,
MP
4, 6, PC, MP

(A

B)

(A

B)

Then, POSSIBILITY:
)
B
( B
)
( B
B)
( B
( B
B)
(A
B)
B)
B
(A
B) & (A
B))
((A
)
(A
)
(6) ((A
B) &
B)
(A
)
A
(7) ( A
) ( A
)
(8) (A
(9) ((A
B) &
B)
A
B)
( A
B)
(10) (A
(1)
(2)
(3)
(4)
(5)

DEF , PC
PC, CLOSURE
VACUITY
1, 2, 3, PC, MP
PC, CLOSURE
4, 5, PC, MP
DEF , PC
PC, EQUIVALENCE
6, 7, 8, PC, MP
9, PC, MP

We now turn to deriving some basic principles of modal logic within counterfactual logic. The weakest normal modal logic is K, which is axiomatized by PC, MP, and the following axiom schema and rule:
(A
B)
K
RN If A then

( A
A

B)

We derive K in our system thus:
A
( A
)
(1)
(2)
A
( A
A)
A)
(3)
A
( B
(A
B)
( B
(A
B))
(4)
A))
(5) (( B
(A
B)) & ( B
B)
( B
(6) ( (A
B) & A)
( B
B)

PC, DEF
1, PC, CLOSURE, MP
2, VACUITY, PC, MP
Like 3
PC, CLOSURE
3, 4, 5, PC, MP

Modal Logic within Counterfactual Logic

(7)

( B

(8) ( B
(9)
(A

B)

( B

B)
B
B)
( A

) REFLEXIVITY,
CLOSURE, PC, MP
7, DEF
6, 8, PC, MP

B)

Here is a derivation of RN:
(1) A
(2)
A
(3) ( A
(4)
A
A
(5)

A)

( A

)

Theorem by assumption
1, PC, MP
2, CLOSURE
3, REFLEXIVITY, PC, MP
4, DEF

Thus all theorems of K are theorems of our system, under our definition of .
We can prove something stronger: the modal principles derivable in our current system are just those derivable in K. More precisely, let L be the language of propositional modal logic, built up from the propositional variables, , and (treated as primitive). Let *
be the mapping from L to L that corresponds to our definition of
:
*p = p for each propositional variable p
* =
*(A
B) = *A
*B
* A = *A
Then for any formula A of L , *A is a theorem of our system ( *A)
if and only if A is a theorem of K ( k A). We have in effect already proved that if K A then *A. The converse is trickier, because the proof of *A in our system may involve formulas such as p q that are not of the form *B for any formula B of L . We define an auxiliary 'unintended' mapping back from L to L : p = p for each propositional variable p
=
(A
B) = A
B
(A
B) = ( A
B) Modal Logic within Counterfactual Logic

We note two easy lemmas.
For any formula A of L, if A then k A. Proof: by induction on the length of proofs in our system.
*A. Proof: by induction on
(II) For any formula A of L , k A
the complexity of A.
(I)

Now suppose that A is a formula of L and *A. By (I), k *A.
By (II), k A *A. Therefore k A, as required. Thus *A if and only if k A.
The system K is far too weak to be an adequate logic of metaphysical possibility and necessity. The most saliently missing principle is that what is necessarily so is so:
T

A

A

We can derive T in our system by adding Lewis’s 'weak centering'
principle (schema (6) in his official logic of counterfactuals (1986:
132); it is also axiom schema (a6) in Stalnaker 1968), which corresponds to modus ponens for the counterfactual conditional given the logic of the material conditional:
MP

(A

B)

(A

B)

T is an immediate consequence of MP
(1) ( A
(2) ( A
A
(3)

)
)
A

( A
A

)

:

MP
1, PC, MP
2, DEF

By a proof along just the same lines as for K (with the same mappings), we can show that for any formula A of L , *A is a theorem of our system extended by MP
if and only if A is a theorem of KT, the result of extending K (as axiomatized above) by
, MP, CLOSURE,
T. Thus PC, REFLEXIVITY, VACUITY, MP
and EQUIVALENCE induce the simple logic KT for metaphysical modality.
MP
is an immensely plausible principle. If we discover that e happened without f, doesn’t that refute the claim that if e had hap- pened, f would have happened?2 Nevertheless, it is worth observing is not needed to derive T. For if we that the full strength of MP
merely add T itself to our original system (read by means of DEF ),
. We can show this by giving an unintended we cannot derive MP
model theory that validates PC, REFLEXIVITY, VACUITY, T, MP,
CLOSURE, and EQUIVALENCE but not MP
. It is a 'possible worlds' semantics, but with the natural numbers playing the role of is this: A
B is true at all worlds the worlds. The clause for iff either A is false at all worlds or B is true at the least world at which A is true ('least' in the sense of the usual ordering of the natural numbers; recall that every nonempty set of natural numbers has a least member); otherwise A
B is false at all worlds. Everything else is standard. It is routine to check (by induction on the length of proofs) that every formula of L derivable from PC, REFLEXIVITY, VACUITY, T, MP, CLOSURE, and EQUIVALENCE is true at all worlds in all such models. For example, in the case of T, is suppose that A is true at a world, which is to say that A
cannot be non-vacuously true, it true at that world; since A
must be vacuously true; thus A is true at every world. But not all are true at all worlds in all such models. For instances of MP
example, let p be true at 0 but false at every other world. Then p is true at every world, while p is false at 1.
A more controversial but still plausible principle about metaphysical modality is the characteristic axiom schema of the modal system
S5, known as E:
E

A

A

KTE is simply S5; in that system, matters of possibility and necessity are always non-contingent. We can also derive in it the characteristic principle of S4:
2

One can accept a counterfactual when rationally unwilling to apply modus ponens to it, in the sense that on learning its antecedent one would reject the counterfactual rather than accept its consequent. For example, I accept 'If Oswald had not shot
Kennedy, Kennedy would not have been shot,' but if I come to accept 'Oswald did not shoot Kennedy,' I will not conclude 'Kennedy was not shot.' But that is no threat to the validity of modus ponens. In circumstances in which both 'If Oswald had not shot Kennedy, Kennedy would not have been shot' and 'Oswald did not shoot Kennedy' are true, so is 'Kennedy was not shot.' A

A

(Hughes and Cresswell (1996) provides appropriate background in modal logic.) If we read E directly in terms of our counterfactual definitions of the modal operators,
A becomes a counterfactual conditional with a (negated) counterfactual conditional in its antecedent, which is quite hard to get a feel for. Lewis adds axioms involving such intractable counterfactuals to his system to obtain S5. Here is a more natural equivalent of E in counterfactual conditional terms:
ES

(A

(B

))

((A

)

(B

))

The embedded counterfactual conditional has been moved into the consequent, where such embeddings occur somewhat more naturally.
Informally, ES says that embedding one possible counterfactual hypothesis inside another cannot lead to an impossibility: even if B
is incompatible with A, counterfactually supposing B within the counterfactual supposition of A takes one back out of the A worlds into the B worlds, not to an impossibility.
The generalization of ES to arbitrary sentences in place of the logical falsehood is much less plausible:
ES+

(A

(B

C))

((A

C)

(B

C))

If I had been a French grocer then I would have been such that if I
had been a philosopher I would have been a French philosopher; but it is not the case that if I had been a French grocer I would have been a French philosopher, nor is it the case that if I had been a philosopher I would have been a French philosopher. In terms of Lewis’s similarity semantics, suppose that p holds only at the counterfactual world w, q holds only at the actual world and a third world x, closer to w than the actual world is, and r holds only at x. Then w is a r world, because the closest q world to w is x, which is an r q
(q r) world, since w is world; thus the actual world is a p the closest p world to the actual world; but the actual world is neither ap r world (since the closest p world to the actual world, w, is not an r world) nor a q r world (since the closest q world to the actual world is the actual world itself, which is not an r world). Thus ES+ is invalid in Lewis’s semantics. By contrast, ES holds on Lewis’s semantics provided that all worlds form a single similarity space
(compare Lewis’s uniformity condition (1986: 120–1)). For then is false at every world if B is true at some world; thus
B
is false at a world, so B is true at some world, then if B
is true at exactly the same worlds as , so A
(B
)
B
have the same truth-value at all worlds; thus ES holds and A
(consequently, ES does not entail ES+). The plausibility of ES depends on the occurrence of a logical falsehood in the consequent. Although we will not attempt to determine here whether ES should ultimately be accepted, it at least gives us a new perspective on the status of S5
(Salmon 1982: 238–40, 1989, and 1993 argue that S4 and therefore
S5 are invalid for metaphysical modality; Williamson 1990: 126–43
and 2000a: 119–20 reply).
We still have to establish the equivalence of ES with E. First, we argue from ES to E in our original system:
(1) (( A
((( A
(2) (( A
(3)
( A
(
( A
A
(4) A

)

(

)
)
)

A
) (
) (

)

))

ES
))
) 1, REFLEXIVITY, MP
2, EQUIVALENCE,
PC, MP
3, DEF , DEF

A
A

)

Now we establish the converse, again in our original system:
(1)
(2)

B
(B

B
)

(3) ( (B
( (B
(4)
(B

)
)
)
(B

(5)
(B
(6) ((A
(A
(7) (A
((A

(

(B

)

)
(B
(B

(
)
))
(A
(B
)) & (A

)
(B
)
(B
))
) (B

))

)

E
1, EQUIVALENCE,
PC, MP, DEF , DEF
CLOSURE, MP, PC

))
2, 3, MP, PC
))
(B

4, VACUITY, MP, PC
))
CLOSURE, MP, PC
5, 6, MP, PC Modal Logic within Counterfactual Logic

Although PC, REFLEXIVITY, VACUITY, MP
, ES, MP,
CLOSURE, and EQUIVALENCE together yield the full strength of
S5, they still constitute a rather weak logic of counterfactuals. For example, they do not yield axiom schema (a7) from Stalnaker (1968), a strengthening of EQUIVALENCE:
(a7)

((A

A))

B) & (B

((A

C)

(B

C))

To check independence, consider another deviant semantics in which
B be true at the possible worlds are the natural numbers. Let A
a world w if and only if three conditions hold: (i) if A is true at w then B is true at w; (ii) if A is true at exactly one world then B is also true at that world; (iii) if A is true at a world x and at some world y such that x > y then B is true at x. In particular, therefore, is true at all worlds if A is false at all worlds; otherwise
A
A
is false at all worlds. Everything else is standard. It is routine to check that all theorems of our system are true in all such models.
But (a7) fails: for if p is true at just 1 and 2, q at just 0, 1 and 2 and q, q p and p r are true but q r false r just at 2, then p at 2 (since q is true and r false at 1, which is not the least world at which q is true). The same semantics shows that the complex axiom schema (5) of Lewis’s official system VC (1986: 132) is not derivable r is true but q
(p r) is false at in our system (since (q & p)
2). We might wish to add some of these further principles to our system.
Moderately natural counterfactual equivalents of other modal principles can also be provided. For example, the 4 schema
A is equivalent to this schema:
A
4S

(A

)

(B

(A

Similarly, the B schema
BS

(A

(B

))

A

))
A is equivalent to this schema:

(B

(A

))

The proofs are similar to some already given. The observations in this appendix merely begin the work of exploring the modal subsystems of logics of the counterfactual conditional. With luck, they will encourage others to explore the matter more thoroughly.

Appendix 2
Counterfactual Donkeys

This appendix experiments with an alternative way of formalizing the anaphora in the major premises of the arguments underlying philosophical thought experiments, by permitting the conditional in them to bind variables. Thus we formalize (5), (6) and (13) in Chapter
6 respectively as:
K(x, p))
(A1) GC(x, p)
x,p (JTB(x, p) &
(A2) (Farmer(x) & Donkey(y) & Owns(x, y))
x,p Beats(x, y)
Monkey(x)
(A3) (Animal(x) & Escapedzoo(x))
x
These give a less unnatural treatment of the anaphora in (5), (6) and
(13) than (3*), (12) and (15) do, without repeating material or pulling a universal quantifier out of a hat. Of course, much depends on the semantics of this variable-binding conditional.
The natural strategy is to build on the preferred semantics for the conditional without variable-binding. Suppose, for a simple example, that we have a crude version of possible worlds semantics for
(allowing, as usual, for vacuous truth):
[

]

A
B is true at a world w if and only if B is true at the most similar worlds (if any) to w at which A is true. Counterfactual Donkeys

x, . . . ,y

] A
x, . . . ,y B is true under an assignment s if and only if
B is true at the most similar x, . . . , y, w-variants of s
(if any) to s at which A is true.

In effect, [
x, . . . ,y] replaces comparative similarity of worlds in
[
] with comparative similarity of assignments, conceived as something like cases. Evidently, many more refined semantic clauses for could be modified in corresponding ways.
Clause [
x, . . . ,y] corresponds to semantic clauses for variablebinding possibility and necessity operators:
A is true under an assignment s if and only if A is true at some x, . . . , y, w-variant of s.
[ x,. . . ,y]
x,. . . ,y A is true under an assignment s if and only if A is true at every x, . . . , y, w-variant of s.

[ x, . . . ,y]

x, . . . ,y

The target analysis is expressible in this notation:
(A4)

x,p

(K(x, p)

JTB(x, p))

We could then rework the Gettier argument from (2) and (3*) to (4)
as an argument from (A1) and (A5) to (A6):
(A5)
(A6)

GC(x, p)
x,p (JTB(x, p) &
x,p

K(x, p))

Together, [
x, . . . ,y] and [ x, . . . ,y] validate the required analogue of the POSSIBILITY principle. The conclusion (A6) is inconsistent with the target analysis (A4), as expected.
Here is one advantage of formalizing (5) as (A1), understood in terms of a semantic clause like [
x, . . . ,y], rather than as (3*), understood in terms of a semantic clause like [
]. As noted in Chapter
6, section 5, (3*) may be false in unexpected ways. For example, suppose that the Gettier case has many instances in the actual world; most of them are instances of justified true belief without knowledge, but a few abnormal instances are not instances of justified belief.
Then (3*) is false, because its antecedent is true and its consequent false in the actual world, even though most actual instances of the
Gettier case are genuine counterexamples to the target analysis. In such circumstances, is Gettier’s argument really unsound? By contrast, (A1) understood in terms of [
x, . . . ,y] may avoid this problem, because the assignments which correspond to the normal instances may be closer to the assignment s with which we started than are the assignments which correspond to the abnormal instances. It is not implausible that they would be if we started with an assignment of ordinary objects to the explicit variables and the actual world to the world variable. Even abnormal instances in the actual world may be trumped in the overall similarity ranking by more ordinary realizations in counterfactual worlds. Although we could achieve some of the same effect by reading the quantifiers in (3*) as contextually restricted, speakers may not know in advance how much restriction is needed, whereas [
x, . . . ,y] does not require any restriction to be specified in advance, and permits a flexible trade-off between similarity in the values of explicit variables and similarity in the value of the world variable.
The preceding remarks highlight an unusual feature of [
x, . . . ,y] as a semantic clause. Normally, the semantic clause for an operator
O binding explicit variables has the effect that a closed formula with
O as its main operator is true under all assignments if it is true under any. For example, on standard clauses for quantifiers, the truth-value of a closed quantified formula is independent of the assignment. Thus
᭙x᭙x A and x᭙x A are equivalent to ᭙x A in any nonempty domain.
By contrast, even when x, . . . , y exhaust the variables in A
x, . . . ,y B,
[
x, . . . ,y] allows it to be true under some assignments and false under others. In this it behaves with respect to both explicit variables and the world variable as counterfactual conditionals do with respect to the world variable in the absence of explicit variable-binding: a semantic clause like [
] allows A
B to be true at some worlds and
A and
A are not equivalent to false at others. Similarly,
A in many modal logics. Although the sensitivity of A
x, . . . ,y B in truth-value to the initial values of x, . . . , y creates no purely technical problem, it does raise the question where the explicit variables are to get their default values from. The context of utterance smoothly provides the world of the context as the default value of the world variable, but how is it to provide corresponding default values for the explicit variables?
It is in any case unlikely that a variable-binding operator in the object-language will give us everything we want, since the anaphora Counterfactual Donkeys

in formulations of the Gettier argument can run across sentences, as in this wooden dialogue:
John: A person and a proposition could have stood in the Gettier relation.
Mary: If they had, they would have been an instance of justified true belief without knowledge.
The interaction of anaphora with intensional contexts creates notoriously thorny problems, which we obviously cannot attempt to solve here (for some of the issues see Roberts 1996). They do not show that the arguments underlying philosophical thought experiments are not to be understood in terms of counterfactual conditionals such as
(5). They reveal some subtle obstacles to articulating a perfectly faithful formal analysis of those arguments, but for all they show the argument from (A1) and (A5) to (A6) (or from (2) and (3*) to (4))
is a perfectly adequate approximation for almost all metaphilosophical purposes. 9
Widening the Picture

9.1 How Did We Get Here from There?
The Transformation of Analytic Philosophy
Opponents of analytic philosophy often associate it with logical positivism. From a historical point of view, it is clear that one main strand in the development of the broad tradition known as 'analytic philosophy' was indeed the logical positivism of the Vienna Circle, with its austerely verificationist principle of significance and its exclusion of metaphysics as cognitively meaningless. Another main strand in the development of the analytic tradition, ordinary language philosophy, tended to be almost equally suspicious of the ways in which metaphysicians made free with ordinary words, far from the everyday contexts of use on which their meaning was supposed to depend. Despite that history, however, recent decades have seen the growth and flourishing of boldly speculative metaphysics within the analytic tradition.
Far from being inhibited by logical positivist or ordinary language scruples, such analytic metaphysics might be described by those unsympathetic to it as pre-critical, ranging far outside the domain of our experience, closer in spirit to Leibniz than to Kant.
How did a species of philosophy with so much anti-metaphysics in its gene pool evolve so quickly to the opposite extreme? Enough time has passed for us now to start achieving the historical perspective necessary to answer the question in a systematic way. That project is too extensive to be properly carried out in less than a book.
In this section, I attempt no more than to make some informal and unsystematic remarks on the transformation of analytic philosophy.
Especially in Section II, I write as someone who lived through the latter stages of the process, and concentrate on the parts of which I have the closest knowledge. That will at least provide some sense of what it was like to experience the transformation at the time, from a broadly sympathetic point of view. I close with a few sketchy remarks on the historiography of recent analytic philosophy, in
Section III.

I
The central, most influential figure in the development of analytic metaphysics over the final quarter of the twentieth century, and the contemporary philosopher most cited within recent analytic philosophy, is undoubtedly David Lewis, also known as 'the machine in the ghost' for his eerie computational power, mechanical diction, faint air of detachment from ordinary life, and beard from another era (by contrast with 'the ghost in the machine,' Gilbert Ryle’s summary description of the immaterial Cartesian ego in the clockwork Cartesian body). The prize specimen of Lewis’s speculative metaphysics is in turn his notorious doctrine of modal realism, according to which there are infinitely many possible worlds, mutually disconnected spatiotemporal systems each as real and concrete as our own actual world (Lewis 1986a). For Lewis, strictly and literally there are talking donkeys, because there could have been talking donkeys (as we may all agree), so some possible world contains talking donkeys, which are just as real, alive, and made of flesh and blood as any donkey you have ever seen. Of course, those other worlds are not open to our observation; there are no trans-world telescopes. Lewis postulates them because they follow from his modal realism, which he regards as the best theory of possibility, necessity, and related phenomena, in respect of simplicity, strength, elegance, and explanatory power: to use C. S. Peirce’s term broadly, Lewis’s argument for modal realism is abductive. In a way, Lewis takes non-actual possible worlds even more seriously than did Leibniz, for whom they are merely unrealized ideas in the mind of God. Leibniz’s God realized only the best of all possible worlds, whereas all of Lewis’s possible worlds are equally realized. We can take Lewis’s modal realism as a case study for the resurgence of speculative metaphysics in contemporary analytic philosophy. Some philosophers treat any appeal to possible worlds at all as a metaphysical extravagance. But that is a mistake, for some theories treat possible worlds as merely abstract objects or representations, harmlessly built from this-worldly materials. Indeed, Rudolf Carnap, the logical positivist anti-metaphysician par excellence, explicitly compared to Leibniz’s possible worlds his state-descriptions, maximal consistent classes of sentences used in his semantics for languages with modal operators such as 'possibly' and 'necessarily.' He also compared them with the possible states of affairs in Wittgenstein’s Tractatus Logico-Philosophicus (Carnap 1947: 9). For Carnap, necessity is a purely intra-linguistic matter of truth guaranteed by meaning, and possibility is a correspondingly semantic form of consistency. Lewis’s modal realism has always been a minority view, even amongst those analytic metaphysicians who work with possible worlds of some sort.
It is an example of extreme metaphysics.
Where did Lewis’s modal realism come from? It already appears in one of his earliest published papers (Lewis 1968). Exciting developments in modal logic, culminating in the work of Saul Kripke, had
already made the idea of possible worlds central to the understanding of languages with modal operators (Kripke 1963). 'Necessarily' is understood as 'in every possible world' and 'possibly' as 'in some possible world.' For technical mathematical reasons, it turned out to be more fruitful not to equate possible worlds with Carnap’s statedescriptions, or other such representational entities, but instead to leave their nature unconstrained when characterizing models for the modal language (Williamson 2013a: 81–4). That did not enforce a more metaphysically speculative conception of possible worlds, but it made space for one.
Another significant factor was the development of tense logic, above all by Arthur Prior. He was acutely aware of the strong structural analogies between modal logic and tense logic, with possible worlds playing the same role in the modal case as moments of time play in the temporal case (Prior 1957). An orthographically identical operator could be read as 'necessarily' in modal logic and as
'always' (or 'always in the past' or 'always in the future') in tense logic. When one read formulas of the logic in temporal terms, they expressed blatantly metaphysical principles about the structure of time and of existence in time. Those readings provided templates for more metaphysical readings of the same formulas in modal terms, on which they expressed analogous metaphysical principles about the structure of possibility and of possible or necessary existence. Carnap’s intra-linguistic modalities could then be replaced by Kripke’s metaphysical modalities, which concern how things really could have been.
But developments within modal logic alone cannot fully explain
Lewis’s modal realism. For Kripke and other leading modal logicians did not go down the modal realist road. Indeed, Lewis’s modal realist semantics for modal languages introduces messy complications that from a purely technical point of view are quite unmotivated, even by
Prior’s analogy between time and modality. In particular, Lewis postulates that no individual exists in more than one world, the analogue of the highly implausible postulate that no individual exists for more than one moment. In order to make sense of the common sense idea that one could have acted differently, Lewis then has to introduce an elaborate theory of counterparthood relations between distinct but similar individuals in different possible worlds. Those complications were motivated by Lewis’s prior commitments.
At this point, one must note that Lewis’s doctoral supervisor at
Harvard in the mid-1960s was Willard van Orman Quine, the leading critic of modal logic. Quine was especially critical of quantified modal logic, as developed by Carnap and Ruth Barcan Marcus, which allows one in effect to reason about the properties and relations that particular individuals could have, as opposed to just the general states of affairs that could obtain. Originally, Quine had tried to prove that quantified modal logic is technically flawed to the point of incoherence, that it collapses the modal distinctions between possibility, necessity, and actuality. As it became clear that his purely formal arguments were technically flawed, Quine gradually switched his line of attack to the informal intelligibility of quantified modal formulas. His standard of intelligibility in logic was austere: first-order non-modal logic, roughly, that of the logical constants 'not,' 'and,'
'or,' 'everything,' 'something,' and 'is.' For Quine, logic is first-order non-modal logic. Lewis assumed modal realism because it permits the reduction by translation of a quantified modal language to a firstorder non-modal language in which one talks about worlds and individuals in those worlds. Crucially, Lewis’s modal realism gave him a way of informally explaining what a possible world is in non-modal terms: roughly, a spatiotemporal system; the individuals in such a system are spatiotemporally connected to each other and to nothing outside the system. Lewis thereby aimed to make quantified modal logic intelligible by his teacher’s standards. Since much ordinary discourse in natural language involves expressive resources at least as great as those of quantified modal logic – 'can' and 'must' are common words, to say the least – Lewis’s procedure is also motivated by a principle of charity (Lewis 1974), which Quine explicitly endorsed: prefer an interpretation of a natural language on which speakers are being sensible to one on which they are being silly (Quine 1960: 59).
Possible worlds other than our own and their inhabitants are needed to make true ordinary statements about what could have been but isn’t. Lewis gave an ingenious solution to the Quinean problem of charitably interpreting quantified modal discourse, on its own Quinean terms, even though Quine rejected the gift.
Quine’s lack of interest in modal realism was no anti-metaphysical stance. He did as much as anyone to put ontology as a branch of metaphysics on the map of analytic philosophy, and his conception of philosophy as continuous with natural science overtly involved a naturalistic approach to metaphysical theorizing. One might rather be tempted to suggest that he rejected modal realism because it lacked support from natural science. However, Quine did not require each point of a metaphysical theory to receive its own specific support from natural science. For instance, although he took mathematics –
with its ontological commitment to abstract objects such as sets or numbers – to be holistically justified by its applications in natural science, he was well aware that the power of the standard axioms of set theory goes far beyond the needs of natural science, but still regarded them as a legitimate rounding out of the fragment actually used in scientific applications, justified by its simplicity, elegance, and other such virtues. Thus Quine’s justification of mathematics is abductive, in a similar spirit to Lewis’s justification of modal realism. No doubt, if Quine had felt some tension between modal realism and current natural scientific theory, he would have treated that as a good reason to reject modal realism, but so might Lewis himself.
However, neither of them seems to have felt such a tension. In my view, there is in fact such a tension, or inconsistency, but the argument for it must be made with some delicacy and was not generally recognized at the time (Williamson 2013a: xii, 17, 2014c: 744–6). Perhaps Quine simply gave modal realism the same 'incredulous stare' that so many other analytic metaphysicians have given it (Lewis 1986a:
133–5). Moreover, Quine encountered modal realism at a stage of his career when he was not disposed to accept radical revisions of his views from outside; publicly retracting his well-entrenched signature skepticism about quantified modal logic would have been a bitter pill to swallow. He showed a similar lack of interest even in the purely technical development of the model theory of modal logic, and in particular of quantified modal logic, by Kripke and others, which is a piece of regular mathematics, no more vulnerable to Quine’s concerns about intelligibility than any other piece of mathematics.
The example of Quine is a salutary reminder that the analytic tradition, as normally understood, has never been a metaphysics-free zone. Before Quine, Bertrand Russell was a major figure in the analytic tradition blatantly engaged in metaphysical theorizing. Indeed, F. H. Bradley may well be right that critiques of metaphysics themselves depend on contentious metaphysical assumptions (Bradley 1893: 1–2).
Nevertheless, the role and status of metaphysics have changed in significant ways over the history of the analytic tradition, and our concern is with those ways.
Lewis’s case for his modal realism itself evolved over time. In the original 1968 paper, the emphasis is on the relation between modal and non-modal languages, and the clarity to be achieved in modal logic by translating the modal language into the non-modal language of Lewis’s counterpart theory (the precursor of his modal realism).
His postulates for counterpart theory are used to validate elementary principles of modal logic, but they also clarify the metaphysical picture. For instance, the postulate that nothing is in two worlds has the advantage, according to Lewis, that it answers the question of the identity of individuals across possible worlds at a stroke, with a uniform negative. That is his answer to Quine’s complaints about the obscurity of trans-world individuation (he cites Quine 1960: 245). By the time he wrote what became the canonical case for modal realism, his book On the Plurality of Worlds (Lewis 1986b), based largely on his 1984 John Locke lectures at Oxford, Lewis’s perspective had changed. He talks much less about linguistic matters, and much more about the abductive advantages of modal realism as a theoretical framework for explaining a variety of phenomena, many of them nonlinguistic. Faced with some objections to specific translation schemes between the language of quantified modal logic (in effect, a formalization of ordinary modal language) and the language of counterpart theory, he tells us not to worry about the details, but instead to abandon the language of quantified modal logic and do our metaphysical theorizing directly in the more perspicuous language of counterpart theory (Lewis 1986a: 12–13). Clearly, from 1968 to 1986 the balance of power in Lewis’s work swung towards metaphysics and away from the philosophy of language.
Writing in 1981, Lewis described 'a reasonable goal for a philosopher' as bringing one’s opinions into stable equilibrium. The trouble with losing 'our moorings in everyday common sense,' according to him, is not that common sense is infallible but that we do not achieve stable equilibrium, since we keep reverting to something like our everyday opinions (Lewis 1983a: x). He requires the equilibrium to be stable under theoretical reflection. In principle, this is not radically different from a Quinean methodology for philosophy and science together of adjustments to ease tensions in one’s web of beliefs (Quine
1951). For Lewis, modal realism does better than other theories of modal metaphysics with respect to stability under reflection, given our other beliefs. Of course, many philosophers would insist that to adopt modal realism is to lose one’s moorings in everyday common sense, but Lewis was adept at interpreting the putative deliverances of everyday common sense in ways that made them consistent with modal realism, often by postulating large measures of tacit contextual restriction in the utterances that gave them voice. Although he admitted some disagreements between modal realism and common sense, for instance on whether (speaking unrestrictedly) there are talking donkeys, he managed to steer the disagreements into abstruse areas that might plausibly be regarded as of low priority for common sense.
Whereas critics condemned Lewis for his extravagant departures from common sense, he saw his modal realism as part of his defense of common sense – just the way Berkeley saw his subjective idealism.
In practice, the process of bringing one’s opinions into stable equilibrium will involve extensive reflection on what one’s opinions actually are. Since one’s general beliefs are typically presented to one as expressed by sentences, whose underlying semantic structure is not perfectly transparent, in reflecting on what it is one believes one is drawn into semantic reflection on one’s own language – or, as some would have it, reflection on one’s own conceptual system. A natural comparison is between Lewis’s Quinean or at least post-Quinean methodology and the methodology of Peter Strawson,
Quine’s leading opponent from the tradition of ordinary language philosophy. By the late 1950s, however, 'ordinary language philosophy' was no longer an apt phrase for what Strawson was doing. He was working in a far more abstract and systematic way than that phrase suggests. His concern was with very general structural features of ordinary thought and talk, such as the distinction between subject and predicate, rather than with the fine detail of ordinary usage.
In 1959 he published Individuals, subtitled An Essay in Descriptive
Metaphysics, a major monograph widely felt at the time to mark a turning-point in the rehabilitation of metaphysics within analytic philosophy. Strawson contrasted descriptive metaphysics with the wilder revisionary metaphysics, which despite its 'partial vision' is nevertheless useful when 'at the service of descriptive metaphysics' (Strawson
1959: 9). Revisionary metaphysics can help at the periphery of our thinking, but goes astray when it tries to revise 'a massive central core of human thinking which has no history' because 'there are categories and concepts which, in their most fundamental character, change not at all' (ibid.: 10). What descriptive metaphysics is supposed to describe are the conceptual connections that constitute the structure of that central core. In Strawson’s view, that structure is not hierarchical, as envisaged by programs of conceptual analysis with their non-circular definitions by necessary and sufficient conditions.
Rather, the descriptive metaphysician traces conceptual interconnections on the same level, going round in complex closed curves: the exploration is horizontal rather than vertical.
How different in kind is Strawsonian metaphysics, which may revise the margins but must only describe the core of ordinary thinking, from Lewisian metaphysics, which must not lose its moorings in everyday common sense in its attempt to steer one’s opinions into equilibrium? At this point, it may be worth recalling that Lewis attended lectures by Strawson, amongst others, when he spent the academic year 1959–1960 as a visiting student from Swarthmore College at
Oxford, tutored by Iris Murdoch, a year that resulted in his momentous decision to major in Philosophy rather than, as he had previously intended, Chemistry. Of course, Strawson’s characterization of descriptive metaphysics as the tracing of conceptual connections relies on some form of the analytic-synthetic distinction, which he had defended with his old teacher Paul Grice against Quine’s massively influential critique (Quine 1951, Grice and Strawson 1956). Indeed, the complex closed curve of definitions that Quine traced from 'analytic' round to other semantic terms and back again in his attempt to show that none of them could be satisfactorily explained was just the sort of explanation the descriptive metaphysician sought. But on this issue Lewis sided with his earlier teacher against his later one. Lewis’s first book concluded with an attempt to rehabilitate analyticity as truth in all possible worlds (Lewis 1969: 208), to Quine’s regret in the book’s Foreword (Quine 1969: xii). Although both Strawson and
Lewis accepted an analytic-synthetic distinction, in their philosophical practice neither of them had much tendency to use it as the sort of glib conversation-stopper it so often becomes in less resourceful hands. Admittedly, Strawson was more prone than Lewis to characterize philosophical questions as questions about words or concepts, or as questions about how we must think about a subject matter, rather than about the subject matter itself. But Lewis himself frequently went metalinguistic, as we have already seen, and Strawson was quite willing to speak in a ground-level metaphysical idiom, as with remarks such as 'A person is not an embodied ego, but an ego might be a disembodied person' (Strawson 1959: 103). They both moved easily between object-language and meta-language, as it were, depending on the argumentative needs of the moment.
Quine insisted on continuity between philosophy and natural science in a way that Strawson did not. In this respect, Lewis was closer to Quine than to Strawson. In practice, however, natural science played only a very minor role in the metaphysics of all three philosophers. A good test is their treatment of the dispute between the three-dimensionalist Aristotelian metaphysics of enduring continuants and the four-dimensionalist metaphysics of occurrents composed of successive time-slices, often associated with Einstein’s theory of special relativity. Predictably, Strawson is a three-dimensionalist while Quine and Lewis are four-dimensionalists. But what is striking is how little Quine and Lewis made of special relativity in their cases for four-dimensionalism. In Word and Object, Quine emphasized the advantages in logical smoothness of treating space and time on a par
(Quine 1960: 170–2). He adds only as a convenient afterthought that
Einstein’s discovery of special relativity 'leaves no reasonable alternative to treating time as spacelike,' but then immediately points out that the logical benefits of doing so 'are independent of Einstein’s principle' and adds, with references, 'the idea of paraphrasing tensed sentences into terms of eternal relations of things to times was clear enough before Einstein' (ibid.: 172). In On the Plurality of Worlds,
Lewis’s case for four-dimensionalism does not mention Einstein or depend on modern science at all; it just relies on rather shaky oldfashioned purely metaphysical reasoning about temporary intrinsic properties, such as shapes (Lewis 1986a: 202–5). Presumably, Lewis was not convinced that special relativity really did leave no reasonable alternative to treating time as spacelike, otherwise he would have mentioned such impressive support for his conclusion. Since the specifics of Lewis’s argumentation fail to take seriously an approach that treats temporal operators as explanatorily basic, it is hard to avoid the impression that what was really decisive with him was a somewhat
Quinean preconception about the proper sort of language for doing metaphysics in, something close to the language of mathematics. Of course, glancing through the pages of On the Plurality of Worlds, one sees them filled with formula-free English prose, just like the pages of Individuals. Nevertheless, the systematicity at which Lewis aims is modeled on that of a scientific theory articulated in a mathematical language. The systematicity at which Strawson aims is different; it is that of a satisfying general account in English itself, or some other natural language. The sort of formal logical smoothness that Quine and Lewis valued so highly, Strawson regarded as a trap. In this less standard sense, despite the similarities, and even in their metaphysics,
Strawson remained at heart an ordinary language philosopher, and
Lewis at heart an ideal language philosopher. Each of them was reluctant to disagree extensively with common sense (or natural science, for that matter), but left some room for maneuver by acknowledging a belt of revisable opinions on the periphery of common sense. As a result of quite a subtle difference in intellectual values, they ended up with radically different theories.
What if Strawson is right, in that Lewis’s views conflict with the unchanging core of ordinary thought? Then those views fail by Lewis’s own criterion, since no totality of his opinions that includes them will be stable under theoretical reflection, for it will also include the unchanging core of ordinary thought. We cannot expect to keep questions about the general methodological position in a philosophical debate clinically isolated from questions about who is right and who is wrong on the specific matters at issue within the debate (see 212–
16, this volume).
We can refine our sense of the intellectual options by comparing both Strawson and Lewis with Kripke. In the 1970s, Kripke and Lewis were often paired as leaders of the 'possible worlds revolution.'
Kripke’s essentialism and his defense of quantified modal logic were radical in relation to Quinean orthodoxy. It took time for them to be understood as articulations of quite ordinary ways of thinking, so not radical in relation to common sense. Of course, the connection between essentialism and Aristotle already noted by Quine was a clue, since Aristotle always had a strong claim to be the founder of common sense philosophy. Strawson names Aristotle and Kant as the great descriptive metaphysicians (1959: 9). Kripke’s arguments in
Naming and Necessity tend to be based on common sense examples, and he explicitly rejects Lewis’s modal realism, in favor of a more deflationary conception of possible worlds as possible states of affairs
(Kripke 1972). His metaphysics is arguably not revisionary in Strawson’s sense. This feature of it may have been obscured by his technical achievements in quantified modal logic, based on the mathematical apparatus of 'possible worlds semantics,' even though it is in itself no more metaphysically problematic than any other piece of mathematics (Williamson 2013a: 81–4).
Although Kripke’s metaphysics initially could seem more revisionary than it really was, his methodology could initially seem more linguistic than it really was. His titles yoked together semantic and metaphysical terms: Naming and Necessity (1972) and Reference and Existence (2013 – the book of his John Locke Lectures given at
Oxford in 1973 under the same title). Of course, it was Kripke who played the central role in distinguishing metaphysical from epistemic or semantic modalities, through his famous examples of contingent truths knowable a priori and of necessary truths knowable only a posteriori, which made trouble for the then-popular Humean slogan
'All necessity is verbal necessity.' Even so, there was a diffuse but influential impression in the 1970s that Kripke had somehow managed to derive apparently substantial metaphysical conclusions about the specific essential properties of individuals and kinds, from his semantic analysis of modal language, in particular his insight that names are rigid designators (their designation remains constant while different possible worlds are considered). Nathan Salmon published a detailed monograph Reference and Essence (1982) to refute that impression.
The title uses 'and' to separate the semantic term from the metaphysical one, rather than to join them together. The front cover showed a rabbit being pulled from a hat. Salmon demonstrated that Kripke had relied on metaphysical premises to derive his metaphysical conclusion (Kripke himself had not claimed otherwise). That did not make
Kripke’s argument merely question-begging, for the plausibility of the premises could still be more immediate than the plausibility of the conclusion. Salmon’s point was widely accepted. That contributed to an increasingly popular conception of metaphysics as separate from the philosophy of language.
Just as it was a mistake to regard Kripke’s metaphysics as derived from his semantics, it would be a mistake to regard them as simply orthogonal to each other. For misconceptions in semantics often induce misconceptions in metaphysics, by causing fallacious metaphysical arguments to be treated as valid, so that coherent metaphysical views are incorrectly dismissed as confused or inconsistent. Quine’s early critique of quantified modal logic is an example. It was crucial to get straight about the semantics of modal language in order to see one’s way through to defending metaphysical theses of essentialism. Thus
Kripke’s semantic theory of rigid designators was after all relevant to his essentialist metaphysics, but its role was negative, in driving off arguments against essentialism, not positive, in driving forward arguments for essentialism.
There is a more general moral here about the famous 'linguistic turn,' a phrase that has looked less and less appropriate as a description of mainstream analytic philosophy over recent decades. Nevertheless, although analytic philosophers are ceasing to regard their central questions as linguistic or even conceptual in any sense that would distinguish them from questions asked in other disciplines, the traces of the linguistic turn are not simply being erased. For it has left a rich legacy of methodological sophistication. In testing the soundness of arguments about non-linguistic matters, analytic philosophers regularly draw on work in both semantics and pragmatics (48–9, this volume). Kripke’s work on quantified modal logic is a good example with respect to semantics.
With respect to pragmatics, the prime exhibit is the work of Strawson’s teacher, Paul Grice, on conversational implicature (1961, 1975).
If you comment after my lecture 'Williamson was sober this after- noon,' you imply that I am often drunk in the afternoon, even though that is not a precondition for the truth of what you said: it is even true if I am a scrupulous teetotaller. Grice developed a powerful theoretical apparatus for analyzing such effects. Although this work emerged from within the Oxford of ordinary language philosophy, it made an important contribution to undermining the methodology of such philosophy. For ordinary language philosophy involved a focus on 'what we would say' in various conversational contexts. By analyzing the diversity of reasons for which an utterance might be conversationally inappropriate, Grice demonstrated the limitations to what can be concluded from such data. But his theory of conversation was not just a factor in the implosion of ordinary language philosophy; it has a far more lasting and positive value. It is massively cited by linguists, because it is the starting-point for much contemporary work in pragmatics. But it also continues to play a vital negative role in contemporary analytic philosophy.
Analytic epistemology provides a good case study of the philosophical application of Gricean pragmatics outside the philosophy of language. Analytic epistemologists today typically regard the object of their study as knowing (or justified believing) itself, as opposed to the corresponding words or concepts. In reflecting on knowledge or justified belief, they work through example after example of epistemologically suggestive situations, often of quite everyday sorts. In determining how to describe such situations, they frequently have to ask themselves whether a proposed description is false or, by contrast, true but conversationally misleading because it has a false conversational implicature. They use Grice’s theory of conversation to filter out contaminated data. They also have to engage with semantics as well as pragmatics, since some of the leading contender theories are contextualist, in the sense that they postulate shifts in the reference of epistemic terms according to the context in which they are used. Despite all that, the epistemologists’ underlying object of study is knowing itself, not the verb 'to know' or the concept of knowing. They sound like ordinary language philosophers, and in a loose enough sense they are ordinary language philosophers, even when ordinary language plays no special role in their epistemological aims (Hawthorne 2004, Stanley 2005 are good examples). In that respect, ordinary language has returned to its origins. For the classic manifesto for ordinary language philosophy, at least in its Oxford form, ap- peared in J. L. Austin’s paper 'A plea for excuses' (1956–1957). But much of Austin’s discussion of philosophical method there appears strongly influenced by similar comments in the work of John Cook
Wilson, Wykeham Professor of Logic at Oxford from 1889 until his death in 1915, founder of an Oxford tradition of realist metaphysics and knowledge-centered epistemology, and by no means a linguistic philosopher as the term is usually understood. For instance, Cook
Wilson’s remark 'Distinctions current in language can never be safely neglected' (1926: 46) is echoed in Austin’s emphasis on the value of starting with distinctions robust enough to have survived in ordinary language. Cook Wilson’s ideas and writings still loomed large in the
Oxford philosophy of Austin’s student days, not least through the influence of his star pupil H. A. Prichard, the White’s Professor of Moral
Philosophy from 1927 to 1937, whose lectures Austin attended as an undergraduate – despite Prichard’s attempt to ban him for asking too many questions. Thus many contemporary analytic philosophers pay close attention to linguistic subtleties, without treating their primary subject matter as in any way linguistic.
The foregoing sketch suggests no easy moral, except that the closer one looks at the history of anything, the less it lends itself to easy morals. But I can add some color to the picture, and another perspective on the transition, by going back to my own experience of it at Oxford.

II
I arrived as an undergraduate at Oxford in 1973, to study Mathematics and Philosophy. Logic played a central role in the course, to my lasting benefit; its centrality is relevant to the point of view from which I observed the scene. I received my undergraduate degree in
1976 and began to study for a doctorate. Originally I hoped to formalize Leibniz’s principle of sufficient reason, but I soon switched to
Karl Popper’s idea of verisimilitude, on which science can progress through a succession of theories that get closer and closer to the truth without ever quite reaching it. I left Oxford in 1980, to start my first proper job, as a lecturer in philosophy at Trinity College Dublin, and received my doctorate in 1981.
In 1973, the two senior professors of theoretical philosophy at
Oxford were A. J. (Freddie) Ayer, Wykeham Professor of Logic from 1959 to 1978, and P. F. (Peter) Strawson, Waynflete Professor of Metaphysics from 1968 to 1987. Austin had died in 1960 and Prior in
1969, both prematurely; Grice had left for Berkeley in 1967. One could schematically associate Ayer and Strawson with the two main strands of mid-century analytic philosophy: logical positivism and ordinary language philosophy respectively. Ayer had studied with the
Vienna Circle and his first book, Language, Truth and Logic (1936)
contained much logical positivist doctrine, including a critique of metaphysics based on the verification principle, although he traced his genealogy further back: 'The views which are put forward in this treatise derive from the doctrines of Bertrand Russell and Wittgenstein, which are themselves the logical outcome of the empiricism of
Berkeley and David Hume' (1936: 31). The book had been notorious for its advocacy of expressivism about morality and religion. Its cheeky, provocative style is conveyed by the title of the last chapter,
'Solutions of outstanding philosophical problems.' Whereas Ayer was a follower of Russell, Strawson’s most famous article (1950) was a critique of Russell’s prize contribution to philosophy, his theory of descriptions, and Strawson’s first book argued more generally that such applications of modern logic did no justice to the subtleties of ordinary language (1952). In live discussion, Ayer used rapid fire,
Strawson elegant rapier play. Ayer was better known to the general public, as a radio personality; Strawson was more highly rated by professional philosophers, as more original. Strawson had been a candidate for the Wykeham Chair of Logic; when Ayer was elected, through the votes of the non-philosophers on the committee, Austin and Ryle resigned in protest. Asked that evening by a colleague whether he felt very disappointed not to have been elected, Strawson replied 'Not disappointed, just unappointed.'
By 1973, it was no longer strictly appropriate to classify Ayer as a logical positivist, or Strawson as an ordinary language philosopher. It was closer to the mark to describe Ayer as a Humean, and Strawson as a Kantian: the contrast between them was no less marked for that.
Strawson’s development into a systematic metaphysician has already been noted. Ayer had retreated from his early radicalism, including the verificationist critique of metaphysics. He commented that the trouble with Language, Truth and Logic was that all its main doctrines were false. In 1976, on the fortieth anniversary of its first publication, he gave a series of lectures about what remained of his original view. In the book, he had quoted as an example of an unverifiable pseudo-proposition of metaphysics 'the Absolute enters into, but is itself incapable of, evolution and progress,' which he describes as 'A
remark taken at random from Appearance and Reality, by F. H. Bradley' (1936: 36). In his lecture, he admitted that, far from having taken the remark at random, he had searched through Appearance and Reality for hours to find something suitably nonsensical-sounding. It is a salutary reminder of the intelligibility by ordinary standards of much metaphysical discourse – especially when not torn out of context in the way he presented the passage from Bradley.
To younger philosophers in 1973, Ayer appeared quite old-fashioned philosophically. So too, though to a lesser extent, did Strawson. The underlying reason was in large part their relation to modern formal logic in philosophy. Officially, Ayer was for it and Strawson against it, but neither of them knew much about it. They had received their philosophical education at a time when such logic did not loom large in Oxford. Philosophers of that generation sometimes referred to formal logic as 'sums,' the primary school word for elementary arithmetic. The effect of Ayer and Strawson’s lack of facility with modern formal logic was that they were poorly placed to deal with the new wave of philosophy of language sweeping across the Atlantic, led by Kripke and Lewis (who was at least as much a philosopher of language as a metaphysician in the 1970s), and other philosophers and linguists such as Donald Davidson, Hilary Putnam, David Kaplan, Robert Stalnaker, Keith Donnellan, Richard Montague, and
Barbara Hall Partee. New-wave philosophy of language involved the application of formal semantics, based on modern logic, to natural languages.
Ayer had never had a detailed interest in the philosophy of language. His resentment of the new wave focused on Kripke’s case for the necessary a posteriori and the contingent a priori, in effect because those categories violated Hume’s supposedly exhaustive distinction between matters of fact (contingent and a posteriori) and relations of ideas (necessary and a priori). An annual ritual took place in Ayer’s 'Informal Instruction,' his class open to all comers, where a short presentation of some recently published work would kick off the discussion. Many of the brightest graduate students attended, even though they had joined the new wave, for Ayer was good at creating an atmosphere conducive to discussion. But every year he would read a short paper purporting to refute Kripke on the necessary a posteriori and the contingent a priori, in fact based on exactly the confusions Kripke had done so much to clear up. When he had finished, the graduate students would by implication plead with Ayer not to misunderstand Kripke – in vain. Strawson was much more of a philosopher of language than Ayer, but even his perception of newwave philosophy of language was distorted by the old-fashioned lens of an exaggerated contrast between, in effect, ordinary language philosophy attentive to speakers’ actual use of natural language in all its complexity and ideal language philosophy trying to project the simple logical structure of a formal language onto natural language, in abstraction from its speakers, with Procrustean effect (Strawson 1971).
What he never properly appreciated was the new-wave conception of the two projects as mutually complementary rather than in competition, so that interpreting a natural language in terms of a comparatively simple formal truth-conditional semantics would make the best sense of the complexities of speakers’ actual use of the language
(Lewis 1975a). That Strawson’s criticisms of new-wave philosophy of language were widely felt to miss the point contributed to his looking like a figure from the past too.
In effect, new-wave philosophy of language achieved a surprising reconciliation between elements from the two main competing strands of mid-twentieth century analytic philosophy, logical positivism and ordinary language philosophy. From logical positivism it took the rigorous use of formal languages with precisely and systematically described syntax and semantics, as found in modern logic, to model meaning. From ordinary language philosophy it took most of its data about use to be explained, as well as ideas about the nature of the relation between meaning and use, in order to bring the formal models to bear on the data. An encouraging precedent was Noam
Chomsky’s success in explaining subtle, apparently messy complexities in the surface syntax of English in terms of formal models of a postulated underlying deep structure (Chomsky 1957). What newwave philosophers of language hoped to do for the semantics of natural languages seemed analogous to what Chomsky and others were already doing for syntax – despite Chomsky’s own skepticism about the scientific status of semantics. Indeed, it was natural to expect a tight relation between the semantic and syntactic structure of an expression, at least at the level of deep structure or logical form. For it was a fundamental tenet of new-wave philosophy of language, coming through Carnap from Gottlob Frege, that the semantics must be compositional, in the sense that the meaning of a complex expression is determined by the meanings of its constituents; how else to explain our ability to understand sentences we have never previously encountered, if made up of familiar words in familiar types of combination?
The initial hypothesis must surely be that the requisite semantic articulation of sentences into their semantic constituents matches their syntactic articulation into syntactic constituents at some deep enough level. The compositionality constraint exerted a powerful force in the direction of systematicity. In practice, the only semantic theories to exhibit (rather than merely claim) such a compositional structure were those for formally specified languages. Without such a formal semantics, a philosophy of language looked badly undeveloped to new wavers. It was partly for this reason that Austin was barely mentioned in Oxford philosophy of language by 1973, since he had no formal semantics to offer. The same went for his protégé and in some respects intellectual heir John Searle, whose major work Speech Acts looked out of date from an Oxford perspective almost as soon as it was published in 1969. Although Austin and Searle continued to exert a significant influence, it was mainly outside the new wave.
New-wave semantics came in two main varieties, though methodologically the differences between them were minor compared to their shared differences from their predecessors. One variety was possible worlds semantics, which went back to Carnap and by 1973 was associated with philosophers of language such as Kripke, Lewis, Kaplan, Stalnaker, and Montague. In 'English as a formal language' (1970), 'The proper treatment of quantification in ordinary English' (1973), and other papers, Montague showed how it could provide a rigorously working compositional semantics for large fragments of a natural language. His work had a major influence on Barbara Hall Partee and has been seminal for a major tradition of intensional semantics as a branch of linguistics. The other main variety of new-wave semantics was extensional, under the influence of Quine. Chastened by his skepticism about meanings, it approached the semantic realm less directly, through theorizing explicitly about reference and truth rather than meaning itself. Nevertheless, its emphasis on the constraint of compositionality was just as strong. Formally, it took inspiration from
Tarski’s theory of truth. Its main proponent was Donald Davidson (1967a). It too had a significant impact on linguistics, most notably through Davidson’s semantics for verbs and adverbs in natural language, which postulated tacit quantifiers over events (Davidson
1967b). A leading Davidsonian linguist was James Higginbotham.
I first encountered new-wave philosophy of language in my first term as an undergraduate, when my tutor encouraged me to attend the John Locke lectures, to be given by the rising young star of American philosophy, Saul Kripke. I was hugely impressed by his clarity, informal rigor, pointed examples, common sense, and humor. The lectures were mostly non-technical, but one both sensed and independently knew of his easy technical mastery of the subject. Although I
did not think of it this way at the time, Kripke combined and reconciled the virtues of ideal language philosophy with those of ordinary language philosophy. At that stage, of course, I knew very little of the background in the philosophy of language to what he was saying, and was in no position to follow everything that went on in the lectures and the discussion that followed them. Nevertheless, Kripke became the nearest I had to a model of how to do philosophy.
Although Kripke’s work was widely discussed in Oxford at that time, especially by younger philosophers, the dominant variety in town of new-wave semantics was extensional rather than intensional.
Davidson had given the John Locke lectures in 1970. The two most admired young theoretical philosophers in Oxford, Gareth Evans and
John McDowell, somehow combined Davidson with Frege as the packed audiences at their joint classes looked on. It was the moment of the 'Davidsonic boom' – although people tended to utter the Tarskian mantra 'The sentence ‘Snow is white’ is true in English if and only if snow is white' in a rather slow and quiet voice. If you wanted to write on the philosophy of X, whatever X was, then you were supposed to start by writing a truth theory for a language for talking about X. I found the atmosphere of reverence for Davidson unhealthy, not to say sickening. It was fine for him to choose a speculative and controversial extensionalist starting point for his program for the philosophy of language, and to take it as far as he could from there, but the project cried out to be undertaken in a scientific spirit, as a test of its assumptions. Instead, they were treated – especially by those lower in the hierarchy – as dogmas of mysterious but compelling power, an attitude encouraged by Davidson’s elliptical and slightly evasive style. It was recognized that Davidson’s program had to meet the challenge of providing a compositional semantics for various apparently non-extensional constructions in natural language, for ascribing beliefs and desires or possibility and necessity, for example, but the discussion of alternative proposals muffled the issues with a lack of openness and clarity about the rules of the game. Philosophers, some with only a rather tenuous grasp of technical matters, would invoke obscurely motivated technical constraints – a ban on substitutional quantification, say, or a requirement of finite axiomatizability – to exclude rival hypotheses. Kripke’s critique of Davidsonians’ objections to substitutional quantification (1976) has been condemned as cruel, but to me it came as a breath of fresh air; I can attest to the presence at the time of the sort of atmosphere about which he complained.1
By contrast, intensional semantics seemed to be conducted in a more open, scientific spirit, though Davidsonians objected, darkly, to its possible worlds as creatures of darkness.
Davidsonians did not expect the philosophy of language to be independent of metaphysics. Davidson (1977) explicitly motivated an ontology of events by a Quine-inspired principle of charity in interpretation, through the semantics of adverbs. This was not so different from Lewis’s original motivation of his ontology of possible worlds, in effect by the principle of charity, through the semantics of modal operators. But Davidson gave his metaphysics a turn reminiscent of
Strawson, with a transcendental argument to show that it was not really possible to think differently (Davidson 1974). As so often with transcendental arguments, it turns out to depend on concealed verificationist assumptions (see the later remarks on Wittgenstein’s Private
Language Argument). More recent metaphysics has been much less tempted by transcendental arguments.
Amongst the important features shared by the extensional and intensional varieties of new-wave semantics was truth-conditionality: they both treated the meaning of a declarative sentence as in some sense the condition for it to be true. By contrast, the senior Oxford philosopher properly to engage new-wave philosophy of language,
Michael Dummett, opposed such truth-conditional semantics in favor of assertibility-conditional semantics, which treated the meaning of a
My first article to be accepted for publication, though not my first to be published, protested against the Davidsonian dogma that theories of truth qua theories of meaning had to be finitely axiomatizable (Williamson 1984).

1 declarative sentence as the condition for it to be assertible, or verifiable, rather than true. Assertibility-conditional semantics was inspired by the proof-conditional semantics for mathematical language developed by Heyting, Prawitz, and other intuitionists, which equated the meaning of a sentence in the language of mathematics with the condition for something to be a proof of it. The plan was to generalize this semantics to the whole of language by treating mathematical proof as a special case of verification. This may be seen as a descendant of a logical positivist conception of the meaning of a sentence as its method of verification, although Dummett did not present it as such.
Unlike the logical positivists, Dummett saw the subversive threat that verification-centered semantics posed to classical logic, given the compositionality constraint which he accepted, in line with new-wave philosophy of language. For example, the natural compositional semantic clause for disjunctive sentences of the form 'A or B' says that
'A or B' is verified if and only if either 'A' is verified or 'B' is verified. But that makes immediate trouble for the classical law of excluded middle, 'A or not A.' For the special case of the semantic clause where 'B' = 'not A' says that 'A or not A' is verified if and only if either 'A' is verified or 'not A' is verified. But often we cannot verify a sentence and cannot verify its negation. For instance, we cannot verify 'Napoleon had an even number of hairs at his death' nor can we verify 'Napoleon had an odd number of hairs at his death.' Thus, by the semantic clause, we cannot verify 'Napoleon had an odd or even number of hairs at his death.'
In these ways, Dummett saw the philosophy of language as calling into question a realist metaphysical conception of reality as how it is quite independently of our capacity to find out how it is, and pointing towards an alternative anti-realist metaphysics. In his view, the role of the philosophy of language here is not merely evidential, to give us reasons to believe one metaphysical theory and not another. Rather, he saw alternative theories of meaning as giving something like the cash-value of alternative metaphysical pictures. Methodologically, he proposed to replace futile quarrels between metaphysical pictures by comparisons between the corresponding theories of meaning as the only scientific way to resolve the issue. For him, metaphysical disputes are not senseless; nor are they what they seem, since they are implicitly disputes in the philosophy of language. One might compare
Dummett’s understanding of metaphysics with Strawson’s. For both of them, metaphysical questions turn into questions about the structure and limits of coherent thought, to be answered by systematic inquiry. But Dummett was more open to revisionary metaphysics than
Strawson was, because he took seriously the danger of fundamental incoherence in our current ways of thinking (as with our acceptance of the law of excluded middle), which Strawson did not. Dummett also differed from Strawson in regarding modern logic as a decisive advance over its predecessors, including its capacity to provide formal methods and model formal languages for use in the philosophy of language: he was adept himself in such methods. In that sense too, he was a new-wave philosopher of language.
Dummett laid out his program early on in his career (1959). The year Kripke gave the John Locke lectures, Dummett brought out his first magnum opus, Frege: Philosophy of Language (1973), in which he engaged creatively with Frege to develop his own views. Central to
Oxford philosophy in my student days was the dispute between, on one side, realism and truth-conditional semantics, represented by the
Davidsonians, and, on the other side, anti-realism and assertibilityconditional semantics, represented by Dummett. My sympathies were strongly with realism, though not with Davidsonianism. Dummett supervised me for the last year of my doctoral studies (1979–1980), at the start of his period as Wykeham Professor of Logic (1979–1992), the first holder of that chair with a deep knowledge of modern logic. He was remarkably tolerant of the strident realism of my thesis, which effectively presupposed the futility of his life’s work and pursued other issues from that starting-point. I cannot resist a couple of memories from that period.
When I told other philosophers at Oxford that I was working on the idea of approximation to the truth as applied to scientific theories, their reaction was always to ask 'Is that something to do with vagueness?' For vagueness was a big issue in Oxford then, being conceived as a major challenge to realism, truth-conditional semantics, and other forms of orthodoxy (Dummett 1975a, Fine 1975, Wright
1975). I always found that reaction annoying, because I thought it betrayed a myopic obsession with the philosophy of language. I would reply that my thesis had nothing at all to do with vagueness, pointing out that, of two perfectly precise but false scientific theories, one may be a better approximation to the truth than the other (I also enjoyed shocking people by saying that I found Popper more interesting than Davidson). On the narrow issue I was right, but my later trajectory suggests that my interlocutors were not completely wrong about the direction of my interests (Williamson 1994a). Indeed, one of my main reasons for later working on vagueness was that it was generally regarded as a paradigm of a phenomenon in need of anti-realist treatment. I wanted to strike at what was supposed to be the safest fortress of anti-realism.
Another memory comes from a supervision with Dummett. We were discussing an argument that I thought one of the best in my thesis, and he thought one of the worst; it later became the kernel of the only publication that emerged from my doctoral studies (Williamson 1988). After a while, Dummett reflected and said 'The difference between us is that you think that inference to the best explanation is a legitimate method of argument in philosophy, and I don’t.' I realized that his characterization of the difference was right, although I
was a little shocked at his outright rejection of inference to the best explanation in philosophy. His view was something like this: the deep philosophical issue will be about which of the theories that yield the putative explanations is so much as meaningful; that issue must be settled first before we can judge the value of those putative explanations; but once it has been settled, nothing much is left for inference to the best explanation to do. I still favor inference to the best explanation and an abductive methodology in philosophy (Williamson
2013a: 423–9). Indeed, it is hard to see how the kind of positive, systematic, general theory that Dummett sought in the philosophy of language could be established by any other means. He was optimistic about the long-run prospects of settling philosophical issues in a decisive, systematic way, just as he took to happen in science (Dummett
1978). But if one tries to establish the meaningfulness of a theory by an argument more decisive than abduction, won’t one have to first establish the meaningfulness of that argument by a further argument more decisive than abduction? There starts an infinite regress. Dummett’s dislike of inference to the best explanation may help to explain why his discussion of assertibility-conditional semantics never really got beyond the programmatic stage to the nitty-gritty of properly developing models of such semantics for non-trivial fragments of non-mathematical language. Even if such models had worked well
(a tall order), they would at best have provided him with some sort of abductive argument in favor of his program, whereas he wanted something more decisive. In the long run, the failure of his program to develop such working models has been a major reason for its marginalization, especially when combined with its radically revisionary and implausible consequences for logic and metaphysics.
Dummett presented his views on the relationship between the philosophy of language and metaphysics in his William James Lectures at Harvard in 1976, the same year that Hilary Putnam gave the John
Locke Lectures at Oxford. A book soon grew out of Putnam’s lectures, showing signs of Dummett’s influence in some rather unfortunate arguments against something called 'metaphysical realism'
(Putnam 1978). But it was not long before the anti-realist Dummett was replaced by the realist (if not metaphysical realist) J. L. Austin as the main Oxford presence in Putnam’s work (Putnam 1994). Dummett’s lectures took much longer to appear in print, as The Logical
Basis of Metaphysics (Dummett 1991). For a key work of a major philosopher, it had comparatively little impact. One problem was that its discussion of proof theory as the foundation of semantics was informal, often elliptical, digressive, or vague, with philosophical and purely technical matters all mixed together, making it excessively and unnecessarily hard for logicians to extract and perhaps answer the purely technical questions raised. Moreover, the generalization of the semantics to non-mathematical language still remained at a tentative, programmatic stage, not conducive to applications in linguistics. A more general problem for Dummett was that by 1991
the philosophical zeitgeist was even less receptive to anything like
Dummett’s program than it had been earlier. He did not engage with the new paradigms of metaphysics, such as the work of David Lewis.
There was no obvious way to interpret the new metaphysical theories as picturesque guises for views in the theory of meaning, nor did the new generation of metaphysicians wish to do so. Metaphysics itself had grown in self-confidence and felt no need to present itself as anything else. Incidentally, despite its title, my own book Modal Logic as Metaphysics (2013a) is very far from a return to Dummett’s understanding of the relationship between logic and metaphysics. As a first approximation, 'logic' in Dummett’s title means something like
'philosophical reflection on the meaning of the logical constants,'
while in mine it means 'generalizing about the world in terms just of the logical constants.' For Dummett, logic is metalinguistic, for me it is not. By the 1990s, few readers felt in danger of being compelled, against their wills, by Dummett’s convoluted arguments, even when they understood them. One of several reasons was that he discussed the mind in ways that still carried behaviorist baggage from a philosophy of mind widely rejected by younger generations since the collapse of behaviorist psychology and its replacement by cognitive psychology in the 1960s. Such baggage is detectable in remarks like this about knowledge of meaning: 'we should […] not be content with saying what is known, without saying what it is to have that knowledge, that is, how it is manifested by one who has it' (Dummett 1991: 104–5), where the manifestation is in observable behavior. In this respect,
Dummett can be compared to Quine, who was influenced by his Harvard colleague Skinner’s behaviorism in psychology. One might think that behaviorism about language had been outdated since the publication of Chomsky’s famously destructive review of Skinner’s Linguistic
Behavior (1959), but digestion can be a slow process. I remember sophisticated young philosophers of language at Oxford in the late
1970s still talking of children learning their native language by being
'drilled' in it by adults. In Dummett’s case, his behaviorist tendencies came from his reading of Wittgenstein rather than Skinner, and were correspondingly subtler and less eliminativist than Quine’s. Nevertheless, the differences should not be exaggerated. An anecdote from late in Dummett’s career: A group of younger Oxford philosophers were discussing what he meant, in the great man’s silent presence.
Suggestion after suggestion was rejected because it would attribute to him 'crude old-fashioned behaviorism.' Eventually, someone turned to him and asked 'So what is your view, Michael?' Dummett replied 'I think it’s the one you’ve been calling ‘crude old-fashioned behaviorism.’'
For Dummett, as for other British philosophers of his generation,
Wittgenstein’s central contribution to the philosophy of mind was his Private Language Argument. Its interpretation was disputed, but it was widely supposed to show something very deep about the need for talk about mental states to involve observable criteria (in some sense) for attributing them to others. The putative insight had widespread repercussions for the philosophy of language, concerning not just the semantics of mental state ascriptions but the nature of the mental states in play for speakers and hearers of any speech act, and in particular the nature of understanding. Dummett’s preference for assertibility-conditions over truth-conditions in the theory of meaning was rooted in the close linkage of assertibility-conditions to the observable use of the language, which realist truth-conditions lacked, since users of the language might have no idea whether they obtained.
He combined this Wittgenstein-inspired focus on use with a Fregeinspired insistence on the need for a systematic, compositional theory of meaning, modeled on the semantics of a formal language. In thus uniting elements of the two previous traditions of analytic philosophy, ordinary language philosophy and ideal language philosophy,
Dummett resembled the younger new-wave philosophers of language, although his selection of elements to combine differed from theirs.
At this point something must be said more generally about the influence of Wittgenstein on British philosophy in the period under discussion – as has often been remarked, his influence in North America was never as great as in Europe, one reason being the greater sway of naturalism or scientism in North America, led by Quine and others. In the case of Dummett, since he was a student at Oxford in 1950 when
Wittgenstein spent some time there living in Elizabeth Anscombe’s house, future historians might wonder whether there was face-to-face influence. It is therefore worth recounting the story Dummett liked to tell about his only meeting with Wittgenstein. Dummett was going for a tutorial at Anscombe’s house. She kept the door unlocked. As was the practice, Dummett went in, and sat down to await her summons. An elderly man in a dressing-gown came downstairs and asked
'Where’s the milk?'; Dummett replied 'Don’t ask me.' That was the extent of his conversation with Wittgenstein. What mattered instead was Anscombe’s mediating role. She was probably the strongest transmitter of Wittgenstein’s influence at Oxford until she left in 1970 to take up a chair at Cambridge, although of course she was always a fiercely independent-minded philosopher in her own right. Other Oxford ordinary language philosophers such as Ryle, Austin, and Grice were not molded by Wittgenstein, and the number of card-carrying
Wittgensteinians at Oxford was never very high. Nevertheless, his influence was still pervasive when I was a student in the 1970s. Gordon
Baker and Peter Hacker, guardians of the flame, had a large following amongst graduate students. They were later to have an ill-tempered dispute about the value of Frege’s philosophy with Dummett: when their disparaging book on Frege was published, Dummett organized an emergency series of graduate classes to denounce it (Baker and Hacker 1984, Dummett 1984). It is easy to list many Oxford philosophers of the time whose work showed significant Wittgensteinian influence to varying extents, even though it would be crass to classify them simply as Wittgensteinians: Dummett, Strawson, Philippa Foot,
Iris Murdoch, David Pears, Anthony Kenny, of a younger generation
John McDowell and Crispin Wright, and so on. What may be less obvious is how wary even those who barely mentioned him were of plainly saying that he was wrong about something. One knew that doing so incurred the automatic charge of shallow misinterpretation.
It was best to step quietly around, and let sleeping dogs lie.
Wittgenstein’s main influence at that time was through his later work, although few of those under the influence imitated his style of philosophizing in that work. Most engaged in overt theorizing of a more or less systematic kind. The citadel was the Private Language
Argument, from which he exerted his power over the philosophy of mind and the philosophy of language. The growing external threat to that power from cognitive psychology was surprisingly little felt in
1970s British philosophy. But there was also an internal threat. For how exactly was the Private Language Argument supposed to work?
Wittgenstein’s presentation was notoriously Delphic. The simplest and clearest reconstructions had the argument rest on a verificationist premise to the effect that one couldn’t be in a mental state unless some independent check was possible on whether one was in that state. But it was generally agreed that if the argument rested on a verificationist premise then it was not compelling, because verificationism could not just be assumed without argument. Defenders of the argument insisted that it worked without such a premise, but could not satisfactorily explain how (a similarity with Davidson’s transcendental argument mentioned earlier). Wittgenstein’s citadel was in danger from within; his power was waning as a result. At this point an unlikely would-be rescuer arrived: Saul Kripke. In lectures from 1976 onwards, and in his book on the Private Language Argument and the associated considerations on rule-following (Kripke 1982), he offered a conjectural interpretation of the argument that was clearly non-verificationist and, if not compelling, at least powerful. The question was: did it fit what Wittgenstein meant? The consensus amongst Wittgensteinians was that it did not, and as a matter of historical scholarship they may well have been right. But they seemed not to realize that in taking the negative attitude they did, they were also rejecting their last chance to avoid marginalization from the philosophical mainstream. The power of Wittgenstein’s name resumed its decline. As for Kripke’s argument in its own right, it inadvertently gave the new metaphysics an opportunity to spread its influence. For Kripke’s argument took the form of a skeptical paradox, to which Kripke offered a rather unclear and unattractive radically skeptical solution. By contrast, David Lewis offered a clearer and more attractive non-skeptical solution, by means of a highly metaphysical distinction between objectively natural and objectively non-natural properties (Lewis 1983b). It was something like Lewis’s solution, not Kripke’s, that was widely accepted.
Here are two snapshots of the decline in Wittgenstein’s standing.
The first is of a meeting in about 1994 of the 'Tuesday group,' originally founded by Ayer on his return to Oxford in 1959 as a counterweight to Austin’s Saturday morning meetings. Susan Hurley read a carefully reasoned paper against the Private Language Argument to an audience that included many leading Oxford philosophers. The audience divided by age. Roughly, those over fifty did not take the possibility seriously that Wittgenstein’s argument was fundamentally flawed, although they also did not explain how it worked or what it showed; those under fifty were more sympathetic to Hurley’s objections. The second snapshot is of a large graduate class on philosophical logic shortly after my return to Oxford in 2000. One student kept pressing the Wittgensteinian line that contradictions are meaningless rather than false. I kept giving the standard responses, that contradictions have true negations while the negation of what is meaningless is itself meaningless so not true, that the compositional semantics generates meanings even for contradictions, and so on, whose effect was merely to elicit variations on the same theme that did not meet the objection. Eventually I became exasperated and said 'Maybe Wittgenstein was just wrong; it wouldn’t be the first time.' There was a collective gasp of shock. I have never again witnessed such a reaction when Wittgenstein’s name was taken lightly.
Of course, the flame is kept alive by surviving groups of Old Believers. Some others, more willing to believe that there has been progress in philosophy since 1970, still find value in engaging with Wittgenstein’s work. Nevertheless, his influenced has declined drastically over the past forty years. No doubt that could be roughly measured by his proportion of citations in journals. But what strikes me most forcefully is that the fear factor has gone. As a test of authority, of intellectual or other kinds, admiration tells less than fear. In the 1970s, even nonWittgensteinian philosophers were often afraid to speak out against
Wittgenstein. They are so no longer. Another philosopher who has ceased to elicit the fear factor is Quine. Originally, he was frightening because few could match his skill with the weapons of formal logic in philosophical debate. By the 1970s that was no longer so, but philosophers were still very nervous of relying on ordinary semantic notions such as synonymy, because they were afraid of being caught out by Quine’s argument for the indeterminacy of translation. That fear too gradually evaporated in the 1970s, as Quine’s behaviorist assumptions fell into disrepute.
Having said so much about the Oxford philosophical scene in the
1970s, I should continue the story into the 1980s and 1990s. It was not at all a linear extrapolation from the 1970s. Strikingly, new-wave philosophy of language receded fast (though it proved temporarily)
in Oxford, less so elsewhere. One reason was tragically extrinsic: Gareth Evans died at the age of 34 in 1980. With him, the new wave in Oxford lost much of its technical panache, and detailed work in semantics dropped off. Although James Higginbotham was Professor of General Linguistics from 1993 to 2000, not much else was going on at Oxford in Davidsonian semantics for him to engage with. The
Davidsonic boom had come to an odd end, morphing into moral philosophy in the work of John McDowell, David Wiggins (Wykeham
Professor of Logic from 1994 to 2000, in succession to Dummett),
Mark Platts, and others. The transition was made through the Davidsonian emphasis on the legitimacy of homophonic truth theories, in which a word is used to state its own reference. Contrary to appearances, it is not trivial that 'round' in English applies to all and only round things, because one has that to learn in learning English.
Semantic analysis cannot go on forever; eventually we reach semantic atoms, and switching to a non-homophonic semantics achieves nothing to the purpose, because the aim of semantics is not to write a textbook that one might read in order to learn the object-language from scratch, but rather to say explicitly what its expressions mean in a systematic, compositional way, to those who may already understand them implicitly. Those in the intensionalist strand of newwave philosophy of language had to resort to homophonic lexical semantics too. The Davidsonians realized that, in particular, they could just as well give a homophonic semantics for moral language too (Wiggins 1976). For instance, 'evil' in English applies to all and only evil things. Nothing in their philosophy of language made it problematic to give such an ostensibly out-and-out realist treatment of moral language. Nor did it require any further semantic analysis of moral terms; they could be treated as unanalyzable. Thus Davidsonian philosophy of language found itself in the unaccustomed role of providing a protective environment for Aristotelian moral realism.
By contrast, Dummett put much heavier explanatory demands on the theory of meaning, perhaps too heavy to be satisfiable.
From the late 1970s onwards, Dummett also found himself fighting a more global trend in analytic philosophy: a move away from the philosophy of language towards the philosophy of mind. On his picture of the history of philosophy, Descartes had made epistemology first philosophy, the engine for the rest of philosophy, then Frege had replaced epistemology by the philosophy of language as first philosophy. Analytic philosophy was philosophy downstream from that linguistic turn. But many analytic or ex-analytic philosophers were starting, heretically, to treat the philosophy of mind as more fundamental than the philosophy of language. Cognitive psychology made a far more interesting and attractive conversation partner for philosophy than behaviorist psychology had done, and had a natural interface directly with the philosophy of mind, for instance in the theory of perception. Computer models of the internal workings of the mind were also increasingly influential. Once again, many of the innovations came from North America. As behaviorism lost its authority, Thomas Nagel (1974) led the way in talking directly about conscious experience. Although Daniel Dennett (1981) still showed some influence from his Oxford supervisor Ryle, he engaged with psychology through the philosophy of mind, not the philosophy of language. Jerry Fodor (1975) postulated a language of thought, on the model of a computer’s machine code, but it was to be studied by the methods of psychology and computer science, not those of linguistics. Moreover, it was not a public language, whereas Dummett envisaged first philosophy as the philosophy of public language, in line with the Private Language Argument.
In Oxford, the move into the philosophy of mind took a very specific form, which Dummett had unintentionally facilitated. For him, much of Frege’s achievement in the philosophy of language depended on his distinction between sense and reference. Sense is individuated cognitively: two senses may present the same reference in ways which count as different because they fail to render the sameness of reference transparent to the thinker. The cognitive nature of sense promised to make the connection Dummett wanted between the semantics of a language and speakers’ use of that language. Thus 'Hesperus'
and 'Phosphorus' differ in sense and use but not in reference. Dummett followed Frege in making sense a level of linguistic meaning distinct from the level of reference. Initially, this gave Fregean semantics a large head start over one-level referential semantics, like that associated with Russell, in explaining linguistic phenomena such as the apparent difference in truth-conditions between 'Mary thinks that
Hesperus is bright' and 'Mary thinks that Phosphorus is bright.'
However, new-wave philosophy of language in North America turned against Frege, especially at the level of public language. In particular, the semantic property of a name that speakers share is its reference; as Kripke and even Frege emphasized, the name’s cognitive connections may vary wildly from one speaker to another. Something similar applies to terms whose reference depends on context: the linguistic meaning of the phrase 'that dog' does not encode the rich cognitive connections that it will have when used as a perceptual demonstrative by a particular speaker on a particular occasion. Most of the younger
Oxford philosophers of language in the 1970s and 1980s followed
Dummett in his Fregean sympathies. But, more impressed than Dummett by the work of Kripke and other North American new-wave philosophers of language, they applied the sense-reference distinction only at the level of individual users of the language, not at the level of the language as a whole. If senses are cognitively individuated determinants of reference, a proper name expresses different senses for different speakers, and a perceptual demonstrative expresses different senses on different occasions even for the same speaker. If senses are structured, much of that structure will be at the level of thought and not at the level of language. 'Sense' was often glossed as 'a way of thinking of the referent.' This shift in focus from language to thought was already visible in the work of Evans (1982). By Dummett’s standard, it meant that Evans and the others who took that turn no longer even counted as analytic philosophers.
Thus Dummett found himself fighting on the home front too, trying to reassert the primacy of language over thought in philosophical method. Although he was happy to regard philosophy as the study of thought – of what is thought, not the act of thinking it – he insisted that the proper way for philosophers to study thought was by studying it as expressed in public language, which the neo-Fregean philosophers of thought no longer did. Perhaps they were not in direct contravention of the Private Language Argument, because their senses could in principle be shared. Nevertheless, from Dummett’s methodological perspective, they had taken a step backwards, because the study of public language gave philosophy the objective discipline it needed. To replace that discipline by the objective discipline of experimental psychology would be, from his perspective, to commit the disastrous error of psychologism, against which Frege had railed: it would involve confusing what is thought with the act of thinking.
Dummett seemed to be fighting a losing battle. Globally, the center of gravity of analytic or post-analytic philosophy moved towards the philosophy of mind in the 1980s. Logic and semantics suffered a significant loss of prestige: graduate students became less convinced of the need, intellectual or professional, to put in the hard work of learning them. Locally, neo-Fregean philosophers of thought were taking over. For instance, Strawson was succeeded as Waynflete Professor of
Metaphysics by Christopher Peacocke, who held the post from 1988
to 2000. Senses became concepts (Peacocke 1992).
Since the 1980s, the philosophy of mind worldwide has continued to enjoy a far more fruitful relationship with experimental psychology than it did in the heyday of behaviorism. However, it did not become first philosophy in the way it had been expected to do. Nor did the philosophy of thought, which anyway never solidified as a recognized branch of the subject. For instance, developments in metaphysics have typically not been driven by anything in the philosophy of mind. After all, with regained confidence in metaphysics, its contemporary practitioners tend to see themselves as investigating the most general and fundamental nature of a world in which human minds play only a very minor role. Why should the philosophy of mind or the study of concepts drive metaphysics any more than it drives physics? In principle, even if it cannot contribute towards constructive metaphysical theory-building, it might help towards understanding the folk metaphysical beliefs that may obstruct our acceptance of the correct revisionary metaphysics. In practice, the philosophy of mind and the study of concepts have had little impact on recent mainstream metaphysics even in that modest negative way. For the past several decades, no branch of philosophy has played the fully fledged role of first philosophy within analytic philosophy.
To some extent, that reflects the increasing specialization of academic research in general. But it also concerns a change more specific to analytic philosophy (in a sense broader than Dummett’s), in what philosophers take their subject matter to be. As already noted, an increasingly prevalent, broadly realist attitude is that when you are doing the philosophy of X, you are primarily interested in X itself, in its most general and fundamental aspects, and only secondarily in the word 'X,' or our concept of X, or our beliefs about X, or our knowledge of X. You are not surreptitiously doing the philosophy of language or thought or mind or knowledge. This reconception of the subject gives no branch of philosophy a head start over the others.
However, the situation is more complicated than those simple formulations suggest. For they might lead one to expect the philosophy of language to be just one more branch of philosophy alongside all the others, the philosophy of a phenomenon specific to humans and perhaps some other species scattered here and there over the universe. It looked like that to some in the 1980s, and taken in isolation it may still sometimes look like that. But, as already suggested, the philosophy of language also plays a more general role throughout analytic philosophy, in the evaluation of arguments. Of course, we do not need the philosophy of language to determine whether an argument is deductively valid in simple cases. But on almost any view of philosophy, it often involves arguments with a subtle illusion of validity, and other arguments that are really valid but need to be checked for such subtle illusions. The illusion may come from confusions between entailments and presuppositions or conversational or conventional implicatures, or from concealed shifts in context, or from lexical or syntactic ambiguities, or from other linguistic complexities.
Any discipline that uses subtle, complex would-be deductive arguments in natural language about abstract issues is liable to such illusions, and philosophy characteristically uses arguments of that kind.
That is of course not to say that it uses nothing else, or that no other discipline uses them at all; nevertheless, philosophical methodology past and present may put more weight on such arguments than does the methodology of any other discipline. The shift from a deductive to an abductive methodology makes less difference here than one might have expected, because abduction involves the assessment of – amongst other factors – a theory’s strength, explanatory power, and consistency with the evidence, which in turn depend on its deductive consequences. Thus, simply using the methods of analytic philosophy critically, by contemporary standards, takes some sophistication in both semantics and pragmatics, irrespective of the subject matter under philosophical investigation. That is a robust legacy from analytic philosophy of language for all philosophy.
One day, perhaps, cognitive psychology will have developed to a point at which it can be usefully deployed to locate likely trouble spots for philosophical reasoning, for instance where framing effects may be exerting an undue influence. Some 'experimental philosophers'
believe that we have already reached that point. However, perhaps with a few limited exceptions, it is doubtful that purely psychological methods have yet reached an adequate level of discrimination to be usefully applied in the way that linguistic methods already can be.
Just to be told that the order in which material is presented can influence our judgment is of little help, since either we ignore the material or it is presented in some order or other. For the time being, linguistics and the philosophy of language offer more help than do psychology and the philosophy of mind when we check an alleged deduction. In this limited respect, Dummett was right about the methodological danger of assigning priority to thought over language, but not for the deep and permanent reasons he envisaged.
For the evaluation of deductive arguments, the relevance of logic is even more obvious than that of the philosophy of language. Of course, some would-be deductive arguments in philosophy are cast in such seamlessly discursive form that no extant logical theory is of much use in evaluating them. Nevertheless, in most branches of contemporary analytic philosophy complex would-be deductive arguments often are articulated with sufficient clarity for formal logical skills to make a significant difference to the reliability with which their validity is assessed. Thus logic makes an instrumental contribution to philosophy in general similar in kind to that made by the philosophy of language, and perhaps greater in degree.
The development of formal methods in recent philosophy has also extended the scope for logic to make a more direct contribution to branches of philosophy usually conceived as 'other' than logic.
For instance, in epistemology, models of epistemic logic enable us to work through the consequences of epistemological claims in exactly  escribed, appropriately simplified situations in a far more rigorous d
and systematic way than would otherwise be available. Something similar goes for decision theory too. The model-building methodology that has proved so successful in the natural sciences can thereby be applied in philosophy too, and provides new insights into old problems. In metaphysics, rival logics often supply powerful structural cores to rival metaphysical theories: for instance, a quantified modal logic is the structural core of any properly developed theory of modal metaphysics. Although not all of modal metaphysics is usefully treated as logic, a vital part of it is. Logic, far from displacing metaphysics as the logical positivists hoped, is at its center.
The history of philosophy makes a mockery of any limited vision of what philosophy is. It has not followed the path laid out for it by the logical positivists, nor that laid out by the ordinary language philosophy. Nor has it (perhaps with a few limited exceptions) become a branch of psychology, or of physics. Nevertheless, under all the surface turbulence, it somehow manages to extract the residue it needs from each changing fashion. Who knows where the cunning of reason will take it next?

III
History is often said to be written by the winners. In the case of analytic philosophy, however, there is a danger that history will be written predominantly by the losers. One reason is that analytic philosophy is a somewhat anti-historical tradition, especially where it most resembles a science, in aspiration or achievement. For there it tends to be oriented towards the future rather than the past, in the manner of a science – hardly surprising when progress is expected. Those who do not like history cannot complain when their history is written by people who are not like them. A second reason is that recent analytic philosophy seems to subvert the global narratives it might otherwise be tempting to tell about the history of the subject – most notably, in the resurgence of realist metaphysics, often unashamedly concerned with things in themselves. For those sympathetic to Kant or Wittgenstein or Dewey, it must be tempting to see much recent analytic philosophy as an insignificant anomaly, a passing throwback, in the long march of philosophy. A case in point is Richard Rorty, who was admirably willing to step back, identify bold patterns in the then-recent history of analytic philosophy, and list his heroes – Kant, Hegel, Wittgenstein, Dewey,
Heidegger, Sellars, Brandom, …; no wonder his racy, deliberately provocative stories have been so widely read. It is striking that the very large number of names of contemporary philosophers – villains as well as heroes – in the index to Philosophy and the Mirror of Nature
(Rorty 1979) does not contain that of David Lewis, who had already published two much-discussed books and many articles, and been
Rorty’s colleague at Princeton since 1970. Rorty’s radar had missed a serious threat, the central figure in analytic philosophy for the coming decades. Rorty was out of sympathy with most new-wave philosophy of language, and the metaphysics that increasingly accompanied it, because its referential approach to semantics came too close for his comfort to making language a mirror of the world. For the future, he put his money instead on the inferential approach, particularly in the neo-pragmatist form offered by Robert Brandom (1994), focused on the commitments and entitlements of speakers to make moves in the language game. Brandom himself has his own grand narrative of the history of philosophy, in which – tongue partly but not wholly in cheek – he presents himself as the natural successor to Kant and Hegel (Brandom 2009b). But his inferentialism has remained at an even more programmatic stage than Dummett’s, lacking an equivalent of
Dummett’s connection with technical developments in proof theory by Dag Prawitz and others. As a result, inferentialism has been far less fruitful than referentialism for linguistics. In that crude sense, referentialism beats inferentialism by pragmatic standards.
Of course, we cannot expect a history of recent philosophy to remain neutral about the future. Even the driest chronicle of who published what when has implicit standards of historical significance in selecting whom and what to include. Good historical narratives discern patterns in their material more explicitly and reflectively. This section – which manifestly does not aspire to the depth or rigor of serious history – has indicated a few of the messy complexities that any history of recent analytic philosophy must try to order. Nevertheless, it does at least gesture towards some larger patterns to be made explicit and reflected on. A chronicle is not enough.
The power of fashion in philosophy already ensures that its history will exhibit some patterns, if only of the mob rushing here and there. Some of those fashions look foolish in retrospect; most of them did at the time to non-sympathizers. But fashion is powerful in all academic disciplines, even in mathematics – for instance, concerning which branches of the subject or styles of work carry most prestige.
Nor is that merely an inevitable defect in any collective human enterprise. Academic fashions arise because people trained in a discipline have some respect for the judgment of others trained in the discipline as to what is good or fruitful work, worth imitating or following up. When things go well, that mechanism enables the community to concentrate its energies quickly where progress is being and will be made, to avoid wasted effort, and to raise collective standards. It is a way of learning from others. The word 'fashion' is most appropriate when the level of deference to majority opinion becomes too high, stifling diversity and independence of mind, making it harder in the long run for the community to back up out of a wrong turning, since it loses its sense of the alternatives. But the rule of fashion is only an exaggerated form of something no community can do without. Even the time and energy spent on bad ideas and misconceived programs has its value, since the effect of the investment is that their limitations are properly explored and tested, so lessons are properly learnt. The history of academic fashions is the history of how things once looked to highly intelligent and knowledgeable people.
The changes in philosophy discussed in this section occurred in a period whose political, social, and cultural history is already being written. Its philosophical history needs to be properly written too, by historians of philosophy with at least enough sympathy for them to understand why what so many philosophers did seemed a good idea at the time. There are encouraging signs that such histories are just starting to be written. I look forward to reading them.

Acknowledgments
This section is a slightly corrected version of an article in the Belgrade
Philosophical Annual (Williamson 2014a), which derived from a talk given at the Faculty of Philosophy of Belgrade University in September 2014. I thank Professor Miroslava Trajkovski for the suggestion that I might depart from my usual practice and give a talk on an historical theme, based in part on my own experience. Thanks to the au- dience for constructive discussion, and to Peter Vallentyne, Zhaoqing
Xu, and Isaac Choi for spotting some bad typos. Additional thanks go to Professor Slobodan Perović for inviting me to write up the paper for publication in this journal. He also pointed out the thematic connection with Peter Strawson’s 1977 lecture at Belgrade University on the nature of analytic philosophy, subsequently translated into SerboCroat (as it then was) and published in Theoria (Strawson 1977).
On that visit to Yugoslavia, Strawson lectured in Belgrade, Zagreb, and Sarajevo. He later commented: 'I registered a certain difference in atmosphere in the three places. At least in academic circles the intellectual style seemed relatively untrammeled in Belgrade and Zagreb, though the political tone was different. In Sarajevo, where I
was only allowed to give one of my two scheduled lectures and had minimal contact with fellow academics, one perhaps time-serving young man in my audience suggested that my lecture revealed an essentially bourgeois outlook. I replied ‘But I am bourgeois – an elitist liberal bourgeois.’ My interpreter commented, sotto voce, ‘They envy you’' (Strawson 1998: 14). The contrast between Strawson’s account of analytic philosophy and the present one, almost forty years later, may be instructive. 9.2 Abductive Philosophy
Abduction is an informal method of non-deductive, ampliative inference and theory choice familiar from the natural sciences. Although the term goes back to Charles Sanders Peirce, I will not attempt to align my use of it exactly with any of his various characterizations of 'abduction.' The term is approximately equivalent to 'inference to the best explanation,' when 'explanation' is understood to cover non-causal as well as causal explanations. I will suggest that philosophy sometimes already uses an abductive methodology and ought to use it more in the future. I will also argue that in using an abductive methodology philosophy can still remain a primarily 'armchair'
discipline.

1. Michael Dummett and inference to the best explanation
Using abduction in philosophy never struck me as problematic. The methodological issue became salient for me when Michael Dummett took over as my supervisor at Oxford for the final year of my doctoral studies (1979–1980). My dissertation was on Karl Popper’s idea of verisimilitude – that scientific theories may approach closer and closer to the truth yet never get there. Dummett had just taken up the Wykeham Chair of Logic, which I now hold. My approach was broadly realist; he may well have felt that it presupposed the futility of his life’s work in philosophy, but he made no complaint about that and simply discussed my dissertation with me on its own terms. He seemed to find it a refreshing change from supervising dozens of theses critically assessing his own writings. In one supervision, we were discussing what I regarded as one of the best arguments in my thesis and he regarded as one of the worst (it was the origin of Williamson
1988, the only publication to emerge from my dissertation). Dummett paused for a while, then said: 'The difference between us about how to do philosophy is that you think that inference to the best explanation is a legitimate method of argument in philosophy, and I don’t.' I
realized that he was right about that being the methodological difference between us. My dominant reaction was, and to some degree still is, surprise at the idea that philosophy could or should get by without something like inference to the best explanation. Dummett’s view seemed to be something roughly like this (in my words, not his): 'The deepest, most important philosophical questions are about meaning. If someone proposes a philosophical theory to explain some data, there is a prior question as to whether the theory even has a coherent meaning. If not, it offers no genuine explanation. While that question remains unsettled, attempts to apply inference to the best explanation are premature. But once the question of meaning has been settled, the question of explanation will be comparatively trivial.'
In response to the meaning-based argument, several points should be made. First, if one can advance a philosophical argument only after showing its terms to have coherent meanings, then in particular one can advance the latter argument for coherent meaningfulness (which will itself be philosophical) only after showing its terms to have coherent meanings too, and so on. Clearly, we have embarked on a vicious infinite regress. Philosophy could never get started. Second, Dummett held that we can settle general questions of meaning only by establishing a systematic theory of meaning. But how can we establish it if not by inference to the best explanation? The uncontested data will not entail any non-trivial systematic theory of meaning.
A more promising attitude is to apply an abductive methodology to questions of meaningfulness as well as to questions of truth. If a theory does well by abductive criteria, that is reason to take it to be coherently meaningful as well as true. After all, if a theory really had no coherent meaning, one would expect that defect to show up most quickly when one tried to put the theory to serious use.
Dummett’s repudiation of the abductive method in philosophy is particularly striking since he regarded philosophy as a nascent science. He wrote (Dummett 1978: 454):
I am maintaining that we have now reached a position where the search for such a theory of meaning can take on a genuinely scientific character; this means, in particular, that it can be carried on in such a way, not, indeed, that disputes do not arise, but that they can be resolved to the satisfaction of everyone, and, above all, that we may hope to bring the search within a finite time to a successful conclusion.

How is philosophy to achieve the eventual unanimity allegedly characteristic of mature science if it is not permitted to use a key method at least of mature natural science? Would Dummett have denied that natural science does rely on abduction?
One subtlety deserves notice. The most famous form of non-deductive inference is enumerative induction, whereby one infers a general conclusion 'Every F is G' from many of its particular instances
('This F is G') and no counter-instances. Enumerative induction does not seem vulnerable to Dummett’s skepticism, since its conclusion contains only standard logical constants that everyone needs
('every,' 'is') and expressions already present in the premises ('F,'
'G'). Thus the passage from premises to conclusion seems to incur no significant new risk of incoherence in meaning. Indeed, Dummett discusses inductive generalization in non-skeptical terms (Dummett
1991: 276–7). Thus he has at least one form of non-deductive inference at his disposal. However, enumerative induction is inadequate for systematic philosophical theorizing, which often requires introducing new distinctions at a more abstract level not given in the data.
A glance at Dummett’s own writings will show that he often introduces new meaning-theoretic distinctions, like that between 'assertoric content' and 'ingredient sense,' which cannot simply be read off the data (Dummett 1991: 48). Moreover, enumerative induction itself is arguably legitimate only when it can be subsumed under inference to the best explanation (Harman 1965).
I will not go deeper into Dummett’s methodological views here.
The rest of this section leaves aside his rejection of abductive philosophy, to concentrate on developing a positive alternative.

2. A sketch of abduction
Before considering abduction in philosophy, we need to characterize the method in terms general enough to be applicable to philosophical theories. We may start by understanding abduction as inference to the best explanation. The following remarks are merely indicative; they do not aspire to be a full account (for something closer to which see
Lipton 2004).
We can rank theories (or hypotheses) as potential explanations of our evidence. The point of the qualifier 'potential' is that a false theory is not the actual explanation of the data; in that sense, it does not really explain them. But we need to rank theories as potential explanations before knowing whether they are true, in order then to use the ranking to guide our judgments as to which theory is true. A
potential explanation of the evidence is anything that would explain the evidence if it were true. A theory T is a better potential explanation of evidence E than a theory T* if and only if T would explain E if
T were true better than T* would explain E if T* were true – in brief,
T would explain E better than T* would.
In the best case, T explains E by entailing E. More typically, T
must be conjoined with auxiliary hypotheses to entail E. Those auxiliary hypotheses must be evaluated in turn; they may be independently plausible, or the abductive assessment may have to be of their conjunction with T. Obviously the auxiliary hypotheses should not entail
E by themselves, otherwise T would be redundant. In still other cases, the connection is irremediably probabilistic: E is probable conditional on T, perhaps in conjunction with auxiliary hypotheses, which as before must themselves be evaluated, and should not render T redundant. At a bare minimum, T must be consistent with E. In brief, the closer T comes to entailing E, the better (ceteris paribus).
Apart from its relation to E, the more T has the intrinsic virtues of a good theory, the better (ceteris paribus). It should be elegant and unified, not arbitrary, gerrymandered, ad hoc, or messily complicated.
It should be informative and general. In brief, it should combine simplicity with strength.
When a theory T scores highly enough as a potential explanation of our evidence E, and better than its rivals, we may infer T from E by inference to the best explanation. Such an inference is of course usually non-deductive: there was no suggestion that the closer E comes to entailing T, the higher T should be ranked as a potential explanation of E (ceteris paribus). Inference to the best explanation is obviously fallible; it can lead us from some true evidence E to a false theory T.
Nevertheless, fallibility does not justify skepticism. Inference to the best explanation is a vital means to knowledge.
We use inference to the best explanation continually in both the natural sciences and ordinary life. For example, it is often the natural way to reach conclusions about past events of which we have no more direct evidence through perception, memory, testimony, or the like: think of a cosmologist concluding that the Big Bang was the origin of the universe, an archaeologist concluding that three thousand years ago a city on this spot was destroyed by enemy attack, and a hunter concluding that several deer passed this way a few hours ago going east. All do it on the basis of present evidence, which can be explained as the traces of such past events. But inference to the best explanation can also be used to arrive at general theories, not just conclusions about particular past events. Indeed, it is the archetypical means of arguing for theories in natural science. The theories may concern either the observable but unobserved, or the unobservable, or both. When two theories make the same observable predictions, inference to the best explanation may still be able to select one over the other because the former is simpler and less ad hoc. In taking us from the observed to the unobservable, inference to the best explanation is far more powerful than enumerative induction.
Of course, we rank only those potential explanations that have been thought of. Sometimes there is a better potential explanation that nobody has thought of. Sometimes it is the actual explanation. In such cases, inference to the best explanation may lead us astray. But, as already noted, fallibility does not justify skepticism. Consolingly, the potential explanations we have thought of will tend to be simpler than those we have not thought of, and so do better on the criterion of simplicity.
Inference to the best explanation does not directly rank potential explanations according to their probability. This does not automatically make it inconsistent with a probabilistic epistemology, for instance a Bayesian one. Inference to the best explanation may be a good heuristic to use when – as often happens – probabilities are hard to estimate, especially the Bayesian prior probabilities of theories. In such cases, inference to the best explanation may be the closest we can get to probabilistic epistemology in practice.
Nothing in this account requires the evidence propositions, the explananda, to be of some special kind. Any known truths will do (Williamson 2000a). They may be theory-free or theory-laden, particular or general. Nor does anything in the account require the explanations to be causal. They may be constitutive instead. An example of both points is the use of Kepler’s laws of planetary motion as evidence for
Newton’s far more general laws of motion. Given that such laws are timeless, they are neither causes nor effects. Newton’s laws explain but do not cause Kepler’s laws, by subsuming them. Strictly speaking, of course, the explanation is only potential in this case, since Newton’s laws are only approximately true, but the point is clear enough. How wide should the evidence base be? In principle, we want the theory T to be consistent with all our evidence. That suggests making the evidence base E be our total evidence. In practice, however, we only expect a theory to explain a tiny fraction of our total evidence.
If a theory is a good (potential) explanation of some key pieces of evidence, and at least consistent with the rest, we are often happy enough. Indeed, the criteria above for a good (potential) explanation do not depend on treating the relation between T and E as specifically explanatory. This suggests that we should envisage the required relation between theory and evidence in more general terms. To acknowledge that generalization, I will use Peirce’s word 'abduction' instead of 'inference to the best explanation' (although Peirce sometimes spoke of explanation in characterizing abduction).
The foregoing sketch leaves it far from clear what makes abduction such a good method. For instance, why should aesthetic criteria such as elegance contribute to the pursuit of truth? Nevertheless, the central role of abduction in the success of the natural sciences provides good reason to think that it is a good method, even though we do not fully understand why. For the time being, we can reasonably proceed on that basis. Crucially for present purposes, nothing in the characterization of the abductive method limits its use to the natural sciences. In particular, it can be applied in philosophy, whether or not it should be.

3. Abduction in philosophy
I propose that philosophy should use a broadly abductive methodology. Indeed, to some extent it already does so. I propose that it should do so in a bolder, more systematic, more self-aware way.
From what evidence base should we start when applying abduction to the construction and selection of philosophical theories? As always, the answer is in principle: our total evidence. That is arguably no less than the total sum of human knowledge. It includes whatever knowledge the natural and social sciences, philosophy, and common sense have already gained. None of our knowledge is irrelevant in principle to philosophy, for any philosophical theory inconsistent with any of it is false (since what is known is true). In particular, there is no restriction to knowledge gained in some special 'conceptual' or
'a priori' or 'intuitional' or 'armchair' way. A tempting retort to this view of philosophy as an abductive inquiry with an unrestricted evidence base is the claim that, if adopted, it would turn philosophy into an embryonic natural science – for good or ill. It is not just that the evidence base contains the results of all the natural and social sciences, which will require philosophy to keep up to date with new developments in them, including new experimental and observational data. On such a conception, shouldn’t we also expect that sometimes the choice between rival philosophical theories will require philosophy to generate new evidence, for instance to test their consequences? In that case, won’t philosophers have to start doing their own experiments and making their own observations? After all, the most salient models of successful systematic abductive inquiry are the natural sciences.
One reply is that philosophers can generate their own new data by doing thought experiments. Natural scientists themselves sometimes use thought experimentation, so why shouldn’t philosophers do so too? But although the method of thought experiments is legitimate in philosophy (see Chapter 6), that reply is inadequate, for it gives no reason why the method should satisfy all of philosophy’s needs for new data, any more than it does for the natural sciences.
Indeed, it is independently plausible that philosophical progress does sometimes depend on the generation of new data from real life experiments. For instance, contemporary philosophy of perception is deeply informed by recent experimental results from the psychology of perception. Sometimes the experiments most relevant to a question in the philosophy of perception will not yet have been performed, or even conceived. Of course, the execution of the experiments is better left to experimental psychologists, since they have the relevant practical expertise, rather than to philosophers acting as amateur experimentalists, but philosophers can and occasionally do play a significant and legitimate role in their design and interpretation.
There is no methodological firewall between philosophy and real life experiments. However, that does not mean that once philosophy becomes a more systematically abductive inquiry, its current methodological differences with the natural sciences will fade away altogether. For natural science is not the only form of systematic inquiry in which abduction plays a significant role. It also does so in at least one highly successful form of 'armchair' inquiry: mathematics. Of course, it would be foolish to expect philosophy to adopt exactly the same methodology as mathematics, but no more foolish than expecting it to adopt exactly the same methodology as a natural science.
Rather, mathematics is a useful foil to the natural sciences in exhibiting the wide range of methodologies consistent with a significant role for abduction.
Since the use of abduction in mathematics may not be obvious, it is sketched in the next section.

4. Abduction in mathematics
At first sight, mathematics looks like a paradigm of a purely deductive form of inquiry. Mathematical journals are filled with deductive proofs of theorems. However, those deductive proofs ultimately rely on first principles, principles for which no further deductive proof is expected, even on demand. Whatever one thinks of circular or infinitely regressive proofs, contemporary mathematics does not rely on them.
What are the first principles of contemporary mathematics? Admittedly, working mathematicians are often vague about that, because they can get by with a multitude of proof techniques certified by the mathematical community, whose derivation from more fundamental principles they are happy to leave to others. On a standard view, the first principles of contemporary mathematics include the axioms of a set theory such as ZFC (Zermelo-Fraenkel set theory with the
Axiom of Choice), as well as the principles of classical first-order deductive logic and arguably second-order logic too. However, some set theorists deny set-theoretic axioms the status of first principles.
Instead, they treat them as simply defining a class of mathematical structures, the models of the set theory at issue, about which they take themselves to be proving theorems just as they might prove theorems about other classes of mathematical structures, such as groups, rings, or fields. But that makes less difference than one might think, since in proving theorems about models of the set theory they rely on implicit principles as to what mathematical structures there are, which they treat as first principles. Indeed, those implicit principles about mathematical structures bear a striking resemblance to standard principles about sets. Principles of higher-order logic may also do some of the work otherwise done by axioms of set theory. For present purposes it does not matter exactly what the first principles of contemporary mathematics are, and in particular whether they are general rules of logic or specifically mathematical axioms.
The alternatives are at least roughly equivalent in deductive power.
The question is how the first principles, whatever exactly they are, attain that status in mathematics.
It was once thought that the first principles of mathematics were all self-evident. However, that is no longer plausible. Although the axioms of a set theory such as ZFC can be made plausible, with a bit of hand waving, they do not all seem self-evident. One can understand them but still doubt their truth without obvious irrationality. Indeed, all contemporary set theories are very significantly shaped by the need to avoid the paradoxes of set theory, in particular Russell’s and Burali-Forti’s, which unexpectedly arose from simpler and seemingly more evident principles, such as Frege’s notorious Basic Law V and the unrestricted comprehension principle that there is a set of all and only those things satisfying any given predicate of the mathematical language. Moreover, by Gödel’s second incompleteness theorem, even the mere consistency of ZFC can be established only in a theory ZFC+ stronger than ZFC itself. Such a consistency proof does little to quell skeptical doubts, for if ZFC
is inconsistent then so too is ZFC+, in which case it 'proves' the consistency of ZFC because it 'proves' everything. The same problem affects any other formal theory cast in the same foundational role as ZFC.
The natural alternative to self-evidence for the first principles of mathematics is an abductive justification. The first principles must be strong enough to prove all established mathematical theorems; they must not be strong enough to prove a contradiction. Subject to those constraints, we naturally want the first principles to maximize simplicity and similar virtues.
Bertrand Russell developed such a view of mathematics as early as 1907 (long before the second incompleteness theorem was proved or even conceived). He proposed first principles or foundations for mathematics in a logical rather than epistemological sense, emphasizing both the 'logical simplicity' of the first principles and the nondeductive nature of their support:

c09.indd 359 360   Widening the Picture
… we tend to believe the premises because we can see that their consequences are true, instead of believing the consequences because we know the premises to be true. But the inferring of premises from consequences is the essence of induction; thus the method in investigating the principles of mathematics is really an inductive method, and is substantially the same as the method of discovering general laws in any other science. (Russell 1907: 273–4; see also Russell 1919: 1–2)

For Russell, the first principles of logic and mathematics bear an abductive relation to the less fundamental but more firmly established parts of mathematics, of which the most obvious are simple arithmetical truths such as '2 + 2 = 4.' We believe the first principles because we can derive those more obvious truths from them (and cannot derive their negations). Although he wrote 'induction,' Russell clearly had in mind something more general than mere enumerative induction. For the first principles as Russell conceived them are not expressible in the language of arithmetic; he formulates them in the more abstract logical framework of type theory. The first principles of logic and mathematics are not universal generalizations of truths of arithmetic or any more concrete branch of mathematics, although those truths (once suitably analyzed) are consequences of the first principles. The term 'abduction' better conveys that relationship.
For Russell, not even the obviousness of simple arithmetic truths amounts to self-evidence. Rather, they in turn bear an abductive relation to observable matters such as counting sheep (Russell 1907). But his view is not the same as Quine’s idea that mathematics is confirmed empirically by its indispensability for natural science. For Russell allows mathematics more autonomy with respect to natural science than Quine does. Once mathematics has got started, the move to more fundamental principles depends on abductive relations between more fundamental and less fundamental principles of mathematics, for
Russell, whereas for Quine it depends on abductive relations between mathematics and natural science as it develops. Arguably, Russell’s view makes a better fit than Quine’s with the history of mathematics.
Over the past two hundred years, foundational inquiries in mathematics have generally lacked specific connections with applications of mathematics in natural science, in part because only quite weak fragments of mathematics are needed for such applications. (Einstein’s successful application of non-Euclidean geometry to physics left little room for the conception of geometrical axioms as self-evident truths about physical space, but the independent reconstruction of geometry as more like a branch of algebra had in any case left that conception far behind.) Instead, the most important evidence on which to base the relevant abductions for foundational inquiries in mathematics is itself mathematical – less foundational mathematics, just as Russell suggests. It consists not just of fairly trivial truths such as '2 + 2 = 4,'
but of the whole body of established theorems of mainstream mathematics. That is how a standard set theory such as ZFC is abductively confirmed. If a proposed alternative global framework theory for mathematics does not prove all those theorems, it is thereby deeply problematic.
The search for first principles of logic and mathematics is not a completed project. It is arguably not even a completable one. We may accept all the axioms of ZFC as first principles on abductive grounds, but some claims expressible in the language of ZFC cannot be decided on the basis of those axioms. The classic example is Cantor’s Continuum Hypothesis (CH). Cantor proved that there are more real numbers (those on the continuous number line) than there are natural numbers (the finite counting numbers 0, 1, 2, 3, …).
CH says that no set has more members than the natural numbers yet fewer than the real numbers. From the work of Gödel and Paul
Cohen, we know that CH is neither provable nor refutable in ZFC.
Indeed, CH cannot be settled either way on the basis of currently accepted mathematical principles. But it may still be true or false, even if we are not yet in a position to know which. Some contemporary mathematicians, such as Hugh Woodin, seek more powerful new axioms for set theory that will prove or refute CH. Of course, we need good evidence for the truth of those new axioms: we cannot solve the problem trivially just by arbitrarily choosing CH itself or its negation as a new axiom. The desired sort of evidence for the new axioms is abductive: in combination with the other axioms, they should as far as possible yield a simple, elegant, natural, unified theory of sets strong enough to settle many mathematical questions left open by our current theories, yet which also makes a good fit with our current mathematical knowledge (see Maddy 2011 for more discussion of the nature of the evidence for axioms of set theory).
On an alternative view, CH is neither absolutely true nor absolutely false, but simply true of some set-theoretic universes and false of oth- ers, so the attempt to prove or refute CH rests on a confusion. If so, set theorists should be generalizing over those universes, not singling one of them out. But then we still need first meta-principles about what set-theoretic universes there are, for instance in order to prove that that CH holds in some and fails in others, and more generally to reason about the differences amongst set-theoretic universes. Those meta-principles will themselves need abductive support. Moreover, they will still be subject to Gödel’s incompleteness theorems, and so leave many questions unanswered (perhaps including an analogue of
CH), which we shall need new first meta-principles to decide, which will in turn require abductive support, and so on ad infinitum.
For present purposes, we need not pursue those mathematical issues. What matters here is that mathematics is a precedent for a successful discipline with an 'armchair' methodology that still has a key role for abduction. Thus it would be myopic to assume that an abductive methodology for philosophy implies its assimilation to the experimental sciences.
Unsurprisingly, abduction in philosophy is and should be less
'pure' than in mathematics. The evidence on which it does and should depend is often exogenous, generated from outside the discipline itself. It is perfectly proper for philosophers of time to appeal to
Einstein’s theory of special relativity, for philosophers of perception to use experimental results from the psychology of perception, and for political philosophers to consider the historical outcomes of attempts to apply various political theories.
However, philosophy does not always need other disciplines for its data. In philosophical logic, for example, an armchair methodology closer to that of mathematics is appropriate, though input from the semantics of natural languages as a branch of linguistics is sometimes illuminating. Indeed, the standard non-modal logic of quantification, predication, and identity just is the background logic for mathematics, and no more vulnerable than mathematics itself to objections from linguistics or other extraneous disciplines. Even when we extend the object-language with non-mathematical operators, the methodological repercussions may be quite mild. For instance, suppose that we introduce sentential operators for possibility and necessity (in specified senses). We then have to assess schemas like (I) and (II):
(I) Possibly (A or B) if and only if (possibly A or possibly B).

c09.indd 362 Widening the Picture   363
(II) Necessarily (A or B) if and only if (necessarily A or necessarily B).

Without going interdisciplinary, we can evaluate simple instances of (I) and (II) with declarative sentences substituted for the schematic letters 'A' and 'B,' by evaluating their constituents. We find a counterexample to (II) in the left-to-right direction when we substitute
'It is raining' for 'A' and 'It is not raining' for 'B'; we find no counterexample to (I). Abductively, we conjecture that the universal generalization of (I) is true while the universal generalization of (II) is false (on their intended interpretations). Although such armchair abductive assessments of simple principles in logic are not the last word, they take us a long way. They are no more likely to be overturned by experimental data than are armchair abductive assessments of simple principles in set theory. Since I have defended an abductive methodology for philosophical logic in more detail elsewhere (Williamson
1994a: 186, 2013a: 423–9, 2017b), I will concentrate in what follows on less formal areas of philosophy.

5. What difference would an abductive methodology make to philosophy?
As just seen, an abductive methodology for philosophy does not automatically force a change in what evidence it uses, although in some circumstances such a change may be needed. That raises the question: how revisionary of contemporary philosophical method is the abductive proposal?
Of course, contemporary philosophy is far from uniform in its methods; only a near-vacuous methodological proposal would be entirely non-revisionary. In particular, some contemporary philosophers reject the conception of philosophy as a systematic truth-directed theoretical inquiry. They may instead conceive it as clarifying, creating, or subverting concepts, as critical or emancipatory, or as otherwise engaged in projects quite incommensurable with those of the sciences.
Such philosophers can hardly be expected to endorse an abductive methodology in principle or conform to one in practice. This is not the place to criticize such radically alien conceptions of philosophy.
A more interesting because subtler comparison is with a deductive methodology still used by many contemporary analytic philosophers, including many who do regard philosophy as a systematic truth-directed theoretical inquiry. Indeed, it may be what they have in mind when they say that analytic philosophy is distinguished from other sorts of philosophy by the imperative to argue for one’s claims.
Deductivists argue deductively for their claims. Much competent work in contemporary analytic philosophy follows the deductive paradigm, sometimes with great skill. For negative conclusions, such a methodology can work well. Using uncontroverted principles of logic, one may succeed in showing that an opponent’s universal generalization is inconsistent with an uncontroverted description of an example, or even with itself. However, if philosophy is a systematic truth-directed theoretical inquiry, one should presumably aspire to more positive conclusions too, such as informative universal generalizations of one’s own. But, in non-formal areas, one typically needs informative universal premises in order to derive an informative universal conclusion. All too often, if the argument is deductively valid, opponents simply reject one of those informative universal premises as 'question-begging.' One can try deducing the rejected premise from further informative universal premises, but that way an infinite regress looms. To avoid the regress, one may declare the premise
'self-evident,' a 'Moorean fact,' or an 'intuition,' but no such talk forces a skeptic to accept one’s premise. Such rules of engagement are conducive to deadlock. But in effect that outcome constitutes defeat for the argument, since in putting it forward the proponent by implication accepted the burden of proof, and failed to discharge that burden. It is so hard for an argument to succeed on those terms that the methodology puts pressure on its practitioners to water down their conclusions to a point where they can be deduced from uncontroversial premises, but that is a recipe for trivializing the discussion.
When both sides follow the deductive paradigm, the usual result is stalemate.
One form of the deductivist methodology is the attempt to refute a rival theory by reductio ad absurdum, which often ends in deadlock as to whether the derived consequence of the theory really is absurd. There is in effect a race between proponents and opponents of a theory to derive its bad consequences. If the proponents spot a bad consequence first, they can claim it as simply 'part of the view'
and so no objection to it. If the opponents spot it first, they can claim it as a reductio ad absurdum of the view. Of course, it is not only in philosophy that arguments rarely produce switches in allegiance between rival theories. In a famous passage quoted by Thomas Kuhn, Max Planck wrote: 'a new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die, and a new generation grows up that is familiar with it' (Planck 1949:
33–4, quoted at Kuhn 1970: 151). Human obstinacy and pride are potent factors in all intellectual life. Individual irrationality may even contribute to group rationality, by helping ensure that a theory’s resources for dealing with problems are fully explored, so that it is not given up prematurely. The concern about the deductivist methodology in philosophy is not that it produces so few conversions, but that it channels energy in unproductive directions. For example, an ad hoc hypothesis with little explanatory potential may nevertheless be very hard to refute in a deductivist sense. Yet a deductive argument for any theory incompatible with that hypothesis must deductively rule out the hypothesis. Thus considerable time may be spent in trying to refute a hypothesis of no serious interest. That time would have been better used in exploring the explanatory potential of more promising theories.
An abductive methodology bypasses deductive deadlocks, by encouraging both the accumulation of more evidence of various kinds and the development of better explanations of that evidence (which may simply bring it under illuminating generalizations). There is less need to lock horns over one piece of evidence as many others become available. Discriminations between theories gradually emerge on the abductive scoresheet. Given Planck’s warning, we should not expect even this abductive methodology to make diehard proponents of the losing theories renounce them. But the discipline as a whole may make progress in the usual way: new entrants to the profession, less invested in any of the competing theories, may be more sensitive to their comparative merits.
Deduction still plays a major role within abductivist inquiry, since deducing consequences from a theory (usually with some auxiliary hypotheses) is integral to the explanatory enterprise. More generally, abduction values theories of great deductive strength (at least, when they are consistent with the evidence). Indeed, the abductive methodology gives more scope to deduction, by eliminating the deductivist pressure for the premises to be uncontentious, and replacing it with pressure for them to include an informative general theory. In that sense, abduction and deduction play complementary roles – and logic is a vital part of philosophy.
Conversely, abduction often plays a significant role on the quiet within deductivist inquiry, since it may be used unofficially to support premises of the official deduction. Once that role is acknowledged, one might even wonder how much abductivism really differs from deductivism. But they do not collapse into each other. The dialectical role of deduction within the two paradigms is quite different: as just seen, deductivism exerts pressure for uncontentious premises in a way that abductivism does not. Indeed, once one is permitted to use abduction in supporting the premises of the deduction, why not use it directly to support the conclusion? The rationale for deductivism is undermined. Moreover, within the deductivist paradigm, the cases for the individual premises are normally made separately from each other, so that abduction is applied one premise at a time. By contrast, within the abductivist paradigm, it makes more sense to apply abduction to the conjunction of the premises together. For instance, each of several premises may give a nicely unified picture, while their conjunction gives a nastily disunified one. It is better to use deduction within an overall abductivist methodology than to use abduction within an overall deductivist methodology.
Contrary to some stereotypes of analytic philosophy, abduction rewards boldly speculative theories. Bolder theories are riskier but stronger, in other words more informative; they entail more and so tend to have more explanatory potential, but are easier to falsify. For the same reason, abduction rewards precise theories. Many wildly unclear, obscure, and vague theories have the air of setting off into the unknown, and so look bold, when really they are the opposite.
Since it is quite unclear what they are supposed to entail, they avoid the risk of falsification, but by the same token they give up the hope of explaining anything. Such theories rank low on the abductive scale.
Abduction also rewards virtues such as simplicity, elegance, generality, and unificatory power, which all tend to make for bold theories.
As already emphasized, an abductive methodology will not infrequently lead us to false theories. But the clearer those theories are, other things equal, the better able we are to discover their falsity, and so learn from our mistakes. This is another advantage of precise theories over vague ones, which are much harder to falsify. 6. Simplicity, over-fitting, and error-fragility in the method of thought experiments
One of the main puzzles in understanding the effectiveness of an abductive methodology, even in natural science, is its apparent reliance on simplicity, elegance, and similar factors in ranking theories.
Such more or less aesthetic criteria have no obvious connection with truth: why should the truth be simple or elegant? Someone might even be tempted to think, desperately, that the use of such criteria requires a pragmatist or anti-realist understanding of natural science.
These puzzles arise just as much for an abductive methodology in philosophy. Someone might likewise be tempted to think that the use of such criteria requires a pragmatist or anti-realist understanding of abductive philosophy too.
Experience of theorem-proving in logic suggests that without a strong aesthetic sense in such matters one is lost, directionless, unable to discriminate fruitful from pointless definitions, promising conjectures from dead ends. Such an aesthetic sense is surely connected to a capacity for abstract pattern recognition, though that is not yet to say very much.
We still do not fully understand the role of simplicity in science.
The problem itself may have no simple solution: on closer analysis, it may turn out to involve several interacting issues. As Nelson Goodman’s new riddle of induction suggests, the problem arises even at the level of enumerative induction about observable matters: why should we expect emeralds next century to be green rather than grue (Goodman 1955)? When we cross a bridge, we presumably rely on abductive reasoning. It is quite unclear that pragmatism or anti-realism has anything useful to offer in such cases.
Nevertheless, some piecemeal progress has been made, and it is compatible with a fully realist conception of science. In particular,
Malcolm Forster and Elliott Sober (1994) have made a strong case that at least part of the story concerns the problem of 'over-fitting'
in natural science. I will suggest that their account has a significant moral for the role of simplicity in philosophy.
Consider the scientific challenge of curve-fitting, extrapolating a curve (a general equation) from the finite set of currently available data points for some given variables. By using sufficiently complex equations (such as polynomials with sufficiently many parameters) we can normally fit the available data very accurately. However, scientific experience shows that doing so leads to the problem of overfitting, where such equations tend to be predictively inaccurate: although they fit present data well, they fit future data badly.
Forster and Sober (1994) point out that restricting ourselves to simple equations (such as linear or quadratic ones) helps avoid the problem of over-fitting. Although it typically leads to equations that fit present data slightly less well, they tend to be predictively more accurate, that is, to fit future data better. The reason is that they are less vulnerable to distortion by errors in the data. The restriction helps us avoid mistaking noise for signal, which we do if we fit the current data too closely. This account of the role of simplicity and similar aesthetic criteria in abductive methodology is consistent with a fully realist, non-pragmatist understanding of science.
What is meant here by 'errors in the data?' Elsewhere I have defended the thesis E = K, that the total content of our evidence is the total content of our knowledge (Williamson 2000a). Since only truths are known, E = K entails that all our evidence is true. How then can our evidence contain errors? The answer is that it does not. The 'data'
here are merely measurements of the values of the relevant variables.
Typically, scientists do not even believe that the measurements are perfectly accurate. At best, they know what the measurements were and that they were accurate within a given margin for error. That is the limit of their evidence, but the best method in such cases is to find the simple equation that best approximates the measured values.
Indeed, we are often wrong about the extent of our evidence too, thinking that something is part of our evidence when really it is not
(thinking we know something when really we don’t). An abductive methodology allows for the near-inevitability of some such errors.
Forster and Sober’s rationale for the criterion of simplicity can be extended to philosophy, even though quantitative data are not involved. For something very like the problem of over-fitting occurs in philosophy too. Consider, for instance, the research program of reductively analyzing knowledge in response to Gettier’s refutation by counterexamples (in the form of thought experiments) of the 'justified true belief' analysis of knowledge, one of the main activities of analytic epistemologists. (Gettier 1963, Shope 1983). Notoriously, what happened was a cycle of proposed analysis, followed by new counterexamples (again in the form of thought experiments), fol- lowed by a revised analysis, with an extra epicycle, a new disjunct or other complication, in order to finesse both the new counterexamples and all the old ones. Just as in the quantitative case, tolerance for highly complicated, messy, gerrymandered analyses yielded a succession of proposals that fitted the current data but succumbed to new ones. Other programs for reductive analysis in philosophy, for instance of causation or meaning, have had similar track records.
Strikingly, the philosophical community showed very little aversion to the multiplication of complication. A firmer preference for simplicity and elegance would have warned the community that something was going wrong. Indications of over-fitting remain quite widespread in analytic philosophy.
Of course, abductive criteria of simplicity and elegance do not license one simply and elegantly to ignore recalcitrant data. Rather, they encourage a more critical attitude to the data. In the case of thought experiments, we should be more willing to countenance the possibility that our verdict was mistaken, especially in unclear cases.
This does not imply that it is wrong to use thought experiments in philosophy, any more than Forster and Sober’s point implies that it is wrong to use quantitative data in natural science. It is just that serious inquiry requires sophistication in the handling of evidence. We need a strategy to take account of our own fallibility.
These considerations suggest a response to one of the more interesting criticisms of reliance on thought experiments, advanced by experimental philosophers. Joshua Alexander and Jonathan Weinberg
(2014) have argued that the method of thought experiment is errorfragile, in the sense that it tends to multiply the effect on the output theories of any errors in the supposed input evidence. For instance, one misjudgment of a thought experiment could lead us to mistakenly treat it as a counterexample to a theory that is in fact true, and thereby dismiss the true theory. This is like the error-fragility of a naïve falsificationist methodology in natural science, which treats a theory as refutable by a single observation: if there is an error in the observation, we may thereby dismiss a true theory as refuted. Since all evidence is true, if our evidence really contains one counterexample to a theory then the theory is false: but inevitably we sometimes take our evidence to contain things that it does not really contain. Since we cannot keep our premises completely free of error, we need robust methods of theory choice that do not crash every time an error enters. By giving weight to simplicity and elegance as a counterbalance to evidential fit, an abductive methodology avoids error-fragility in both the experimental sciences and philosophy.
There is another dimension to the problem. In the special sciences, such as economics, psychology, and even biology, we study systems so complex that informative exceptionless universal generalizations about them are rare. Instead of vainly seeking such laws, we can often make more progress in understanding the phenomena by building highly simplified, elegant, precise formal models of them and exploring their consequences. We do not expect the models to be perfectly accurate. We must be satisfied with a reasonable approximation instead. In such cases, at least some of the discrepancies between model and evidence are genuine. We can treat model-building as a special case of the abductive methodology in which the requirements of evidential fit are relaxed. Thinking beings, especially human beings, are paradigms of systems too complex to be best understood in terms of exceptionless universal laws; the model-building methodology is more appropriate. Many branches of philosophy focus on thinking beings, especially human beings: for instance epistemology, philosophy of mind, philosophy of language, and moral, social, and political philosophy. I have argued elsewhere that the model-building methodology is appropriate for such branches of philosophy (Section 9.3). In the case of epistemology, I have shown how combining the methods of model-building and of thought experimentation can give more robust results than either method on its own (Williamson
2013b, 2015a). In other branches of philosophy, such as philosophical logic and fundamental metaphysics, there is much more hope of informative exceptionless universal generalizations, and a more direct approach is often appropriate, with no relaxation of the requirements of evidential fit. In both kinds of case, however, the underlying methodology is abductive.

Acknowledgments
This section first appeared in an issue of Philosophical Forum containing papers presented to the 2015 conference on 'Williamson,
Logic, and Philosophy' at Peking University. Earlier versions of the material were presented in my 2013 Kim Young-Jung lectures at Seoul National University, at a conference on 'Realism and Objectivity' at Matera, at a workshop on 'Philosophical Methodology' at St
Andrews, and in classes and seminars at the universities of Göttingen,
Michigan (Ann Arbor), Oxford, and Trnava. I thank participants in all these events for helping me develop my ideas. 9.3 Model-Building in Philosophy
One notable form of progress in the natural and social sciences over the past century has been the development of better and better models of the phenomena they study. The models are typically presented in mathematical terms: for instance, by differential equations for the rise and fall in population of a predator species and a prey species, interacting only with each other, or by a set of ordered pairs for the networking relations in a society.
When a system resists direct study, because it is so complex or hard to observe, model-building constitutes a key fall-back strategy. Studying a model often yields insight into the phenomena it models. When one model is replaced by another that captures more about how the phenomena work, science progresses.
Sometimes such progress is a step towards discovering universal laws of nature, non-accidentally exceptionless generalizations. However, macroscopic phenomena are typically too complex and messy to obey many informative exceptionless generalizations framed in macroscopic terms. (Some microscopic phenomena are like that too.) In such cases, the discovery of universal laws may not be a reasonable aim for those branches of science, even if there are still useful rules of thumb. It may be more realistic and more fruitful to aim at building increasingly good models instead. Special sciences such as economics and psychology are salient examples. Even in evolutionary biology, progress may consist more in the development of better models than in the discovery of universal laws.
This section argues that in philosophy, too, one form of progress is the development of better and better models – especially, but not exclusively, in those branches of philosophy, such as ethics, epistemology, and philosophy of language, which deal primarily with the human world in all its complexity and mess. Not only can philosophy make progress through model-building, it has been doing so for quite some time. Philosophers tend to feel embarrassed by the question 'So what has philosophy discovered recently?' When we try to think of an informative generalization whose universal truth has recently come to be known through the efforts of philosophers, we may well not come up with much. We tend to assume that most of the natural and social sciences are doing far better. Surely they are indeed making progress, but this may consist much less than we suppose in the discovery of universal generalizations and much more in the development of better models. Once we look for progress of that kind in philosophy, it is not hard to find. It is there right under our noses.

What are Models?
Philosophers of science use the word 'model' in a confusing variety of ways, as do scientists themselves. Clarity has not been served by a universalizing tendency in the philosophy of science to define the word in a way meant to apply to all scientific theories or all uses of the word 'model' in science. For present purposes, a more helpful recent trend in the philosophy of science has been to use the term
'model-building' to identify a specific recognizable type of theoretical activity that some but not all scientists engage in, some but not all of the time (Godfrey-Smith 2006a, Weisberg 2007). A scientific research group may advertise a position as a 'modeler'; some but not all members of the group will be modelers. Similarly, I do not suggest that all philosophizing is model-building. Rather, some but not all philosophers build models, some but not all of the time.
Even on the restricted use of 'model,' there are different views of what models are. For the sake of simplicity and clarity, I will give my own account, but what I say could be adapted to other accounts: it is easier to agree on whether a scientist is presenting a model than on what sort of thing that model is.
Here, a model of something is a hypothetical example of it. Thus a model of predator-prey interaction is a hypothetical example of predator-prey interaction. The point of the qualification 'hypothetical'
is that the example is presented by an explicit description in general terms, rather than by pointing to an actual case. For instance, one writes down differential equations for the changing population sizes of the two species, rather than saying 'the changing numbers of foxes and rabbits in Victorian Sussex.' The description picks out a type of case, rather than one particular case: for instance, the type of any predator-prey interaction that obeys the given differential equations.
For the model-building methodology to work well, the description of the hypothetical example must be precise and specific enough to be formally tractable. That is, it should enable us to derive answers to many relevant questions about the example. When we explore the model, we do so on the basis of what follows from the description itself, which is designed to facilitate that process. We do not assume that the model fits the knowledge we already have of the phenomenon under study, since that is one of the main questions at issue.
But if the fit turns out to be reasonably good, exploring the model becomes a way of indirectly exploring the original phenomenon. The mathematical clarity of the description helps make direct study of the model easier than direct study of the phenomenon itself.
The hypothetical example, the type picked out by the description, may or may not have actual instances. Indeed, it may or may not have possible instances. For example, evolutionary biology typically uses differential equations for population change, even though they treat the change in the number of group members as continuous whereas really it must be discrete; answers to 'How many?' questions do not form a continuum. Strictly speaking, such a model is impossible; it is a type metaphysically incapable of having instances. But that does not mean that the model collapses. The differential equations are mathematically consistent; we can still make a stable tripartite distinction between what follows from them, what is inconsistent with them, and what is neither. Moreover, the mathematical consequences of the description may turn out to be similar enough to descriptions in similar terms of the observed behavior of the target real-life phenomenon for the model to provide considerable theoretical insight into the target.
In advance, we might not have expected impossible models to have such cognitive value, but it has become clear that they can.
The role of formal consistency in a model-building methodology provides a link between this meaning of 'model' and its meaning in mathematical logic. In the logical sense, a model of a theory (call it a
'logic-model') is an interpretation of the theory on which it comes out true. The interpretation must give the purely logical expressions
(such as 'if' and 'not') their intended interpretations but may radically reinterpret non-logical expressions (for instance, by treating the word 'fox' as applying to numbers). A theory is logically consistent if and only if it is true on at least one such interpretation, in other words, it has a logic-model. A sentence logically follows from a theory if and only if it is true on every interpretation on which the theory is true, in other words, every logic-model of the theory is a logic-model of the sentence. We can apply those logical distinctions to model-building in science by treating the description of the model as a mini-theory, and the purely mathematical expressions in the description as logical, so that their interpretation is held fixed. On its intended interpretation, the description of the model may pick out an impossible type (for instance, because it describes population growth as continuous). Nevertheless, the description is logically consistent, because it has a logicmodel: it is true on some unintended interpretation.
The mathematical clarity of the description typically makes such a logic-model easy to construct, for instance by reinterpreting its nonlogical terms (such as 'predator' and 'prey') as applying to purely mathematical entities with the right formal structure. The purely logical consequences of the description do not depend on the intended interpretations of its non-logical terms; they are determined by the whole class of intended and unintended interpretations alike. Nevertheless, the non-logical terms are not idle, for they are needed to co-ordinate comparisons with the real-life phenomenon. If we interchange the words 'predator' and 'prey' in the description, the comparisons go differently.
The simplified and sometimes idealized nature of models is no surprise on this account. They are typically intended to be easier to explore than the real thing; simplicity and idealization contribute to that.
A warning is in order. The talk of building models might suggest a constructivist philosophy of science, on which model-building is a matter of invention rather than discovery, and is not in the business of uncovering truths independent of the inquiry itself. But that would be a very naïve conclusion to draw. Rates of population change in predators and prey are not figments of the scientific imagination. If we are investigating a complex reality out there, it is not at all surprising that it is sometimes best to use a sophisticated, indirect strategy, to ask questions quite subtly related to the overall aims of the inquiry. To build a model is just to identify by description a hypothetical example which we intend to learn about in hope of thereby learning about the more general subject matter it exemplifies. Nothing in that strategy is incompatible with a full-bloodedly realist nature for the scientific inquiry. The same goes for model-building in philosophy.
On a full-bloodedly realist conception of model-building, we should expect it under favorable conditions to provide knowledge.
But, since only what is true is known, and virtually no model descrip- tion is strictly true of its real-life target, what knowledge can modelbuilding provide? What could its content be?
When we explore a model by valid deductive reasoning from the model description, we learn necessary truths of the general conditional form 'If a given case satisfies the model description, then it satisfies this other description too.' That broadly logico-mathematical knowledge has the virtue of precision, but by itself is less than we want, since it says nothing unconditional about how close the original phenomenon (such as predator-prey interaction) comes to satisfying the model description. Fortunately, we can also learn unconditional though vaguer truths of the general form 'This model description fits the phenomenon better than that one does in the following ways,'
where the fit is usually approximate. Although much more needs to be said about what such approximation consists in, for present purposes the general picture will do. Such a combination of precise conditional knowledge and vague unconditional knowledge of the target is ample reward for the work of model-building. (For a far more detailed account of model-building in science see Weisberg 2013.)

Models in Philosophy
The need for model-building is hardest to avoid where the complex, messy nature of the subject matter tends to preclude informative exceptionless universal generalizations. The paradigm of such complexity and mess is the human world. Hence the obvious places to look for model-building in philosophy are those branches most distinctively concerned with human phenomena, such as ethics, epistemology, and philosophy of language. Of course, categories like goodness and duty, knowledge and justification, meaning and communication are not restricted to humans. Even those that do not apply to nonhuman animals on earth can in principle apply to actual or possible non-human agents, perhaps vastly more sophisticated intellectually than we will ever be. Philosophers typically want their theories to apply to such non-human agents too. But that only makes exceptionless universal generalizations still harder to find. By contrast, pure logic supplies fertile ground for powerful exceptionless universal generalizations. One might expect the same of fundamental metaphysics too. Although the metaphysical question of personal identity looks more complex and messy, it also looks less fundamental.
As it happens, the few extant discussions of model-building in philosophy have tended to concentrate on model-building in metaphysics (Godfrey-Smith 2006b, 2012, Paul 2012). One reason is perhaps that metaphysics has the worst press of any branch of philosophy, so the need for a new methodological defense may be felt most strongly there. Model-building is indeed sometimes used even in fundamental metaphysics. An example is the idea of gunk, stuff (or space itself) of which every part has a lesser part, so it has no perfectly atomic parts.
Gunk may not be actual, but is it metaphysically possible? It is very tricky to work out which natural assumptions about the part-whole relation are logically consistent with gunk. Constructing mathematical models of gunk provides a good way of answering such questions
(see Arntzenius 2008, Russell 2008, and Wilson 2008 for a debate).
If we turn to more obviously likely branches of philosophy, such as epistemology and philosophy of language, examples of model-building are easy to find.
In epistemology, a standard model of epistemic uncertainty is a lottery. Here is a typical description:
There are exactly 1000 tickets in the lottery, numbered from 1 to 1000.
Exactly one will win. The lottery is fair. That is all you know about it.
Thus, on your evidence, each ticket has probability 1/1000 of winning.

That description involves various assumptions typically false of lotteries in real life. For instance, it assumes that it is certain on your evidence exactly how many tickets will be in the draw. Nevertheless, a good test of epistemological theories is to work out what they say about this simple case. For instance, consider the proposal that you should accept a proposition if and only if it is at least 90% probable on your evidence. If so, you should accept that the winning number will be greater than 100, and you should accept that it will be at most
900, but it is not the case that you should accept that it will be greater than 100 and at most 900. You are obliged to accept one conjunct and you are obliged to accept the other, but you are not obliged to accept their conjunction. That is at best an uneasy combination. One can show that a similar problem arises for any probabilistic threshold for acceptance more than 0% and less than 100% (varying the number of tickets when necessary). Although lottery models are elementary, they already have enough structure to make trouble for many superficially attractive ways of thinking about uncertainty. Moreover, their simple mathematical structure makes it trivial to define mathematical logic-models with that structure, so their consistency is not in doubt.
The branch of epistemology known as formal epistemology is much concerned with model-building. The models come from two main sources. Some, like the lottery example just discussed, are probabilistic, often in the Bayesian tradition of thinking about probability, which has been hugely influential in the natural and social sciences
(see Howson and Urbach 1993). Others are models associated with epistemic logic in a rich tradition originating with Jaakko Hintikka
(Hintikka 1962, Ditmarsch, Halpern, Hoek, and Kooi 2015): although not all standard logic-models of epistemic logic are models in the present sense of epistemic situations, they can all be reinterpreted in a natural way as such models. One can also add probabilities to models of epistemic logic in a natural way (Williamson 2000a). When our models exclude something observed in real life, we may build more sophisticated models to include the observed phenomenon. For instance, the simplest epistemic models exclude ignorance of one’s own ignorance. But people such as holocaust-deniers are ignorant of their own ignorance. More sophisticated epistemic models include agents ignorant of their own ignorance.
Model-building in epistemic logic has found numerous applications in computer science and theoretical economics, for instance in understanding the relations between public and private knowledge.
When one looks back on the vast body of results produced by modelbuilding in formal epistemology over the past half-century, it seems idle to deny that considerable progress has been made in understanding the epistemic subtleties of many kinds of situation. Nor should one imagine that the progress is primarily mathematical. Although mathematics is usually involved, as in model-building throughout the natural and social sciences, the main interest of the models is not in their abstract mathematical structure but in their epistemic interpretation.
In the natural and social sciences, models are often tested by their predictions of measurable quantities. Models of epistemic logic typically make no such predictions, so how are they to be tested? But even in the natural and social sciences, models are often tested by their qualitative predictions (Weisberg 2013: 136). Models of epistemic logic can be tested that way too. For instance, we can ask whether they allow for ignorance of one’s own ignorance. For some purposes we can legitimately abstract away from such cases. But once we become interested in the limitations of self-knowledge, such cases matter, and our models must permit them. Of course, such qualitative testing presumes that we have some model-independent knowledge of the target phenomenon, but that is equally true of quantitative testing. If we started in total ignorance of the target, we could hardly expect to learn much about it by modelling alone.
Many developments in philosophy of language can also be understood in model-building terms.
Originally, Frege and Russell introduced formal languages into philosophy as languages in which to carry out proofs more rigorously than was possible in natural languages, because the formal languages were more precise and perspicuous. That was not model-building.
Later, Russell and the younger Wittgenstein argued that such formal languages articulate the covert underlying structure of ordinary thought and language. That was still not model-building.
Carnap did something different. He defined the syntax and semantics of simple, artificial examples of languages in meticulously explicit detail (Carnap 1947). He did not intend to work in these languages, nor did he intend them to have the expressive power of natural languages. Rather, he intended them as models of language, to show exactly how his intensional semantics could in principle assign meanings to all the expressions of a language. It did so compositionally, determining the meaning of a complex expression as a function of the meanings of its constituents, in a way that explains how we can understand new sentences we have never previously encountered by understanding the familiar words of which they are composed and the ways in which they are put together.
The key challenge was to explain how modal operators like 'possibly' and 'necessarily' work. They did not fit the available model for sentence operators, truth-functionality. Operators like 'and,' 'or,'
and 'not' are truth-functional in the sense that they are used to form complex sentences out of simpler ones, where the truth-value of the former is determined by the truth-values of the latter. For instance, the conjunction 'A and B' is formed from the simpler sentences A and B; it is true if they are both true, false if one of them is false. But modal operators are not truth-functional. That A is false does not determine the truth-value of 'Possibly A,' which depends on whether A is contingently false or necessarily false.
Carnap solved the problem by taking as the crucial semantic property of a sentence not its extension, its actual truth-value, but its intension, its spectrum of truth-values across all possible worlds (in his terminology, 'state-descriptions'). Although the extension of A does not determine the extension of 'Possibly A,' the intension of A does determine the intension of 'Possibly A.' For if the intension of A has truth at some possible world, then the intension of 'Possibly A' has truth at every possible world, while if the intension of A has truth at no possible world, then the intension of 'Possibly A' also has truth at no possible world.
Carnap’s insight is the root of the immensely fruitful tradition of possible world semantics, which has been central to later developments in both philosophy of language and formal semantics as a branch of linguistics. Although various aspects of his account are no longer widely accepted, it still constitutes major progress. He provided a simple working model of the semantics of a language with modal operators. Much subsequent work in formal semantics has in effect provided increasingly sophisticated model languages whose expressive power comes increasingly close to that of natural languages. For instance, they predict more and more subtle effects of the way tricky words like 'if' work.
Even if one thinks that formal models can never capture all the untidy complexity of natural languages, it is obscurantist to conclude that they provide no insight into the workings of natural languages, just as it would be obscurantist to claim that formal models in natural science provide no insight into the untidy complexity of the natural world. (One might even treat the later Wittgenstein’s carefully described language games as partial models of language, emphasizing links to action and imperative rather than indicative utterances, intended as a corrective to over-emphasis on language’s descriptive function. Presumably, he would have hated their assimilation to a scientific method.) The philosophical significance of those semantic insights extends far beyond philosophy of language. For instance, philosophers in virtually all branches of the subject ask what is possible or necessary. If they use such modal terms in their reasoning with no reflective understanding of how their meanings work, they are liable to commit logical blunders.
The future may well see radical changes in the overall theoretical frameworks within which epistemic, semantic, and other models are built. Nevertheless, it is reasonable to expect that insights embodied in current models will be preserved, refined, and deepened in models constructed within those future frameworks, just as happens in the natural and social sciences.
Perhaps, in the future, research groups in philosophy will advertise positions for modelers.

Methodological Reflections
Not all the advantages of formal methods in philosophy depend on model-building. Sometimes one formalizes the premises and conclusion of a tricky philosophical argument in order to show that the latter follows from the former in a recognized proof system for the formal language. That is progress, but it is not model-building in any distinctive sense.
Model-building is more relevant to showing that a conclusion does not follow from some premises. As already noted, model descriptions facilitate the construction of uncontentious logic-models with the appropriate mathematical structure. When a model description seems informally consistent with the premises but not with the conclusion of a philosophical argument, one can often construct a corresponding logic-model on which the premises are true but the conclusion false, and thereby demonstrate that the conclusion does not logically follow from the premises. As a special case, when a model description seems informally consistent with a philosophical theory, one can often construct a corresponding logic-model on which the theory is true, and thereby demonstrate that it is logically consistent: it does not logically entail a contradiction.
Of course, those logical relations are not all that matters; a logically consistent theory may still be obviously false, and a conclusion that does not follow logically from some premises alone may follow from them plus some obvious truths as auxiliary premises. But the same model-building methodology helps us track those further logical relations too. Thus one advantage of model-building – not the only one – is to make us more efficient and accurate at mapping the logical space in which we are theorizing. Without such a map, we blunder about in a fog, bumping into unexpected obstacles, falling over cliffs. It is not uncommon for elaborate philosophical theories to suffer some form of logical collapse: if not inconsistency, the erasing of vital distinctions. Many such disasters could have been avoided if the theory’s proponents had thought to subject it to preliminary testing by model-building, for instance by trying to build a model yielding a non-trivial logic-model on which the theory came out true.
For the efficient mapping of logical relations, the advantages of simple models are obvious. Simplicity conduces to computational feasibility, so we can in practice derive the model’s mathematical properties by deductive reasoning from its description. This is particularly important for the strategy of learning about the target phenomenon by manipulating the model, adjusting it (by varying the values of parameters or in other ways) to see what difference it makes – for instance, whether a prediction of the model is robust under such perturbations.
One can gain large cognitive rewards, as well as pleasure, from playing even with a toy model, because such variations are so easy to track.
Simple models have other, less obvious advantages. One is the avoidance of arbitrary features. The more adjustable parts a model has, the more opportunities it offers the model-builder to rig the results, to gerrymander the model by setting parameters and arranging structure in ad hoc ways to fit preconceived prejudices. Simplicity, elegance, symmetry, naturalness, and similar virtues are indications that the results have not been so rigged. Such virtues may thus ease us into making unexpected discoveries and alert us to our errors.
Simplicity is often connected with idealization. An idealized surface is frictionless; an idealized planet is a mass at a point. Those idealizations simplify the mathematics. But idealization is also a means of abstracting from 'noise,' complicating factors that interfere with, and obscure, the phenomenon we are trying to understand.
Here is an instance from formal epistemology. Standard epistemic logic treats agents as logically omniscient: the structure of its models presupposes that if one knows some things, one also knows anything else they entail. Standard probability theory makes a similar though slightly weaker assumption: if one thing entails another, the latter is at least as probable as the former. Such models ignore the computational limits of actual agents. Even if two mathematical formulas are logically equivalent, we may accept one but not the other because we are unaware of their equivalence; mathematics is difficult. However, idealizing away such computational limits is not just a convenient over-simplification. One may be interested in the epistemological effects of our perceptual limits: our eyesight is imperfect, our powers of visual discrimination are limited. Since ignorance may result from either perceptual or computational limits, we must separate the two effects. A good way to do so is by studying models where the agent resembles a short-sighted perfect logician, with perceptual limits but no computational ones, whose ignorance therefore derives only from the former. For that purpose, the structure of standard models of epistemic logic is just right (Williamson 2014b). More generally, modelbuilding allows us to isolate one factor from others that in practice always accompany it.
Although model-building already plays a significant role in philosophy, philosophers have not fully adjusted to its methodological implications. For instance, counterexamples play a much smaller role in a model-building enterprise than they do in traditional philosophy.
The traditional philosopher’s instinct is to provide counterexamples to refute the simplifications and idealizations built into a model, which rather misses the point of the exercise. A theoretical economist once remarked to me that a paper like Gettier’s classic refutation of the analysis of knowledge as justified true belief by means of a couple of counterexamples (1963) would be considered unpublishable in economics. For economics is primarily a model-building discipline: since no model is expected to fit the actual phenomena perfectly, pointing out that one fails to do so is not considered newsworthy. What defeats a model is not a counterexample but a better model, one that retains its predecessor’s successes while adding some more of its own.
For reasons explained earlier, that does not mean that model-building disciplines are unconcerned with truth. They too pursue truth, but by more indirect strategies. Of course, it is unfair to suggest that Gettier missed the point of model-building, for the analyses of knowledge he was refuting were not intended as models; they were meant as statements of exceptionless necessary and sufficient conditions for knowledge, to which counterexamples were indeed apt. However, if epistemologists and other philosophers start aiming to build good models rather than provide exceptionless analyses, different forms of criticism become appropriate. Models can also play a role in the criticism of would-be universal generalizations. If we are willing to dismiss theories on the basis of one-off negative verdicts in a single type of thought experiment, as with Gettier cases, we risk sometimes dismissing true theories because a glitch in the human cognitive system causes us to deliver mistaken verdicts in those thought experiments (Alexander and Weinberg
2014). A robust methodology should have ways of correcting such errors, even granted that thought experimentation is in general a legitimate method. After all, sense perception is a legitimate method for gaining knowledge, but we still need ways of catching and correcting perceptual errors. Elsewhere, I have argued that theoretical considerations about models of epistemic logic lead one to predict failures of the justified true belief analysis of knowledge, independently of thought experiments (Williamson 2013c, 2015a). When the methods of thought experimentation and model-building converge on the same conclusion, it has more robust support than when it relies on either method alone.
Another respect in which rigorous-minded philosophers may find the method of model-building alien is that selecting and interpreting models is an art – in science as well as in philosophy. It depends on good judgment, honed by experience. One must distinguish simplifications that abstract away inessential complications from those that abstract away crucial features of the phenomenon, and genuine insights from mere artefacts introduced for mathematical convenience. This raises the general issue of realism versus instrumentalism, familiar from the philosophy of science. Which aspects of a model tell us something about reality itself, and which are there only as instruments of the model-building process? We should not expect to settle all such issues in advance. Sometimes the successes of a model may indicate that what originally looked like a mere artefact should instead be regarded as a genuine insight. Although we can expect good model-builders to be reasonably articulate in explaining why they have selected one model rather than another and drawn one conclusion from it rather than another, there is no foreseeable prospect of reducing their skills and expertise to mechanical rules.
Some philosophers may continue to find the methodology of model-building mysterious, and resist. How can we learn from models that embody assumptions we know to be false? How exactly are we supposed to decide which false assumptions are legitimate? The short answer is: in the same way as the natural and social sciences. A full answer will be hard to articulate. Nevertheless, accumulating experience of model-building in philosophy provides good evidence that it does work.

Conclusion
Model-building already plays a significant role in contemporary philosophy. One neglected form of progress in philosophy over the past fifty years has been the development of better and better formal models of significant phenomena. It shares that form of progress with the natural and social sciences. Philosophy can do still better in the future by applying model-building methods more systematically and self-consciously. Although it is neither likely nor desirable for modelbuilding to become the sole or even main philosophical method, its use enhances the power and reliability of philosophical thinking.

Note
This section originally appeared as Williamson 2017a in Russell Blackford and Damien Broderick (eds.), Philosophy’s Future: The Problem of Philosophical Progress (Wiley). Earlier versions of the material were presented at the universities of Athens, Cologne, Michigan (Ann
Arbor), Olomouc, Oxford, Peking University, Seoul National University, and the Inter University Centre in Dubrovnik; thanks to all the audiences and to Alexander Bird for helpful questions and comments. 9.4 Morally Loaded Cases in Philosophy
1. The question
Dialectical effectiveness in philosophy can pattern in surprising ways.
For instance, when apparently morally neutral issues are debated in epistemology and metaphysics, philosophical logic and philosophy of language, morally loaded examples sometimes have greater dialectical power than morally neutral examples based on knowledge from ordinary life or natural science. One might have expected it to be the other way round, given the contested status of moral knowledge. By
'morally loaded' I mean cases explicitly described in moral terms, or at least in ways which make moral matters very salient, as with
Holocaust denial. Such cases seem to be so dialectically powerful because they are so highly emotive. That raises an obvious question: is this dialectical power legitimate, or does it involve a kind of cheating, getting readers or hearers worked up to a point where they are in no mood to apply subtle but necessary distinctions? We are usually supposed to be best at assessing philosophical claims in a cool hour.
2. Three classes of example
Before addressing the main question, we should look more closely at the phenomenon to be understood. I will sketch three classes of philosophical view which seem vulnerable to such moralizing critiques.
The list is far from exhaustive.

Relativism
I have in mind full-blown relativism about truth, the idea that when you and I seem deadlocked in disagreement, the bottom line is that some things are true for me but not for you, while other things are true for you but not for me; there is no question of one of us being really or absolutely right and the other really or absolutely wrong. Such a view is hard to articulate in a coherent or even fully intelligible way, for reasons going back to Plato. Nevertheless, in more or less radical forms, it has a massive cultural presence in many contemporary societies, including our own, outside as well as inside academia. For confused reasons, many people treat relativism as the required intellectual basis for tolerance of diversity (fortunately, there are better non-relativist reasons for tolerance). Although few analytic philosophers take it seriously, most have encountered it in their students. Elsewhere in the humanities, it is widely taken as the default metatheory, however unsuited such an elusive doctrine is to informing day-to-day practice.
It survives rigorous criticism by Protean shapeshifting.
Extreme relativists are often unperturbed by the usual counterexamples from common sense or natural science. 'Anyone who thinks the Earth is flat is simply wrong.' 'That’s just your point of view.'
They are more likely to start ducking and weaving when faced with morally loaded cases. In response to 'Anyone who thinks the Holocaust never happened is simply wrong,' a plain 'That’s just your point of view' seems to cast the relativist in the uncomfortable role of defending Holocaust deniers. Expect some convoluted special pleading. The difference in response does not come from a difference in the strength of evidence. Decisive though the evidence for the Holocaust is, it is not more decisive than the evidence for the roundness of the
Earth. Rather, the difference comes from the moral wrong-footing of the relativist in one case and not the other. Few relativists rushed to the defense of US Counselor to the President Kellyanne Conway when she was widely derided for using the phrase 'alternative facts'
in explaining White House Press Secretary Sean Spicer’s false statements about attendance numbers at Donald Trump’s inauguration as
President.
In the heyday of post-modern Theory, its protagonists flirted with relativism, though they may have had a commitment problem. Within that intellectual environment, the pushback to relativism came not so much from defenders of common sense or natural science as from
Marxists, concerned that relativism would undermine the imperatives of political action. That concern was not morally neutral: they feared that the political effect of relativism would be to reduce the pressure to do what (they thought) ought to be done.
Although Richard Rorty disliked being described as a relativist, he was at the very least an anti-absolutist. But he was much more comfortable disparaging the absoluteness of truth than the absoluteness of justice, no doubt with an eye to the moral and political repercussions. Relatedly, in discussing Orwell’s 1984, Rorty allows him the distinction between cruelty and kindness, but dismisses his appeals to the distinctions between truth and falsity and between appearance and reality as contributing nothing of substance to his critique of totalitarianism (1989: 173). Of course, Rorty was right that making the latter distinctions is not sufficient for adequately reasoned resistance to tyranny, but Orwell makes a strong case that it is necessary. Indeed, how effectively can we oppose cruelty, if we cannot distinguish its real absence from its apparent absence?

Skepticism
The skeptic rejects claims to knowledge, and even to epistemically justified belief, either globally or over some large domain, such as morality, about which we usually take ourselves to have significant knowledge.
What could be more academic in the pejorative sense than the problem of skepticism? What theory could be further from practical consequences? It does not interfere with a game of backgammon, even if neither player knows that the other exists. The skeptic feels comfortably at home disavowing knowledge that he has hands, that he is not dreaming, that he is not a brain in a vat. He takes the moral high ground, as the open-minded inquirer, quite willing to believe if only someone would show him a good reason to do so. But when skeptical arguments are deployed against scientific studies of climate change, the philosophical skeptic becomes uneasy. Again, the difference is not evidential. Those studies are no more resistant to radical skeptical scenarios than is anything else. It is just that philosophical skeptics do not want to find themselves fighting on the same side as climate change skeptics when there is a danger of their arguments being taken seriously and applied to a specific case, perhaps with the effect that policy is no longer made on the basis of (supposed) scientific knowledge. For when philosophical skeptics are off-duty, their political and scientific beliefs are very little different from those of their non-skeptical fellow-academics.
The slogan 'Doubt is our product' goes back to public relations consultants on behalf of the tobacco industry (https://www.
industrydocuments.ucsf.edu/tobacco/docs/#id=psdw0147). The strategy is not to try to prove that smoking has no harmful effects on health, but merely to create enough doubt in people’s minds about the scientific evidence to make them feel licensed to ignore it and follow their inclination to smoke. That strategy is closely related to the 'post-truth' atmosphere of current politics, which makes skepticism look a rather less benign intellectual force. Create enough confusion and doubt, and people will fall back on believing what they would anyway like to believe.
Skeptical arguments in political and commercial advertising are not somehow of a fundamentally different kind from philosophical arguments for skepticism. They make standard skeptical moves, appealing to skeptical scenarios and shifting the burden of proof to their anti-skeptical opponents, but in concrete, localized applications, which obscure the very general form of the underlying arguments.
When the United Kingdom participated in the 2003 invasion of
Iraq, Tony Blair, then Prime Minister, justified the action by appeal to the existence of weapons of mass destruction (WMD) in Iraq. After it became clear that there had been no WMD there at the time, Blair said in a 2004 speech to his party conference: 'I’m like any other human being – fallible. Instinct is not science. I only know what I believe'
(https://www.theguardian.com/uk/2004/sep/28/labourconference.
labour1). In the last sentence, was he just making the point that knowledge entails belief, so if in 2003 he lacked the belief that there were no WMD in Iraq he also lacked the knowledge? That entailment has nothing to do with fallibility. The context suggests another interpretation: all he could really know at the time was that he believed that there were WMD in Iraq. He could know his own current mental states, but not the states of affairs on the ground in Iraq to which they were supposed to correspond. Perhaps skepticism about the external world is not the best basis for deciding foreign policy. Of course, Blair was not really a philosophical skeptic, but as a practical politician he was able and willing to take opportunistic advantage of the cultural credibility of implicitly skeptical moves.
In brief, local skeptical moves made for bad political or commercial reasons look much more sinister than globalized versions of the same skeptical moves made for bad epistemological reasons.

Internalism
Here is a still-influential view in epistemology; for short, we may call it 'internalism': The key normative status for belief is justification. Whether a belief is justified at a time depends on its coherence with the internal consciously introspectible mental states of the subject at that time, especially seemings, and perhaps other beliefs too. Seemings are pre-doxastic; they are neither beliefs nor inclinations to believe.
You have a seeming when things seem to you a certain way, either sensorily or intellectually. Seemings can be false: sometimes things seem to you to be some way even though they are not in fact that way.
Still, when it seems to you that P, you are at least prima facie justified in believing that P. You are all-things-considered justified in believing that P when so believing also coheres with your other relevant mental states, especially your seemings. Consequently, false beliefs are sometimes justified. For example, a standard brain in a vat has a justified belief that it has hands, because that belief coheres with how things seem to the brain. The internalist regards that consequence of the view as a benefit, not a cost.
A similar consequence of internalism is that an unconscious bias can result in a bigoted false seeming and so, provided that coherence is maintained, in a bigoted but justified false belief (compare
Siegel 2017). We may as well use the familiar figure of the consistent
Nazi. I call him (or her) a neo-Nazi to emphasize that such people are alive and active, politically and criminally, in contemporary society.
Of course, in practice neo-Nazis no doubt tend to be inconsistent, but the same goes for other people too. The paradox of the preface, sorites paradoxes, and Liar-like paradoxes all show that it is very hard for anyone to maintain consistency amongst their beliefs. Nevertheless, in principle, someone can have a mass of the most obnoxious neo-Nazi beliefs while still maintaining consistency, and indeed coherence: their beliefs are mutually supporting. In effect, difficulties about consistency are only a delaying tactic. The internalist must eventually face the question: what to say about the consistent neo-Nazi?
Suppose that it seems to the consistent neo-Nazi that he ought to kill such people, with reference to some totally innocent members of one of the many groups neo-Nazis target, just because they belong to that group. Moreover, that intellectual seeming perfectly coheres with all his other seemings and beliefs, thanks to the harmonizing effects of his unconscious biases. As a result, he goes ahead and forms the belief that he ought to kill such people. By internalist standards, the neo-Nazi is justified in believing that he ought to kill such people. Of course, the internalist will emphasize, it does not follow that the neo-Nazi in fact ought to kill such people, for justified beliefs may be false. The point is 'merely' that, by internalist standards, the neoNazi’s belief is justified, and so possesses the key normative status for belief. For the internalist, the neo-Nazi is a moral brain in a vat. But is that really an appropriate way to view a consistent neo-Nazi? There is something dodgy about the way in which internalism of the sort described makes unconscious biases self-laundering, manufacturing the very seemings that justify the corresponding belief.
In a fascinating recent paper, 'Radical Externalism,' Amia Srinivasan has used related cases to argue against internalist accounts of justification (Srinivasan 2020). The titles of her three main examples convey their flavor: 'Racist Dinner Table,' 'Classist College,' and
'Domestic Violence.' The idea is that if internalists appeal to pretheoretic verdicts on skeptical scenarios in support of their view, they are in trouble when pre-theoretic verdicts on Srinivasan’s cases go against them. Readers can judge her cases for themselves, but for better or worse they certainly seem to derive some of their dialectical force from their moral loading.
No two of relativism, skepticism, and internalism are mutually equivalent. Nevertheless, there are structural similarities between them. They share a tendency to assign the same cognitive status in some important respect to both parties in a deadlocked dispute. For the relativist, there is no absolute truth of the matter, but each side’s view is justified and true by its own lights. For the skeptic, there may be an absolute truth of the matter, but neither side knows what it is, or even has a justified belief in it. For the internalist, there is an absolute truth of the matter, but both sides may be justified in their internally consistent, mutually inconsistent beliefs as to what it is.

3. Emotive cases
Is the use of morally loaded examples against relativism, skepticism, and internalism cheap, or even cheating? In a morally heated exchange, one may well be reluctant to concede anything at all against the good guys, or in favor of the bad guys. When the red mist of righteous indignation descends on us, we lose sight of nuances. Perhaps the loaded cases gain their boost in effectiveness by illicitly bringing down moral and political opprobrium on one’s opponents. They have to shift their ground to avoid guilt by association.
Autobiographical confession: I was brought up in a family that had a plentiful supply of moral outrage, usually directed not at family members but at various politicians, policies, and political arrangements. Probably, most philosophers, both now and then, would find the outrage appropriately or at least defensibly directed. However, it has left me with a lifelong suspicion of moral outrage, as likely to direct all the critical scrutiny in one direction, and to obscure the messy, paradoxical complexity of real political problems. For that reason, I
give considerable weight to concerns about the philosophical use of morally loaded examples.
Nevertheless, something else may be going on. One hypothesis is that it is moral encroachment, roughly, the hypothesis that high moral stakes raise the standard for what it takes to know, or to have a justified belief (Moss 2018). However, that does not fit the role of morally loaded cases as counters to skepticism. For the point of mentioning climate change skepticism and attempts to create a cloud of doubt around the health hazards of smoking is to warn against raising epistemic standards too high. Indeed, raising the moral stakes can have the effect of lowering epistemic standards, at least those perceived as appropriate: 'This is so morally urgent, we don’t have time to examine the evidence carefully.' By contrast, the role of morally loaded cases as counters to internalism can be to put pressure in the opposite direction: the point of mentioning the consistent neo-Nazi is to warn against setting epistemic standards so low that his terrible beliefs count as justified. Even if moral encroachment occurs, it does not provide a uniform explanation of the dialectical effectiveness of morally loaded cases. A different approach is needed.
In all three classes of example – concerning relativism, skepticism, and internalism – the morally loaded cases make salient the potential connections between an abstract philosophical issue and serious practical and political problems: how to deal with those who deny the Holocaust, man-made climate change, the health hazards of smoking, and so on. Such connections pose a threat to one popular strategy for defending what on first hearing may sound like wildly radical philosophical ideas. We may call it the strategy of intellectual isolationism. It involves cutting those ideas off from their appar- ent practical consequences. The reassuring message is: don’t worry, if these philosophically radical ideas are accepted, for all practical purposes life will go on just as before (though with a better intellectual conscience, or in a more ironic spirit). Science funding will not be cut; educational policy will not be changed; you should treat other people just as you always did. This quietism may be connected to the 'playful' or 'ludic' aspect of some postmodern discourse: play Theory as freely as you like, because there will be no serious consequences.
The morally loaded cases call into question the supposed practical neutrality of such radical philosophical ideas. They indicate that glorious intellectual isolation has not been fully achieved. Those ideas may have practical consequences after all. The playful attitude starts to look irresponsible.
Of course, the isolationist can try to execute the strategy more completely, cutting any remaining links between theory and practice.
The next section considers that approach in more detail, with special reference to internalism in epistemology.

4. Case study: internalism and isolationism
We are considering the epistemological internalist who asserts (1), but of course denies (2) – we may assume that the internalist is not himself (or herself) a neo-Nazi:
(1) The consistent neo-Nazi is justified in believing that he ought to kill such people.
(2) The consistent neo-Nazi ought to kill such people.
The reader can substitute 'Jews,' 'Muslims,' 'homosexuals,' 'Romani,' or 'disabled children' for 'such people.'
To fill out the case: The envisaged neo-Nazi does believe that he ought to kill such people, and he bases his belief on the coherence of its content with his other beliefs and seemings in the prescribed internalist way. The internalist will therefore say, in the jargon of epistemology, that (1) is true on the doxastic as well as the propositional sense of 'justified' (the latter does not even require the subject to have the belief). For definiteness, 'justified' in (1) will be understood in the doxastic sense. One natural-looking way to implement the isolationist strategy is by making a clean break between the justification of belief and the justification of action. In particular, this internalist will deny (3) as well as (2):
(3) The consistent neo-Nazi is justified in killing such people.
For commensurability with (1), we may suppose that the neo-Nazi does kill such people, and that his action is based on his belief that he ought to kill them, and coheres with all his other beliefs and seemings.
Accordingly, 'justified' in (3) will be understood as applied to that token of the action type, killing such people, rather than to the action type in general.
How comfortable is the internalist’s position? Of course, one would expect any decent person to deny (2). The issue is the tenability of the combination: asserting (1) while denying (3). For if (1) holds while (3) fails, someone can be justified in believing that they ought to do something, yet at the same time not justified in doing it.
Another standard distinction in epistemology between different senses of 'justified' gives initial hope to this way of implementing the isolationist strategy. For epistemologists typically explain that when they apply the term 'justified' to beliefs, they mean epistemically justified, rather than pragmatically justified. Pascal’s Wager provides a standard example of the distinction. It is intended to give a pragmatic justification for believing that God exists, by showing that having the belief maximizes expected utility. It is not intended to give an epistemic justification for believing that God exists; it involves no attempt to provide proof or evidence of any kind that God exists. Similarly, if someone is about to undergo a medical intervention, which has a
20% chance of success for those who lack the belief that it will succeed, but a 40% chance of success for those who have the belief that it will succeed, she has a pragmatic justification for believing that it will succeed, but not an epistemic justification for so believing – even for those who have the belief, the intervention is more likely to fail than to succeed. Thus the internalist can say: 'justified' in (1) means epistemically justified, whereas 'justified' in (3) does not mean epistemically justified, instead it means morally justified, or pragmatically justified, or all things considered justified, or something else actionoriented like that; thus it is not at all surprising for (1) to be true while
(3) is false. However, merely distinguishing senses of 'justification' is not enough to make the isolationist strategy work. For the distinction does not guarantee that norms of belief and norms of action are quite independent of each other. After all, the nature of a belief is that the believer is disposed to act on it. That is what makes the difference between believing a proposition and just warmly entertaining it. Given that connection with action in the nature of belief, we can expect it to be reflected in norms for belief. According to epistemological internalists, justification is the key normative status for belief; by
'justification' there they normally mean epistemic justification. For epistemic justification to merit being the key normative status for belief, it should somehow reflect the nature of belief as that on which the agent acts.
Such a connection between belief and action is manifest in standard decision theory. One’s epistemic state is taken to be encoded in one’s probabilities. Those probabilities, combined with one’s utilities or preferences, are then used to calculate the expected utilities of actions. When pragmatic justifications are in play, those actions include getting oneself (perhaps by indirect means) to form a belief, such as the belief that God exists, or the belief that the medical intervention will succeed. Such calculations of the expected utilities of various potential actions are in turn used to determine which of those actions are rational – and which beliefs one is pragmatically justified in getting oneself to form. Thus one’s epistemic state plays a key role in determining pragmatic justification. For epistemological internalists, epistemic justification is in turn a central determinant of one’s epistemic state. Thus epistemic justification is in turn a major determinant of pragmatic justification.
States of knowledge or belief play a fundamental role in other forms of decision theory too. Presumably, a central norm for belief should reflect which states are well fitted to have the connection to action that a good decision theory assigns to belief states.
Indeed, epistemic and pragmatic justification can be expected normally to go together. For, normally, if it is the case that P, then it is useful to believe that P, while if it is not the case that P, then it is not useful to believe that P. Moreover, we normally seem to be epistemically justified in believing such conditionals. Thus there is some presumption that if one is epistemically justified in believing that P, then one is epistemically justified in believing that it is useful to believe that P. Conversely, there is a similar presumption that if one is epistemically justified in believing that it is useful to believe that P, then one is epistemically justified in believing that P. Moreover, being epistemically justified in believing that it is useful to believe that P
seems quite close to being pragmatically justified in believing that P.
Such considerations suggest a strong correlation between epistemic and pragmatic justification. The correlation is not perfect, as the previous examples showed, but they depend on quite unusual conditions.
Although the presumptions of the argument are defeasible, and some other aspects of it are not watertight, they suggest that the default is for epistemic and pragmatic justification to go together. Those considerations in favor of the default are available to the internalist.
To get more specific, such connections between belief and action are also discernible in an internalist treatment of the favored case of a brain in a vat. Why is the brain not justified in taking steps to drop its belief in the false proposition that it has hands? By internalist standards, the brain is epistemically justified in believing that it has hands. Similarly, it is epistemically justified in believing that its belief that it has hands is both true and useful, and in believing that it would be worse off without its belief that it has hands. For reasons like that, the brain is not justified in taking steps to drop its belief that it has hands.
Consider a more straightforward case of action. The brain seems to itself to see a baby drowning in a shallow pond. That all coheres with the brain’s other seemings and beliefs. On that basis, it believes that it sees a baby drowning in a shallow pond. That belief is epistemically justified, by internalist standards. Presumably, the internalist also thinks that the brain is justified in trying to rescue the baby (the actual effects of its action will depend on how the mad scientist has wired up the vat). In explaining why that action is justified, the internalist will appeal to the brain’s epistemically justified beliefs. Such an appeal will not be avoided by citing the brain’s pragmatically justified beliefs, because such pragmatic justifications eventually trace back to epistemic justifications.
The envisaged internalist cannot reject the distinction between epistemic and pragmatic justification, because it is being used as the main obstacle to moving from (1) to (3). The trouble is that the
internalist seems quite happy to move from (1*) to (3*), even though
'justified' means epistemically justified in (1*) and not in (3*): (1*) The brain is justified in believing that it ought to try to rescue the baby.
(3*) The brain is justified in trying to rescue the baby.
But the moves from (1) to (3) and from (1*) to (3*) instantiate the same relevant pattern: from 'S is justified in believing that he/she/it ought to φ' to 'S is justified in φing.' Moreover, from an internalist perspective, nothing seems to disrupt the analogy between the consistent neo-Nazi and the consistent brain in a vat. The internalist was trying to make a clean break between the justification of belief and the justification of action, and so between (1) and (3). But presumably the internalist does not want to make the analogous clean break between (1*) and (3*). Even from the internalist perspective, the attempt to have (1) without (3) is not looking very unpromising.
Someone might argue that the word 'ought' is not strong enough in meaning to force the move from 'S is justified in believing that he/
she/it ought to φ' to 'S is justified in φing.' After all, it is sometimes reasonable to say things like 'I ought to go to the lecture, but I’m just too busy.' However, that point will not help the internalist. For the example can simply be set up from the beginning with a stronger deontic operator in place of 'ought.' For instance, the consistent neoNazi may believe that he has an indefeasible duty of the most imperative kind to kill such people. Such a belief may fully cohere with his other beliefs and seemings, and so be epistemically justified by internalist standards. Then the relevant move is from 'S is justified in believing that he/she/it has an indefeasible duty of the most imperative kind to φ' to 'S is justified in φing.' Perhaps the dial can be turned even higher on the content of the belief. Even if no strength of the operator can make the move purely logical, it is still hard to resist.
For convenience, I will continue to use 'ought,' but the reader should bear in mind that it can be strengthened if required.
Suppose that the internalist gives up on the attempt to drive a wedge between the justification of belief and the justification of action, between (1) or (1*) and (3) or (3*) respectively. What if the internalist simply allows the move from 'S is justified in believing that he/she/it ought to φ' to 'S is justified in φing,' at least in the cases at issue, and accepts (3), as well as (3*)? That would smooth the internalist’s analogy between the consistent neo-Nazi and the consistent brain in a vat. It also looks more faithful to the internalist’s underlying motivation. For the internalist picture is that justification depends solely on factors directly accessible to consciousness, the first-person present-tense perspective; hence the focus on seemings and internal coherence. That picture seems equally applicable to the justification of belief and the justification of action. To apply it to one while refusing to apply it to the other looks unmotivated.
But is it not simply outrageous for internalists to claim that the consistent neo-Nazi is justified in killing such people? Of course, they can still deny that the neo-Nazi ought to kill such people. They can even insist that he ought not to kill them. Thus the idea is that the neo-Nazi is justified in doing things which he is in no way permitted to do. The difficulty for internalists is to maintain this line without either compromising their condemnation of the neo-Nazi or marginalizing the role of justification. They can try to downplay what they have conceded in saying that the neo-Nazi is justified in killing such people by emphasizing that justification is just a matter of consistency with the agent’s perspective. But what is supposed to be so good about consistency with something bad? Unless consistency with the agent’s perspective is supposed to bring something else good with it, such consistency does not seem to be what matters most. Despite internalist claims to the contrary, it does not look like the key normative status for either belief or action. Then justification as consistency with the agent’s perspective is marginalized. But if consistency with the agent’s perspective is supposed to bring something else good with it, then in evaluating the neo-Nazi’s beliefs and actions as justified, because consistent with his perspective, internalists are implying that there is something else good about the neo-Nazi’s beliefs and actions, which is where they risk compromising their condemnation of those beliefs and actions.
For example, if internalists take consistency with the agent’s perspective to bring blamelessness with it, then in evaluating the neoNazi’s beliefs and actions as justified, because consistent with his perspective, they are implying that his beliefs and actions are blameless. But the neo-Nazi should be blamed for killing those innocent people, which suggests that his belief that he ought to kill them is also blameworthy. That the brain in a vat’s beliefs and actions are blameworthy is much less obvious, which may suggest some underlying asymmetry between the two cases. No doubt there is much more to be said, both for and against internalist epistemology (for some of it see Boghossian and Williamson 2020). But the challenge to produce a morally decent account of the consistent neo-Nazi has turned out to be genuinely difficult for internalists; it is not just bluff by moral grandstanding. That it turns on the stock figure of the consistent (neo-)Nazi only makes it worse for internalists, by emphasizing how long they have had to work on their defense.1
The case of the neo-Nazi brings out general problems for the isolationist strategy. Given the close connection between belief and action, and so between norms for action and norms for belief, it is rather unlikely that a philosophical theory will have radical implications for belief but no repercussions for action. In particular, when a dispute is assessed as involving some epistemic symmetry between the two views –
which is what relativism, skepticism, and internalism in their different ways all involve – there is always the danger that a corresponding symmetry will be implied between actions based on the opposing views.

5. Conclusion
Morally loaded cases serve a legitimate and distinctive function in areas of philosophy that are not distinctively moral, such as general epistemology. They highlight potential consequences of theories in such areas for action. Where those practical consequences are objectionable, so are the theories that entail them.
It has been suggested that non-internalist accounts of justification face similar problems in dealing with the consistent neo-Nazi. For even on views of evidence which award facts about appearances no special privilege in an agent’s total evidence, the fact that it seems to the neo-Nazi that he ought to kill such people may still be thought to give him some evidence that he ought to kill them. But even if that point is granted, the evidential probability that he ought to kill them may still be negligible, given that evidential probability is not subjective probability (Williamson 2000a). In any case, there is a stark asymmetry between internalist views on which justification, understood as internal coherence, is the central norm of belief and hardline externalist views which endorse a knowledge norm for belief (Williamson 2017c), and in particular for belief qua premise in practical reasoning (Hawthorne and Stanley 2008). On that externalist view, since it is false that the neo-Nazi ought to kill such people, he does not know that he ought to kill them, so he is in no position to use the proposition that he ought to kill them as a premise in his practical reasoning.

1 Acknowledgments
This section originally appeared as an article in Proceedings and
Addresses of the American Philosophical Association (Williamson
2019a), based on the 2019 Sanders Lecture, delivered at the 2019
Central Division meeting of the American Philosophical Association in Denver. Earlier versions of the material were presented at these universities: Belgrade, Canterbury (Christchurch), Düsseldorf, Edinburgh, Oxford, and Yale. I thank audiences at all these events for their questions, and Paul Boghossian, Georgi Gardiner, Rae Langton,
Sarah Moss, Jennifer Nagel, Jason Stanley, and Amia Srinivasan for discussion of relevant issues, all of which has been very helpful. The section inherits an intentionally broad-brush, big-picture quality from the lecture. 9.5 Reply to Dennett and Kuznetsov on Abductive
Philosophy
In 'Armchair Philosophy' (Williamson 2019c), I characterized a broadly abductive methodology for philosophy. To emphasize that this need not give philosophy the character of a natural science, I
cited the example of foundational inquiry within mathematics. Anton
Kuznetsov (2019) objects: 'Mathematics and philosophy are significantly different – the ontology of formal systems is known without a trace: we know all the basic laws of these systems.' But that is not true of foundational mathematics. As Kurt Gödel and Paul Cohen proved, neither Cantor’s Continuum Hypothesis (CH) nor its negation is derivable from standard set theory (given the consistency of the theory). If CH is true, it is a basic law of set theory. If CH is false, its negation is a basic law of set theory. Either way, there is a basic law of which we are ignorant. Of course, on some views there are many set-theoretic universes, with CH holding in some and failing in others. Then the more basic framework is that in which we investigate the space of all set-theoretic universes. But then we do not know all the basic laws of that more general framework, for reasons connected with Gödel’s incompleteness theorems. Although there are many obvious differences between mathematics and philosophy, whether our knowledge has limits is not one of them.
Daniel Dennett (2019)’s main concern with philosophers’ use of an abductive methodology is that if they take intuitions as the input, the abductively derived outputs will be no more reliable than the inputs – unless the outputs are recycled as a theory about the content of the implicit folk theory which generated the intuitions, not as a theory about whatever the intuitions themselves are about. The radical unclarity of 'intuition' discussed in Section 10.5 clouds that concern too. Dennett mentions David Lewis in connection with an
'intuition'-based abductive methodology, but Lewis spoke of 'intuitions' just as our opinions, in describing something like the method of reflective equilibrium in philosophy, with no intention to exclude natural scientific opinions.
Dennett seems a little unfair to advocates of an 'intuition'-based abductive methodology when he describes them as 'taking their intuition-pumped consensus as a sure path to the ‘real nature’ of whatever they were talking about.' His words 'a sure path' suggest that they expect something like certainty from their methodology. But many of them would settle for a much weaker epistemic status, such as high rational credence. Dennett also flirts with a reading of a passage I
quote from Austin as 'a complacent assurance that the time-honored, well-honed home truths of the manifest image are the last word on anything,' but in that discussion Austin explicitly proposes that ordinary language should just be the first word on some things; he offers no candidate for the last word.
In my view, the conception of philosophical methodology as directed towards reflective equilibrium suffers from the usual defects of internalist and coherentist epistemology. It ignores crucial questions about where our evidence comes from. To discuss the methodology of natural science as directed towards reflective equilibrium without mentioning our interactions with the external world through observation and experiment would, rather blatantly, be to miss half the picture. Although the omission is less obvious when philosophical methodology is described in terms of reflective equilibrium, it is still there. Our knowledge of the world includes many findings of natural science; it also includes much else besides. In principle, our evidence base for abduction in philosophy comprises all of that knowledge.
In practice, parts coming from natural science are highly relevant to some philosophical questions; to ignore them would be foolish. But, again in practice, not all philosophical questions are like that. For example, the findings of natural science often have no distinctive relevance to abductive arguments for first principles of logic or mathematics, though there is no ban in principle on appeal to them even there. Sometimes, common sense knowledge is enough; sometimes, high-powered mathematical knowledge is needed. When things go well, we acquire knowledge (not just high rational credence) in the form of the abductive conclusions. It does not follow that the conclusions are the last word on anything. That something is known does not imply that no one is allowed to question it.

Acknowledgment
This section first appeared as part of Williamson 2019d, which was in turn part of a symposium on Williamson 2019c, a short summary of my philosophy of philosophy, in Epistemology and Philosophy of
Science (Moscow). I thank Daniel Dennett and Anton Kuznetsov for their interesting contributions. 9.6 Reply to Kuznetsov and Stoljar on ModelBuilding in Philosophy
In 'Armchair Philosophy' (Williamson 2019c), I proposed that philosophy, like much of natural science, often makes progress by constructing better models of matters of interest, rather than by discovering new universal laws of those matters. Of course, models in philosophy are usually not geared to making testable quantitative predictions, but the same applies to some models in natural science.
For example, a model of evolution with three-sex rather than twosex reproduction need not aim at making quantitative predictions: instead, its purpose may be to help explain why three-sex reproduction tends not to occur. Similarly, the purpose of models in philosophy tends to be explanation, not prediction. Anton Kuznetsov (2019)
seems to have an overly predictive conception of models when he writes 'Model building in science relies on empirical results and is mediated by them.'
Daniel Stoljar (2019) agrees that the conception of progress as the discovery of new universal laws is far too narrow for both philosophy and natural science, but he argues that it is for a more general reason as well: 'progress in both science and philosophy consists in the provision of better information about dependency structures.'
Such structures may involve relations of either causal or constitutive dependence.
I was certainly not suggesting that discovering new universal laws and constructing better models are the only forms that progress in either philosophy or natural science can take. Nor have I anything against progress in either case by providing better information about dependency structures. However, I do not see what is so special about dependency structures. Progress in philosophy or natural science might be made by providing better information about almost any general kind of relational structure, whether they involve dependency relations or relations of some other sort.
Dependency relations typically involve an ordering, irreflexive (x does not depend on itself), asymmetric (if x depends on y, then y does not depend on x), and transitive (if x depends on y, and y depends on z, then x depends on z). But many relations of philosophical and natural scientific interest are not dependency relations. Logical relations, such as entailment, are an example. That p entails q tells us nothing about whether p depends on q, or q depends on p, or neither. For a start, the entailment may be mutual. Of course, we can rig up an irreflexive, asymmetric, and transitive relation of one-way entailment, where p one-way entails q just in case p entails q but q does not entail p. But it still implies nothing about dependency. For example, 'This is red and square' one-way entails 'This is red,' where the temptation is to say that the entailer depends on the entailed, but 'This is red'
one-way entails 'This is red or square,' where the temptation is to say that the entailed depends on the entailer. Nevertheless, better information about entailment is often highly explanatory, in both philosophy and natural science. Something similar goes for mereological relations: to say that x is a proper part of y is not yet to say whether x depends on y, or y depends on x, or neither. Yet better information about parthood can be explanatory. In philosophy, better information about the existence, identity, and distinctness of things can also be explanatorily crucial, yet it is not naturally understood as information about a dependency structure.
The significance of progress by building better models is not that it is the only alternative to progress by discovering new laws, but that it is a different, widespread, and theoretically very powerful form of progress, distinctive of advanced natural science and, as it turns out, advanced philosophy too. How much progress in advanced natural science really consists of finding out more about dependency structures?

Acknowledgment
This section first appeared as part of Williamson 2019d, which was in turn part of a symposium on Williamson 2019c, a short summary of my philosophy of philosophy, in Epistemology and Philosophy of
Science (Moscow). I thank Anton Kuznetsov and Daniel Stoljar for their interesting contributions.

c09.indd 405 10
Experimental Philosophy

10.1 Reply to Weinberg
Experimental results can in principle undermine the procedures of any intellectual community, by revealing patterns of variation in its members’ judgments that are hard to reconcile with the supposition that those judgments are even moderately reliable. It does not follow that every intellectual community should suspend its procedures until the relevant experiments have actually been done and shown to have reassuring results, otherwise all inquiry would come to a halt, since the procedures for interpreting experimental results would themselves have been suspended. In 'On Doing Better, Experimental-Style'
(Weinberg 2009), Jonathan Weinberg recognizes that the experimentalist challenge to the armchair methods of philosophy must do better than appeal to the mere skeptical possibility of seriously disquieting experimental results. Such results must actually have been obtained, if the challenge is to attain any urgency. According to Weinberg, such results have indeed been obtained, enough of them to remove any initial presumption in favor of the procedures of a well-established discipline like philosophy.
In the first edition, I complained about experimentalists’ use of experiments on undergraduates just beginning philosophy to cast doubt on its methods as applied by highly trained practitioners (193, this volume). Weinberg responds that the existence of 'real expertise' in philosophy is just another empirical hypothesis in need of
experimental test. By the same token, the existence of real expertise in physics is just another empirical hypothesis in need of experimental test. As before, the question is how urgent the challenge is. Weinberg does not directly claim that any actual experimental results cast doubt on the existence of real expertise in philosophy. He does cite a paper by Shanteau (1992) as showing something about the characteristics of domains conducive to the development of real expertise.1 It will be useful to consider whether Shanteau’s work really does support
Weinberg’s argument.
One of Shanteau’s main conclusions is that expert competence fares better where the stimuli to be evaluated are static, and worse where they are dynamic (as in making real-time judgments about unfolding events). A moving target is harder to hit. Armchair philosophy typically involves the evaluation of constant stimuli, such as the scenario of a thought experiment, often presented by a written description, so in that respect Shanteau’s paper is encouraging. He also suggests that it is easier to achieve expert competence with stimuli that involve things, and harder with stimuli that involve human behavior. In that respect general metaphysics may be better off than moral philosophy, although it is unclear whether Shanteau would count a written description of a moral predicament as a stimulus that involves things or as one that involves human behavior.
Shanteau also argues that expert competence tends to be associated with tasks of recurrent types, on which frequent feedback is
possible. Of course, intellectually taxing research in any discipline
In Shanteau’s terms, some armchair philosophers are clearly experts in philosophy, since he in effect defines an 'expert' in a field as someone generally regarded as an expert in the field by those who work in that field, and some armchair philosophers are clearly generally regarded as experts in philosophy by philosophers. Similarly, he defines 'competence' in a field as what the experts in the field generally regard as competence in the field; by that standard, there is clearly competence in armchair philosophy, since some of it is clearly generally regarded by those generally regarded by philosophers as experts in philosophy as showing competence in philosophy. Reliance on such operational definitions is widespread in the literature on expertise that Weinberg cites, because non-experts often have no expert-independent way of assessing expertise. This is one of several reasons why the bearing of that literature on the status of philosophy is much less direct than Weinberg appears to suggest. For the sake of argument, I will go along with his apparent assumption that Shanteau’s conclusions about the bearing of task characteristics on competence in experts apply similarly to real expertise; unless he is assuming that, it is not obvious why he cites Shanteau’s paper. I concentrate on that paper because the other work that Weinberg cites from the expertise literature, Ericsson, Charness, Feltovich, and Hoffman (2006), is even less relevant to his claims.

1 is not wholly repetitive. Nevertheless, anyone with a PhD from a program in analytic philosophy is likely to have received feedback from their teachers on their evaluations of scores of thought experiments and arguments, many of them variations on recognizable themes.
The feedback process continues throughout an academic career in philosophy in the form of reactions from colleagues, audiences, and referees. In this respect too, armchair philosophy does not seem especially badly off.2
Another feature of experts, according to Shanteau, is that they tend to decompose complex problems. Armchair philosophy lends itself to that process. For example, in determining whether a thought experiment provides a counterexample to a complex proposed analysis, one often decomposes the task into subtasks corresponding to the sub-clauses of the analysans.
The literature on expertise that Weinberg cites does not constitute even a prima facie challenge to the natural assumption that there is real expertise in armchair philosophy. His challenge to the assumption is not urgent. More specifically, he does not identify any respect in which he has shown the challenge to be more urgent for philosophy than it is for other academic disciplines, such as physics or psychology. It is no better than routine skepticism about the results of unspecified experiments that have not been carried out. Scientists perform only a tiny fraction of all the experiments that it would be physically possible for them to perform. Virtually any scientific theory has implications for the results of experiments that will never be performed. If scientists had to remain neutral about the results of all unperformed experiments, they would have to avoid commitment to virtually any scientific theory.
The question of expertise arose as a challenge to experimental philosophers’ reliance on data about beginners in philosophy to cast doubt on work by experienced, intensively trained armchair philosophers. Since Weinberg’s response to the challenge in his paper provides no evidence against the assumption that there is real expertise in philosophy, it fails to legitimize his use of such data. 18-08-2021 19:21:42 Is Weinberg’s use of other psychological data any more convincing? He cites evidence that verdicts on thought experiments are
affected by factors that vary independently of the correctness of those verdicts. For instance, the verdicts sometimes show sensitivity to the order in which the thought experiments are considered, to differences in wording between logically equivalent descriptions, and to whether they are made in a clean, tidy environment or a dirty, messy one.3 The conflicting verdicts cannot all be correct.4 However, in u
 sing these data Weinberg ignores the difference between one-off individual judgments and consensus reached through the interaction of many participants in a public philosophical debate, conducted over several years in conferences and journals. In the course of such a debate, most participants are forced by their opponents to consider the thought experiments in orders and wordings more favorable to those opponents. Some participants consider them in clean, tidy environments, others in dirty, messy environments, many sometimes in one and sometimes in the other. Of course, these interpersonal and intrapersonal variations do not guarantee convergence on the right answer.
Nevertheless, if the initial individual judgments are more accurate than chance, without being perfectly reliable, then the m
 ajority view has a higher probability of being right. Such social controls are as important in philosophy as they are in the natural sciences, and the social dimension of philosophy is frequently e mphasized in the first edition, for example on the first page. Weinberg would have to work much harder to show that verdicts on thought experiments are no more accurate than chance, especially since the relevant data include
uncontroversial thought experiments as well as controversial ones.
Thus his appeals to such framing effects are undermined by his n
 eglect of the psychological and social conditions of actual philosophical practice.

The importance of order effects in verdicts on thought experiments is, of course, already emphasized in Williams (1970).
4
Attempts to reconcile the verdicts by contextualist hypotheses about their content would be far-fetched in most of these cases. Williamson (2005b) suggests that the data used to support contextualist or subjective-sensitive invariantist hypotheses in epistemology are better explained in terms of errors induced by giving too much weight in some settings to factors that are psychologically salient in those settings.
3 Weinberg repeatedly cites the use of double-blind methods as a way in which science has learned to do better. So it has, but in its modest way armchair philosophy uses double-blind methods too where appropriate, most notably in the refereeing of submissions to journals.
Although many such social mechanisms in philosophy are common to most academic disciplines, they are none the worse for that.
Weinberg makes no attempt to specify the psychological or social nature of armchair philosophy. He sprays his experimental data in its general direction, as though everything in the area deserves to be hit – at least by the charge of not currently deserving our confidence.
Such an indiscriminate approach is peculiarly liable to shoot itself in the foot, or worse. Its targets include informal qualitative epistemological judgments, such as verdicts on Gettier cases. But Weinberg’s paper is itself full of informal qualitative epistemological judgments, for example about whether we are justified in believing that armchair methods in philosophy are reliable. Nor could any current natural science proceed without such judgments. Even statistical data need to be interpreted; the judgment that they render some hypothesis untenable remains an informal, qualitative one, whatever formal and quantitative considerations it draws on. Presumably, Weinberg thinks that we are entitled to accept many informal qualitative epistemological judgments made by natural scientists, without special qualms about their reliability. He does not seem to think that we are entitled to accept many informal qualitative epistemological judgments made by armchair philosophers, without special qualms about their reliability.
Does anything in his data justify this differential attitude?
It would not help Weinberg to say that the natural scientists’ epistemological judgments are supported by empirical data while the armchair philosophers’ are not. First, the relevant judgments concern the relation between data and theory, not the correctness of the data themselves. Both natural scientists and philosophers can make them in the armchair. Although natural scientists’ epistemological judgments may be informed by background knowledge, the first edition shows that the same is true of verdicts on Gettier cases (187, this volume). In any case, there are real-life Gettier cases as well as imaginary ones; for epistemological purposes, it matters little which sort one uses (194–5, this volume). Second, Weinberg offers no evidence (experimental or otherwise) that informal qualitative epistemological judgments are more reliable about real-life cases than about imaginary ones. In practice, Weinberg lays down the experimental challenge for armchair philosophy and simply fails to mention that it could be laid down for natural science too. Of course, experimental philosophers have tested for framing effects in informal qualitative epistemological judgments in armchair philosophy without testing for framing effects in informal qualitative epistemological judgments in natural science.5
Framing effects threaten to constitute a rather general problem for human cognition, although not a wholly insuperable one. The experimental philosophers’ practice of testing for them in philosophy and not elsewhere is analogous to that of a group of men who spend their time testing for framing effects in women’s judgments, and find many.
They never do the tests on men. They conclude that women’s judgments are unreliable, and not to be trusted. When asked about men’s judgments, they reply that since there is no evidence that they are unreliable, they can be trusted. Such experimental misogyny would not deceive Weinberg, but his own experimental anti-philosophy is scarcely more respectable from a scientific point of view. The experiments are not properly controlled, because the experimenter is looking for framing effects only where it suits him to find them.
Some experimental results on human judgment are disquieting.
We really are less reliable than we thought we were. Our judgments are often influenced by irrelevant factors. We need to map out our intellectual vices, in order to manage them more effectively. Many disciplines have in effect already evolved methods that may allow them to work round some of the worst effects of the vices. We can reasonably hope that future advances in cognitive psychology will enable us to do better. The first edition is quite explicit that philosophy can learn from experiment (not just of the thought kind), and itself applies experimental work on the psychology of reasoning to philosophical issues (8, 104–8, this volume). But one point of the book is that any psychological kind that includes armchair philosophical judgments includes a mass of non-philosophical judgments too. In order to manage framing effects more successfully, we need to know

The possibility of framing effects in natural science should hardly come as a surprise after Kuhn (1970) and much subsequent empirical work on the practice of science.
Weinberg speaks of scientific practices as 'unchallenged'; they are not unchallenged in general, just by experimental philosophers.

5 more about what the relevant psychological kinds are. There is no reason to b
 elieve that they will be restricted to psychological processes that are dispensable in the way in which experimental philosophers may suppose armchair philosophy to be dispensable.
On the basis of the evidence that Weinberg offers, the idea that armchair philosophy is peculiarly at risk from experimental results is a bluff. The experimental critique discredits itself by confusing a scientistic spirit with a scientific one. Bad science does not make good philosophy.

Acknowledgment
This section originally appeared in Philosophical Studies as part of my half of a symposium on the first edition (Williamson 2009b).
Thanks to Jonathan Weinberg for his interesting questions, and to participants at the Arché workshop in St Andrews which led to this exchange symposium for discussion, including Stephen Stich, who
co-authored the paper with Jonathan Weinberg as presented there. 10.2  Philosophical Expertise and the
Burden of Proof

1
An eye-catching feature of contemporary analytic philosophy is the argumentative weight it lays on thought experiments. This feature has been the target of an extended critique by self-described 'experimental philosophers' since Jonathan M. Weinberg, Shaun Nichols, and
Stephen Stich published their 'Normativity and Epistemic Intuitions'
in 2001. They have conducted extensive trials of some well-known philosophical thought experiments on a variety of subjects under a variety of circumstances. Their results suggest that the answers given to key questions in the thought experiments are sensitive to the ethnicity of the subjects, the order in which the questions are asked, and other factors presumably irrelevant to the truth of the answers.
On this basis, experimental philosophers have argued that the use of thought experiments in philosophy should be substantially restricted, because on our current evidence they do not deserve our trust.
In the first edition, I developed an account of thought experiments in philosophy as employing deductively valid arguments with counterfactual premises that we evaluate as we evaluate other counterfactuals, using a mixture of imaginative simulation, background
information, and logic. In response to the experimental philosophers’
critique, I noted that their trials have been conducted not on professional philosophers but on lay subjects, typically undergraduates, with little or no philosophical training:
Yet philosophy students have to learn how to apply general concepts to specific examples with careful attention to the relevant s ubtleties, just as law students have to learn how to analyze hypothetical cases. Levels of disagreement over thought experiments seem to be significantly lower among fully trained philosophers than among novices. […] We should not regard philosophical training as an illegitimate contamination of the data, any more than training natural scientists how to perform experiments properly is a contamination of their data. Although the philosophically innocent may be free of various forms of theoret- Call this way of defending the use of thought experiments in contemporary philosophy the expertise defense.
As the quotation makes clear, the expertise defense does not imply that a good philosophical education involves the cultivation of a mysterious sui generis faculty of rational intuition, or anything of the kind. Rather, it is supposed to improve far more mundane skills, such as careful attention to details in the description of the scenario and their potential relevance to the questions at issue.
In 'Are Philosophers Expert Intuiters?' (2010), four experimental philosophers – Jonathan M. Weinberg, Chad Gonnerman, Cameron
Buckner, and Joshua Alexander (WGBA) – provide the best-developed response to the expertise defense currently available. In brief, WGBA
argue that whether philosophical training confers genuine expertise
(significantly greater reliability) in conducting thought experiments is a squarely empirical question, to be answered by detailed empirical investigation in the light of the extensive scientific literature on
expertise, and that the burden of proof is on proponents of the expertise defense to carry out such investigations and show that they deliver the requisite results. Since no such detailed investigations have in fact been carried out, the four authors treat the experimental critique as still holding the field: in their view, philosophers are not currently justified in laying argumentative weight on thought experiments as they do.
This article is a response to WGBA.1 I argue that they have misconstrued the dialectical situation, which it is currently the experimental critique of professional philosophers’ use of thought experiments that lacks adequate evidential support, and that philosophers are currently justified in laying argumentative weight on thought experiments. Of course, it is never completely satisfying just to return the burden of proof to one’s opponents. It would be more fun to lay out a vast array of specific experimental evidence for the value

The present article builds on points briefly made in Section 10.1, in response to
Weinberg 2009. 2
WGBA describe the target of the experimentalist critique as 'analytic philosophy’s longstanding practice of deploying armchair intuitive judgments about cases' (331).2 This description is a little misleading.
Critics of 'armchair philosophy' tend to forget that there are real life analogues of some philosophical thought experiments; stopped clocks really do show the right time twice a day (see 194–7, this volume). One can argue against the justified true belief account of knowledge just as easily with such real life Gettier cases as with the original fictions. But experimental philosophers never suggest that actualizing the scenarios of thought experiments would help solve the methodological problem. Rather, in discussion they have typically been quick to insist that their critique should be applied equally to
All quotations are from, and pages references to; Weinberg, Gonnerman, Buckner, and Alexander 2010 unless otherwise specified.

2 the analogues for the real life cases of the judgments at issue in philosophical thought experiments. Since the real life cases can be encountered far from the armchair, the word 'armchair' should be deleted from WGBA’s description of the target of the experimentalist critique.
Deleting 'armchair' leaves 'analytic philosophy’s longstanding practice of deploying intuitive judgments about cases.' Presumably,
WGBA have nothing against deploying judgments about cases; one does not make philosophy more scientific by compelling philosophers to speak only in generalities. Thus the weight falls on 'intuitive.' Unfortunately, WGBA do not explain what they mean by the word. When is a judgment about a case intuitive? If I judge 'You do not know how many coins I have in my pocket,' is that an intuitive judgment about a case? If experimental philosophers judge 'There is currently insufficient evidence to deny that there is knowledge in this Gettier case,' is that an intuitive judgment about a case? WGBA
give no help in answering such questions. If such examples do count as judgments we are not currently justified in trusting, then the experimentalist critique is self-destructively general. If we are currently justified in trusting such judgments about cases, what is supposed to differentiate them from those judgments in which, according to the experimentalist critique, we should not trust?
The extreme unclarity about the target of the experimentalist critique does not render the critique completely vacuous. It is clear at least that full-dress philosophical thought experiments are supposed to lie in the center of the target area; what is unclear is how far out the area is supposed to extend. That is not simply a matter to be left for further experimental investigation. For, according to the experimentalists, on present evidence we should already be withdrawing our trust from some 'judgments about cases'; they should tell us, at least roughly, which ones. Presumably, they feel justified in assuming that their own judgments in the article fall outside the present target area.
Again, when they discuss 'the areas of philosophy in which appeals to intuition about cases are still central, such as epistemology and action theory' (345), they treat themselves as already having some capacity to discriminate between what is an appeal to intuition about a case and what is not.3
WGBA’s concern in the quoted passage is not only with explicit appeals to intuitions about cases.

3 Having signaled this major problem with the experimentalist critique, I will not elaborate on it in what follows. Nor will I discuss objections that have been raised to details of the experimental designs, such as the wording of the questions. Moreover, I am quite willing to grant that the apparent disagreements between the answers of different subjects were genuine, so that if one answer was true another was false.4 My concern is with the experimentalist response to the expertise defense.
I will not be questioning the expertise literature, or WGBA’s interpretation of it. In one respect they sometimes misrepresent the
expertise defense itself, when they speak of their opponents as claiming that a philosophical education 'immunizes' one against the
influence of whatever psychological factors distort the judgments of untrained subjects in their trials. It is not plausible that philosophical training will totally eradicate such influence, just as it is not plausible that historical training will totally eradicate the influence of whatever psychological factors distort the judgments of untrained subjects about historical matters. But the expertise defense requires no such extreme claim. The defense is vindicated if philosophical training substantially reduces the influence of the distorting factors, even short of total eradication. WGBA’s more circumspect formulations
acknowledge this obvious point: 'What the purveyors of the expertise defense require is that philosophers’ intuitions are sufficiently less susceptible to the kinds of unreliability that seem to afflict the folk intuitions studied by experimental philosophers' (333, their italics).

3
In assessing the dialectical status of the expertise defense, it is useful to start with some general points about observational evidence. Since they are near-platitudes, they are presumably points of agreement in theory between proponents and opponents of the expertise defense.
The issue will be whether opponents of the defense have respected them in practice. 18-08-2021 19:21:42 Experimentation and other systematic forms of observational evidence-gathering use scarce resources of time, energy, and money
(for brevity, I will say only 'experiments' in what follows). Even on a comparatively long timescale, the human race will only perform a tiny fraction of all the experiments it is humanly feasible to perform.
Many possible experiments appear to lack any value; no outcome of them appears to provide significant evidence on any significant theoretical or practical question. Other possible experiments have more apparent value than that, but still deserve far lower priority than more urgent ones to which the resources should go instead.
What attitude should we take to the outcome of an unperformed experiment? It may sound laudably open-minded to insist that we should not commit ourselves as to the outcome. On reflection, however, that attitude reveals itself as a damaging form of skepticism. For let T be a scientific theory so well confirmed by a mass of experimental and theoretical considerations that it is unreasonable to continue testing T, and reasonable to commit ourselves to T. Nevertheless, we cannot have separately tested all the experimentally testable consequences of T, since there are infinitely many. Thus T has some experimentally testable but untested consequence O. The proposed attitude to unperformed experiments requires us not to commit ourselves to O. But since T entails O, commitment to T involves commitment to
O. Thus the proposed attitude requires us not to commit ourselves to
T. But, by hypothesis, it is reasonable to commit ourselves to T. Thus the attitude requires us not to do something it is in fact reasonable to do. Hence the attitude is not binding. Indeed, it is worse than that. For the argument is very general: the attitude in question forbids commitment to virtually any scientific claim, however well confirmed within the limits of human feasibility. We should not take such an attitude.
The case of skepticism about global warming shows just how pernicious such an 'open-minded' attitude to missing data can be. No one is more dogmatic than skeptics in their skepticism. It is sometimes reasonable to commit oneself as to the outcome of an experiment that has never been performed, and perhaps never will be. More generally, it is sometimes reasonable to commit oneself to a hypothesis (such as
O) that could be tested by systematic experiment but never has been, whether or not it ever will be.
Care is needed in applying the argument. Presumably, T does not entail that the experiment will not be performed incompetently or on an unluckily unrepresentative sample. It may be unwise to assume that no misfortune or mistake will occur in the performance of the experiment. But that is not the issue. As a consequence of T, O too does not rule out such performance noise. What is reasonable is to commit oneself to O itself, which could be tested by systematic experiment but never has been. Similarly, the mere fact that the expertise defense could be tested by systematic experiment but never has been is consistent with the present reasonableness of commitment to the expertise defense. Any critique of it must be based on far more specific considerations.
For purposes of comparison, consider the hypothesis that professional physicists tend to display substantially higher levels of skill in cognitive tasks distinctive of physics than laypeople do. The hypothesis could be tested by systematic experiment. But even before that has happened, one can reasonably accept it. More generally, consider how philosophers of science (in the broadest sense) proceed when working on the philosophy of mathematics, physics, chemistry, biology, psychology, economics, linguistics, history, or almost any other academically well-established discipline with departments in most major universities across the world. They normally assume that professional academics in a discipline tend to display substantially higher levels of skill in its distinctive cognitive tasks than laypeople do. For example, they assume that professional judgments on its distinctive questions carry more weight than do the judgments of laypeople or philosophers. The assumption is defeasible: external criticism of the discipline is not forbidden, but it must be based on a body of evidence strong enough to defeat the initial presumption that the professionals are the people best placed to distinguish between good and bad work within their own discipline. In practice, that initial presumption is hard but not impossible to overturn.
Of course, professional training filters as well as educates. Professional academics in a discipline might tend to display substantially higher levels of skill in its distinctive cognitive tasks than laypeople do even if their professional training did not enhance those skills but merely selected people who already had them to a higher degree than others did. In practice, that 'mere selection' hypothesis is grossly implausible for many cognitive skills in most academic disciplines. If it were true of skill in thought experimentation in philosophy, that would anyway suffice for purposes of the expertise defense, but in this section the focus is on professional academic training as an enhancer of cognitive skills in given individuals.
To some extent, the efficacy of professional training in academic disciplines as an enhancer of relevant cognitive skills is a matter of common experience. In principle, it can be assessed in more systematic ways too, but such assessment itself involves reliance on cognitive skills distinctive of an academic discipline such as psychology.
Without an initial presumption that such skills are higher amongst those with relevant professional training than amongst laypeople, the assessment would be problematic. Moreover, it is hard to devise and apply credible tests of a skill in an intellectual discipline without relying on someone’s already accredited skill in that very discipline. If every implicit claim to cognitive skill faced a burden of experimental proof, inquiry would grind to a halt. The defeasible presumption in favor of the relevant cognitive skills of those trained in a discipline plays a significant role in enabling intellectual progress.
From a sociological perspective, philosophy is a fairly normal academic discipline. Consequently, since thought experimentation is a cognitive task distinctive of contemporary analytic philosophy, the initial presumption should be that professional analytic philosophers tend to display substantially higher levels of skill in thought experimentation than laypeople do. Although that initial presumption is in principle open to experimental testing, it does not follow that the onus is on proponents of the expertise defense to do the testing. Rather, the burden of proof is on experimental philosophers to demonstrate that, contrary to initial expectations, professional training in analytic philosophy fails to enhance skill in one of its central cognitive tasks, and the corresponding professional qualifications do not select for such skill. They must point to specific features of our present evidence that tell against the expertise defense. What are those features?
Thoughts naturally turn to the difference in track record between philosophy and many other academic disciplines. Although it would be myopic to deny that philosophy has made some progress, one must admit that in most areas it has not made as much progress as the natural sciences (formal logic is an exception). The suggestion is that the comparative lack of philosophical progress is what defeats the initial presumption in favor of genuine philosophical expertise.
However, this is not what WGBA intend, for it does not distinguish between different cognitive skills in philosophy. For some cognitive skills, WGBA explicitly concede that philosophical expertise is genuine. In particular, they assert that 'philosophical training does typically bring a mastery of relevant literatures both contemporary and historical, and even specific technical skills such as argument evaluation and construction' (334), without providing any experimental evidence such as they require their opponents to produce for genuine expertise in thought experimentation. Similarly, they grant 'philosophers’ possession of such demonstrable skills as, say, the close analysis of texts, or the critical assessment of arguments, or the deployment of the tools of formal logic' (335), without explaining how such skills have been demonstrated in ways for which thought experimentation would have no analogue. In these cases, they treat the positive e ffect of philosophical training as obvious. Thus their objection to the expertise defense must turn on specific differences between thought experimentation and other cognitive skills in philosophy, not on the general phenomenon of philosophy’s poor track record.
Thought experiments in any case constitute an unpromising scapegoat for the discipline’s lack of progress, for if the category is understood narrowly enough to save the experimentalist critique from self-defeat, it has played a comparatively small role in the history of philosophy, even though one can find examples in Plato and other great philosophers. Nor was thought experimentation to blame for what experimental philosophers might regard as some of the more embarrassing episodes in the history of philosophy, such as the shift from logic to rhetoric in the Renaissance or the idealist turn in the eighteenth and nineteenth centuries (to paint with the broadest of brushes).
WGBA must therefore specify which differences between thought experiments and other cognitive tasks in philosophy are supposed to explain why the philosophical training they presume to enhance the latter cannot be presumed to enhance the former. One of the problems they face in doing so is that thought experimentation overlaps the skills they presume philosophical training to grant. For example,
'the close analysis of texts,' which WGBA describe as a 'demonstrable skill' possessed by philosophers, is exactly what one needs adequately to take in and digest the description of the scenario in a thought experiment. Similarly, on many accounts of thought experiments, including that in the first edition, thought experiments employ arguments. In effect, conducting a thought experiment is a special case of 'argument construction and evaluation,' which WGBA d
 escribe as a 'technical skill' that 'philosophical training does typically bring'
(334–5). WGBA appear not to notice this problem. Although they might classify the areas of overlap as somehow untypical (they would need to say why), the tasks for which they regard philosophical expertise as presumptively bogus are strikingly close to some of those for which they regard it as obviously genuine.
WGBA accuse proponents of the expertise defense of giving a merely generic argument, rather than one specific in the requisite way to skill in thought experimentation. They conjecture that we are relying on a 'folk theory of expertise' according to which 'expertise at one aspect of an activity is closely correlated with expertise in other aspects of that activity' (333). I rely on no such theory. It takes very little experience of teaching philosophy to know that expertise in solving logic problems is not closely correlated with expertise in reading historical texts. WGBA cite my comparison between the training of philosophers and the training of lawyers as an example of the generic approach, failing to notice that the comparison was specific to skills relevant to thought experimentation: 'Philosophy students have to learn how to apply general concepts to specific examples with careful attention to the relevant subtleties, just as law students have to learn how to analyze hypothetical cases' (193, this volume). Nothing they say undermines the analogy. They neglect it just as they neglect the overlap between the skills they explicitly treat as enhanced by philosophical training and those relevant to thought experimentation.

4
WGBA do try to identify some relevant differences between thought experiments and other cognitive tasks in philosophy in terms drawn from the scientific literature on expertise. In that literature, various characteristics of training regimes have turned out to be conducive to the production of genuine expertise. WGBA maintain that these characteristics are absent from philosophical training with respect to thought experiments (and presumably not with respect to the cognitive tasks for which they take philosophical training to confer genuine expertise). We might therefore interpret WGBA as accepting the gist of the analysis in section 3 of the dialectical situation, while
attempting to discharge the burden of proof on them by providing specific evidence of the relevant differences between thought experiments and other cognitive tasks in philosophy.
From WGBA’s discussion of the expertise literature, one can e xtract three characteristics of training regimes that have turned out to be conducive to the production of genuine expertise. They are:
(a) repetitive practice with fast, accurate feedback;
(b) decomposition of the task into sub-tasks;
(c) use of external decision aids.
I accept that (a) to (c) are conducive to the production of genuine expertise, and that their absence has the opposite effect. In their published article, WGBA concentrate on arguing that training regimes in philosophy are deficient with respect to (a). Let us take each feature in turn.
(a) By the time one has a PhD in analytic philosophy, one has typically read many dozens of articles and books in which thought experiments play a key role, has thought, talked, and written about them on numerous occasions, and has received extensive feedback on one’s reactions from one’s teachers, much of it immediate (for example, in class). These uses of thought experiments often involve exploring many variations on the same theme (brains in vats, twin earths, G
 ettier cases, trolley cases). According to WGBA, the number of such occasions for a given individual is still orders of magnitude less than for a chess player practicing a given opening (342). But who ever claimed that the difference in skill at thought experimentation between a professional philosopher and an undergraduate is as dramatic as the difference in skill at chess between a grandmaster and a beginner? A more relevant comparison is with the number of occasions on which the trainee philosopher receives feedback with respect to philosophical skills for which WGBA acknowledge the efficacy of a standard training, such as the close analysis of texts and the critical assessment of arguments. Another relevant comparison is between feedback in legal and philosophical training with respect to hypothetical cases. WGBA’s vague remarks ignore the more appropriate comparisons. They also confuse the issue by failing to distinguish between feedback for trainee philosophers and feedback for already trained philosophers (341–2). In short, they provide no serious evidence of deficiency with respect to (a), and so fail to shift the burden of proof on to their opponents. (b) It is not hard to decompose the task of thought experimentation into consciously discernible sub-tasks. First, one must read and digest the description of the scenario; this is the part that corresponds to WGBA’s 'demonstrable skill' of 'the close analysis of texts.' Then one must judge what would be the case in the scenario described, which in turn often decomposes into answering several questions, such as Is it a belief? Is it true? Is it justified? Is it knowledge? One must also judge whether the scenario is really possible, for otherwise the thought experiment may not be fit for purpose. Finally, one must determine whether the premises, if verified, do entail the proposed conclusion; this part corresponds to WGBA’s 'technical skill' of
'argument construction and evaluation.'
(c) Formal methods as decision aids facilitate some, although not most, thought experiments. For example, consider the proposed law of tense logic 'If P then it will be the case that it was the case that P.'
One can test it by a thought experiment in which one envisages a last moment of time, using formal techniques to check that the schema has a false instance in that scenario. The exercise is no merely formal one, for it concerns the intended interpretation of the tense operators. A more commonplace example is the regular use of outcome tables and other visual aids in perspicuously displaying the structure of thought experiments in decision theory. Although aids of that kind are 'purely notational,' a good notation can do much to facilitate understanding and insight, as mathematicians know.
On closer inspection, therefore, philosophical training with respect to thought experiments may have about two and a half of the three characteristics conducive to the production of genuine expertise, for all WGBA say. Their elaborate invocation of the expertise literature threatens to undermine their own argument.
WGBA make several points that could be construed as objections to the foregoing assessments of (a) to (c). These points must now be evaluated.
First, WGBA insist that we cannot determine from the armchair how much practice is needed for genuine expertise, and likewise for the other factors. That is obviously correct, but it is a quite generic point; it does not discriminate between thought experimentation and the skills WGBA acknowledge to be developed by philosophical training. For example, my comments about practice and feedback on thought experimentation could equally be applied to practice and feedback on 'argument construction and evaluation' (WGBA’s comments on that 'technical skill' are not aimed at formal logic, and their own arguments are informal). After all, it is often the thought experiments that absorb classroom time because their vivid details grip the imagination, to the detriment of drier material on the structure of informal arguments. Since WGBA provide no evidence that thought experimentation fares worse in such respects than the other skills, they give no reason to expect philosophical training to be relevantly less efficacious for the former than for the latter.
Second, to the suggestion 'that philosophers train their intuitions against other, already-certified expert intuitions,' WGBA respond:
'This appears to be a non-starter, since it just invites an explanatory regress: how did the purveyors of those intuitions develop their expertise?' (341). Such an objection might be made concerning the feedback philosophy students receive from their teachers on thought experiments, mentioned earlier under (a). Incompetent feedback is not conducive to genuine expertise. This point too is dangerously generic for WGBA’s purposes. When students receive feedback from their teachers on 'argument construction and evaluation' or 'the close reading of texts,' how did their teachers develop their expertise? The infinite regress concern would be more serious if thought experimentation did not decompose into sub-tasks, for then there might seem to be little for the feedback to consist of beyond bare verdicts. Even there, however, the teacher might also suggest other related thought experiments for purposes of comparison. Moreover, in most branches of philosophy there are many sufficiently uncontentious thought
experiments, such as fictional cases of unjustified true beliefs that do not constitute knowledge, on which beginners are often started; it is their very uncontentiousness that makes them comparatively inconspicuous. In any case, given the decomposition of the task of thought experimentation into sub-tasks, described under (b), feedback can be far more articulated. For example, the teacher can draw the student’s attention to overlooked aspects of the description of the scenario. In any academic discipline, the capacity of teachers to provide correct and useful feedback depends to some extent on the teachers’ expertise, but the regress need not be vicious. We sometimes have a high enough level of expertise to bootstrap ourselves to a higher level of expertise by mutual criticism without input from anyone already at the higher level. Pupils sometimes surpass their teachers without having more innate ability. WGBA provide no evidence that this does not happen for thought experimentation just as it happens for other cognitive skills.
Third, WGBA complain about a hypothesis on which trained philosophers do better than laypeople when 'the correct verdict turns on a very subtle detail' that it is 'not what is needed here, dialectically,'
because it 'will not help explain away a difference in intuitions found between different groups of the folk, or between different orders of consideration of cases by the folk, that would lead us to expect philosophers not to recapitulate the same variation' (347–8). But that is to impose an unreasonable explanatory demand. The effect of education is often to increase uniformity on some cognitive task; explaining the effectiveness of the education need not involve explaining the specific patterns of variation amongst the uneducated. For example, one can explain why very few professional historians are Holocaust deniers or very few professional biologists are creationists without explaining why Holocaust denial or creationism is much commoner amongst relevantly uneducated people in some countries than in others. WGBA provide no reason to expect a different pattern in philosophical training on thought experiments.
In summary, the dialectical situation is this. The experimental critique presents evidence that philosophically untrained subjects
perform poorly at thought experimentation, a cognitive task characteristic of contemporary analytic philosophy. In general, given a cognitive task characteristic of a discipline, it is unwarranted to project data about the performance at the task of subjects untrained in the discipline onto subjects trained in the discipline, without specific evidence that training in the discipline makes no substantial difference to skill at that task. WGBA’s attempt to provide such specific evidence consists of a few vague and casual claims about training in philosophy and thought experimentation. They provide no significant evidence that thought experimentation is worse off in the relevant respects than the cognitive skills they acknowledge to be enhanced by training in philosophy, such as informal argumentation and the close analysis of texts. Consequently, they provide no reason to rely less on trained philosophers’ skill at thought experimentation than on their skill at those other cognitive tasks. 5
The fear is sometimes expressed that philosophical training merely enforces orthodoxy in thought experiments. It socializes the malleable into eventually accepting the standard judgments, whatever their initial views. Those who stubbornly resist are excluded from the profession. They fail to get into a top graduate school, or fail to get their doctoral dissertation accepted, or fail to get a proper job in philosophy. Even if they somehow manage to sneak into the profession, referees for prestigious journals and publishers reject their article and book manuscripts. WGBA briefly raise such a possibility (351).
Of course, one can see academic training in many disciplines in such reductively sociological terms. It surely has some tendency to filter out unpopular views in all academic fields, including the natural sciences. But a view may be unpopular for good reason. By the arguments above, the onus is on those who suspect the professional consensus in philosophical thought experiments of being a merely sociological phenomenon to provide solid evidence for their suspicion, to distinguish this professional consensus from more benign ones.
Otherwise the suspicion is just one more conspiracy theory. WGBA
provide the skeptic with no such evidence.
We have more to rely on than that general consideration. As
WGBA note, philosophical training fosters a variety of cognitive skills, which they treat as obviously genuine (close analysis of texts, argument construction and evaluation, formal logic, and so on). We might expect that if thought experimentation were a rogue pseudoskill, orthodoxy in thought experiments would be at best poorly correlated with possession of all or most of the genuine cognitive skills in philosophy. Since a significant minority even of Western students give unorthodox responses to thought experiments, according to the experimental philosophers’ own results, such responses should sometimes be combined with genuine cognitive skills in philosophy, if the latter are poorly correlated with orthodoxy. Given that highly rated performance on most dimensions can compensate for poorly rated performance on one or two in academic tests, we should not expect philosophical training to exclude all or almost all of those who deviate from orthodoxy in thought experiments, any more than it excludes all or almost all of those who are not much good at formal logic.
Furthermore, orthodoxy in thought experiments is not all or nothing. People who ascribe knowledge in a Gettier case may give
orthodox answers in other thought experiments. If they fail in epistemology, they can try metaphysics or moral philosophy instead. If they are good enough in all other respects, they can still make it in the profession. Having achieved tenure and prestige, they are in a position to go back to their old grievance, deliver lectures in which they skillfully construct arguments to show that their unorthodox answer in the thought experiment fits a better overall theory, and use their reputation to have their arguments published in books and articles.
After all, a powerful challenge to orthodoxy brings rich professional rewards in philosophy.
Once one seriously considers what it would take to enforce a given response to a particular thought experiment across the philosophical profession purely by a process of social exclusion, with no deeper cognitive basis, the scenario looks increasingly paranoid.
It is, in any case, not the scenario most experimental philosophers had in mind.

6
The claims of this article do not entail that we should be complacent about trained philosophers’ skill at thought experimentation. There are too many internal tensions between common verdicts in different cases for that.5 But we should also not be complacent about trained philosophers’ skill at the construction and evaluation of informal arguments. Given the widespread negative evaluations of the experimental philosophers’ informal arguments, and the many arguments against their conclusions, experimental philosophers presumably cannot rate trained philosophers’ skill in that respect very highly either.
Plainly, however, the proper response is not to give up the practice of informal argumentation in philosophy. That would only make c10.indd 428 things worse (much worse). Rather, we must try to refine the practice from within, as we do. Why should we not do the same with thought experimentation?
Psychological evidence may well have a significant role to play in refining our skill at thought experimentation. It can alert us to unexpected sources of bias and distortion in our verdicts, and help us correct for them. We are likely to have most to learn from general psychological theories of judgment that are well established on the basis of a broad range of evidence, rather than from data gathered with a specific philosophical (or anti-philosophical) agenda on complex, philosophically contested judgments. Some such work is already available.6 That is a far more promising way forward than a wholesale ban on thought experimentation. Indeed, given the point from Section 1 that the target of the experimental critique is not just thought experimentation but the more general practice of relying on
'intuitive judgments about cases,' whether made in or out of the armchair (since otherwise the experimental critique would not make the intended difference), it is quite unclear what philosophy without the practice at issue would be, if such a thing is even possible.
Consider, for example, a theory of confirmation. We may hope to test it by drawing out its predictions for a range of specific counterfactual cases, kept artificially simple in order to make it as clear as possible, independent of the theory, which hypotheses would really be better confirmed than which. Those tests are thought experiments.
To follow the experimentalists’ advice not to use such tests is to make philosophy less scientific, not more.

Acknowledgments
This section first appeared in Metaphilosophy (Williamson 2011a). I
thank Jonathan Weinberg for detailed written comments on related material, both him and others for useful discussion at an Arché workshop entitled 'Philosophy Without Intuitions?' at St. Andrews, a graduate conference at Trinity College Dublin, the 26th International
Philosophical School of the Institute for Philosophical Research of the 18-08-2021 19:21:42 Bulgarian Academy of Sciences conference 'Applied and Experimental Philosophy in Knowledge Based Society East and West' in Sofia, and meetings of philosophical societies at Oriel College Oxford and the University of Geneva, where I presented other versions of this section, and likewise participants in the December 2009 symposium marking the 40th anniversary of the founding of the journal Metaphilosophy, 'The Future of Philosophy: Metaphilosophical Directions for the 21st Century,' at the Institute of Philosophy, School of
Advanced Studies, University of London. 10.3  On Joshua Alexander’s Experimental
Philosophy: An Introduction
Most philosophers accept that experimental findings can in principle bear on philosophical questions. Experimental confirmation of the theory of special relativity is relevant to the philosophy of time, as are results from experimental psychology to the philosophy of perception. The usual pattern is that experimental findings about X bear on the philosophy of X by showing something about X in real or apparent conflict with assumptions on which philosophers of X had relied. The movement calling itself 'Experimental Philosophy' does not fit that pattern. The experiments it promotes as bearing on the philosophy of X are not directly about X. Rather, they are about what people say about X. The people surveyed are typically not experts on X. Their reactions are supposed to bear on the philosophy of X
by showing something about the everyday concept 'X,' perhaps that philosophers had misunderstood its structure, or neglected its variation from one social group to another. Reconsidering the concept 'X'
is supposed to lead philosophers indirectly to reconsider X itself. In the philosophy of time, such a method might involve, not physicists’
experiments about time, but statistical surveys (carried out by the philosophers themselves) of ordinary people’s verdicts on examples from the philosophy of time, and even (if funding permits) scans of their brains as they react.
Advocates present Experimental Philosophy as a revolution in philosophy, starting about the new millennium. But the approach is older than they suggest. During the heyday of ordinary language philosophy in the 1950s, the complaint was sometimes heard that if philosophers want to discuss the ordinary uses of words, they should go out and see how ordinary people really use those words. The Norwegian philosopher Arne Næss put an early version of the approach into practice in the 1930s with questionnaires about truth. His results had very little impact. His approach was generally treated as eccentric, although quite what entitled ordinary language philosophers to dismiss it was not altogether clear. The current philosophical climate is more favorable; an atmosphere of excitement surrounds Experimental Philosophy.
Joshua Alexander, an activist in the movement, has written a clear and accessible introduction to its work. The reader obtains a good sense of what Experimental Philosophers are doing and why. The impression is conveyed that the revolution will triumph eventually, though not without an arduous struggle. Much of the book is devoted to showing how tricky the data are to interpret and to confronting critics of Experimental Philosophy (including this reviewer).
The starting-point of Alexander’s account is that 'philosophical intuitions,' glossed as 'what we would say or how things seem to us' (1, 101), play a central evidential role in much contemporary philosophy. They constitute data against which theories are measured.
He discusses contrasting accounts of the nature of intuitions without settling on any, but continues on the basis that we can recognize when they are being invoked. If philosophers are indeed using what we would say or how things seem to us as data, then they should be careful to find out what we really would say or how things really do seem to us, and large-scale surveys are relevant to that enterprise.
The first person plural pronouns are a clue. If I am relying on what we would say or how things seem to us, what entitles me to assume without asking that what the rest of us would say is what I would say, or that how things seem to the rest of us is how they seem to me?
Anyway, who are 'we?' If we include people who differ from me in race, gender, culture, or education, isn’t the assumption of uniformity in the data hopelessly shaky? If we include only those who resemble me in all such respects, what value has a philosophical theory based on so narrow a range of data? The stage is set for Experimental Philosophy. Alexander illustrates the range of roles it can play in alerting us to unexpected and theoretically suggestive complexities and variations in responses, using case studies of its application in epistemology, ethics, and the philosophy of mind. His general moral is that we are not yet in a position to draw firm conclusions: more Experimental
Philosophy is needed because the data so far do not point unequivocally to a single explanation.
Alexander’s case studies are detailed and readable. Unfortunately, they can mislead in philosophically crucial respects. For instance, he discusses the recent debate between contextualists and subject-sensitive invariantists in epistemology (36–48). He presents contextualism as the view that the standard for knowledge varies with how salient possibilities of error are, and subject-sensitive invariantism as the view that it varies with how much is at stake. Readers unfamiliar with the debate will not realize that the fundamental difference between contextualism and subject-sensitive invariantism has nothing to do with either salience or stakes, but concerns instead the difference between the context of the ascriber of 'knowledge' and the context of the subject to whom it is ascribed: according to contextualism, the truth-value of the ascription is sensitive to the ascriber’s context even when the subject’s context is held fixed; according to subject-sensitive invariantism, the truth-value of the ascription is sensitive not to the ascriber’s context but to features of the subject’s context traditionally thought to be epistemically irrelevant. Thus to hold the truth-value of 'knowledge'-ascriptions sensitive to how much is at stake for the ascriber but not to salience is to be a contextualist rather than a subject-sensitive invariantist, while to hold it sensitive to how salient error possibilities are for the subject but not to stakes or the ascriber’s context is to be a subject-sensitive invariantist rather than a contextualist. In an endnote, Alexander acknowledges an over-simplification in his statement of the issue, but not the crucial one; he says that the debate is really 'about whether or not salience matters' (119n19).
His discussion shows no care in distinguishing between the ascriber’s context and the subject’s. In several of his examples, error possibilities are salient in both contexts, so the experiments are not properly controlled. It is hard to design a good experiment to test a theory if you do not pay attention to what the theory says.
Another chapter illustrates the use of experimental methods to distinguish between conceptual competence and conceptual performance with examples where the application of the concept 'intentional action' is apparently sensitive to normative judgments about the agent.
Alexander concludes that survey methods are of little help in determining whether the influence of some factor in an application of the concept was part of conceptual competence or just of conceptual performance. 'What is needed instead, for example,' he proposes, 'are neuroanatomical accounts of the cognitive processes and mechanisms responsible for our folk psychological judgments and evolutionary
(or other teleological) accounts of the work that our folk concepts are supposed to be doing' (69). However, those accounts will be of limited use in determining the bounds of conceptual competence if
'conceptual competence' is ill-defined. Alexander explains it thus:
'The central idea is that certain factors (e.g., resource limitations or interference from other cognitive processes) can influence a person’s use of a given concept without influencing her knowledge of that con- cept or being reflective of the meaning of that concept' (60). Suppose that on seeing my son spill his milk I judge that he did it intentionally.
Presumably, my visual perception is not itself part of my competence with the concept 'intentional action,' since it involves another cognitive process, even though the latter’s role is hardly just 'interference.'
Rather, my conceptual competence is meant to be something I bring to perception. Is it some mechanism for determining whether what I
perceive is an intentional action? Such accounts are suspiciously verificationist. The mechanism will be less than 100% accurate. I could change it without changing the meaning of 'intentional action.' Or does my conceptual competence consist in a list of analytic truths about intentional action written in my brain? The analytic-synthetic distinction is notoriously problematic and ambiguous. 'Conceptual competence' as Alexander presents it is so unclear that trying to determine its parts through neuroanatomical or evolutionary investigations would be a waste of time. It is hard to design a good experiment to test an ill-defined theory.
If some Experimental Philosophers neglect traditional philosophical skills in their enthusiasm for experimental methods, that is not an essential feature of Experimental Philosophy. In principle, it could disappear as the movement matures – although the divisions between experimentalists and theoreticians in natural science hint that some trade-off between the two sorts of skill is not easily avoided. A more central worry is that the project of Experimental Philosophy, as characterized by Alexander, does not withstand scrutiny.
What the Experimental Philosophy revolution is supposed to change – systematize, restrict, or abolish – is a philosophical method: the use of philosophical intuitions as evidence. Alexander’s startingpoint is that such a method is obviously widespread in, and distinctive of, contemporary philosophy (1, 11). The systematic deployment of elaborate hypothetical cases is indeed an eye-catching feature of much recent analytic work. But what Experimental Philosophers target is neither the systematicity nor the elaboration. Nor, officially, is it the hypothetical nature of the cases. For many of them can be replaced by real life cases. For example, hypothetical Gettier cases are famously used to refute the equation of knowledge with justified true belief. Experimental Philosophers have argued that verdicts about such cases are too culturally variable to carry weight in epistemology (although recent work by Jennifer Nagel has cast doubt on the robustness of their results). But there are also real-life Gettier cases; stopped clocks sometimes really do show the right time. Epistemologists can easily use them instead to make the same point. Unsurprisingly, that does not satisfy Experimental Philosophers. They insist that verdicts on real-life cases involve philosophical intuitions just as much as do verdicts on hypothetical cases. If so, the judgment 'He does not know that it is noon' may involve a philosophical intuition just as much as does the judgment 'In the hypothetical case, the agent does not know that it is noon.' But 'He does not know that it is noon' is not distinctively philosophical; it is a judgment in ordinary language for which there is perceptual evidence: you see him at noon setting his watch by the stopped clock.
Although philosophical intuitions are often treated as non-inferential, one must be careful about the relevant sense of 'inferential.' Just as the judgment 'He does not know that it is noon' somehow derives from information such as 'He is relying on a stopped clock,' so the judgment 'In the hypothetical case, the agent does not know that it is noon' somehow derives from information such as 'In the hypothetical case, the agent is relying on a stopped clock.' Although one normally reaches such verdicts without conscious deductive or inductive argument, the same applies to vast numbers of unproblematic judgments in natural science and everyday life, including many nonperceptual judgments. For instance, conscious deductive or inductive argument is not how scientists usually make their overall judgments as to which of several rival theories is best confirmed by a mixed body of evidence. I doubt that the reader used conscious deductive or inductive argument to reach the reasonable belief that there are no hobgoblins (I certainly didn’t). Few of the statements made in Alexander’s book appear to be based on conscious deductive or inductive argument. The sense in which verdicts on cases in philosophy are non-inferential covers far too much to characterize a distinctive philosophical method.
The criterion that the cases be philosophically significant is equally unhelpful. Any judgment whatsoever has potential philosophical interest, because it will be inconsistent with some whacky philosophical theories.
If the judgments that involve philosophical intuitions are in ordinary language, concern examples, and are not based on conscious deductive or inductive argument, so are vast numbers of u
 ncontroversially unproblematic everyday and scientific judgments, including many made by Experimental Philosophers themselves. Who imagines that philosophy would be improved by a ban on examples, or an insistence that it be conducted entirely in technical jargon? Nor can all judgments in philosophy be based on conscious deductive or inductive argument; some premises are needed too.
Alexander’s own gloss on 'philosophical intuitions,' 'what we would say or how things seem to us,' does no better. In both everyday and scientific situations, when I say that P, I would say that P, and
(if I am sincere) it seems to me that P. If I am not idiosyncratic, we would say that P, and it seems to us that P. If I believe that I am not idiosyncratic, I believe that what we would say, and how things seem to us, is that P.
Alexander proceeds on the assumption that, even if he cannot define 'philosophical intuition,' we can recognize when one is being used as evidence, and thereby demarcate a tractably narrow class of cases. But although we may indeed be able to recognize when a judgment about an explicit hypothetical case is being used as evidence, that is not the point. As just seen, under dialectical pressure Experimental Philosophers have applied the term 'philosophical intuition'
so broadly that it fails to capture anything useful. If Experimental
Philosophers want to put their activities on a proper scientific basis, they would do well to drop misleading terms like 'philosophical intuition,' and face up to their failure to identify any distinctive philosophical method to be transformed or overturned by their revolution.
Eliminating all the parts of Alexander’s book that depend on talk of 'philosophical intuitions' does not leave nothing. His case studies need not be described in such terms. If the experiments have been properly designed and conducted, they still reveal unexpected and intriguing patterns in ordinary human judgments about philosophically central matters such as knowledge, intentional action, causation, and morality. What to make of those patterns is unclear, but simply ignoring them would be imprudent and incurious. Even if they turn out to result from various kinds of bias, a philosophical training is unlikely to render one entirely immune to such bias. Understanding a source of bias is a step towards correcting for it. To be credible, the diagnosis of bias should be backed by an appropriate psychological theory, independently tested on philosophically uncontentious evidence. Such a theory is more likely to come from cognitive psychology than from Experimental Philosophy, and to rely on experiments designed and conducted by psychologists with the requisite experience and knowhow. The methodological moral for philosophers to draw will concern ways of correcting for bias of the psychologically identified kind. It will not be to avoid or reduce reliance on 'philosophical intuitions,'
because that term does not pick out any specific psychological kind.
Alexander’s reliance on the ideology of 'philosophical intuition' is not the only problematic aspect of his discussion of the epistemology of philosophy. His arguments tend to instantiate all-purpose skeptical forms. His comments on evidence are an example. Consider a philosopher who uses a Gettier case to refute the theory that justified true belief is knowledge. The key premise of her refutation is that the subject does not know. One might suppose that she is using that premise as evidence against the theory. But Alexander claims that further evidence is needed for the premise. His point is that further evidence is needed to persuade those whom the premise does not initially persuade (104–7). But such an argument could be formulated about any premise whatsoever. The upshot would be that no premise is ever good enough to use as evidence, because further evidence would always be needed to persuade those whom it did not initially persuade.
Although Alexander naturally does not endorse or even consider that conclusion, he gives no reason why his form of argument should work in the case to which he applies it but not in general.
When one puts forward a premise p, one usually hopes that one’s audience will accept p. If they do not, one may use whatever further evidence one expects to carry weight with them. One may say 'The
Pope believes p' or 'Daniel Dennett believes p,' depending on circumstances. One may emphasize anything the challenger believes that favors p. But one is unlikely to get far by saying 'I philosophically intuit p' or 'We philosophically intuit p.' Appeals to further evidence typically reflect the dialectical needs and opportunities of the moment rather than revealing the standing basis on which one believes p.
Sometimes, when you fail to persuade your interlocutor, that reflects shortcomings on his part rather than on the part of your evidence. Alexander does not engage with the task of showing that it is otherwise when a philosopher uses a Gettier case as evidence.
Alexander also falls back on generic skeptical arguments in his discussion of philosophical expertise. For example, he sees an explanatory regress in the idea that students train their judgments against those of established experts, and worries that various kinds of bias may make us overconfident of the value of our training (94). Those are skeptical possibilities for any academic discipline. Alexander provides no serious evidence that they are more urgent in philosophy than elsewhere. To the suggestion that theoretical reflection may improve philosophical judgment, he responds 'theoretical commitments are just as likely to contaminate as they are to clarify.' The next sentence backs off from the unsubstantiated 'just as likely' to a mere claim of possibility: 'The fact that expert philosophical intuitions are theoretically informed doesn’t ensure that they are more theoretically valuable than folk intuitions' (95). Indeed; but in no academic discipline does the fact that expert judgments are theoretically informed ensure that they are more theoretically valuable than lay judgments.
Alexander also objects that 'If our theoretical commitments shape our philosophical intuitions, it is hard to see how our philosophical intuitions can help us independently assess the accuracy of those theories' (ibid.). That is just a version of the old concern, familiar from the philosophy of science, that the theory-ladenness of observation undermines the rationality of theory testing. But a theory can get into trouble on its own terms; its influence on our observations does not entail that they will always favor it. Anyway, the theory under test need not be one of those with which our observations are laden.
Alexander applies such all-purpose concerns about expertise to argue that we need Experimental Philosophy to test whether the purported experts in philosophy are any good. He does not explain why, if at all, such testing of expertise is more urgent in philosophy than in other disciplines.
Confronted with Alexander’s restriction of generic forms of skepticism to philosophy, it is hard not to suspect some anti-philosophical bias. 'Calls for change,' he reminds the reader, 'are often met with resistance, especially by those heavily invested in the orthodox' (89).
But those heavily invested in revolution have their own reasons for resisting their opponents. Fortunately, Experimental Philosophy shows signs of outgrowing the sort of polemical philosophy-hating philosophizing from which it has not been entirely free. The best work reported in this book does not reflect any such anti-philosophical agenda.
Experimental Philosophers did not invent the idea of 'philosophical intuition.' It belonged to the ideology of one faction of the ancien régime. Against that faction, their use of it was dialectically legitimate. For constructive purposes, however, it has outlived its utility. The psychological and sociological study of philosophy will make more progress once it ceases to work within a framework of obsolescent epistemology.

Acknowledgment
This section first appeared as a review of Alexander 2012 in Philosophy (Williamson 2013f). 10.4  Philosophical Criticisms of Experimental
Philosophy
1. Introduction
The phrase 'experimental philosophy' can mean many things. In a broad sense, it covers any experimental inquiry with a philosophical purpose (Rose and Danks 2013 argue for a similarly broad understanding of 'experimental philosophy'). On that reading, few philosophers today object to experimental philosophy as such. For example, it is generally agreed that the philosophy of perception has much to learn from experiments on the psychology of perception. Although the experiments tend to have been conducted by psychologists for psychological rather than philosophical purposes, in principle philosophers of perception themselves could initiate and even conduct similar experiments for philosophical purposes – although in practice the results will be better if they do so in collaboration with experimental psychologists, who have more of the required know-how in designing, conducting, and interpreting experiments. Analogous considerations apply to the philosophy of space and time and experiments in physics. A few diehard Wittgensteinians may still claim that no outcome of scientific experimentation is of special relevance to philosophy, whose role they confine to dissolving conceptual confusions. This section assumes that philosophy is a theoretical discipline with more constructive ambitions than that.
In a narrower sense, 'experimental philosophy' refers to a more specific kind of philosophically motivated experimental inquiry, in which verdicts on hypothetical cases relevant to some philosophical question are elicited from significant numbers of subjects, sometimes under controlled conditions, and hypotheses are tested about the underlying patterns. Again, there is no reason in principle why philosophy cannot learn from the results of such activities, though their bearing on the original philosophical questions needs to be clarified. But within experimental philosophy in the narrower sense, there is a minority movement, sometimes known as the 'negative program,' which has attracted attention disproportionate to its size, because its proponents’ claims seem to have radical implications for  hilosophical methodology. The negative program offers a naturalisp tic critique of the non-experimental ('armchair') methods of much recent analytic philosophy, and in particular of its reliance on thought experiments (for these purposes, thought experiments do not count as experiments themselves). The well-known paper by Weinberg, Stich, and Nichols (2001) may conveniently be taken as the opening broadside of the negative program, at least in its contemporary form. The results of some of its experiments are interpreted as showing that the crucial verdicts in thought experiments on which philosophers have relied are sensitive to factors presumably irrelevant to their truth, such as the ethnicity or gender of the experimental subjects, or the order or environment in which they are presented with the thought experiments. Although most experimental philosophy even in the narrow sense is independent of that critique, this section focuses on the negative program, and criticisms of it. Nor does it concern all such criticisms. Various objections have been raised to the specific design, execution, interpretation, and repeatability of specific experiments on which proponents of the negative program have relied. This section does not discuss such objections. Rather, it concentrates on broader theoretical challenges to the negative program that arise even if the specific experiments at issue are well designed, well executed, well interpreted, and repeatable.

2. 'Philosophical Intuitions'
Many proponents and many opponents of philosophical thought experiments describe them as eliciting 'philosophical intuitions,'
corresponding to the crucial verdicts. For example, it is said to be a philosophical intuition that, in the hypothetical scenario, the subject ought to divert the trolley to save five lives at the expense of one, or does not know that it is 3 p.m. by looking at a stopped clock that happens to be showing the right time. Thus many proponents of the negative program define the overall target of their methodological critique as reliance on philosophical intuitions, or on intuitions more generally (see, e.g., Alexander and Weinberg 2007: 63). Against them, many other philosophers defend reliance on philosophical intuitions, or on intuitions more generally (Sosa 2007). Still others deny that philosophical thought experiments involve reliance on such intuitions
(Deutsch 2009, Cappelen 2012). The phrase 'philosophical intuition' is obviously technical jargon, in need of explanation. Surprisingly, both proponents and opponents of the negative program tend to use the phrase as though it were selfexplanatory. Alternatively, they give it a perfunctory vague gloss such as 'what we would say or how things seem to us' (Alexander 2012:
1). At first sight, this does not look like much of a problem, since it seems clear enough from examples what is meant. We can recognize a philosopher’s thought experiment when we see one, and the crucial verdict in it is the one the philosopher subsequently invokes. Of course, examples do not reveal the underlying psychological nature of philosophical intuitions, but we need not know that nature in order to recognize when they are being relied on.
We can start to appreciate the inadequacy of that attitude by considering real life analogues of thought experiments. In epistemology,
I have sometimes played tricks on audiences to create actual Gettier cases (see 194, this volume). Instead of judging that in the hypothetical scenario the subject has justified true belief without knowledge of the given fact, audience members judged (after I revealed the trick)
that they themselves had had justified true belief without knowledge.
Instead of judging that the man you imagine relying on a stopped clock would not know that it is 3 o’clock, you can judge that the man you observe relying on a stopped clock does not know that it is 3 o’clock. Indeed, you can receive the description of the imaginary case in the very same words as a report of a real life case, and judge whether he knows on that basis. For epistemological purposes, such actual cases do just as well as hypothetical ones in showing justified true belief to be insufficient for knowledge.1 If epistemologists rely on actual cases rather than hypothetical ones, are they still relying on philosophical intuitions? If the negative program’s answer is 'No,' its critique of reliance on philosophical intuitions will be quite easy to get round in some key debates: just bring about a real life analogue of the contested thought experiments. Of course, that will often be a
Arguably, what most epistemologists call 'justified belief' is better classified as blameless belief (Williamson 2021a), but the experimental critique of Gettier cases concerns the denial of 'know,' not the application 'justified,' which most epistemologists use as a theoretical term, since they intend a restriction to epistemic (as opposed to moral or pragmatic) justification. In this section, I apply the term 'justified' in the way analytic epistemologists have usually done.

1 laborious business, and in moral philosophy an unethical one, since lives will be lost in the non-fictional analogues of trolley cases. Nor is such an alternative available for the more science-fictional cases.
Nevertheless, for some of the thought experiments which negative programmers have expended most effort resisting, their resistance would have been futile.
Understandably, negative programmers have preferred to rule that using real life cases instead of the corresponding philosophical thought experiments still counts as relying on philosophical intuitions. That ruling is not ad hoc. It is very plausible that the cognitive processes underlying the crucial verdicts on the imagined hypothetical cases have much in common with the cognitive processes underlying the crucial verdicts on the corresponding experienced real life cases (see
181–209, this volume). Thus it is natural for negative programmers to extend suspicion of the cognitive processing of imaginary cases to suspicion of the cognitive processing of corresponding real-life cases, since one might expect biases in the former to be inherited from similar biases in the latter. However, this extension has a price. Our fairly straightforward ability to discriminate situations where thought experiments are being performed from other situations no longer
constitutes an ability to discriminate situations where philosophical intuitions are being used from other situations, since many situations where philosophical intuitions about real life cases are being used are situations where no thought experiment is being performed. For virtually any judgment one makes on an actual case, there is a corresponding judgment to be made on an analogous hypothetical case, and using that hypothetical case for a thought experiment may suit the dialectical purposes of some philosopher, since some other philosopher may have inadvertently proposed a theory to which it is a counterexample. The obvious danger is that the category of philosophical intuitions will be stretched so wide, encompassing virtually anything one says about actual cases, that the negative programmers’
critique of reliance on philosophical intuitions will become a global skepticism, at odds with their conception of their general enterprise as a positive contribution to naturalistic inquiry.
Can negative programmers reply that what counts as a 'philosophical intuition' is itself a matter for further experimental inquiry to determine, by uncovering underlying similarities? The trouble with such a reply is that negative programmers take their critique in its current state already to have present practical implications for philosophical methodology. They face the challenge of articulating those implications without assuming that we are already in a position to recognize a philosophical intuition when we see one. As already explained, the methodological ambitions of the negative program require us to reform our practices with respect to real life cases as well as fictional ones, but they leave it quite unclear how much they intend that category to include.
In the heady early days of the negative program, a commonly drawn moral was that philosophers should stop relying on philosophical intuitions, at least until substantial experimental evidence was produced of their reliability. But how can philosophers act now on that moral if they have no idea how far the category of philosophical intuitions extends? If negative programmers are banning some parts of current philosophical practice, they had better make it clear enough for present working purposes which parts they are banning.
Thus, if they define those parts as the ones that involve reliance on
'philosophical intuitions,' they had better make it clear enough for present working purposes which situations involve reliance on philosophical intuitions. Mere appeal to the results of future experimental inquiry is not enough for present working purposes.
Since those early days, negative programmers have become more cautious, in response to both philosophical criticisms and difficulties in reproducing experimental results. As noted earlier, there is an increasing realization that the category of 'philosophical intuitions'
may be so broad that general skepticism about them can easily lead to hopeless global skepticism. A view something like the following is now widespread: The overall reliability of philosophical intuitions may well be quite high: non-accidentally, a reasonable proportion of them are true. However, such moderate global reliability is consistent with both extreme local unreliability here and there, and less extreme but more global unreliability more widely, resulting from bias, distortion, and sensitivity to irrelevant factors. In the background of this picture may be an evolutionary line of thought: for central, common cases our practices of applying a concept have enough causal repercussions for a propensity to serious error to have a significant cost in fitness, but in rare or marginal cases that is not so.
One might try stating the proposed methodological moral of the negative program in a more circumscribed way: we should not rely on a specific philosophical intuition until we have experimental evidence that it is widely shared. However, the difficulty remains: how can we act on that advice unless we can recognize a philosophical intuition when we see one?
The difficulty depends on the presumption that the methodological moral is not being generalized beyond the category of philosophical intuitions. If mad-dog naturalists make such a generalization, and insist that we should not rely on any judgment at all until we have experimental evidence that it is widely shared, it may not matter for their purposes whether the judgment counts as a philosophical intuition. But the more general moral is hopeless, because it generates an infinite regress: the experimental evidence takes the form of a report of the experiment, that report consists of the authors’ judgments, on which we are told not to rely until we have experimental evidence that they are widely shared, and so on. Negative programmers do not endorse such mad-dog generalized morals. Their methodological moral is specific to philosophical intuitions, which is why its application depends on our ability to distinguish in practice between philosophical intuitions and other judgments.
Not all negative programmers insist that we must wait until we have experimental evidence that a philosophical intuition is widely shared before we rely on it. A more moderate moral is that we may rely on a philosophical intuition even in the absence of experimental evidence that it is widely shared, as long as no one rejects the intuition –
but once someone has rejected it, we must suspend judgment on it until we get such experimental evidence. But the workability even of that more moderate moral depends on our ability to distinguish in practice between philosophical intuitions and other judgments,
unless the moral is generalized to those other judgments. Once again, the generalized moral is hopelessly immoderate. It implies that we must suspend any judgment that someone has rejected until we have
experimental evidence that it is widely shared. That principle would make it all too easy for a troublemaker to bring any inquiry he or she disliked to a grinding halt, simply by rejecting a key judgment on which its practitioners relied, then rejecting a key judgment in the report of the experimental evidence that the former judgment was widely shared, and so on. In particular, such a malicious critic could soon stop the negative program in its tracks. The methodological moral can be watered down still further, so that more than one lone troublemaker is required to trigger the obligation to suspend judgment until experimental evidence is obtained.
But numbers are not the issue: naturalists cannot accept any generalized methodological moral that would enable large teams of postmodernists or religious fundamentalists to bring natural scientific inquiry to a standstill just by rejecting key judgments whenever it suited them, in order to trigger a potentially infinite regress of
experimental demands. Thus the point remains: the intended methodological moral of the negative program mandates some sort of special treatment for a category of 'philosophical intuitions' so its present workability depends on our present ability in practice to determine when we are faced with a member of that category. Negative programmers are treating disagreement in philosophical intuitions differently from disagreement in other judgments. They cannot simply sidestep the demand for a workable demarcation of the category.
What differentiates philosophical intuitions from the rest?
There is no promise in the idea of distinguishing philosophical intuitions by something distinctively philosophical in their content.
The only candidate in the content of the supposed philosophical intuition 'He doesn’t know that it’s 3 p.m.' is the reference to knowledge, a philosophically interesting relation. But if the use of the ordinary term 'know' for a philosophically interesting relation suffices to make 'He doesn’t know that it’s 3 p.m.' a philosophical intuition, then the discourse of experimental philosophers themselves is packed with philosophical intuitions, since they often apply ordinary terms such as 'learn' (acquire knowledge) and 'evidence' for philosophically interesting relations to specific cases. The problem of
over-generation remains.
Intuitive judgments are often contrasted with reflective judgments
(see, e.g., Nagel 2012: 497–503, drawing on Mercier and Sperber
2009). The difference is not that reflective judgments are based on evidence, for so are many intuitive judgments. Thus the 'philosophical intuition' in a real life Gettier case 'He doesn’t know that it’s 3
p.m.' depends on evidence such as that the clock he looked at has stopped, that he is wearing no watch, and so on. In the c orresponding thought experiment, 'He doesn’t know that it’s 3 p.m.' presumably relies on hypothetical evidence in a similar way, and when one steps back outside the imaginative exercise to judge 'In the story, the man doesn’t know that it’s 3 p.m.,' that does not undo the original use of evidence; it simply involves a further step of conditionalization, marked by the introduction of the operator 'in the story.' The difference is rather that reflective judgments are reached through something like consciously controlled reasoning, in a series of steps, whereas intuitive judgments are not. For instance, if one reasons to oneself 'No one who relies on a stopped clock knows the time; he is relying on a stopped clock; therefore he does not know that it is 3
o’clock,' the concluding judgment is reflective rather than intuitive.
Consciously controlled reasoning has distinctive psychological features: unlike intuitive judgment, it is slow, it makes heavy demands on working memory, and it can only integrate very limited amounts of information.
By the proposed standard, the judgment about the thought experiment 'In the story, the man doesn’t know that it is 3 o’clock' may count as less intuitive than the judgment about the real life case 'He doesn’t know that it is 3 o’clock,' since the former but not the latter involves the extra step of conditionalization noted earlier, marked by
'in the story,' which may well be a piece of consciously controlled reasoning. However, we can allow that there is a spectrum from intuitive judgments through increasingly reflective ones, and that here we are still close to the intuitive end. But grading intuitiveness does not mean that the negative program can confine itself to judgments that are not highly reflective. For example, having judged 'He doesn’t know that it is 3 o’clock,' through a series of steps of consciously controlled reasoning one can conclude 'A son of a child of a child of that man’s great-grandmother in the maternal line has a justified true belief that it is 3 o’clock without knowing that it is 3 o’clock,' which counts as a highly reflective judgment by the proposed standard. It does just as well as the original intuitive judgment for arguing against the justified true belief account of knowledge.
Clearly, the negative program needs to extend to reflective judgments derived from intuitive judgments. But what reflective judgments are not derived from intuitive judgments? If a reflective judgment results from several steps, what about the first judgment in the series? Suppose that one reflectively concludes 'Socrates is mortal'
by s yllogistic reasoning from 'All men are mortal' and 'Socrates is a man.' One’s judgment 'Socrates is a man' may well be intuitive; if one consciously recognizes the valid pattern of the reasoning, the judgment in which one does so may also count as intuitive. If those judgments are not intuitive, others earlier in the process will be. As the distinction has been drawn, all reflective judgments rely on intuitive judgments. If intuitive judgments are the outputs of system 1 and reflective judgments of system 2, the point is that all system 2 thinking involves system 1 thinking. Thus skepticism about intuitive judgments generalizes to skepticism about all judgments. It is an illusion that reliance on intuitive judgments, characterized along anything like the lines sketched above, constitutes a distinctive method of armchair philosophy. In that sense of 'intuitive,' all human thinking relies on intuitive judgments.
Both opponents and proponents of a postulated distinctively philosophical method of 'reliance on intuitive judgments' need to demarcate 'intuitive judgment' much more narrowly. Another sign of this is that ordinary perceptual judgments come out as intuitive rather than perceptual, but they are far from the only non-reflective judgments that are not supposed to be at issue. Even mathematical reasoning ultimately relies on non-reflective pattern recognition. But it is quite unclear how this required narrower type of 'intuitive judgment' is supposed to be demarcated.
Unfortunately, the terms 'intuition' and 'intuitive' continue to be used by all sides in debates on philosophical methodology without remotely adequate clarification. This is a significant obstacle to progress. A more hopeful sign is that some negative programmers have seen the need for a much more nuanced and qualified characterization of the target of their methodological critique, one that puts little or no weight on the category of philosophical intuition. Such a redefinition of the terms of debate should facilitate progress. The next section discusses the redefined debate.

3. Proper Domains for the Application of Concepts
For definiteness, I will concentrate on a paper by Edouard Machery
(2011) that argues for the combination of moderate global reliability with local unreliability in the setting of the negative program. To his credit, Machery avoids the term 'intuition' altogether, so the concerns of Section 2 do not arise directly for him. Machery is sympathetic to what he calls 'the Ordinary Judgment
Proposal,' that 'the judgments elicited by thought experiments are underwritten by the psychological capacities that also underlie the judgments we make about everyday situations' (2011: 194). What he calls 'the Parity Defense of Thought Experiments' argues from the Ordinary Judgment Proposal to the conclusion that one cannot challenge the 'reliability and thus trustworthiness' of the judgments elicited by thought experiments 'without also challenging the reliability and thus trustworthiness of all our judgments – a price too high to pay for even the most ardent critics of thought experiments'
(2011: 196). Machery attacks the Parity Defense, and indeed argues that the Ordinary Judgment Proposal has skeptical implications for philosophical thought experiments (2011: 197).
According to Machery, 'the main criticism of the Parity Defense'
is that we have reason to believe that philosophical thought experiments involve the application of concepts in situations outside the proper domain of the psychological capacities underlying our application of those concepts, where the proper domain of a psychological capacity is defined to comprise the circumstances in which it is reliable (2011: 201). Machery is obviously right that the Ordinary
Judgment Proposal does not entail the Parity Defense. It is logically consistent to hold that the psychological capacities underlying our application of a given concept are reliable in everyday situations but unreliable in philosophical thought experiments. The question is whether we have any reason to believe that combination of claims, and in particular whether the Ordinary Judgment Proposal gives us any reason to believe it.
The mere atypicality of the circumstances does not give us good reason to believe that we are outside the proper domain of the relevant concept. Atypicality does not imply unreliability. For example, some people have exceptionally good memories; they are good to a rare, atypical degree. That does not give us reason to believe that we are outside the proper domain of the concept of remembering when we apply it to them. Although atypicality may tend to increase the chance of unreliability, it does not in general do so enough to warrant agnosticism.
After all, situations of danger tend to be atypical in various ways; we are in trouble if our cognitive systems fail whenever we need them most.
Machery himself is sometimes quite liberal about proper domains.
'At an abstract level,' he says, the situations described in science f iction novels 'are clearly very similar to everyday situations, and we thus have reason to believe that they belong to the proper domains of the relevant psychological capacities' underlying our judgments about those science fictional situations (2011: 202 n11). In Machery’s view, the most important characteristic of philosophical thought experiments in giving us reason to believe that they fall outside the proper domains of the relevant concepts is that they 'typically pull apart the features that go together in everyday life' (2011: 203). As he points out, if the imagined cases have this characteristic, then their real life counterparts will share it.
Machery’s first example is that in a standard thought experiment from moral philosophy (pushing a fat man off a footbridge to save five other people), 'using physical violence and doing more harm than good are pulled apart,' whereas using physical violence and doing more harm than good supposedly go together in everyday life.
Thus, his argument goes, we have reason to believe that the psychological capacities underlying our application of moral concepts are unreliable in such cases, and therefore to be skeptical about our initial moral judgment. But consider a woman who fights off her would-be rapist, kicking him in the groin and having him arrested.
We judge that her action was morally permissible, indeed right. But this too is a case of using physical violence without doing more harm than good, and therefore pulls apart the features that go together in everyday life. According to Machery’s argument, therefore, we have reason to believe that the psychological capacities underlying our application of moral concepts are unreliable in this case too, and therefore to be skeptical about our initial judgment that the woman’s action was morally permissible. Surely this skepticism is unwarranted, and potentially pernicious. More generally, although professors at top universities may rarely encounter at first-hand situations in which physical violence is the only effective form of self-defense or defense of innocent people, such situations have been quite common in human experience. Thus Machery’s argument as he states it severely over-generates skepticism about moral judgment. No doubt it is rare to be able to save many people by killing one, but to characterize the supposedly problematic feature of the case so narrowly would smack of special pleading.
The treatment of epistemologists’ thought experiments is similar.
According to Machery (2011: 204):

c10.indd 450 Experimental Philosophy   451
When people fail to know something, their beliefs are typically false, unjustified, and the products of unreliable methods. When people know something, their beliefs are typically true, justified, and the product of reliable methods. By contrast, Gettier cases sever truth and justification from the reliability of the methods of belief formation since they describe situations where truth comes about by luck. [Footnote:
Here the method is not the tendency to endorse one’s perceptual experience (which is a reliable method) but the use of a broken clock.]
Thus, one has a reason to believe that the situations described by Gettier cases are beyond the proper domain of our everyday capacity to ascribe knowledge.

Here Machery seems to assume that we have a reason to believe that any situation where the three features of truth, justification, and reliability of the methods of belief formation fail to go together is beyond the proper domain of our everyday capacity to ascribe knowledge (or its absence). Therefore we should be skeptical about our initial judgment that the protagonist of the Gettier case lacks knowledge. Now consider a man who irrationally forms beliefs simply on his guru’s authority. The guru makes assertions at random; a few of them are true, so the follower forms some true beliefs. Those cases sever truth from justification and the reliability of the methods of belief formation. Therefore, by the principle on which Machery seems to be relying, we have a reason to believe that the situation of the follower’s true beliefs is beyond the proper domain of our everyday capacity to ascribe knowledge or its absence. Therefore we should be skeptical about any initial judgment we may have made that the follower lacks knowledge. Again, this skepticism is surely unwarranted. Thus Machery’s argument severely over-generates skepticism about epistemological judgment.2
Machery’s takes the same line about the sort of thought experiment that Kripke (1980) uses to refute descriptivist theories of reference for proper names (2011: 204): 18-08-2021 19:21:43

452   Experimental Philosophy
Situations involving proper names associated with a single description that happens to be false of the original bearer of the name are probably beyond the proper domain of our capacity to identify the reference of proper names since in everyday circumstances many of the numerous descriptions associated with a proper name tend to be true of the original bearer of the name.

But it is just false that in everyday circumstances numerous descriptions are always associated with a proper name. Think of the proper names we picked up when half-attending to lessons in schools, the conversations of others, the television, or the internet, and subsequently forgot the source (as often happens to me). Kripke’s examples are of an utterly familiar type, slightly schematized only to make the point clearer. For instance, someone uninterested in sport may associate only the description 'professional soccer player' with the name
'Toby Flood' and falsely believe 'Toby Flood is a professional soccer player'; in fact, 'Toby Flood' refers to a professional rugby union player (meta-linguistic descriptions like 'the person called ‘Toby
Flood’' need special discussion, which Kripke (1980) gives them).
Such cases occur frequently in everyday circumstances. Here Machery’s argument over-generates skepticism about semantic judgment.
Although the psychological capacities underlying our application of ordinary concepts are doubtless unreliable in some circumstances,
Machery’s diagnostics for falling outside their proper domain are far too weak to provide good evidence of unreliability. They severely underestimate the range of variation amongst the cases with which we need to deal reliably in everyday life. Animals need minds in order to deal flexibly and appropriately with the somewhat complex, novel situations they not infrequently find themselves in. A high proportion of ordinary cases are complex enough to fit Machery’s diagnostics.
For instance, he gives this example of a reliable everyday judgment about knowledge: 'judging by her answer to the test, one of my undergraduate students does not know what the DN account of explanation is' (2011: 195–6). By the loose standards Machery applies in assessing philosophical thought experiments, the features of lacking elementary knowledge in an academic field and of never having taken a course on it 'typically' go together in everyday life, but they pull apart in this case, so we have reason to believe that the psychological capacities underlying his judgment that his student does not know what the DN account of explanation is are being applied outside their proper domain, and we should be skeptical of his judgment. Once again, his style of argument severely over-generates skepticism. Far more exacting criteria would be needed to provide serious reason to expect unreliability in a given case. Machery does not offer such criteria. Since the Ordinary Judgment Proposal is in no way committed to his easy-going criteria that over-generate skepticism about judgment, Machery’s claim that it implies skepticism about philosophical thought experiments is unfounded.
Like Machery, Joshua Alexander and Jonathan Weinberg (2014)
defend a qualified version of the negative program. Unlike him, they still make frequent use of the unclarified term 'intuition.' Concerned to avoid global skepticism, they envisage intuitions as moderately reliable in general but subject to various potential sources of error over which, they claim, only experimental methods will give us control.
Alexander and Weinberg propose some specific features of thought experiments that we might take as danger signals of a potential e rror source. For instance, they suggest as such a danger signal that the reader of many epistemological thought experiments is supplied with more information about their protagonists’ mental states than is typically available in everyday life. That is true; philosophers supply such information in hopes of making their thought experiments as watertight as possible. However, Alexander and Weinberg give no evidence that supplying less information would make a significant difference to the outcome. For example, the man who truly believes that it is 3
p.m. by looking at a stopped clock can be described from the perspective of an external observer watching the man. That does not reverse the verdict that he does not know that it is 3 p.m.
Alexander and Weinberg suggest that the 'subtle' or 'unusual and marginal sorts of cases that are popular with epistemologists' are prime candidates for local unreliability, although they also allow that some sources of bias may be present in more ordinary cases too, and that our 'intuitions' may sometimes withstand experimental tests even in extraordinary cases. They do not expand on what it takes for a case to be 'subtle' or 'marginal.' As for 'unusual,' their use of the term is vulnerable to the problem of generality. Any case whatsoever falls under many descriptions, some more specific than others, and so belongs to many sorts. The narrowest sorts to which it belongs will be highly unusual ones; however ordinary the case, a sufficiently fine-grained description of it will apply to few or no actual cases. At the other extreme, the broadest sorts to which the case belongs will be very usual ones; however extraordinary the case, a sufficiently coarsegrained description of it will apply to many actual cases. In Machery’s phraseology, at an abstract enough level the situations described in epistemological thought experiments are clearly very similar to everyday situations, just as the situations described in science fiction novels are. At a less abstract level, in practice every application of a concept is made in a situation different in some respects from all previous situations. The action is in the sorting of cases in the first place, which Alexander and Weinberg fail to discuss. The sorts need to be individuated in such a way that the differences between them may reasonably be expected to correlate with differences in the reliability of the relevant psychological capacities. Without such a principle of individuation, the emphasis on the rarity of the sorts of cases to which epistemologists appeal is just the kind of generic skeptical move that will discredit the experimental philosophers’ critique.3
One consequence of this failure to provide useful danger signals of unreliability is that it remains unclear what methodological moral philosophers are supposed to draw from the negative critique. 'Avoid unusual, marginal, or subtle cases!' is not very helpful advice. After all, compared to everyday life, a carefully controlled experiment looks like an unusual, marginal, and subtle sort of case, but presumably we are allowed to apply ordinary epistemological concepts such as 'evidence' and 'learning' to it. One challenge to the negative program is to provide a much clearer, more workable and less generic specification of what are supposed to be the serious danger signals.

4. Further Questions about the Parity Defense
Machery (2011) raises several other interesting issues about the Parity Defense of Thought Experiments, which this section will discuss.
Machery reasonably points out that if psychological capacities underlying the application of a concept are unreliable in everyday life, the Ordinary Judgment Proposal suggests that they will be unreliable 18-08-2021 19:21:43 in thought experiments too. We cannot normally expect imagination to do better than observation. So far so good. Moreover, he argues,
'everyday causal judgments in the social domain are biased, and they are unlikely to be reliable' (a sweeping generalization for which he provides minimal evidence). He concludes that 'causal judgments elicited by thought experiments provide no evidence for the premises of philosophical arguments when the judgments bear on whether an agent caused an outcome' (2011: 200).4
Once again, Machery’s argument severely over-generates skepticism. Consider this thought experiment:
Life has not advanced beyond stone-age technology. A community has been living on an island for many years without communicating with the rest of the world. A woman there utters a word. A second later, a man ten thousand miles away utters another word. Did her utterance cause his utterance?

Presumably, we judge that the answer is 'No.' That judgment 'bears on whether an agent caused an outcome.' Therefore, given Machery’s conclusion, that judgment should not be relied on in philosophical argument. This seems rather extreme. To vary the example, consider
Machery’s own case (quoted earlier) of a reliable everyday judgment: judging by her answer to the test (he uses the female pronoun), he judges that one of his undergraduate students does not know what the DN account of explanation is. That judgment is in the social
domain, and it depends on the causal judgment that her bad answer was caused by her ignorance rather than by her determination to get a bad grade in order to win a bet. Should we therefore reclassify the judgment as unreliable? Presumably not. What all this really shows is again that one must take much greater care to avoid more or less generic skepticism about judgment.
What Machery calls his least important criticism of the Parity
Defense is that some philosophical thought experiments have no counterparts in everyday life because they involve matters that lay people do not consider (2011: 197–8). That may be so. For example, some thought experiments about reference may involve a more
Machery makes these claims after considering cases involving the apportionment of blame, but does not restrict his claim to such cases.

4 theoretically constrained reading of 'reference' than is employed in everyday life – and they may be none the worse for that, if the theoretically constrained reading is clear.
Machery’s own example of the point is Burge’s arthritis thought experiment (Burge 1979). We are to imagine two situations, in which the medically untrained protagonist (Oscar) is in all the same internal physical states and sincerely says 'I have arthritis in my thigh.'
The underlying difference between the two situations is in how the rest of Oscar’s speech community uses the word 'arthritis.' In situation S1, they apply it as in the actual world only to arthritis, an ailment of the joints but not of the thighs. In situation S2, they apply it much more broadly, to both ailments of the joints and ailments of the thighs. Burge argues that Oscar’s beliefs differ in content between the two situations – in S1 but not in S2 Oscar believes that he has arthritis – and therefore that the contents of propositional attitudes do not always supervene on internal physical states, but may depend on the external social environment. Machery complains that since lay people do not consider the individuation of the content of propositional attitudes, the psychological capacities used in everyday life do not support Burge’s thought experiments. We can certainly grant
Machery that asking theoretical questions about the individuation of content is no part of everyday life. But that is far less damaging to
Burge’s thought experiment than Machery assumes. Note first that
Oscar does not have arthritis in his thigh in either S1 or S2, since it is a medical fact that one cannot have arthritis in one’s thigh. After all, Oscar does not have arthritis in his thigh in the straightforward situation S1, and he is in exactly the same medical state in S2 as in S1, so he does not have arthritis in his thigh in S2. Note second that in S1 Oscar believes that he has arthritis in his thigh. This is an everyday propositional attitude ascription, reporting the sort of ordinary medical error to which non-experts are prone. Machery himself describes Oscar in S1 as 'convinced that he has arthritis in his thigh' (2011: 197). Therefore, if Oscar believes in S2 what he believes in S1, Oscar believes in S2 that he has arthritis in his thigh.
In that case, however, he believes falsely in S2 that he has arthritis in his thigh, since in S2 he does not have arthritis in his thigh. But there is no reason whatsoever to impute error to Oscar in S2. In S2, he is using the word 'arthritis' correctly; it does apply to the ailment in his thigh. Since Oscar does not believe falsely in S2 that he has ar- thritis in his thigh, Oscar does not believe in S2 that he has arthritis in his thigh.5 Therefore, in S1 but not in S2 Oscar believes that he has arthritis in his thigh, which is exactly Burge’s point. Of course, the argument as just laid out uses explicit though fairly elementary deductive logic, which is untypical of everyday life. But it also makes essential use of the thought experiment, to establish the premises of the reasoning, in part by rather easy applications of the psychological capacities underlying our everyday ascriptions of propositional attitudes. Despite the residual opposition of some philosophers with internalist commitments in the philosophy of mind, there is no good reason for skepticism about the argument.
The arthritis example also brings out one role for philosophical expertise in some thought experiments: in this case, broadly logical expertise acquired through training in logic, a form of philosophical expertise which even experimental philosophers seem willing to grant. Such expertise is relevant not only to constructing the explicit argument, but also to avoiding various confusions to which the folk may be vulnerable. For instance, if one is careless about the usemention distinction, one may be tempted to think that in S2 Oscar does have arthritis in his thigh, because the word 'arthritis' as used in S2 does correctly apply to the ailment in Oscar’s thigh. Some ordinary subjects may indeed give false verdicts on Burge’s thought experiment as a result of such undergraduate errors. They warrant no more skepticism than other undergraduate errors do. Alas, however, not even a PhD in philosophy guarantees immunity to use-mention confusions.6

5. Acts of Judging and Evidence
Machery (2011) assumes that the main evidence for the truth of the key judgment in a thought experiment is the act of judging itself (even if it is poor evidence). For example, the main evidence that in the
Gödel-Schmidt case 'Gödel' refers to Gödel is that (some) subjects

A few loose ends need to be tied up, for example to ensure that Oscar in S2 does not have some other word that refers to arthritis and so does not apply to the ailment in
Oscar’s thigh. They do not affect the point in the text.

5 judge that in the Gödel-Schmidt case 'Gödel' refers to Gödel. Is this epistemological claim correct?
Machery justifies his assumption by analogy with ordinary judgments: 'If I judge of an object that it is a chair, my judgment that it is a chair is evidence that it is a chair because I am reliable at sorting chairs from nonchairs' (2011: 194). This remark blurs a crucial distinction between two issues. First, is the act of making the judgment evidence for its truth from the standpoint of a third party? Second, is the act of making the judgment evidence on which that very judgment is based? Clearly, these two questions can have different answers. Suppose that initially I know nothing about an object o except that there is such an object. I have the background information that
Machery is reliable at sorting chairs from nonchairs. Now I learn just that Machery judges that o is a chair. Obviously, the probability that o is a chair on my evidence goes up considerably. In that sense, Machery’s act of judging that o is a chair can of course be evidence for me that o is a chair. But that does not mean that his act of judging was evidence on which that very judgment of his was originally based. It could not have been, for his act of judging was not available as evidence until the judgment had already been made. Typically, he knows that o is a chair much more directly, by seeing that o is a chair. If he needs further evidence, he has much better and more direct evidence from perception: he can see that o has legs, a seat, a back, and so on.
Even when o is no longer in sight, he can remember that o has legs, a seat, and a back. For Machery to go instead by the fact that he once judged that o was a chair would be a pointlessly indirect detour. And if for some reason he starts doubting that his original judgment that o was a chair was correct, the consideration that he did indeed make that judgment is unlikely to reassure him. It is unclear why anyone would attribute a special evidential role to the fact of judging itself, 18-08-2021 19:21:43 except under the influence of the psychologization of evidence, which
I have criticized elsewhere (see 236–40, this volume).
Parallel considerations apply to thought experiments. Suppose that initially I know nothing about a situation GS except that there is such a counterfactual situation. I have the background information that Kripke is reliable at doing thought experiments. Now I learn just that Kripke judges that in GS 'Gödel' refers to Gödel. Obviously, the probability that in GS 'Gödel' refers to Gödel on my evidence goes up considerably. In that sense, Kripke’s act of judging that in GS
'Gödel' refers to Gödel can of course be evidence for me that in GS
'Gödel' refers to Gödel. But that does not mean that his act of judging was evidence on which that very judgment of his was originally based. It could not have been, for his act of judging was not available as evidence until the judgment had already been made. Presumably, Kripke knows that in GS 'Gödel' refers to Gödel much more directly, by considering GS appropriately in his imagination. If he needs further evidence, he has much better and more direct evidence from noting the stipulated features of GS itself: he knows that in GS
there is a stipulated historical connection of a certain kind between
'Gödel' and Gödel (which is good evidence that the former refers to the latter on any reasonable theory of reference for proper names).
For Kripke later to go instead by the fact that he once judged that in
GS 'Gödel' refers to Gödel would be a pointlessly indirect detour.
And if for some reason he starts doubting that his original judgment that in GS 'Gödel' refers to Gödel was correct, the consideration that he did indeed make that judgment is unlikely to reassure him. Again, it is unclear why anyone would attribute a special evidential role to the fact of judging itself, except under the influence of the psychologization of evidence.
According to Machery (2011: 194 n4): 'it is hard to see what other kind of evidence [than the act of judging] could be put forward to support the claim that, e.g., in the situation described by the Gödel case ‘Gödel’ refers to Gödel.' This incomprehension seems to be related to the error, against which Section 2 warned, of regarding the crucial judgments in thought experiments as involving no role for ordinary evidence, which comes of forgetting how those judgments correspond to evidence-based judgments about observed cases.7 6. Error-fragility
The use of elaborate imaginary cases is a distinctive methodological feature of much contemporary philosophy, even though our verdicts on them do not form a psychological kind. Despite all that has been said, we might still reasonably hope for some independent corroboration of those verdicts. Even when verdicts on many different thought experiments corroborate each other, we might still hope for some independent corroboration of the lot of them. One can take that view while regarding the method of thought experiments as evidentially quite respectable. Compare Whewell’s idea of the consilience of inductions: a conclusion supported by one sort of inductive evidence is much better off if it is supported by other sorts of inductive evidence too.
Still, if thought experimentation can yield knowledge of a fact, why should more support be needed? That is like asking: if naked-eye vision can yield knowledge of a fact, why should more support be needed? Methodological questions are not just about the epistemology of a one-off situation. They concern what general epistemic policies we should follow, for instance in philosophy. Although naked-eye vision without further checks can yield knowledge, a general policy of relying on naked-eye vision without further checks must be expected to yield errors too, since the faculties we use in naked-eye vision are fallible. Similarly, although thought experimentation without further checks can yield knowledge, a general policy of relying on thought experimentation without further checks must be expected to yield errors too, since the faculties we use in thought experimentation are fallible.
The point is reinforced by what Alexander and Weinberg (2014)
call 'error-fragility.' A method is error-fragile if it multiplies error: pursuing it tends to make one error produce many more. Pure deduction is an error-fragile method. Although genuine deductions preserve truth, an imperfect logician applying a purely deductive method will occasionally mistake fallacies for genuine deductions, with potentially disastrous consequences. By contrast, simple induction is not very error-fragile, when based on more or less independent observations.
That one may have both direct evidence for a proposition by perception or imagination and also indirect evidence for it by knowing that others believe it does not undermine the points in the text.

7 Requiring a consilience of inductions makes it even less error-fragile.
Pure falsificationist methods are also error-fragile, since they involve rejecting a theory on the basis of a single counterexample. If the supposed counterexample is erroneous, one may reject a true theory. But analytic philosophers have typically used thought experiments in applying just such a falsificationist method. For instance, a proposed analysis of knowledge is rejected when one thought experiment is judged to yield a counterexample. Thus a single erroneous verdict on a thought experiment might eliminate the true analysis of knowledge (if there were one).
Evidently, we need some system of checks on thought experiments.
That does not imply their marginalization. After all, mathematics has an adequate system of checks on the error-fragile method of deduction without marginalizing it at all. One mathematician’s proof is checked by others, and in the long run even if a fallacy in the proof passes unnoticed a false 'theorem' is likely to be found incompatible with true ones. To some degree, a method based mainly on thought experiments has analogues of those error-correcting mechanisms. But does it have them to a high enough degree? We might reasonably hope for a more robust philosophical methodology where the method of falsification by thought experiment is checked and balanced by other methods. But which other methods should they be?
Experimental philosophers will of course propose experimental methods. For these purposes, it does not matter whether philosophers were involved in designing and conducting the experiments. As noted in Section 1, experimental science already has an important input to several branches of philosophy. But it is unclear how much it can offer to constructive theorizing in those branches where the experimental critique of thought experiments has been most salient, especially moral philosophy and epistemology. Results about what lay people think about goodness or knowledge is only very indirect evidence about which theory of goodness or knowledge is true. Nevertheless, it is not unlikely that received verdicts on some thought experiments do reflect cognitive bias of some kind, for instance when high stakes are involved, and we may hope that, in the long run, experimental methods will help us filter out such cases. And, of course, cognitive psychology will surely contribute much to epistemology through experimental studies of perception, memory, and reasoning, although one must not imagine that popularizing such work is an adequate substitute for properly epistemological theorizing.8 Some branches of philosophy, such as philosophical logic, have far more to gain from formal methods than from experimental ones.9 We should not assume that moral philosophy and epistemology are nothing like that. Moral philosophy learns from mathematical decision theory and game theory. Epistemology learns from probability theory and epistemic logic. Of course, moral philosophy and epistemology cannot be reduced to branches of mathematics, on pain of losing their connection to their subject matter. Formal models of moral or epistemic phenomena need informal motivation. Nevertheless, they provide a powerful means for thinking through the consequences of moral and epistemological hypotheses.
Combining the use of mathematical models, results from cognitive psychology, and pre-theoretic verdicts on real or imaginary cases constitutes a more robust methodology than reliance on any one or two of those three sources. Each source can alert us to errors made through reliance on the others. A consilience of them gives us more robust grounds for confidence. For instance, mathematical modelling supports the conclusion of Gettier’s thought experiments (Williamson
2013c). Moreover, information from those sources must be integrated within the overall setting of informal philosophical theorizing in a broadly abductive spirit, where theories are compared by familiar criteria such as simplicity, strength, unifying power, and fit with the evidence.

We should also remember that the interpretation of real life experiments can involve cognitive bias of its own, such as concentration on those experiments that give the results one is hoping for.
9
Of course, experimental methods may show that many people are willing to assent to 'It is and it isn’t' when they feel pulled both ways about whether a borderline shade is red. That is roughly as much of a threat to classical logic as experimental evidence that many people are willing to assent to 'One plus one equals one' when drops of water coalesce or 'One plus one equals ten' when rabbits breed is to standard arithmetic.
This is not to deny that there are connections between philosophical logic and the semantics of natural languages (for instance, in the study of conditionals), and that experimental methods are in principle relevant to the latter. Nevertheless, interpreted logical theories are not metalinguistic theories unless they happen to concern metalinguistic logical constants (such as a truth predicate), still less psychological theories.
The appropriate methodology for testing them is similar to that for testing interpreted theories in mathematics, for instance set theories.
8 What happens if we delete the pre-theoretic verdicts on cases from such a methodology? Suppose that we are interested in some philosophically central distinction that neither mathematics nor cognitive psychology themselves supply us with, such as the distinction between right and wrong or between knowledge and ignorance. Mathematics says nothing special about the distinction. Cognitive psychology may tell us how humans apply it, but not whether they apply it correctly or incorrectly. If we want to start talking on our own behalf about the distinction, we must rely initially on our own pre-theoretic applications of it, even though we reserve the right to revise them in the light of subsequent theorizing. If we are not allowed to start from our pre-theoretic judgments about cases, then all we have left are our pre-theoretic general judgments about the distinction ('Ought implies can'; 'Knowledge implies belief'). But if we do not trust our particular judgments about the distinction, why trust our more general ones? After all, any pressure in the history of our species to apply the distinction correctly is far more likely to have come from the practical need to classify particular cases at hand correctly than from the theoretical desirability of formulating true generalizations about it. 'Stick to generalities' and 'Avoid examples' are not recipes for good philosophizing, or indeed good theorizing of any kind. Philosophy cannot be reduced to psychology; no clear or plausible picture of an alternative philosophical method has emerged from experimental philosophers’ critique of armchair philosophy. There may indeed be a role for experimental philosophy in refining current philosophical method, but only once the method of experimental philosophy has itself been considerably refined.

Acknowledgments
This section first appeared in Justin Sytsma and Wesley Buckwalter
(eds.), A Companion to Experimental Philosophy, Wiley-Blackwell, as Williamson 2016b. Thanks to an audience in Oxford for discussion and to Joshua Alexander, Wesley Buckwalter, Joshua Knobe, Edouard Machery, Peter Millican, Jennifer Nagel, Justin Sytsma, and
Jonathan Weinberg, for detailed written comments on earlier drafts of this section. 10.5  Reply to Dennett, Knobe, and Kuznetsov on
'Philosophical Intuitions'
Joshua Knobe (2019)’s title is 'Philosophical Intuitions are Surprisingly Robust Across Demographic Differences.' He writes that 'the aim of experimental philosophy […] is to find the truth about people’s intuitions.' He takes for granted that a central issue can be neutrally articulated in the question: how reliable is 'a method that relies on intuitions?' According to Anton Kuznetsov (2019), my view in the first edition of this book is ('Roughly speaking') 'that there are special philosophical intuitions that support philosophical inquiry'
which 'are, to some extent, universal and need special philosophical training.' In their pieces, neither Knobe nor Kuznetsov makes any attempt to explain what they mean by an 'intuition,' or by describing one as 'philosophical.' Daniel Dennett (2019) characterizes 'naïve axiomatic auto-anthropology' as 'thinking that the royal road to truth is to attempt to axiomatize, with your companions, your shared intuitions,' though he is careful not to ascribe that methodology to me. He too does not say what an 'intuition' is. Daniel Stoljar (2019)
is the only one of the four respondents in the symposium not to use the 'i'-word.
In Williamson 2019c, I simply avoided the 'i'-word. Given the limitations of space, I preferred not to use any of it explaining my reasons for avoidance. Since 'Philosophical ‘Intuitions’ and Scepticism about Judgment' (Williamson 2004a; the clue is in the scare quotes),
I have been arguing that the debate about the reliability of 'philosophical intuitions' is ill-posed, because the extension of the quoted phrase is quite unclear. The point is not just that there are borderline cases; we cannot eliminate all vagueness from our vocabulary, and at the margins is usually does little harm. With the term 'intuition,' it is much worse: most human judgments are in the disputed territory.
Let me explain.
Psychologists distinguish between 'intuitive' and 'reflective' judgments. Roughly, reflective judgments are those based on conscious reasoning; intuitive judgments are those not based on conscious reasoning (for simplicity, I concentrate on judgments, but the distinction can be extended to inhibited inclinations to judgment and the like). Some philosophers use the word 'intuition' with explicit reference to the psychologists’ distinction. An example is Jennifer Nagel’s excellent paper, Nagel 2012. However, as Nagel emphasizes, one consequence of so defining the term is that normal perceptual judgments
(and many others) count as intuitions. Thus relying on normal perceptual judgments would count as relying on intuitions. That is not what the metaphilosophical debate was supposed to be about. Indeed, in that sense of the term, avoiding reliance on intuitions is not an option. For all judgments based on conscious reasoning rely on judgments not based on conscious reasoning. For instance, when you do a complex arithmetical calculation in your head, your final answer is based on conscious reasoning, but you did not go through an infinite regress of conscious reasoning: at some point in the calculation you made a judgment not based on conscious reasoning.
Can one finesse the problem for philosophical purposes by stipulating that 'intuitions' are based neither on conscious reasoning nor on perception? That too would wrong-foot the metaphilosophical debate. For our judgments about thought experiments are typically made by using offline, in imagination, the very cognitive capacities we use online, in perception. For example, the proposed stipulation would allow us to sidestep reliance on intuitions in Gettier cases by making judgments based on perception of real-life Gettier cases. We observe someone at 3 o’clock setting his watch by a clock that happened to have stopped at 3 o’clock, and judge that he does not know that it is 3 o’clock. Our judgment that he lacks knowledge is not an
'intuition' in the stipulated sense, since it is based on perception, but critics of the case method in epistemology will be just as uneasy about it as they are about the verdict on the corresponding thought experiment – as I have put to the test by tricking audiences at my lectures into real Gettier cases. Thus the proposed restriction misconstrues the metaphilosophical debate.
In Williamson 2013b, I used this easy exchangeability between online and offline judgements to argue that the distinction between the a priori and the a posteriori is epistemologically superficial. Kuznetsov uses the traditional distinction to characterize my account of armchair philosophy. That is bound to be misleading, given how little I
think of the traditional distinction.
As for the problem of defining 'intuition,' an alternative strategy is to concede that ordinary non-reflective judgments based on  erception are intuitions, but deny that they are philosophical intuip tions. That too is unpromising. For what is distinctively philosophical about the judgment 'He doesn’t know that it’s 3 o’clock?' 'Know' is one of the commonest verbs in the English language. If such an everyday judgment counts as philosophical, it is hard to guess what would count as unphilosophical. Virtually any judgment can be used in a counterexample to some suitably wrong-headed philosophical theory.
To vary the example, for most adults the judgment '2 + 2 = 4'
counts as intuitive in the psychologists’ sense, since they do not base it on conscious reasoning. They also do not base it on sense perception.
Moreover, '2 + 2 = 4' is philosophical in the sense that many philosophers of mathematics rely on the truth of such arithmetical equations in their arguments. I have certainly heard experimental philosophers define 'philosophical intuition' in a way that makes '2 + 2 = 4' a philosophical intuition. When the method of relying on 'philosophical intuitions' is debated, are elementary arithmetical equations to be included?
The moral is this: do not use the word 'intuition' in debates on philosophical methodology unless you have properly clarified what you mean by it. Such clarification requires, at a minimum, answering the questions raised over the past few paragraphs.

Acknowledgment
This section first appeared as part of Williamson 2019d, which was in turn part of a symposium on Williamson 2019c, a short summary of my philosophy of philosophy, in Epistemology and Philosophy of Science (Moscow). I thank Daniel Dennett, Joshua Knobe, Anton
Kuznetsov, and Daniel Stoljar for their interesting contributions.

c10.indd 466 11
Naturalism

11.1 Reply to Kornblith
My agreement with Hilary Kornblith (2009) goes deeper than any remaining disagreement. We agree that armchair methods have a legitimate place in philosophy, for instance in logic. We agree that appeals to experimental data also have a legitimate place in philosophy, for instance in the philosophy of mind and the philosophy of time, and that those branches study mind and time themselves, not just our concepts of them. We agree that the proper balance between armchair and other methods cannot be fully determined in advance, but should to some extent emerge from the future development of the discipline.
Nevertheless, as Kornblith says, we are not placing quite the same bets on what that balance will be. I expect armchair methods to play legitimately a more dominant role in future philosophy than he expects them to – of course, such differences in emphasis can result in widening divergence in practice.
The first edition welcomes a significant degree of methodological diversity short of 'Anything goes,' for often the best long-run way to evaluate a philosophical method is for many able philosophers to use it for many years (287, this volume). That includes methods that make heavy use of experimental data. The book is not an attack on experimental philosophy, in which I have even dabbled myself
(8, this volume). I could hardly object to Kornblith’s suggestion that experimental psychology should contribute to epistemology, since in
discussing the epistemology of logic I appeal to experimental data from the psychology of reasoning (105–8, this volume). Indeed, it would be a grave failure of philosophy in its current state of devel- opment if it neglected to explore the philosophical applications of experimental data far more extensively than has hitherto been done.
It is work that needs doing and surely will be done, although I do not expect to do much of it myself, since my own interests tend to lie elsewhere (as my work makes obvious).
Unfortunately, 'experimental philosophy' has acquired a bad name in mainstream philosophy, in view of the crudity with which it is too often carried out: poor experimental design and crass philosophical errors in the interpretation of the data, perhaps as a result of philistine contempt for more traditional philosophical skills and methods (such as long, subtle chains of armchair reasoning). Those defects can charitably be regarded as growing pains, even if holding theoreticians in low esteem is an occupational hazard for experimentalists (and vice versa). Kornblith and I agree that in principle and sometimes in practice the use of experimental data is compatible with the highest degree of philosophical sophistication.
The legitimacy in principle of experimental philosophy does not make armchair philosophy illegitimate in principle. It would be legitimate in principle for mathematicians to conduct large-scale trials concerning the effect of coffee consumption on susceptibility to computational error, and to modify their practice in consequence if sufficiently alarming results were obtained; that does not make it illegitimate in principle for them not to bother. The book defends an armchair methodology as a good way to address many philosophical problems, not as the only good way to address any philosophical problem. It does so without compromising a straightforwardly realist view of what philosophy is about by any restriction to words or concepts.
Kornblith worries that I overplay the scope for armchair methods, especially formal methods. He focuses on a passage in which
I advocate the use of mathematical modelling wherever possible in philosophy (293, this volume). He rightly points out that some idealizations yield pointless mathematical models, and that much excellent philosophizing cannot be formalized. It would be a disaster for philosophy to be confined to formal methods, just as it would be a disaster for it to be confined to experimental methods. In the passage
I wrote of producing mathematical models of fragments of philosophy: 'when we can, we should.' The conversational implicature was that sometimes we cannot. As an example of valuable philosophizing that cannot be formalized, Kornblith cites Laurence BonJour’s discussion of coherence.
BonJour lists five conditions on coherence (BonJour 1985). They are:
(1) A system of beliefs is coherent only if it is logically consistent.
(2) A system of beliefs is coherent in proportion to its degree of probabilistic consistency.
(3) The coherence of a system of beliefs is increased by the presence of inferential connections between its component beliefs and increased in proportion to the number and strength of such connections.
(4) The coherence of a system of beliefs is diminished to the extent to which it is divided into subsystems of beliefs which are relatively unconnected to each other by inferential connections.
(5) The coherence of a system of beliefs is decreased in proportion to the presence of unexplained anomalies in the believed content of the system.
Although (1)–(5) are of course not fully formal, they are not totally lacking in formal content. Indeed, an attempt at formal modelling is a natural next step in exploring the implications of BonJour’s account.
His conditions have the sort of complexity that often produces unexpected consequences; working formalizations of them through in toy cases would be an excellent way of gauging their effect. There will certainly be different ways of formalizing them, involving different idealizations. Some of those idealizations will be hopelessly misleading, others will be hard to choose between. Those are just normal hazards of mathematical modelling. They are not fatal in physics, and
Kornblith does not really think them fatal in philosophy either.
The use of mathematical models in philosophy is largely neutral over the extent of experimental input. They can figure in an entirely armchair methodology, but they can also play the sort of role they do in physics, economics, and other natural and social sciences. In playing down the role of 'highly idealized formal approaches uninformed by such [experimental] input,' Kornblith writes 'For that very reason, I would see the role of armchair theorizing in philosophy as quite limited, as it is in physics.' This underplays the central role of armchair theorizing in physics: many theoretical physicists spend most of their time doing mathematics, string theory being only one of the more extreme examples. Far from being rivals, formal and experimental methods often complement each other. Hypotheses often require some degree of formal modelling before they can deliver predictions that are capable of being experimentally tested as Kornblith recommends; the test results often suggest new models. One might eventually want to test experimentally whether coherence according to BonJour’s conditions is increased or decreased in simple real-life cases of learning from perception or testimony. That testing would hardly be possible without some further degree of formalization. My suspicion is that in practice purely armchair methods would provide a far more efficient way of identifying any problems in BonJour’s account of coherence, but I will not try to establish that here.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in Analysis Reviews (Williamson
2009a). I thank Hilary Kornblith for his interesting comments, which help bring into relief some main themes of the book. 11.2 Reply to Stalnaker
It is good to find that Robert Stalnaker (2011) and I are in so much agreement about philosophy. I remain reluctant to describe the general picture on which we agree as 'philosophical naturalism,' because that label inappropriately emphasizes philosophy’s affinity to what are usually called 'natural sciences' over its affinities to other forms of truth-directed inquiry, such as history, linguistics, economics, and mathematics. Stalnaker says 'the general message is that philosophy is continuous with natural science and more generally with empirical inquiry.' History, linguistics, and parts of economics presumably count as 'empirical inquiry,' if not as 'natural science,' but what sort of inquiry is 'empirical' supposed to exclude if not mathematics? Although philosophy is continuous with natural science, it is also continuous with mathematics; neglect of that fact has made the near-absence of non-fictional experiments in philosophy look more worrying than it really is. If the term 'natural science' is stipulated to cover mathematics, economics, linguistics, and history as well as physics and biology, what sort of inquiry is 'natural' supposed to exclude? I suspect, however, that Stalnaker did not intend 'natural'
and 'empirical' in any very exclusive sense, and that the apparent difference of emphasis between us here would largely disappear on clarification.
In the latter half of 'The Metaphysical Conception of Analyticity,'
Stalnaker argues that the first edition’s account of most philosophical questions as neither metalinguistic nor meta-conceptual still faces a residual challenge. Most philosophical truths are necessary truths.
Consider a philosophical question 'P?,' where it is non-contingent whether P and we do not know the truth-value of the sentence 'P.'1 If
'P' is true, it expresses a necessarily true proposition. If 'P' is false, it expresses a necessarily false proposition. But any necessarily true proposition is distinct from any necessarily false proposition. Thus, it seems, the proposition 'P' expresses if it is true is distinct from the proposition it expresses if it is false. So what proposition 'P'
expresses depends on the truth-value of 'P.' Therefore, not knowing its truth-value involves not knowing what proposition it expresses. c11.indd 471 The philosophical question whether P is inseparable from the metalinguistic question: what proposition does 'P' express?
Although Stalnaker does not endorse the reasoning in exactly that form, he takes very similar reasoning quite seriously. But he also takes quite seriously seemingly contrary reasoning. For 'P' may be a readily intelligible sentence of English, in which case we surely know what proposition 'P' expresses, even before we are in a position to answer the question 'P?': 'P' expresses the proposition that P. He thinks that
'A reconciliation will […] exploit the obvious context-dependence of the notion of ‘knowing what’ a sentence means or says.' The suggestion may be that the first line of reasoning induces a context in which the sentence 'We know what proposition the sentence ‘P’ expresses'
expresses a true proposition, while the second line of reasoning induces a context in which the same 'knowledge'-ascribing sentence expresses a different and false proposition.
I agree with Stalnaker that 'knowing what' exhibits a sort of context-dependence. In some contexts we count someone familiar with quartz but ignorant of its chemical constitution as 'knowing what quartz is'; in other contexts we count the same person at the same time as not 'knowing what quartz is.'2 However, it is not clear that the original reasoning to the conclusion 'We do not know what proposition ‘P’ expresses' induces a context in which that conclusion expresses a truth; the reasoning may instead simply be fallacious.
The reasoning as formulated above does not even depend on its being non-contingent whether P. With the modal elements deleted, it runs:
If 'P' is true, it expresses a true proposition. If 'P' is false, it expresses a false proposition. But any true proposition is distinct from any false proposition. Thus the proposition 'P' expresses if it is true is distinct from the proposition it expresses if it is false. So what proposition
'P' expresses depends on the truth-value of 'P.' Therefore not knowing the truth-value of 'P' involves not knowing what proposition it expresses.

Compare Boer and Lycan 1985 on 'knowing who.' Gareth Evans’s neglect of the closely related context-dependence in the phrase 'knowing which' is unfortunate for his discussion and use of 'Russell’s Principle' 'that in order to have a thought about a particular object, you must know which object it is about which you are thinking'
(1982: 74; his italics).

2 Such an argument would prove far too much: that whenever we do not know the truth-value of a sentence, we do not know what proposition it expresses (by contextually relevant standards). The fallacy is fairly clear. We can grant that if 'P' is true, the proposition it expresses is true, and that if 'P' is false, the proposition it expresses is false, where the scope of the definite description 'the proposition it expresses' is in each case just the consequent of the relevant conditional. That is just the principle that the truth-value of a sentence reflects the truth-value of the (unique) proposition it expresses, which for present purposes is harmless. But we cannot conclude, concerning 'P,' that the proposition it expresses if it is true is true, or that the proposition it expresses if it is false is false. Thus we cannot conclude that the proposition 'P'
expresses if it is true is distinct from the proposition it expresses if it is false. The displayed argument is really no better than this:
If Oxford has a pre-Roman university, the name 'Oxford' denotes a city with a pre-Roman university. If Oxford has no pre-Roman university, 'Oxford' denotes a city without a pre-Roman university. But any city with a pre-Roman university is distinct from any city without a pre-Roman university. Thus the city 'Oxford' denotes if Oxford has a pre-Roman university is distinct from the city 'Oxford' denotes if
Oxford has no pre-Roman university. So what city 'Oxford' denotes depends on whether Oxford has a pre-Roman university. Therefore not knowing whether Oxford has a pre-Roman university involves not knowing what city 'Oxford' denotes.
Such reasoning is spurious. In fact, no city has a pre-Roman university. To either the indicative question 'What city does the name
‘Oxford’ denote if Oxford has a pre-Roman university?' or the subjunctive question 'What city would the name ‘Oxford’ have denoted if Oxford had had a pre-Roman university?,' no city (for example,
Cambridge) has a better right than Oxford to be the answer. Of course, someone well acquainted with Oxford while uncertain of the denotation of the name 'Oxford' might think of a different city, but that is not the case of interest: it fails to show that for ordinary competent speakers the question 'Does Oxford have a pre-Roman university?' raises metalinguistic issues in any significant way. Although it is in effect equivalent to the question 'Is the sentence ‘Oxford has a pre-Roman university’ true?,' every question is in effect equivalent to a metalinguistic one in that uninteresting way, as emphasized in the first edition (28–32, this volume). Merely switching to non-contingent matters does not improve the displayed form of argument. This instance is equally bad:
If 8191 is prime, the numeral '8191' denotes a (necessarily) prime number. If 8191 is composite, '8191' denotes a (necessarily) composite number. But any prime number is distinct from any composite number.
Thus the number '8191' denotes if 8191 is prime is distinct from the number '8191' denotes if 8191 is composite. So what number '8191'
denotes depends on whether 8191 is prime. Therefore not knowing whether 8191 is prime involves not knowing what '8191' denotes.

In fact, 8191 is prime. To either the indicative question 'What number does the numeral ‘8191’ denote if 8191 is composite?' or the subjunctive question 'What number would the numeral ‘8191’ have denoted if 8191 had been composite?,' no number (for example,
8192) has a better right than 8191 to be the answer. Of course, someone well acquainted with advanced arithmetic only through a different notation might think of a different number, but that is not the case of interest: it fails to show that for ordinary competent speakers the question 'Is 8191 prime?' raises metalinguistic issues in any significant way. Although it is in effect equivalent to the question 'Is the sentence ‘8191 is prime’ true?,' every question is in effect equivalent to a metalinguistic one in that uninteresting way, as already emphasized.
The antecedent '8191 is composite' is impossible. On many theories of conditionals, including Stalnaker’s, a conditional with an
impossible antecedent is vacuously true.3 So interpreted, 'If 8191 is composite, ‘8191’ denotes n' is true for any value of 'n' (so there is no such thing as the number that '8191' denotes if 8191 is composite).4
We can make the conditional non-vacuous by using the metalinguistic antecedent 'The sentence ‘8191 is composite’ is true' instead, if we interpret the inner quotation as referring to an orthographically individuated string that could have had a different meaning.5 But that
The first edition defends this view of subjunctive conditionals at 173–7, this volume.
A similar point applies to 'If Oxford has no pre-Roman university, ‘Oxford’ denotes c'
on the truth-functional reading of indicative conditionals (which Stalnaker does not accept): it is vacuously true whatever the value of 'c' since the antecedent is false.
5
This is similar to considering the 'diagonal proposition' Stalnaker associates with the sentence '8191 is prime'.
3
4 hardly helps the argument. To the indicative question 'What number does the numeral ‘8191’ denote if ‘8191 is composite’ is true?' still no number has a better right than 8191 to be the answer, for ordinary competent speakers. To the subjunctive question 'What number would the numeral ‘8191’ have denoted if ‘8191 is composite’ had been true?' we can imagine that the answer is 8292, because in the closest world in which '8191 is composite' is true the numeral '1'
denotes the number 2: but those counterfactual circumstances have no useful bearing on the epistemic predicament of someone who has mastered our actual system of numerals without knowing whether
8191 is prime.
The same lessons apply to Stalnaker’s own example, a case of the
Kripkean necessary a posteriori, taken as a proxy for philosophical claims about non-contingent matters.6 The crucial reasoning goes thus:
If the sentence 'Hesperus = Phosphorus' is true, it expresses a necessarily true proposition. If 'Hesperus = Phosphorus' is false, it expresses a necessarily false proposition. But any necessarily true proposition is distinct from any necessarily false proposition. Thus the proposition
'Hesperus = Phosphorus' expresses if it is true is distinct from the proposition it expresses if it is false. So what proposition 'Hesperus =
Phosphorus' expresses depends on whether it is true. Therefore not knowing whether 'Hesperus = Phosphorus' is true involves not knowing what proposition 'Hesperus = Phosphorus' expresses.

We should be very suspicious of this argument, given its similarity to the bad arguments displayed earlier. We can grant that if
'Hesperus = Phosphorus' is true, the proposition it expresses is necessarily true, and that if 'Hesperus = Phosphorus' is false, the proposition it expresses is necessarily false, where the scope of the definite description 'the proposition it expresses' is in each case just the consequent of the relevant conditional. But that does not 23-08-2021 14:47:43 show, concerning 'Hesperus = Phosphorus,' that the proposition it expresses if it is true is true, or that the proposition it expresses if it is false is false. Thus we cannot conclude that the proposition 'Hesperus = Phosphorus' expresses if it is true is distinct from the proposition it expresses if it is false.
The potential for Frege puzzles is ubiquitous. For any denoting term t, there can be another term t* that non-obviously has the same denotation as t. That 'Phosphorus' non-obviously has the same denotation as 'Hesperus' does not show that our grasp of the name
'Hesperus' is unusually shaky. By normal standards, we all know what proposition ordinary sentences such as 'Hesperus is more distant than the moon' and 'Phosphorus is more distant than the moon'
express. We must therefore know what the names 'Hesperus' and
'Phosphorus' contribute to such propositions. We also know what the identity sign '=' contributes, and we have mastered the grammar of the sentence 'Hesperus = Phosphorus.' Thus we know what proposition it expresses, by means of our mastery of the compositional semantics of the language. That we do not know whether the proposition it expresses is necessary just shows that we are not omniscient about it.
Does Stalnaker’s puzzle look more compelling if we adopt his own extremely coarse-grained theory of propositions, which identifies a proposition with the set of possible worlds in which it is true? He does not explicitly invoke that theory in 'The Metaphysical Conception of
Analyticity': dialectically, to do so would be a large concession on his part. Not only is the first edition far from endorsing the theory: conceding that the puzzle arises only on that theory would risk turning the puzzle into an argument against his theory. Nevertheless, let us see whether his theory of propositions strengthens his puzzle.
On Stalnaker’s view, exactly one proposition is necessarily true, the set W of all possible worlds, and exactly one proposition is necessarily false, the empty set {}. Thus we know in advance that if 'Hesperus =
Phosphorus' is true it expresses W and if 'Hesperus = Phosphorus'
is false it expresses {}. Since W and {} are evidently distinct, this does create a strong temptation to say that if we do not know whether
'Hesperus = Phosphorus' is true, we do not know what proposition it expresses. That temptation must be scrutinized.
The set-theoretic representation of propositions should be bracketed. Although it provides one convenient way of registering Stalnaker’s idea that necessarily equivalent propositions are identical, thinking in set-theoretic terms is not supposed to be essential to knowing what proposition a sentence expresses by the relevant standard. For finding out that 'Hesperus = Phosphorus' expresses a necessary truth is supposed to be sufficient for knowing what proposition it expresses by the relevant standard, even if the thinker has never been introduced to the theory of propositions as sets of possible worlds. Such a theoretically innocent thinker is also supposed to know what propositions everyday sentences express, despite not knowing that those propositions are sets of possible worlds. For otherwise ordinary people would not know what propositions their sentences expressed, so if philosophers also failed to know what propositions their sentences expressed, that would show nothing peculiar about the situation of philosophy.
We do better to represent the necessary truth and the necessary falsehood by an obvious tautology and an obvious contradiction respectively. For definiteness, we could use 'If it’s snowing, it’s snowing' and 'It’s both snowing and not snowing.' The picture is that once competent English speakers are in a position to know that
'Hesperus = Phosphorus' expresses the same proposition as 'If it’s snowing it’s snowing' (rather than the same proposition as 'It’s both snowing and not snowing'), they know what proposition 'Hesperus =
Phosphorus' expresses by the relevant standard, but not before.7 The underlying assumption seems to be this:
COMPARISON If one knows what proposition a sentence s expresses, and one knows what proposition a sentence s* expresses, then one is in a position to know whether s and s* express the same proposition.

One knows all along what proposition 'If it’s snowing it’s snowing'
expresses. Before one is in a position to know that 'Hesperus = Phosphorus' is true, one is not in a position to know that 'Hesperus =
Phosphorus' and 'If it’s snowing it’s snowing' express the same proposition. By COMPARISON, it follows that one does not then know what proposition 'Hesperus = Phosphorus' expresses. When
The phrase 'in a position to' covers both people who have not considered whether s and s* express the same proposition and those who have but do not think that for propositions necessary equivalence entails identity, inter alia.

7 one learns that 'Hesperus = Phosphorus' is necessarily true, one in effect also learns what proposition it expresses, and is therefore in a position to know whether the two sentences express the same proposition.
However attractive COMPARISON may look, it is too strong for ordinary standards. As already noted, Frege puzzles for a term t are too commonplace to show that competent speakers do not know what propositions ordinary sentences involving t express. Competent speakers who are not in a position to know whether 'Hesperus =
Phosphorus' is true still count as knowing what propositions the sentences 'Hesperus is more distant than the moon' and 'Phosphorus is more distant than the moon' express. Therefore, by COMPARISON, those speakers are in a position to know whether 'Hesperus is more distant than the moon' and 'Phosphorus is more distant than the moon' express the same proposition. But they are not, for if they were they would be in a position to know whether 'Hesperus = Phosphorus' was true. Consequently, COMPARISON fails on ordinary standards for knowing what proposition a sentence expresses. If it holds on extraordinary standards, the upshot would merely be an argument that by extraordinary standards we do not know what propositions most of our sentences express, which would again show nothing peculiar about philosophy. Thus, even if we grant Stalnaker’s extreme theory of propositions, his puzzle still seems to rest on assumptions too contentious to disturb the conception of much inquiry into noncontingent matters, including much philosophical inquiry, as having no special connection with the metalinguistic or the meta-conceptual.
We can try articulating Stalnaker’s concern without using the notion of knowing what proposition a sentence expresses or his theory of propositions. The result that knowing that Hesperus = Hesperus literally just is knowing that Hesperus = Phosphorus is not exclusive to Stalnaker’s theory. It can also be defended on the basis of a more moderately coarse-grained Russellian theory of propositions as structured complexes built out of the objects, properties, and relations they are about, on which co-denoting names contribute exactly the same object, their denotation, to the propositions expressed by sentences in which they occur (Salmon 1986).8 Such a view may tempt one to
There are indications in Stalnaker’s comments that he may have taken me to be more sympathetic to Fregean theories of content than I actually am.

8 describe the ignorance in Frege puzzles as essentially metalinguistic: astronomically ignorant but linguistically competent speakers do in fact know that Hesperus = Phosphorus; what they fail to know is that the sentence 'Hesperus = Phosphorus' is true. A similar treatment will then be suggested for many philosophical claims, such as 'Pain =
π,' where 'π' is a name whose denotation is fixed by a neuroscientific description (69, this volume): if the identity is true, we knew all along that pain = π, because we knew all along that pain = pain, and knowing that literally just is knowing that pain = π; the ignorance is essentially metalinguistic, as to whether the sentence 'Pain = π' is true.
That view of Frege puzzles is inadequate as it stands. Consider this argument:
(P1) If Hesperus = Phosphorus, the sentence 'Hesperus = Phosphorus' is true.
(P2) Hesperus = Phosphorus.
(C)   The sentence 'Hesperus = Phosphorus' is true.
On the proposed view, astronomically ignorant but logically and linguistically competent speakers know both P1 and P2 but are in no position to know C. Why not? What stops them from applying modus ponens? The answer is that they know P1 only under the guise of a sentence like 'If Hesperus = Phosphorus, the sentence ‘Hesperus = Phosphorus’ is true,' whereas they know P2 only under the guise of a sentence like 'Hesperus = Hesperus'; since the guises do not match with respect to P2 and the antecedent of P1, the speakers are in no position to apply modus ponens. To understand their epistemic predicament, we must describe not simply what they know but what linguistic guises they know it under. They know that Hesperus =
Phosphorus under the guise of the sentence 'Hesperus = Hesperus'
but not under the guise of the sentence 'Hesperus = Phosphorus.'9
Similarly, philosophers may know that pain = π under the guise of the sentence 'Pain = pain' but not under the guise of the sentence 23-08-2021 14:47:43 'Pain = π.' As emphasized in the book, 'If propositions are individuated in that coarse-grained direct reference way, what matters for progress in philosophy is less which propositions we know than which sentential guises we know them under' (68, this volume).
Once we have this apparatus in place, we can see what a distortion it is to conceive the ignorance in Frege puzzles as metalinguistic.
Ancient astronomers wondering 'Is Hesperus Phosphorus?' were not wondering about metalinguistic matters; their attention was fixed firmly on the skies. They were not wondering whether a sentence like
'Hesperus = Phosphorus' was true; they were wondering under the guise of such a sentence whether Hesperus was Phosphorus. When they looked up in the evening and thought 'There’s Hesperus' but not 'There’s Phosphorus,' they were not thinking that there was the denotation of the name 'Hesperus'; they were just thinking that there was Hesperus, but they were thinking it under the guise of a sentence like 'There’s Hesperus.' Similarly, philosophers wondering 'Is pain
π?' are not wondering primarily about metalinguistic matters; they are wondering under the guise of the sentence 'Pain = π' whether pain is π. The role of the metalinguistic discourse here is not in fully articulating covert contents of philosophical claims: it is in describing how philosophers are related to their overt contents. Metalinguistic discourse plays such a role in the description of any complex inquiry.
Perhaps Stalnaker would agree.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in Philosophy and Phenomenological
Research (Williamson 2011d). 11.3 Reply to Bianchi
As Andrea Bianchi notes in 'What Do Philosophers Do?,' many of the main themes of the first edition, such as its anti-exceptionalism about philosophy, can be found in the naturalist tradition, as represented most famously by Quine’s 'Two Dogmas of Empiricism.' He is therefore surprised that the book does not have more to say about naturalism.
In fact, I did take the trouble to situate my critique of analyticity in relation to Quine’s (52–4, this volume). I pointed out that although the analytic-synthetic distinction does much less work in contemporary philosophy than it did when Quine wrote, that is not well explained by acceptance of his arguments, since they depend on its interdefinability with other supposedly disreputable semantic distinctions, like that between sameness and difference of meaning, that are now generally considered legitimate. I conjectured that the current marginalization of the analytic-synthetic distinction has more to do with Kripke’s redrawing of the interrelations between the necessary, the contingent, the a priori, and the a posteriori in Naming and Necessity, which decisively broke apart the previously dominant stereotypes of the analytic and the synthetic. Nevertheless, I concluded, 'There is something robust about ‘Two Dogmas of Empiricism’: insights remain even when its skepticism towards meaning is stripped away' (54, this volume). I took my critique of analyticity to be a
development of those insights.
The reason why I use the term 'naturalism' so little in the book is that I regard it as an obstacle to understanding. In my experience, the main function of the words 'As a naturalist, I …,' like that of the words 'As a Christian, I …,' is to avoid thought. 'Naturalism' stands for a loose bundle of logically independent doctrines. If you reject any of them, you count as an anti-naturalist and are expected to reject all of them. If we are to examine each of the constituent doctrines on its merits, we must stop using the word 'naturalism' (or 'anti-
naturalism') as a comfort blanket.
Here is an example. My anti-exceptionalism about philosophy treats it as one more branch of human inquiry, not more different from other branches than they are from each other. I emphasized that this does not imply any special affinity of philosophy with the natural sciences closer than its affinity with, for instance, mathematics (6, this volume). By contrast, Bianchi says 'what characterizes naturalism is the idea that philosophy is akin to natural sciences in theorizing starting from empirical data.' Indeed, the word 'naturalism' almost irresistibly suggests such a special connection with the natural sciences. Central to Quine’s naturalism is his privileging of fundamental physics as our best theory of the world, and a reductionist attitude to everything else. Such dogmas tend to be smuggled in under the naturalist label with remarkably little supporting argument, just the implied threat that the only alternative is superstition. How drastically impoverished a view of the philosophical options!
Bianchi seems to assimilate my devaluing of the distinction between the a priori and the a posteriori to a Quinean rejection of the a priori: 'If armchair philosophy is philosophy supposedly pursued by traditional a priori methods, then certainly philosophical naturalism rules it out, but Williamson does not like it, either.' I do indeed regard the traditional stereotype of a priori knowledge as almost useless for purposes of serious epistemology, but he neglects to add that I regard the traditional stereotype of a posteriori knowledge as equally useless. My attitude to the distinction does not mandate a conception of philosophy modelled exclusively or even primarily on the natural sciences. There is no barrier in principle between philosophy and physics; equally, there is no barrier in principle between philosophy and mathematics. Unless the natural sciences include the social sciences and the humanities (in which case the term 'natural science' is uninformatively broad), analogies with disciplines such as economics, linguistics, and history point up other significant and legitimate aspects of philosophy obscured by analogies with the natural sciences.
Bianchi’s description of the starting-point of philosophy as 'empirical data' also suggests a special connection between philosophy and the natural sciences. The unclear term 'empirical' seems to imply 'a posteriori.' Of course, I agree that any data that may be legitimately used in the natural sciences may in principle be legitimately used in philosophy too: the only question is whether they do in fact bear on the question at hand. I also agree that in practice such data sometimes are applied effectively in philosophy. But I also hold that any knowledge that may legitimately be used in mathematics may in principle be legitimately used in philosophy too, and that in practice effective philosophical applications are made of such knowledge. To describe mathematics as theorizing starting from 'empirical data' too would be to stretch the description to the point of uninformativeness. Although some parts of philosophy (such as the metaphysics of space, time, and matter) are closer to physics than to mathematics, other parts (such as philosophical logic) are closer to mathematics than to physics. If we cannot understand philosophy by classifying it as a priori, no more can we understand it by classifying it as a posteriori.1

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of this book in Richard Davies (ed.), Analisi: Annuario e Bollettino della Società Italiana di Filosofia Analytica (SIFA)
2011 (Williamson 2011f). I thank Andrea Bianchi for the care and attention he spent on the book. Like him, I focus on points of divergence. All page references are to the first edition. 23-08-2021 14:47:43 11.4 What is Naturalism?
In the first edition, I defended a view of philosophy as much less different in aims and methods from other forms of intellectual inquiry than its self-images usually suggest. Some commentators treated this anti-exceptionalism about philosophy as a form of naturalism, and wondered why I did not characterize it explicitly as such. I will explain why not.
Many contemporary philosophers describe themselves as naturalists. They mean that they believe something like this: there is only the natural world, and the best way to find out about it is by the scientific method. So why do I resist being described as a naturalist? Not for any religious scruple: I am an atheist of the most straightforward kind. But to accept the naturalist slogan without looking beneath the slick packaging is an unscientific way to form one’s beliefs about the world, so not something that even naturalists should recommend.
What, for a start, is the natural world? If we define it as the world of matter, or the world of atoms, we are left behind by modern physics, which characterizes the world in far more abstract terms. Anyway, the best current scientific theories will probably be superseded by future scientific developments in various respects. Naturalism is not intended to be hostage to the details of scientific progress. We might therefore define the natural world as whatever the scientific method eventually discovers. Thus naturalism becomes the belief that there is only whatever the scientific method eventually discovers, and
(not surprisingly) the best way to find out about it is by the scientific method. That is no tautology. It is not self-evident that there cannot be things only discoverable by non-scientific means, or not discoverable at all.
Still, naturalism is less restrictive than one might think. For example, some of its hard-nosed advocates undertake to postulate a soul or a god, if doing so turns out to be part of the best explanation of our experience, for that would be an application of scientific method.
Naturalism is not incompatible in principle with all forms of religion.
In practice, however, most naturalists doubt that belief in souls or gods withstands scientific scrutiny.
What is meant by 'the scientific method?' Why assume that science only has one method? For naturalists, although natural sciences like physics and biology differ from each other in specific ways, at a sufficiently abstract level they all count as using a single general method. It involves formulating theoretical hypotheses and testing their predictions against systematic observation and controlled experiment. This is the hypothetico-deductive method.
One challenge to naturalism is to find a place for mathematics.
Natural sciences rely on it, but should we count it a science in its own right? If we do, then the description of scientific method just given is wrong, for it does not fit the science of mathematics, which proves its results by pure reasoning, rather than the hypothetico-deductive method. Although a few naturalists, such as Quine, argue that the real evidence in favor of mathematics comes from its applications in the natural sciences, so indirectly from observation and experiment, that view does not fit the way the subject actually develops. When mathematicians assess a proposed new axiom, they look at its consequences within mathematics, not outside. On the other hand, if we do not count pure mathematics a science, we thereby exclude mathematical proof by itself from the scientific method, and so discredit naturalism. For naturalism privileges the scientific method over all others, and mathematics is one of the most spectacular success stories in the history of human knowledge.
Which other disciplines count as science? Logic? Linguistics?
History? Literary theory? How should we decide? The dilemma for naturalists is this. If they are too inclusive in what they count as science, naturalism loses its bite. Naturalists typically criticize some traditional forms of philosophy as insufficiently scientific, because they ignore experimental tests. How can they maintain such objections unless they restrict scientific method to hypothetico-deductivism? But if they are too exclusive in what they count as science, naturalism loses its credibility, by imposing a method appropriate to natural science on areas where it is inappropriate. Unfortunately, rather than clarify the issue, many naturalists oscillate. When on the attack, they assume an exclusive understanding of science as hypothetico-deductive. When under attack themselves, they fall back on a more inclusive understanding of science that drastically waters down naturalism. Such maneuvering makes naturalism an obscure article of faith. I don’t call myself a naturalist because I don’t want to be implicated in equivocal dogma. Dismissing an idea as 'inconsistent with naturalism' is little better than dismissing it as 'inconsistent with Christianity.'
Still, I sympathize with one motive behind naturalism, the aspiration to think in a scientific spirit. It’s a vague phrase, but one might start to explain it by emphasizing values like curiosity, honesty, accuracy, precision, and rigor. What matters isn’t paying lip-service to those qualities – that’s easy – but actually exemplifying them in practice – the hard part. To speak of the scientific spirit is not to make the naïve (and unscientific) claim that scientists’ motives are always pure.
They are human. Science doesn’t depend on indifference to fame, professional advancement, money, or comparisons with rivals. Rather, truth is best pursued in social environments, intellectual communities, that minimize conflict between such baser motives and the scientific spirit, by rewarding work that embodies the scientific virtues. Such traditions exist, and not just in natural science.
The scientific spirit is as relevant in mathematics, history, philosophy, and elsewhere as in natural science. Where experimentation is the likeliest way to answer a question correctly, the scientific spirit calls for the experiments to be done; where other methods – mathematical proof, archival research, philosophical reasoning – are more relevant it calls for them instead. Although the methods of natural science could beneficially be applied more widely than they have been so far, the default assumption must be that the practitioners of a wellestablished discipline know what they are doing, and use the available methods most appropriate for answering its questions. Exceptions may result from a conservative tradition, or one that does not value the scientific spirit. Still, impatience with all methods except those of natural science is a poor basis on which to identify those exceptions.
Naturalism tries to condense the scientific spirit into a philosophical theory. But no theory can replace that spirit, for any theory can be applied in an unscientific spirit, as a polemical device to reinforce prejudice. Naturalism as dogma is one more enemy of the scientific spirit.
Philosophy should be done in a scientific spirit. Therefore we should not do it by invoking slogans about naturalism, or dismissing philosophical theories or methods on the basis of results in natural science whose relevance to them is unclear, or engaging in any of the other forms of lazy-mindedness that the word 'naturalism' has so striking a capacity to encourage. Acknowledgment
This section originally appeared in Matthew Haug (ed.), Philosophical Methodology: The Armchair or the Laboratory? (Routledge) as
Williamson 2013d. 11.5 The Unclarity of Naturalism
In response to my question 'What is Naturalism?,' Alex Rosenberg
(2013a) defines it as 'the philosophical theory that treats science as our most reliable source of knowledge and scientific method as the most effective route to knowledge.' In 'Why I Am a Naturalist,' he nicely exemplifies one of my main complaints, by leaving it unclear what he means by 'science' or 'scientific method,' even though it is crucial for what he is committing himself to as a 'naturalist.'
Still, there are clues. He describes 'the test of knowledge that scientific findings attain' as 'experimental/observational methods,' which suggests that theorems of mathematics would not count as scientific
findings. The impression is confirmed by Rosenberg’s phrase 'mathematicians and scientists,' as though he doesn’t see mathematicians as scientists. That’s bad news for his naturalism, for mathematical proof is just as effective a route to knowledge as experimental/observational methods. Of course, since the natural sciences depend on mathematics, Rosenberg is desperate to find a place for it – but admits that he doesn’t know how.
In just the way I noted, Rosenberg’s defense of naturalism trades on ambiguities between boring truths and obvious falsehoods. Rightly noting the successes of physics, he says 'We should be confident that it will do better than any other approach at getting things right.'
Which things? If he means questions of physics, what reasonable person denies that physics will do better than any other approach at answering those questions? But if he means all questions, why on earth should we be confident that physics will do better than history at getting right what happened at Gettysburg?
I raised history and literary theory as further test cases. According to Rosenberg, naturalism treats literary criticism as fun, but not as knowledge. Does he really not know whether Mr. Collins is the hero of Pride and Prejudice? Every normal reader has that sort of elementary literary critical knowledge. Those who know far more about the historical context in which literary works were produced, read them many times with unusual attention, carefully analyze their structure, and so on, naturally have far more knowledge of those works than casual readers do, whatever the excesses of post-modernism. As for history, Rosenberg leaves the question of whether it should count as science open. He doubts that it can provide 'predictively useful knowledge.' Scientific predictions about complex systems with initial conditions of which we have only approximate knowledge are probabilistic. Historical knowledge enables us to make probabilistic predictions too: for example, that if a US president publicly describes his policy on the Middle East as a 'crusade,' it is more likely to inflame than to calm the situation. Does Rosenberg really think that historical knowledge of the past records of politicians is of zero value in making probabilistic predictions about their future behavior? It isn’t even clear how natural science could manage without historical knowledge, as Collingwood long ago pointed out, since knowledge of the results of past experiments and observations is itself historical.
Rosenberg apparently expects it to turn out that 'reality contains only the kinds of things that hard science recognizes.' By 'hard science' he presumably means something like physics. He doesn’t explain how that could turn out. How could physics show that reality contains only the kinds of things that physics recognizes? It sounds embarrassingly like physics acting as judge and jury in its own case.
That physics does not show that there is such a thing as a debt crisis does not mean that physics shows that there is no such thing as a debt crisis: physics simply does not address the question. That is no criticism of physics; it has other work to do. For it to turn out that reality contains only the kinds of things that hard science recognizes, where they exclude things like debt crises, it would have to turn out that a radically reductionist metaphysical theory is true. That in turn would require industrial-scale argument at a characteristically philosophical level of reasoning. Does Rosenberg count philosophy as hard science?
We can formulate the underlying worry as a sharp argument against the extreme naturalist claim that all truths are discoverable by hard science. If it is true that all truths are discoverable by hard science, then it is discoverable by hard science that all truths are discoverable by hard science. But it is not discoverable by hard science that all truths are discoverable by hard science. Therefore the extreme naturalist claim is not true. 'Are all truths discoverable by hard science?' is not itself a question of hard science. Truth is a logical or semantic property, discoverability an epistemic one, and hard science a social process. Although truths discoverable by hard science may be relevant to whether all truths are discoverable by hard science, by themselves they do not answer the question, since they are framed in the wrong terms – for example, those of physics.
Such problems pose far less threat to more moderate forms of naturalism, based on a broader conception of science that includes mathematics, history, much of philosophy, and the sensible parts of literary criticism, as well as the natural and social sciences. But we should not take for granted that reality contains only the kinds of things that science even in the broad sense recognizes. My caution comes not from any sympathy for mysterious kinds of cognition alien to science in the broad sense, but simply from the difficulty of establishing in any remotely scientific way that reality contains only the kinds of thing that we are capable of recognizing at all. In any case,
Rosenberg does not rest content with some moderate form of naturalism. He goes for something far more extreme, in the process lapsing into hard scientism.
Rosenberg concludes: 'What naturalists really fear is not becoming dogmatic or giving up the scientific spirit. It’s the threat that the science will end up showing that much of what we cherish as meaningful in human life is illusory.' But what people really fear is not always what most endangers them. Those most confident of being undogmatic and possessing the scientific spirit may thereby become all the less able to detect dogmatism and failures of the scientific spirit in themselves. If one tries to assess naturalism in a scientific spirit, one will want to get more precise than most self-labelled naturalists
(and anti-naturalists) do about what hypothesis is under test. Nor will one dogmatically assume that, once a clear hypothesis is on the table, testing it will be just a matter for hard science. The evidence so far suggests otherwise.

Acknowledgment
This section originally appeared in Matthew Haug (ed.), Philosophical Methodology: The Armchair or the Laboratory? (Routledge) as
Williamson 2013e. 11.6  On Penelope Maddy’s What Do
Philosophers Do? Skepticism and the
Practice of Philosophy
The hero of this book, whom the author clearly admires, goes by the title of the Plain Inquirer. This generic character is the child of the
Plain Man. At the beginning of the book she sets off from her birthplace in common sense to explore the world, driven by scientific curiosity. She encounters a variety of philosophers, including Descartes,
Locke, Berkeley, Hume, Reid, Moore, Austin, and Wittgenstein, and occasionally glimpses the darker shadow of the contemporary epistemologist. Some of the philosophers try to lure the Plain Inquirer into more radical projects than science requires, but she is never seriously tempted, though she respects their contributions to early vision science and other approved activities. She learns from twentieth-century therapists how weaker spirits fell. The book, based on Maddy’s Phi
Beta Kappa Romanell Lectures for the public understanding of philosophy, is accessible to non-philosophers, though professionals will find plenty of interest. The text has been left as for lectures, with plural 'you' and tasters of what will happen 'next time.'
The first lecture concerns Descartes’ dream argument. When asked
'How do you know you’re not dreaming?,' the Plain Inquirer follows
Austin and contemporary science by pointing out various differences between ordinary dreaming and waking experience. In response, the skeptic raises the stakes by asking, as Maddy puts it, 'How do you know you’re not extraordinary dreaming?' Extraordinary dreams have all the sensory fullness and narrative coherence attributed to waking experience; their content includes all of Plain Inquiry. The
Plain Inquirer dismisses that extraordinary question, rightly insisting that the achievements of Plain Inquiry do not depend on being proved 'from scratch,' a starting-point neutral between scientifically informed common sense on one side and the extraordinary dream hypothesis on the other – though she is disappointingly willing to retreat from proclaiming such achievements as knowledge and describe them only as 'probable opinions' instead, in the all-purpose name of fallibilism.
Slightly disingenuously, the Plain Inquirer treats the extraordinary dream question as if it came quite out of the blue, with no affinity to her methods of inquiry. Yet she was reared in the assumptions and methods of the Plain Man, many of which she later had to question and even reject. That must often have involved asking whether she had any independent evidence for the reliability of the assumptions and methods at issue, and at least temporarily distancing herself from them while looking elsewhere for support. Perhaps, for instance, she grew up relying on her father’s stories about their ancestors for her view of the distant past, and later wondered whether what he said happened really did happen; she suspended her belief in his stories, and sought different sources of information. In the long run, the result is the serious discipline of history, a Plain Inquiry by any nonphilistine standard. We may agree with Maddy that the extraordinary dream question takes that form of testing too far, but insist that even
Plain Inquiry involves discovering the limitations of our methods by taking them beyond the limits of workability. We have to try meeting the extraordinary dream challenge if we are to understand why it is unreasonable. Similarly, if we want to learn the limitations of mathematical methods, we must be willing to try applying them in areas where they may (or may not) turn out unfruitful. Curiosity killed the cat. The Plain Inquirer should accept that her curiosity will sometimes take her into intellectual danger.
The second lecture concerns the notorious argument from illusion, representative theories of perception, and the corollaries skeptics draw from them. The Plain Inquirer rejects the representative theories as inconsistent with the modern science of perception. Local skeptical questions about perception in specific circumstances are answered by common sense and scientific results about perception in those circumstances. Global skeptical questions about perception as such are rejected as involving an unreasonably radical demand for a basic cognitive faculty to be certified as reliable by other faculties. Maddy rightly emphasizes the weirdness of the idea, still found in some contemporary internalist epistemology, that introspection has epistemic priority over perception, but her central objection is to demands on the Plain Inquirer to justify her methods 'from scratch.'
The third lecture interprets Moore’s much-maligned proof of an external world congenially to the Plain Inquirer, as putting the skeptic on the spot, by meeting the challenge to provide such a proof with a counter-challenge to explain exactly what standard of proof is being demanded and why the demand is legitimate. Wittgenstein is inter- preted as a therapist who may cure us of the sick tendency to make such demands, but philosophy escapes being sentenced to be nothing without the sickness, 'a sadly crimped view of the philosophical project' (200). It is allowed to survive as a humble part of Plain Inquiry,
'employing just common sense and ordinary empirical methods'; the latter can 'include some more specialized tools, like ordinary language investigations, appropriate conceptual analyses, and therapeutic cautions' (220).
Although the title asks 'What do philosophers do?,' much of the book is about what philosophers should do. Contemporary philosophers are portrayed as often straying beyond the bounds of Plain Inquiry, and suffering the predictable consequences. Epistemologists are singled out as wrongdoers. Epistemology since Gettier is represented as sterile and inward-looking, having lost touch with natural science, obsessed with increasingly complex counterexamples in the pointless search for an analysis of the concept of knowledge, and neglecting
'the central question of how we manage to acquire reliable information about the world' (214). Plain Inquiry is capacious, but not all-inclusive.
Maddy’s assessment of current epistemology is neither completely wrong nor completely fair. In one respect it is out of date. Increasingly, epistemologists see themselves as studying knowledge itself, not the concept knowledge. They want to understand the nature of epistemological states, not our concepts of those states. Contrary to Maddy’s account, they are not doing conceptual analysis. However, if her critique of attempts to analyze the concept knowledge were sound, it would also devastate many other current epistemological projects.
She endorses Austin’s nominalistic deriding of 'concept' talk; in her summary: 'there are no concepts, the linguistic usage is all there is'
(66). If her argument shows that there is no concept knowledge, it also shows that there is no relation of knowing (or second-order analogue thereof), and no extension, intension, or Kaplan-style character of the word 'know.' Attempts to study knowledge itself would be as futile as attempts to study the concept knowledge.
Shouldn’t the Plain Inquirer’s curiosity extend to language? Semantics, as a branch of linguistics, is working towards systematic compositional theories of meaning for natural languages. The bestdeveloped such theories provide a general account of the semantic contribution of factive verbs like 'know,' which depends in effect on their having something like an intension in a context. The intension of the word 'know' in an ordinary context is close enough to a relation of knowing for the analytic epistemologist’s project to get started, on terms the Plain Inquirer has no business rejecting.
Of course, 'know' may have different intensions in different contexts. But epistemologists are well aware of that possibility, and have been investigating it for decades. Indeed, such inquiries into linguistic usage have 1950s’ ordinary language philosophy in their ancestry, but they demonstrate the need to go beyond piecemeal observations by interpreting them within a well-developed theoretical framework.
Austin himself was far from anti-theoretical, as his work on speech acts shows.
Maddy cites Weinberg, Nichols, and Stich’s famous 2001 paper
'Normativity and Epistemic Intuitions' for evidence of cross-cultural variations in the use of 'know,' for instance on Gettier cases, which might threaten the interest of the analytic project (62n). She does not mention that numerous more recent and methodologically more careful papers have failed to reproduce their results. Instead, they provide evidence of remarkable cross-cultural similarities in judgments about such cases.
To illustrate contemporary epistemology’s damaging preoccupation with 'ever-more-complex problem cases,' Maddy quotes a long description of one from a recent book by Ernest Sosa, and relates it to issues about knowledge (205). But Sosa’s case can just as easily be used to explain subtle distinctions concerning 'how we manage to acquire reliable information about the world,' which Maddy describes as 'the central question' of good epistemology. For instance, in the quoted passage, Sosa says: my judgments of tomato ripeness are in general apt to be right with no better than even chance. But when it’s the particular (and rare) shade of red now displayed, then I am nearly infallible.

Isn’t that about acquiring reliable information about the world? Presumably, philosophers are allowed to give complex counterexamples to conjectures; mathematicians do it all the time. Perhaps Maddy thinks that epistemology would be better done in terms of reliable information than of knowledge. But 'reliable information' is no more precise or scientific than 'knowledge'; both 'reliable' and 'informa- tion' are notoriously slippery words. It is not even clear how reliable information is supposed to differ from knowledge. With the skeptic’s arguments defused, realistic standards for knowledge can be applied, as they typically are by contemporary epistemologists. The reader is left with very little idea of how in practice the Plain Inquirer would go about doing epistemology differently.
Maddy is surely right that 'no unusual, exclusively philosophical methods appear to be required' for doing philosophy (210). Indeed, no unusual, exclusively philosophical methods are required. The methods used elsewhere suffice, though philosophers may sometimes use them more systematically, carefully, and reflectively. Thought experimentation may be an example.
However, the assumption that there are no exclusively philosophical methods leaves philosophy with more flexibility and autonomy than the reader might be led to suppose. For instance, Maddy does not mention the use of formal methods. Such methods are of course not exclusive to philosophy, but they permit far more ambitious and rigorous constructive philosophical theorizing than she hints at. In particular, there are two main traditions of formal epistemology,
Bayesian probabilism and epistemic logic, both mathematically highly developed. Philosophers such as Frank Ramsey and Jaakko Hintikka played a key in the growth of both branches. The methods of formal epistemology cannot happily be subsumed under Maddy’s concluding description of 'common sense and ordinary empirical methods,'
including 'ordinary language investigations, appropriate conceptual analyses, and therapeutic cautions.' Although both kinds of formal epistemology have been successfully applied in broadly 'empirical'
disciplines such as economics, that does not make their methods any more distinctively empirical than those of mathematics.
Some formal epistemology could have been applied with advantage to Maddy’s Appendix B, on skepticism and the closure of knowledge under deduction. She formalizes a skeptical argument thus:
(i) I don’t know I’m not extraordinary dreaming.
(ii) If this is a hand, then I’m not extraordinary dreaming.
(iii) Therefore, I don’t know this is a hand.
She observes 'that (iii) doesn’t follow from [TW: (i) and] (ii) alone, that I have to be aware of the logical connection in (ii)' and so makes that assumption (230). But there is no logical connection in (ii). Not only does 'if' not specify a logical connection, 'this is a hand' does not logically entail 'I’m not extraordinary dreaming.' The connection, such as it is, depends on the meaning of the non-logical constant
'dreaming'; moreover, in the possible situation in which I fall asleep and have an extraordinary dream while my hand remains intact, the antecedent of (ii) is true and the consequent false. The connection is at best pragmatic: perhaps I can correctly interpret the perceptual demonstrative 'this' only when awake.
Probabilistic distinctions would have clarified the subsequent argument, where Maddy writes 'What makes Closure compelling, after all, is the thought that if p implies q, then any evidence I have for p ought to serve just as well as evidence for q' (231). If evidence for a proposition is what raises its probability, that principle is false. For instance, if p is the proposition that the die came up 6, and q is the proposition that the die did not come up 2 or 4, then p implies q, but if our evidence is just that the die came up even, it raises the probability of p from 1/6 to 1/3 while lowering that of q from 2/3 to 1/3.
Of course, Maddy’s principle holds on another interpretation, where evidence for a proposition is what its probability is high on, but distinguishing such interpretations matters when the transmission of evidence is at issue, as in Maddy’s argument.
The Plain Inquirer comes across as ambivalent about philosophy, drawn to the inquiry but scared of losing her reputation for plainness.
We wouldn’t expect such a half-hearted approach to achieve much in natural science. Why should it do better in philosophy?

Acknowledgment
This section first appeared as a review of Maddy 2017 in The Journal of Philosophy (Williamson 2017d).

c11.indd 496 12
Concepts, Understanding,
Analyticity

12.1 Reply to Jackson
Frank Jackson’s 'Thought Experiments and Possibilities' (Jackson
2009) exhibits a failure to comprehend the extent of the difference between my position and his. In consequence, his arguments are question-begging, because they treat as common ground features of his position that the first edition explicitly calls into question.
A case in point is Jackson’s talk of 'conceptual possibility' and
'conceptual necessity.' He writes as if the issue between us is the relative methodological priority for philosophy of conceptual modalities and metaphysical modalities: he ranks the former before the latter;
I reverse the order. He says 'Williamson isn’t telling us that we cannot learn anything about what’s conceptually possible,' as if I accept such a notion. But the longest chapter in the book (75–135, this volume) is an attack on exactly the sort of epistemological conception of analyticity on which Jackson’s appeals to conceptual modalities rely: the idea of matters on which we must agree in order to share a meaning or concept. Although he provides no explanation of the phrases 'conceptually possible' and 'conceptually necessary,' his use of them makes clear that he has something of the sort in mind.
In effect, my book argues that there is no such thing as conceptual necessity.
Perhaps Jackson was misled by the passage he quotes from page
208 (this volume), in which for the sake of argument I grant a notion of conceptual possibility in order to argue that thought experiments lose much of their interest if their upshot is characterized in such terms – and that conceptual possibility (unlike metaphysical  ossibility) does not interact logically in the required way with the p
counterfactuals that play a central role in thought experiments,
although he does not mention the latter point. He also does not mention that the discussion there ends with a reminder that the idea of conceptual modality has already been rejected on the basis of the 
arguments against epistemological conceptions of analyticity
(208–9, this volume).
According to Jackson: the most serious problem for Williamson’s 'metaphysical possibility first' thesis […] lies in the fact that that our best reasons for concluding that certain claims which aren’t conceptually necessary are metaphysically necessary derive from claims that are about what is or is not conceptually necessary conjoined with a posteriori claims […].

In addition to the uncritical reliance on conceptual modality, another fallacy is surfacing here. Jackson’s view makes conceptual necessity an epistemological status. But even if the epistemological status of our conclusion that something is metaphysically necessary depended on the epistemological status of some premise as conceptually necessary, it would not follow that the proposition that something was conceptually necessary occurred anywhere in the reasoning for the conclusion, as required by his claim that the reasoning is primarily about the conceptual status of the propositions at issue.
A related question-begging feature of Jackson’s discussion here is that he freely appeals to a distinction between the 'a priori' and the
'a posteriori,' without addressing the argument in the book for the untrustworthiness of such a distinction (167–71, this volume).
Although Jackson frequently takes for granted what the book rejects, he does make some comments that bear on the reasons for that rejection. In effect defending an epistemological conception of analyticity, he writes: 'communication and knowing what we are disagreeing (or agreeing) about requires substantial agreement about what the words we read and hear signify'; where that is lacking,
'we aren’t, or need not be, in disagreement.' The passage fudges the crucial distinction. If I say 'Spurs will win' and you say 'Leeds will win' but the word 'win' differs in meaning between your mouth and mine, we may not be disagreeing or properly communicating about the match, even if we think we are. If 'win' has the same meaning in your mouth and mine, we are (ceteris paribus) disagreeing and properly communicating. That is just semantic agreement in the sense of synonymy. It goes no way whatsoever towards establishing what
Jackson needs, that synonymy requires agreement in opinion on some privileged questions. His wording suggests that he may have in mind agreement in opinion on metalinguistic matters. But that is primarily relevant to whether we think we are disagreeing about the initial question, not to whether we actually are. Nor does it address the arguments in the book specifically directed against attempts to save epistemological conceptions of analyticity by appeal to metalinguistic beliefs (111–14, this volume).
In past writings, Jackson defended the idea that shared meanings require shared opinions only by suggesting that there is nothing else for the sharing of meanings to consist in. The first edition responds to that suggestion at length by explaining how the unity of a shared linguistic practice with a word does not require privileged points of agreement and the practice can determine the semantic properties with which all participants use the word (123–31, this volume). Unfortunately, his response does not engage with this alternative.
Jackson conjectures that philosophers with deviant responses to
Gettier cases may express a different concept by the word 'knowledge,' but does not say why it should be classified as a difference of concept rather than of opinion. His introduction of concepts as 'our way of categorizing our world' is notably unhelpful in this respect, since there are many different ways of individuating ways. In one way, someone who relies on The Guardian in categorizing politicians as 'trustworthy' or 'untrustworthy' is categorizing in a different way from someone who relies on The Daily Telegraph, but it does not follow that they mean different things by the word 'trustworthy.'
In another way, two people who use a word with the same extension use it to categorize in the same way, even if they use it with different intensions. Jackson provides no standard of sameness for concepts or ways of categorizing. If attributing different concepts of 'knowledge' to philosophers who respond differently to Gettier cases is just another way of saying that they respond differently, then the terminology is radically misleading. The central question is whether they use the word 'knowledge' with the same reference. That is entirely consistent with responding differently to Gettier cases. Consider a class of law students given a statute and a hypothetical case and asked to apply the former to the latter. That they submit different answers is not good evidence of a failure of coreference in their words. They have noticed different features of the statute and the case, assigned different weights to competing considerations. Why should philosophical thought experiments be so different?
Although there is no law against using a common word with an idiosyncratic sense, that is not what philosophers usually do. They want to engage with other philosophers, and in order to do so hold themselves responsible to the public meanings of their words, while using them to deny what others assert. Unorthodox philosophers who think that there is knowledge in Gettier cases are disagreeing with the rest of us, and we should not pretend otherwise. How much progress would one make in philosophy by classifying objectors as expressing different concepts with their words, whether they like it or not?
Jackson’s comments fail to answer the arguments of the book against epistemological conceptions of analyticity. Gettier cases tell us something about knowledge and – less directly – something about what we believe about knowledge. Although we can recycle that information as information about words or concepts, we gain little from doing so. If not all justified true belief is knowledge, then not everything in the extension of the words 'justified true belief'
or of the concept justified true belief is in the extension of the word
'knowledge' or of the concept knowledge, simply because all and only justified true belief is in the extension of 'justified true belief'
or justified true belief and all and only knowledge is in the extension of 'knowledge' or knowledge. Similarly, if people believe that not all justified true belief is knowledge, then they probably also believe that not everything in the extension of 'justified true belief' or justified true belief is in the extension of 'knowledge' or knowledge, if they have the relevant disquotational beliefs. But there is no reason to think of the information we gain from philosophical thought
experiments as somehow bearing primarily on words or concepts and only secondarily on what those words or concepts about. The first edition provides a far more straightforward account, which Jackson has failed to undermine.
Jackson briefly suggests that conceptual analysis contributes to other sciences:

c12.indd 500 Concepts, Understanding, Analyticity   501
Statisticians discuss the best way to analyze the concepts of randomness and probability; physicist discuss the best way to analyze the probabilities that figure in the equations of quantum theory; biologists discuss which concepts of species and genes are best for their purposes.

None of these examples helps his case. He is right, of course, that armchair theorizing of such kinds plays a valuable role in science.
But it is not conceptual analysis in a distinctively Jacksonian sense, inquiry into the bounds of conceptual possibility for given concepts.
When biologists discuss which concepts of species and genes are best for their purposes, they are discussing which distinctions it would be most useful to draw, which questions it would be most fruitful to ask.
That may come down to asking what it would be best to mean by the words 'species' and 'gene'; it does not come down to asking what we currently mean by them. Nor is Jackson dialectically entitled to assume that word meanings are individuated by conceptual possibility.
When physicists discuss the best way to analyze the probabilities that figure in the equations of quantum theory, they are discussing what in physical reality or our knowledge of it corresponds to the probability terms in those equations, on the assumption that our current ways of thinking about them may well be inadequate. When statisticians discuss the best way to analyze the concepts of randomness and probability, they are probably discussing both what there is to mean and what it is best to mean. In no case is the armchair theorizing primarily driven by conceptual competence. In that respect it illustrates a major theme of the book.

Acknowledgments
This section first appeared as part of my contribution to a symposium on the first edition of the book in Analysis Reviews (Williamson
2009a). I thank Frank Jackson for his interesting comments, which help bring into relief some main themes of the book. 12.2 Reply to Boghossian
In 'Williamson on the A Priori and the Analytic' (Boghossian 2011),
Paul Boghossian defends a conception of a priori knowledge as knowledge in which sense experience plays a purely enabling role: we know a priori that all green things are colored even though sense experience was crucial to our acquisition of the concept of green, for that is a purely enabling role. On Boghossian’s conception, assent conditions on concept possession are central to at least some a priori knowledge, especially of logic. His defense of this view involves him in resisting the arguments of the first edition at several points. In particular, Boghossian maintains that the book’s objections to understanding-assent links (assent conditions on concept possession) do not generalize as far as I claim; he rejects my alternative model of understanding, on which understanding-assent links are not required. I will explain why
Boghossian’s critique leaves me unmoved.
In previous work, Boghossian developed an epistemology of logic based on understanding-assent links corresponding to fundamental rules of logic. His paradigm was modus ponens: a necessary condition for understanding 'if' was supposed to be willingness to assent to inferences by modus ponens involving 'if.' The book presents a series of counterexamples, some actual, some possible, to such putative understanding-assent links, for both modus ponens and other equally fundamental rules (87–123, this volume). The counterexamples concern native speakers of a natural language who come to understand the logical words at issue in the usual way but then go in for deviant logical theorizing without losing their linguistic competence; most philosophers know such people. In response, Boghossian picks what he regards as the clearest understanding-assent link, willingness to assent to 'and'-elimination (the inference from 'P and Q' to 'P' or to 'Q') as a condition for understanding 'and,' and denies that the counterexamples I propose to it (97–8, this volume) make sense.
Strategically, Boghossian’s response is not very promising. If he can rely on understanding-assent links only for 'and'-elimination and a few other equally banal rules, but not for modus ponens or other fundamental principles, then he is in no position to base either a general epistemology of logic or a general account of the understanding of logical constants on understanding-assent links. It is a little lame for him to claim in effect that not every fundamental rule of logic is a counterexample to his original account. A bolder strategy for him would be to seek a way of defending the claim that no fundamental rule of logic is a counterexample to his original account, and in particular of defending his original test case, modus ponens, as a putative understanding-assent link for 'if' against my counterexamples. In keeping away from the bolder strategy, Boghossian concedes so much ground that it is quite unclear what his fallback general epistemology of logic or his fallback general account of the understanding of logical constants could be.
In any case, Boghossian’s defense of 'and'-elimination as a putative understanding-assent link for 'and' is unconvincing. Boghossian notes that in some circumstances my proposed counterexample, Simon, will assent to (1) but not to (2):
(1) Booth saw the balding Lincoln and shot him.
(2) Booth shot Lincoln.
Obviously, if we have just met Simon, and know nothing about his background beliefs, we are likely to find his combined reactions to
(1) and (2) utterly bewildering. We may reasonably wonder whether he knows what the word 'and' means. In practice, independently of his reaction to (1), since it is so well known that Booth shot Lincoln we may also find Simon’s rejection of (2) initially puzzling, and wonder whether he is using the name 'Booth' to refer to the man we mean. Once we become aware of Simon’s conspiracy theory of the assassination, we realize that there was no linguistic misunderstanding over (2); we simply disagree with him about the historical facts.
Similarly, once we become aware of Simon’s deviant theory of logic, an explanation of his unwillingness to deduce (2) from (1) in terms of linguistic incompetence looks much less attractive. On theoretical grounds, Simon holds that borderline cases for vague terms induce truth-value gaps, and that such gaps should be treated by Kleene’s weak three-valued tables, which coincide with the classical two-valued tables when all the constituent sub-sentences are true or false but make the complex sentence gappy when at least one sub-sentence is gappy. Simon also thinks that it is legitimate to assent to gappy sentences as well as to true ones; what matters is to avoid falsity. Since he thinks that Booth saw Lincoln and regards Lincoln as a borderline case for the vague term 'bald,' he thinks that 'Booth saw the balding
Lincoln' is gappy, and that (1) inherits its gappiness. He concludes that it is legitimate to assent to (1). The gappiness does not infect (2).
Simon rejects (2) as straightforwardly false.
Of course, Simon would be quick to point out that in conversational terms it would be highly misleading to assert (1) on grounds of its gappiness when one’s audience had no reason to suspect that one was doing so. In the absence of special background assumptions, asserting 'A(P)' leaves it open whether 'A(P)' is true or gappy, on
Simon’s view. If one knows that 'A(P)' is gappy because it has the gappy constituent 'P,' one can therefore make a simpler and more informative assertion by simply asserting that 'P' is gappy, omitting the other material in 'A(P)' as irrelevant. On Simon’s view, one can gain the effect of asserting that 'P' is gappy without going metalinguistic by asserting 'P and not P.' Thus if Simon asserts (1), his audience is entitled for Gricean reasons to assume that he is not doing so merely on the grounds that 'Lincoln was bald' is gappy, since otherwise he is being conversationally uncooperative and should have said something like 'Was Lincoln bald? Well, he was and he wasn’t'
instead. The default conversational assumption is that one is not dealing with borderline cases; under that assumption one can defeasibly move from 'P and Q' to 'P' and to 'Q.' Nevertheless, according to
Simon, the move is not deductively valid, and the case of (1) and (2)
is a counterexample.
Once Simon has explained his view, it is much less plausible that his unwillingness to infer (2) from (1) manifests linguistic incompetence. It looks much more like a case of theoretical disagreement.
Imagine a community in which no alternative to geocentrism has ever been contemplated. Now someone develops a heliocentric theory.
This first emerges one morning when she dissents from the assertion 'The sun has risen.' She agrees that before the sun was in that direction (pointing down) and now it is in this direction (pointing up), but refuses to conclude 'It has risen.' Initially, other speakers are utterly bewildered, and wonder whether she understands the word
'risen.' However, once she has explained her view, they realize that it is a case of cosmological disagreement. Whether or not her geocentric theory is really correct, and whether or not it really entails the literal falsity of 'The sun has risen,' her denial of that assertion does not constitute linguistic incompetence. Similarly, an unexplained refusal to conclude 'There are more natural numbers than even numbers'
from the two premises 'Every even number is a natural number' and
'Not every natural number is an even number' causes utter bewilderment amongst those unacquainted with Cantorian reasoning, and doubts as to whether the speaker understands the word 'more,' but filling in that reasoning makes it clear that no linguistic incompetence is involved. Unlike Copernicus and Cantor, Simon chose the wrong direction for theoretical unorthodoxy, but that does not make him linguistically incompetent.
Boghossian objects that Simon’s tolerance of assent to gappy statements undermines the presumption that he is assenting to them as true. Quite what Boghossian means by 'assenting to something as true' is unclear. If it means assenting to the explicit claim that it is true, then it involves too much theorizing on the speaker’s part to be pertinent here. For instance, some bad philosophers assent to 'The earth is not flat' but not to 'It is true that the earth is not flat,' on the grounds that Nietzsche or Derrida has deconstructed the idea of truth. Presumably Boghossian does not want their deviant inferential role for 'true' to make their inferential roles for all other words automatically deviant too. Many bad philosophers have quite sensible views about non-philosophical matters. Moreover, unsophisticated thinkers such as children may genuinely assent to various claims about their external environment without having an explicit concept of truth at all.
In any case, Simon applies the same weak Kleene treatment to the sentential operator 'it is true that' as he does to other sentential
operators. The classical two-valued truth-table for 'it is true that'
maps true to true and false to false; thus the corresponding weak
Kleene three-valued table for 'it is true that' maps true to true, gappy to gappy, and false to false. Thus 'It is true that A' always has the same status as 'A.' Consequently, Simon assents to 'It is true that A' when and only when he assents to 'A.' So far, his assenting to something looks like assenting to it as true.
Perhaps it is different when Simon goes meta-linguistic. Let 'T' be the predicate in his meta-language corresponding to the top line of his three-valued tables. If quoted occurrences of sentences do not count as constituents, then the object-language sentence 'A' is not a constituent of the meta-language sentence T('A'), and we may s uppose that T('A') is true when 'A' is on the top line but false when 'A' is on the second or third line. Thus when Simon regards 'A' as gappy, he will assent to 'A' but not to T('A'). Does that show that he is not really assenting to 'A' as true?
The easiest way to finesse that objection is by refining the example. Let Simon think of the weak Kleene tables as using a three-way classification into the definitely true, the indefinite, and the definitely false, and of being indefinite as a way of being true, indefinitely true. Thus, strictly speaking, 'T' does not mean true; it means definitely true. The failures of 'and'-elimination on this semantics have the same structure as before: 'A' is indefinite, so 'A and B'
is also indefinite, even though 'B' is definitely false. When Simon regards 'A' as gappy, he will assent to both 'A' and True('A'), which on his view is true when 'A' is definitely true or indefinite, although he will not assent to T('A'). Like Graham Priest, Simon is a dialetheist, for when he regards something as gappy he assents to it, to its negation, and their conjunction. Nevertheless, his theoretical aberrations provide no sound basis for denying that his assent is genuine.
Simon’s assent to both 'Lincoln was bald' and 'Lincoln was not bald' may be compared to our assent to both 'Every weapon of mass destruction in Iraq belonged to Al Qaeda' and 'No weapon of mass destruction in Iraq belonged to Al Qaeda': both are vacuously true, because there never were any weapons of mass destruction in Iraq. In both cases the assent is genuine, even though its unusual grounds defeat various expectations it might arouse in a hearer ignorant of those grounds. Simon regards both 'Lincoln was bald' and 'Lincoln was not bald' as something like vacuously true.
Thus the main counterexample in the book to the understandingassent link for 'and'-elimination goes through, despite Boghossian’s protests.
The book briefly mentions two other types of counterexample to the understanding-assent link for 'and'-elimination, one concerning actual and robust experimental evidence of a human tendency in some circumstances to treat conjunctions as more probable than their conjuncts, the other concerning possible speakers who dissent from one conjunct in the absence of the others because they mistake a false conversational implicature for a false entailment (96, this volume). Since Boghossian offers no objection to either of these types of counterexample, they too stand.1
In addition to contesting my main counterexample to the understanding-assent link for 'and'-elimination, Boghossian asks what competence with a logical word could consist in, if not in assent of the kind understanding-assent links require. The book sketches an alternative answer, one consequence of which is that when the word belongs to a public language, competence with it constitutively involves causal relations with other speakers of the language, which do not supervene on patterns of assent and dissent. As an analogy, consider what competence in the casual game of beach soccer consists in.
There is no rule R of beach soccer such that, necessarily, one is competent in beach soccer only if one assents to R. Someone who thinks that the slightly different rule R* is in force, rather than R, can still be competent in beach soccer. Oscar and Twin-Oscar may have the same intrinsic dispositions even though Oscar is competent (although not expert) in beach soccer while Twin-Oscar is not even competent in beach soccer, because the game played in Oscar’s world is beach soccer while the game played in Twin-Oscar’s world is beach twin-soccer, which differs from beach soccer in subtle respects of which neither
Oscar nor Twin-Oscar is aware. Once one has joined a game of beach soccer, it takes rather extreme deviance to get slung out. The same applies to participation in a linguistic practice. The unorthodox theorists who counterexemplify understanding-assent links remain competent with the relevant words because they maintain an adequate level of participation in the social practice of using those words. Of course, such remarks are only a beginning. The discussion in the first edition goes further (123–32, this volume), and far more remains to be done. Nevertheless, the analogy already shows the possibility of 23-08-2021 13:10:21 an account of linguistic competence that differs structurally from one based on understanding-assent links.
It is not clear that Boghossian has come to grips with the alternative model of linguistic competence. He asks how societies determine the social meanings that on my view a public language makes available to its speakers. He gives as my answer a sentence from the book:
'A complex web of interactions and dependences can hold a linguistic or conceptual practice together even in the absence of a common creed that all participants at all times are required to endorse' (127, this volume). Boghossian comments 'This repeats the rejection of inferentialism but without providing a substantive alternative.' But the quoted sentence was not intended to address the question of how societies determine social meanings. On my view of meaning, that would involve explaining how the referential properties of expressions of the language supervene on lower-level facts, for example about causal connections between uses of those expressions and objects in the environment. That is a huge task for the philosophy of language, whether the language is public or private. It was not the business of the book to attempt to carry out that task, although the comments in the final chapter on knowledge maximization as a principle of charity are at least relevant (264–75, this volume). The quoted sentence addressed a different question: what unifies a linguistic or conceptual practice enough for it to be a locus for the assignment of meanings, by contrast with a mere collection of such loci corresponding to the more or less similar idiolects of different speakers? The partial answer is that the unification consists in causal interrelations of speakers, not merely in their shared monadic properties. Since competence with the public language depends on participation in such a unity, an inferentialist account of competence in terms of understanding-assent links cannot be right, because it has the wrong structure: the understanding-assent links do not capture the causal interrelations. Even someone who rejects that alternative to inferentialism should be able to see that it is substantive on the point at issue.
Boghossian suggests that the inferentialist is better placed than I
am to handle empty terms such as 'phlogiston.' However, purported understanding-assent links for empty terms are subject to counterexamples of just the same sort as purported links for nonempty terms.
What is unusual about empty atomic terms such as 'phlogiston' is that knowing their referential properties (that they do not refer) is typically of little help in attaining competence with them, whereas knowing the referential properties of nonempty terms (what they refer to) is typically of great help in attaining competence with the latter. That difference is hardly surprising. It does nothing to show that the standard for competence is inferentialist in nature. Even the practice of using 'phlogiston' was unified by a complex web of interactions and dependences; it did not require a universally shared creed to hold it together.
Given the failure of Boghossian’s attempt to rehabilitate the appeal to understanding-assent links or epistemological analyticity, we may turn to his more general remarks about the a priori at the beginning of his piece. In the book, I argue that however the distinction between a priori and a posteriori knowledge is made precise, it does not cut very deep. Modal claims are used as a test case. The idea is that modal claims are logically equivalent to combinations of counterfactual conditionals, and that our cognitive capacity to handle the latter is what gives us the capacity to handle the former too. Our cognitive capacity to handle counterfactual conditionals involves the offline deployment of cognitive capacities originally developed online to handle the antecedents and consequents of those conditionals separately. Consider the example that
Boghossian quotes:

(3) It is necessary that whoever knows something believes it.
I argue that our knowledge of (3) does not involve an understandingassent link; there is no 'epistemologically analytic' connection between 'knows' and 'believes.' Rather, in a nutshell, our knowledge of (3) involves the offline deployment of concepts of knowledge and belief, in a way not radically different from that which occurs in our assessment of a contingent counterfactual such as:

(4) If Mary had known more about John, she would have believed that he was untrustworthy.
Whether we know (3) or (4) depends in part on our skill in applying the concepts of belief and knowledge. That skill was partly developed online, in the classification of cases encountered in sense experience as cases of knowledge or ignorance, belief or unbelief; those e ncounters are constitutively relevant to the epistemic status of our present applications of our concepts of knowledge and belief. Thus sense experience plays a more than purely enabling role in our knowledge of (3) as well as (4) (170, this volume). Yet our knowledge of
(3) would usually be classified as a paradigm of a priori knowledge.
But it would be no less crude to classify our knowledge of (3) as a posteriori, since sense experience does not play a strictly evidential role in that knowledge.
Boghossian complains that the argument ignores the possibility that the difference between those who grasp (3) and assent to it and those who grasp (3) and don’t assent may concern 'the exercise of a faculty of a priori insight' (although that is not his own view).
My argument is openly speculative. It attempts nothing like proof; that would be hopelessly premature for any account of the matter at this stage. Nevertheless, as the book emphasizes (164, this volume), considerations of theoretical economy and psychological plausibility strongly favor explanations of armchair knowledge that invoke more general cognitive capacities for which there is independent evidence
(such as our capacity to evaluate counterfactual conditionals) over accounts that postulate specialized faculties to do philosophically
exciting things for which there is no independent evidence.
Boghossian briefly expresses skepticism as to whether 'knowledge of modal claims can be reduced to knowledge of counterfactuals,'
on the grounds that 'on any plausible account, knowledge of logical, mathematical and constitutive truths will be presupposed in accounting for our knowledge of counterfactuals.' Those comments suggest a misunderstanding of what is at issue. Pace Boghossian, I did not claim that 'knowledge of modal claims is knowledge of counterfactual conditionals.' My point was rather that 'Despite the non-synonymy of the two sides, our cognitive capacity to evaluate the counterfactual conditionals gives us exactly what we need to evaluate the corresponding modal claims too' (164, this volume). More important, modal truths must be distinguished from necessary truths. A theorem of first-order non-modal logic expresses a necessary truth; it does not express a modal truth, for it employs no modal terms. 'It is necessary that 2 + 2 = 4 and John knows that 2 + 2 = 4' does not entail 'John knows that it is necessary that 2 + 2 = 4.' Logical, mathematical, and constitutive truths are typically necessary but not modal. Thus even when our prior knowledge of them plays a role in our knowledge of relevant counterfactual conditionals, that role does not imply any circularity in the account of our knowledge of modal truths. In particular, that role does not require us to have prior knowledge that the logical, mathematical, and constitutive truths are necessary; rather, that knowledge of modality is generated by the same means as the knowledge of counterfactuals. The book explains in more detail how the interplay of modal and counterfactual knowledge involves no circularity in its account (171–3, this volume).
The attraction of epistemological analyticity was that it promised to demystify a priori knowledge. If there were no promising alternative means to do that, we might have some reason to think that there must be understanding-assent link links, despite all the evidence that there are not. Once we see that our ability to handle counterfactual conditionals provides independent evidence of cognitive capacities that are well placed to explain armchair knowledge, we have no need to hanker after epistemological analyticity.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in Philosophy and Phenomenological
Research (Williamson 2011c). 12.3 Reply to Peacocke
In 'Understanding, Modality, Logical Operators' (Peacocke 2011),
Christopher Peacocke contests both the first edition’s epistemology of metaphysical modality and its account of linguistic understanding. I
discuss each challenge in turn.

1
The book explains our capacity to think about the esoteric topic of metaphysical modality as an accidental byproduct of our capacity to use mundane subjunctive conditionals. The explanation starts from the broadly logical equivalence of a claim of metaphysical necessity with a subjunctive conditional whose consequent is logically false, and the dual equivalence for a claim of metaphysical possibility (159, this volume):
A ≡ (¬A →⊥)
◊A ≡ ¬(A →⊥)
Here ⊥ is a logically false sentence. Peacocke concedes these equivalences but denies their epistemological and explanatory significance.
In particular, he argues that neither of them constitutes an 'explanatory definition' (his phrase).
I explicitly disavowed the claim that the equivalences are strict synonymies (162, this volume). What I suggested they show is that a creature with the cognitive capacity to handle subjunctive conditionals thereby already has the cognitive capacity to handle metaphysical modalities, so that it is explanatorily redundant to postulate an additional cognitive capacity dedicated to the latter. Peacocke argues to the contrary that his account of the concepts of metaphysical possibility and necessity provides a substantive explanation of the metaphysical impossibility of contradictions, while my account provides none. Unfortunately, his argument wavers between at least three different explananda such as these (for concreteness, I have replaced his
'q&~q' by a particular contradiction): (1) It is metaphysically impossible that it is hot and not hot.
(2) The proposition that it is metaphysically impossible that it is hot and not hot is true.
(3) The sentence 'It is metaphysically impossible that it is hot and not hot' is true.
When he considers what explanation I can offer, he writes as though only (1) were to be explained: he does not consider how my explanation would treat ascriptions of truth to propositions or sentences. But then he goes on:
An explanatory definition should contribute to an explanation of why the metaphysical impossibility of q&~q results from the semantic contributions of negation and conjunction, and their mode of combination in q&~q. […] A simple explanation of the metaphysical impossibility of p&~p draws on the fact that necessity is truth in all possible worlds
(taken as sets of propositions), where genuine possibility is constrained, inter alia, by the requirement that in any genuinely possible world, the same rules for evaluating logically complex expressions must hold as actually hold for outright truth.

Such considerations might figure in an explanation of (3). They are quite out of place in an explanation of (1): it could not have been both hot and not hot, whatever the words 'and' and 'not' had meant. The natural form for an explanation of (3) is bipartite: a non-semantic explanation of (1), and a semantic explanation of the Tarskian biconditional of (3) with (1). In effect, Peacocke devotes almost all his explanation to the biconditional. Once it is stripped of that semantic material, virtually nothing is left as an explanation of (1) itself. But of course my explanation of (3) can contain corresponding semantic material pertaining to the biconditional of (3) with (1), just as sensitive as Peacocke’s to the semantic roles of conjunction, negation, and the modal operator. What neither of us has, or could reasonably expect, is a story that explains why it could not have been both hot and not hot from a significantly more fundamental starting-point: (1) is close to explanatory bedrock. The best either of us can do is to derive
(1) in a very few steps from standard principles of modal logic (in
Peacocke’s case) or counterfactual logic (in mine), perhaps by deriving the negation of a contradiction in non-modal propositional logic and then applying a rule of necessitation or its analogue in counterfactual logic. Similar points apply to the explanation of (2) (Peacocke sometimes writes of the truth of propositions rather than sentences).
In effect, he has produced the illusion of a substantive explanatory task that his account can fulfil and mine cannot by oscillating between use and mention.

2
Peacocke’s other challenge is to the book’s account of linguistic understanding. In broad terms, he argues that an adequate account of what is to understand expressions of a public language must invoke a level of something like Frege’s cognitively individuated senses for those expressions. By contrast, the book dispenses with such a level, dividing the work between meanings individuated at the level of reference (which may include both Carnapian intensional isomorphism and Kaplanian character) and understanding as full engagement with a public practice of using the expressions, on which the shared meanings supervene.
For Peacocke, the cognitive psychology that individuates senses is individualistic, not social: 'what correct understanding consists in, at the level of sense, has a specification not involving society.'1 An immediate problem for such a view is that Oscar and Twin-Oscar may be duplicates at the level of individualistic cognitive psychology even though Oscar correctly understands our word 'gold' while Twin-Oscar does not. For Oscar may be a normal English speaker while TwinOscar belongs to a speech community whose word 'gold' refers to fool’s gold. Twin-Oscar does not even have our word 'gold'; a fortiori, he does not correctly understand it. When he says 'That is gold,'
he speaks truly if and only if the referent of his demonstrative is fool’s gold, not if and only if it is gold. He is not using our concept gold.
Even if we restrict attention to people who do have our word 'gold,'
it is doubtful that on Peacocke’s own conception of u
 nderstanding the difference between those who understand 'gold' and those who do 23-08-2021 13:10:21 not can be specified without involving society. For he claims that 'understanding an expression […] consists in tacit knowledge of the fundamental reference rule for that expression.' Presumably Peacocke intends tacit knowledge to be a species of knowledge. But then whether a speaker has tacit knowledge of the reference rule or only tacit true belief depends in part on the causal basis of the putative knowledge. Two members of our speech community may be duplicates at the level of individualistic psychology and both have the relevant word with the right reference rule even though one speaker has them in the proper way while the other has them only as a result of a failed attempt to hoax her about the rule by hoaxers who themselves misunderstood the word. The former has tacit knowledge of the reference rule while the latter has mere true belief, yet the difference between them seems constitutively to involve society, since it concerns the difference in their relations to other speakers. If that is not the sort of social difference that Peacocke intends to rule out, it is quite unclear what sort of social difference he does intend to rule out.
Even if understanding is not a matter of tacit knowledge, a sufficiently deviant connection to the public practice of using a word, like the one just sketched, will not constitute understanding.
The preceding examples also reveal a gap in an argument with which
Peacocke tries to destabilize my account of meaning and understanding: a good formulation of a character-rule, especially at the level of concepts, will plausibly coincide with a fundamental reference-rule. But, provided that we are not concerned with the special subcases in which the fundamental reference or character rule actually mentions other language-users, this implies that character-rules can fix a society-
independent understanding-condition at the level of sense.

In specifying the character-rules of many expressions, it is indeed
unnecessary to refer to social matters.2 But that does not imply that 23-08-2021 13:10:21 'character-rules can fix a society-independent understanding-condition at the level of sense.' For one understands a word only if one has that word. Nor will a deviant connection between the word and the right character-rule constitute understanding. Those conditions, as just noted, are not society-independent.
Let us bracket the question of individualism, and consider the example that Peacocke uses to argue that a level of cognitively individuated sense is needed to individuate meanings finely enough:
It is possible that there is a language with a semantically and syntactically unstructured word W for the shape perceived as a regular-diamond (same length sides, right angles). This shape is, at the level of reference, the same shape as a square. But it can be informative that squares are Ws. The story can be developed in such a way as to make it compelling that the understanding-condition for W mentions shapes perceived as diamonds. Yet W and 'square' have the same character.

What Peacocke means by W being 'a word for the shape perceived as a regular-diamond' is not entirely clear. He does not mean that a shape ceases to be a W when it ceases to be perceived as a regular-diamond, so what connection does he intend to stipulate between the word W
and being perceived as a regular-diamond? It is tempting to distinguish between 'square' and 'regular-diamond' by contrasting orientedshapes with ordinary shapes: geometrically, oriented-shape is invariant under translations but not under rotations whereas ordinary shape is invariant under both translations and rotations. In a given plane, rotating a token square (two sides horizontal) through 45o gives a regulardiamond (one diagonal horizontal), the same in shape but different in oriented-shape. However, interpreting W and 'square' as referring to oriented-shapes rather than ordinary shapes would make them differ in reference, which is not what Peacocke wants. Rather, we should imagine that, when shown a square oriented with two sides horizontal and asked 'What shape is that?,' if you say 'A W' you answer truly, although perhaps infelicitously; likewise if you say 'A square' when shown it with one diagonal horizontal. We should also imagine that speakers expect other speakers to prefer to use W when one orientation is salient and 'square' when the other orientation is salient.
We might be able to develop the scenario in such a way that W
and 'square' carry different conventional implicatures about the  rientation of the relevant token; the book explicitly allowed conveno tional implicature as a constituent of meaning (130, this volume). But
Frege classifies differences in conventional implicature (such as that between 'and' and 'but') as differences in coloring, not in sense, because they make no difference to the truth-conditions of the sentences in which they occur. More generally, Peacocke has not explained what difference, if any, the difference between W and 'square' makes to the truth-conditions of containing sentences. Without one, Frege would not count it as a difference in sense. As pointed out in the book, synonymous expressions can differ in ways that speakers expect each other to know about. One is expected to know about differences in sociolinguistic register, such as that between 'gob' and 'mouth,' even though such differences hardly qualify as semantic (131, this volume).
In the absence of any definite suggestion as to what role the difference between W and 'square' might play in a systematic semantic theory for the language, we have no good reason to regard the difference as semantic.
The concern that Peacocke’s invocation of senses in semantics is unsystematic is reinforced by his explicit acknowledgement of a category of expressions with reference but no sense. For the sense of a sentence is supposed to be recursively built up out of the senses of its constituent expressions. If some of those constituents lack senses, then the attempt to assign a complete sense to the sentence will fail.
In Fregean terms, it will not express a complete Thought, even though it still has a truth-value, since it suffers from no corresponding reference failure. If the compositional semantic theory can smoothly handle those sentences without associating them with Thoughts, the role of Thoughts even for those sentences that do have them is likely to be marginal at best.
Finally, I turn to Peacocke’s objection to one of my most extreme examples of someone linguistically competent with a logical constant yet highly deviant in their reasoning with it. Simon, a native speaker of English, regards both truth and indefiniteness as acceptable values for an assertion: what matters is to avoid falsity.3 Simon also endorses
Kleene’s weak three-valued tables for evaluating complex sentences
The example is also discussed in Section 12.2. For convenience, relevant points are repeated here.

3 with indefinite constituents, on which indefiniteness in a part always infects the whole. Thus he rejects the standard rule of conjunctionelimination, since it can lead from an indefinite premise to a false conclusion, when the premise is the conjunction of a false conjunct with an indefinite conjunct (98, this volume). Peacocke objects that
Simon lacks general linguistic competence, since he has an inadequate grasp of the practice of assertion, which – Peacocke and I agree – is governed by the rule that one should assert A only if one knows A.
Therefore, according to Peacocke, 'no one who thinks A is indefinite should be sincerely asserting A.'
The matter is not so straightforward. If Simon applies the spirit of Kleene’s tables to knowledge ascriptions, he may treat 'I know
A' as indefinite when A is indefinite, and faithful to his own principles assert 'I know A.' Thus he may not regard his assertion of A
as violating the knowledge rule. Furthermore, conscious acceptance of the knowledge rule is no precondition for linguistic competence.
Quite a few philosophers consciously reject the knowledge rule without ceasing to be competent speakers of English, just as someone can play a game while partially misunderstanding its rules. The question is whether Simon’s attempts to employ the speech act of assertion will be so deviant as to undermine his engagement in the normal practice of assertion. However, many linguistically competent philosophers have theoretical views that would, unchecked, lead to wildly deviant practice (for example, those who think that no vague sentence is ever strictly speaking true). Typically, they survive by invoking a variety of pragmatic fixes to adjust their practice until it comes within the bounds of the normal. Certainly Simon will not feel obliged to assert everything he takes to be indefinite, just as Peacocke and I do not feel obliged to assert everything we take ourselves to know. Perhaps
Simon will commit some fallacies or at least make some horribly ad hoc moves in adjusting his theory and his practice towards each other.
That would not bother me, since my concern is not to defend the truth of Simon’s theories. I reject them as false, just as Peacocke does.
My concern is just to insist that Simon’s deviant theorizing is consistent with his linguistic competence. Peacocke’s comments do not show that it is not.
Over recent years, theorists of concepts have tended gradually to water down their once-substantive conditions on concept possession in the face of counter-examples. Despite Peacocke’s extended labors, it is doubtful that what remains has enough explanatory power to pay its way.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in Philosophy and Phenomenological
Research (Williamson 2011b). 12.4 Reply to Miščević
As Nenad Miščević indicates in 'An Uncomfortable Armchair'
(Miščević 2013), the main line of argument in the second half of the first edition grew out of a talk I gave to a 2002 workshop on intuition and epistemology at the University of Fribourg, in which we both participated (Miščević 2004, Williamson 2004a). The original talk was far more optimistic about the usefulness of the category of intuition even than my 2004 paper. I set out with the idea of treating
'intuit' as a sui generis factive mental state operator comparable to
'perceive' and 'remember,' in the sense of Knowledge and its Limits
(Williamson 2000a: 34–40). Thus 'S intuits that P' is semantically unanalyzable but entails 'P,' and indeed 'S knows that P.' Formally, such an account is straightforward. What disturbed me somewhat as
I prepared the talk, and much more as I started to write it up afterwards, was the difficulty of finding clean examples. Whatever I tried substituting for 'P,' the knowledge at issue turned out on reflection to involve elements that made the use of the term 'intuition' quite misleading. It dawned on me, uncomfortably, that the problem was not my inability to think of good examples but rather the failure of the category of intuition to cut at the epistemological joints. The sneer quotes around the word 'intuitions' in the title of the 2004 paper expressed my disillusion.
Miščević defends the category of intuition with what he calls the
Moderate Voice-of-Competence view (MoVoC). Although MoVoC
contrasts in spirit with my 2002 account, some of the problems it faces are similar; others are different.
MoVoC identifies intuitions in a core sense with the deliverances of various domain-specific, more or less modular 'competencies'
that normal adult humans are claimed to possess. In Miščević paper, such competencies are postulated for the linguistic, spatial-geometric, mathematical, metaphysical, epistemological, and moral domains.
According to MoVoC, their deliverances, intuitions, are judgments or inclinations to judgment about the domains at issue, not about the words or concepts we use in talking or thinking about those domains (compare the face value interpretations that I defend against
Trobok’s criticisms). In a typical thought experiment, what such an intuition contributes to the verdict is separable from the contribution of background general knowledge. MoVoC’s ability to discern such structure is held up as one of its advantages over an undifferentiated holism.
To illustrate how straightforwardly we can separate intuitions from background knowledge, Miščević gives 7** (his label):
(7**) If John had stolen money from a totally drunk person at a party, that would have been morally unacceptable.

He explains (II.A.31):
What one needs to judge 7** is some moral competence (practical reason, moral feeling, moral sense, whatever you like); the empirical knowledge about money and about effects of drink is clearly distinguishable from the moral point.

Since the moral point is so easy to distinguish, the reader may assume that Miščević has distinguished it, and captured it in 7**. But 7**
depends on background non-moral knowledge. For example, imagine a society in which it is common knowledge that people who get totally drunk at parties usually end the night by paying to sexually abuse and torture children, and that the only effective way to stop them is by stealing their money. In those circumstances, presumably, our moral competence does not tell us that it would be morally unacceptable to steal money from a totally drunk person at a party. Thus
7** does not distinguish a purely moral point from background nonmoral knowledge. But 7** was supposed to be a case for which the distinction is easy to make.
We could try refining 7**, to purify it of all such non-moral elements. However, the prospects of success are dim. One strategy is to try to load all the relevant non-moral assumptions into the antecedent of the conditional. But that is a virtually endless process. There is no limit to the complexity of potentially relevant non-moral factors.
Moreover, if the deliverances of a moral sense really play a causal role in human life, they must be of humanly tractable complexity, closer to c12.indd 521 7** than to its imagined refinements. An alternative strategy is to try to abstract some comparatively simple, very general non-moral feature sufficient for moral unacceptability that stealing money from a totally drunk person at a party would have in our circumstances, and put that feature in the antecedent. But that would involve constructive moral theorizing, whereas the intuitional data are supposed to
'involve no theory and very little proto-theory' (I). Moreover, many of our particular moral judgments – such as 'Hitler was evil' – have much greater epistemic probability for us than any general moral principle from which we could derive them, using relevant non-moral auxiliary premises. To treat knowledge of the particular moral truths as epistemically dependent on knowledge of the more speculative general moral principles is to get the epistemology back to front.2
If a moral sense is a cognitive capacity that supplies moral premises independent of non-moral cognition to ordinary moral judgment, then we have no moral sense. Of course, we have the cognitive capacity to make moral judgments, both online and offline. Seeing
John stealing money from a totally drunk person at a party, we judge
'That is morally unacceptable.' Imagining John stealing money from a totally drunk person at a party, we judge 'That would be morally unacceptable.' But none of that requires a moral module of the sort
Miščević postulates.3
The preceding considerations also undermine Miščević attempt to use MoVoC to uphold some sort of prima facie a priori status for verdicts on thought experiments in ethics, such as 7**. Presumably, what people usually do when they get totally drunk at a party is not an a priori matter.
Similar arguments apply to an epistemological module, which
Miščević also postulates. He says that Gettier cases 'seem to unearth our original and deep seated understanding of what knowledge is'
(Miščević 2013, section III), but does not attempt to articulate that understanding. For reasons explained in the first edition, our verdicts

Miščević (II.A.3) suggests that I am inconsistent in criticizing such factorizing (see
194, this volume) while practicing it myself (188, this volume). What I am doing in the relevant passage is arguing that the verdict on a thought experiment is not a conceptual truth, which is not factorizing in the relevant sense.
3
See McGrath 2004 for relevant further discussion of moral epistemology.
2 on specific Gettier cases are not purely epistemological, just as our verdict on 7** is not purely moral. Miščević himself insists that our original untutored responses to Gettier cases are highly specific and precede 'more general insights' (end of II.A.1): I agree, but the point makes MoVoC’s postulation of purely epistemological premises for those verdicts all the more implausible.4 Miščević attempt to use MoVoC to uphold some sort of limited prima facie a priori status for verdicts on thought experiments in epistemology is also undermined.
We have contingently reliable recognitional capacities for both moral and epistemological qualities, but that does not involve having a moral or epistemological competency in Miščević’s sense. The cognitive preconditions for making a recognition judgment are not built into the content of the judgment itself, and the subject may be utterly incapable of articulating them. Ethics and epistemology are two of the branches of philosophy in which thought experiments have been most salient. In neither case do our verdicts on them derive from intuitions as characterized by MoVoC. The argument can be generalized to other branches of philosophy.
The case of mathematics is a little different. Many people know many truths of pure mathematics, such as those of arithmetic, whereas pure ethics and pure epistemology are in far less advanced states. But the difference does not help MoVoC. For, blatantly, knowledge of pure mathematics varies massively with cultural circumstances, whereas
Miščević seems to regard his modules as innate. If there is an innate mathematical module, why do we have to go to school to learn its deliverances? Of course, children may struggle to learn the g rammar
Miščević worries that my formalization of the verdict on a Gettier case with universal quantifiers (188, this volume) over-intellectualizes it by giving it an unrealistically general content. However, as explained on page 186 (this volume), keeping the original fictional names ('Smith,' 'Jones') in formalizing the thought experiment would be even more problematic, since then the verdict would arguably fail to express a proposition. The natural solution is to replace them by quantified variables.
A direct treatment of thought experiments with fictional names would be even more complex, since it would involve discussing both the semantics of fiction and its interaction with the semantics of modality (to explain how fictions can be used to refute a non-fictional theory about knowledge). In doing the semantics of natural languages, it is commonplace to represent the truth-conditions of apparently simple sentences with formulas of a perspicuous formal language that look very different from anything of which native speakers are conscious.

4 of their native language when it is taught as an explicit theory. But the cases of language and mathematics are quite unlike. For virtually all mature humans have implicit mastery of the highly complex grammar of a natural language, which informs their judgments of well-formedness, whereas nothing comparable holds for mathematics. Without specific mathematical training, our mathematical judgments may not be much better off than our ethical and epistemological judgments.5
Miščević has failed to anchor the category of intuition in modularity or domain-specific competence. He may be forced much further towards 'undifferentiated holism' than he would like. However, he still has an alternative preliminary characterization of intuitions, on which he lays less weight, in more traditional terms of 'their noninferential, self-evident, clear and distinct character' (III). For that characterization does not rely on modularity.
By 'self-evident' Miščević seems not to mean anything technical, such as 'knowable merely by being entertained,' since he appeals to
'our intuition that ordinary material objects exist' (II.A.2). The reading of that phrase relevant to the original context is de dicto rather than de re: the alleged intuition is that there are ordinary material objects; it is not, of some particular ordinary material objects, that there are such things as them. Presumably, one cannot know that there are ordinary material objects merely by entertaining the proposition that there are ordinary material objects. Nor does Miščević seem to mean 'clear and distinct' in its technical Cartesian sense. Perhaps his description 'selfevident, clear and distinct' can be paraphrased simply and informally as 'obvious.' But what is the connection between intuition and obviousness? Amongst friends of intuition, it is not uncommon to speak of some intuitions as being firmer or less tentative than others. Obvious and non-obvious judgments can come from the very same source.
From that perspective, obviousness looks more like a characteristic of those intuitions on which they would most confidently rely, rather than a precondition for being an intuition in the first place.
Even 'non-inferential' is less straightforward than it looks. For in what sense is our intuition that there are ordinary material objects
However, Miščević makes an unnecessary concession in suggesting that the conditional 'If twelve people had come to the party, more than eleven people would have come to the party' depends on the assumption that partygoers do not fuse (II.A.3);
'Twelve Fs G' entails 'More than eleven Fs G' whatever weird changes Fs can undergo.
5 non-inferential? It may not be deduced by existential generalization from any particular premise of the form 'o1, …, on are ordinary material objects,' but we reach very few of our beliefs by deduction in the strict sense from prior premises. Even a scientist’s educated judgment that one theory is better supported than another by a mixed body of evidence is unlikely to be deductive in that sense. If Miščević
means 'inferential' in the strict sense, then characterizing intuitions as non-inferential tells us very little. On the other hand, if he means
'inferential' in a looser sense that applies to any belief that somehow depends on prior beliefs, then the alleged general intuition that there are ordinary material objects may well be inferential, through its dependence on a host of more specific prior beliefs, for example that there are hands and feet, mountains and rivers, sticks and stones.
Thus Miščević auxiliary modularity-independent characterization offers little help in demarcating a useful category of intuition. Since his main modularity-based characterization is also in trouble, he has given us no good reason to indulge in 'intuition'-talk. In passages that he quotes, I argue that we have good reason not to indulge in it, because its function in much philosophical discourse is to fudge issues about the nature of our evidence in philosophy. When philosophers say 'I have the intuition that P,' it is typically unclear whether what they are advancing as evidence is the putative non-psychological fact that P or the putative psychological fact that they have the intuition that P.6 Typically, the former is directly relevant to the philosophical question but easy to contest; the latter is harder to contest but not directly relevant.7 Miščević gives examples in which 'intuition'talk does not serve that obfuscatory function (II.A.2). He is right that it does not have to insinuate any psychologization of our data. But my objection was not that it has to but that it typically does, as a
contingent tendency of current philosophical discourse. Of course, if it also picked out an important psychological kind, the best policy 7

The phrase 'have the intuition that' is to be read non-factively.
Miščević suggests that in describing facts as contestable I am treating them as

beliefs rather than facts, since they can turn out not to be facts (II.A.2). That is not so. The fact that P is contestable because someone may contest it, in the sense of (falsely) denying that P. No fact ever turns out not be a fact, although someone may falsely believe that it has turned out not to be a fact that P, and indeed it has turned out to be a fact that not P. might be to continuing use it while remaining on guard against the psychologizing tendency. But since the best efforts of Miščević and many others have failed to pin down any such kind, another good reason not to indulge in 'intuition'-talk is to avoid the presupposition that we are dealing with a significant psychological kind.8
I turn to Miščević questions at the end of II.A.2 about my positive account of the epistemology of modality and of thought experiments.
In the first edition, I argue that our ordinary cognitive capacity to handle counterfactual conditionals carries with it the cognitive capacity to handle ascriptions of metaphysical modalities, at no extra cost.9
In that case, retorts Miščević, 'ordinary capacities have extraordinary powers, and they should be accounted for.' But why is any special accounting needed? Consider an analogy with logic. Suppose that our ordinary logical capacities include a capacity to apply the rules of some standard system of natural deduction in arguing from contingent premises to contingent conclusions, all about our local environment. Then by the very same rules we can argue from no premises to a necessary logical truth. For example, we can deduce the conclusion
C → C by conditional proof. No special explanation is needed, beyond the proof itself. Similarly, on my account, the very same procedures that we use to evaluate ordinary counterfactual conditionals can also be used to evaluate the 'extraordinary' counterfactual conditionals that are equivalent to ascriptions of metaphysical modalities. No special explanation is needed, beyond the sort of details supplied in the first edition.
It might be objected: the reliability of our ordinary procedures when applied to ordinary cases is no reason to expect them to be reliable when applied to extraordinary cases. Without further support, however, that is just inductive skepticism. Compare the claim that the reliability of our ordinary procedures when applied to past cases is no reason to expect them to be reliable when applied to future cases. To make the doubt serious, the objector must base it on some cognitively pertinent difference between the extraordinary cases and the ordinary
8 This line of objection to 'intuition'-talk is pursued further in Sections 10.3 to 10.5.
Contrary to Miščević’s claim that I need 'some very strong assumptions' about

the logic of counterfactuals to derive the rules for the necessity operator from it
(II.A.3), the counterfactual logic I use to derive the standard modal system KT
is in fact quite weak: for instance, it is significantly weaker than David Lewis’s preferred counterfactual logic (see 295–303, this volume). ones. Extraordinariness itself is not enough. After all, in comparison to ordinary proofs with some contingent premises, proofs with no premises are extraordinary, but not in a way that casts serious doubt on the reliability in extraordinary proofs of standard principles of natural deduction already found to be reliable in o
 rdinary proofs. Since Miščević
proposes no such difference, I will not pursue the matter here.
Instead, Miščević poses another question for me: are only philosophical intuitions 'ordinary?' He draws a potential contrast with moral, mathematical, and linguistic intuitions, for example, and asks whether I want to give a uniform account of both philosophical and non-philosophical intuitions. Although unhappy with the 'intuition'talk, I can say this much. Given the obvious differences between morality, mathematics, and language as subject matters, of course one cannot expect a uniform account to cover all of them in detail, let alone philosophy too. At a more general level of description, however, the same points apply to all of them. Typically, we start with online judgments about perceptually presented cases. We judge actions that we have just witnessed as good or bad; we classify physical objects in front of us by shape, manipulate them to work out which fit inside which, and count collections of them; we hear some people speaking differently from others and comment on the differences. In imagination, we learn to apply the same cognitive skills offline, to hypothetical cases. For example, in deciding what to do, we judge whether an action we could take would be good or bad. By mental manipulation we work out how to make an object of a sort we have never seen, and how to count collections of absent objects. We judge whether a string of words in a foreign language would sound well-formed before uttering it out loud. On the basis of such ordinary cognitive skills, we occasionally go on to think in more general and theoretical terms. Intellectual disciplines emerge: mathematics, philosophy (including moral philosophy), linguistics. In these respects, philosophy is not at all exceptional.
As Miščević notes, he and I agree on many significant points about the nature of philosophy. I hope that they include those made in the preceding paragraph. Indeed, he offers a beautiful illustration of them in the case of mathematics: 'understanding the inverse of a function by imagining its spatial representation. Our imagination moves from one imagined set to the other, and back, and we can assume that it had been honed through a lifetime of bodily movement in opposite directions' (II.B). Of course, the notion of a (one-one) function and of its inverse are general enough to be used in philosophy as well as in mathematics, for example in discussion of the mind-body problem.
Thus the case also shows how a cognitive skill on which philosophy relies may originate in bodily movement. Philosophical methods are rooted in ordinary cognitive skills.10

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in the Croatian Journal of Philosophy
(Williamson 2013g). See also the acknowledgment to Section 12.6.
I confine to this footnote my responses to some specific points Miščević makes about my critique of the a priori–a posteriori distinction (II.B). (a) He quotes a passage in which I envisage two people disagreeing as to whether knowledge entails belief as a result of subtle differences between their courses of experience, for instance in the cases to which they hear the words 'know' and 'believe' applied (170, this volume).
He tentatively interprets me as meaning that they use the word 'know' with different senses. As he notes, that would sit ill with semantic externalism about meaning that
I invoke elsewhere in the book. But in the sentence immediately preceding the one he quotes I say that it would not be plausible to accuse those philosophers who take the minority view that knowledge does not entail belief of failing to understand the words
'know' and 'believe' (in their public senses, of course). The view I am expressing is exactly the same as in the discussion of epistemological analyticity. Sharp differences in the inferences one treats as valid with words do not entail any difference whatsoever in the senses with which those words are used. (b) Miščević criticizes an example I give in my later, more developed critique of the a priori–a posteriori distinction (Williamson
2013b). It involves Norman, who assents to (*) 'All crimson things are red' and (**)
'All recent volumes of Who’s Who are red' on the basis of similar imaginative exercises, even though his knowledge of * would normally be classified as a priori and his knowledge of ** as a posteriori. Miščević objects that if Norman was shown a crimson patch as a sample of 'red' then the defender of the distinction can hold that * is built into Norman’s concept of 'red.' However, this neglects the fact that there are many different shades of crimson. Even if Norman learns from the original ostension that all things of the given shade of crimson are red, that does not entail *. On the other horn of his dilemma, Miščević suggests that if Norman was not shown a crimson patch as a sample of 'red,' his ability to classify crimson shades as red must depend on his having completed something like an inner color solid. But, for the sake of the example, there is no need to suppose that Norman either associates 'red' and 'crimson' with long exhaustive lists of their maximally specific shades or literally has a quasi-spatial analogue model of color space in his head. He may simply associate the words with relevant focal shades and have a capacity to judge comparative similarity in color, online and offline – which is just what my example requires.
10 12.5 Reply to Smokrović
In the first edition and some of its predecessor articles (Williamson
2003a, 2006b), I attacked the core tenet of inferentialism: that understanding some words, or grasping the concepts they express, requires a willingness to assent to some key sentences or inferences in which they occur. On the canonical version of inferentialism, assent itself is necessary for understanding when those sentences or inferences come into play. On a weaker, dispositionalist version, only a disposition to assent is necessary. One can have a disposition to do something yet not do it even when the moment comes, because another disposition intervenes to inhibit the first. For example, you may be disposed to assent to a rude comment about someone but not assent because you know that his mother is within earshot. I attacked both the canonical and the dispositionalist versions of inferentialism. In his commentary 'Are Dispositions to Believe Constitutive for Understanding?,'
(Smokrović 2013), Nenad Smokrović accepts my critique of canonical inferentialism but defends dispositional inferentialism. He brings out clearly why the latter doctrine is harder to refute than the former; he may well have identified the best ground for inferentialists to fight on. He is in any case right that unconscious inferential dispositions are cognitively important.
However, dispositional inferentialism may not serve all the purposes for which philosophers have appealed to canonical inferentialism. For instance, Paul Boghossian uses the assumption that we cannot understand some words without assenting to key inferences involving them in his attempt to explain our epistemic right to make those inferences (Boghossian 2003). If we can understand those words without assenting to those inferences, because we can overrule our disposition to assent, the prospects for such an explanation are even worse. For a dispositional inferentialist, our understanding still leaves us a choice as to whether, all things considered, we make the inference. If we do make it, we cannot simply plead necessity as our defense. Thus canonical inferentialism was more pertinent to my critique of Boghossian (Williamson 2003a). Similarly, if there were inferences to which our understanding of the relevant words bound us to assent, they could play a far more robust role in the methodology of philosophy than inferences over which we had reflective discretion. However, Smokrović is not concerned to uphold those specific applications of inferentialism. He simply undertakes to defend the truth of dispositional inferentialism itself. That is where I will take issue with him.
My counterexamples to dispositional inferentialism involved characters who originally came to understand words of their native language in the normal way, but then through a process of theoretical reflection reach the conclusion that the sentences or inferences at issue were unsound, and so withdraw their original assent. Smokrović
agrees that in so doing they do not cease to understand the words or to grasp the concepts supposedly expressed. So far, nothing excludes the dispositionalist hypothesis that they still retain a sub-personal disposition to assent, whose manifestation has been inhibited by higherlevel processing. We may assume that as they become used to their new view, they are no longer conscious of any such disposition, but that does not entail its absence from their unconsciowus cognitive structures. Nevertheless, to postulate such an unconscious cognitive disposition is to give a hostage to scientific fortune. In the first edition, I argued that there is scant evidence that such a disposition must survive. Smokrović seems more concerned to argue that a disposition might survive than to show that one actually does so.
There is much with which I agree in Smokrović’s general account of dispositions as capable of surviving as sub-personal even when overridden, and of beliefs and assent as typically unreflective. My disagreement with him comes at a more specific level.
To clarify the issues, I will consider a different example. In a system of natural deduction for first-order logic, a simple form of the elimination rule ∃-E for the existential quantifier says that if one has derived a conclusion C from a premise A(c) and some or no auxiliary premises, then one can derive C from the premise ∃x A(x) and the auxiliary premises if any, where A(c) results from substituting the constant c for all free occurrences of the variable x in A(x), provided that c does not occur in A(x), the auxiliary premises, or the conclusion
C. The constant c is used as though it named an 'arbitrary' verifier of the existential premise (which may in fact have many verifiers, or none). Let ∃-E* be the corresponding rule without the underlined restriction. Suppose that when Edward first learns the existential quantifier, he does not realize the need for the underlined restriction on the elimination rule, so he adopts the simple rule ∃-E*, not the correct rule ∃-E. (For present purposes, it does not matter whether at this stage he counts as understanding the quantifier ∃.) At first, everything goes fine; when Edward applies his rule, the restriction happens to be met anyway, so his inferential practice appears normal. However, since A(t) counts as trivially derivable from itself without auxiliary premises, Edward then realizes that he can use his rule to derive A(t)
from ∃x A(x). But that is a disaster. For instance, since Edward believes ∃x x = 1, he derives the conclusion 0 = 1. Since he also believes
0 ≠ 1, he has landed in contradiction. Rather than becoming a follower of Parmenides or Graham Priest, he reflects on his predicament and comes to realize that his rule of existential elimination is invalid; he needs to add the underlined restriction. He therefore rejects ∃-E*
and accepts the correct rule ∃-E instead.
Does Edward still have a sub-personal disposition to reason by the incorrect rule ∃-E*? He might, for all that has been said so far. But he need not. On one legitimate continuation of the example, he loses even the sub-personal disposition to reason by ∃-E*. That is a genuine possibility. Let us take the example that way. After he identifies his mistake,
Edward is disposed to reason just by the correct rule ∃-E. He lacks even a sub-personal disposition to assent to an instance of ∃-E* that violates the restriction on ∃-E. Although dispositions are not destroyed simply by being overridden, they can be destroyed.
For clarity, the example concerned a formal language. However, one can easily describe a structurally similar example concerning a natural language. The rule ∃-E corresponds to a natural rule of deduction for a natural language. The general moral is that through reflection and habituation it is possible eventually to lose even the sub-personal disposition to reason by a given rule.
Now compare Edward with Peter and Stephen in the original cases
(Chapter 4). Whereas Edward starts with an invalid elimination rule for the existential quantifier and restricts it to form a valid elimination rule, they start with a valid introduction rule for the universal quantifier and restrict it to form introduction rules that are unnecessarily weak, although still valid. Peter’s restriction avoids assent to vacuous universal generalizations; Stephen’s restriction avoids assent to universal generalizations that involve borderline cases in a specific way. From an internal psychological perspective, however, the cases are very similar. Initially, all three reason by a given rule. Subsequent reflection convinces them that the rule is invalid, and requires a
restriction. By the end of the process, all three reason by the restricted rule, and have lost even the disposition to reason by the original unrestricted rule. We have no reason to exclude any of the cases as impossible. Even though some inferential dispositions may be quite robust in human psychology, they are not immutable of necessity.
Once Peter and Stephen have lost the disposition to reason by the original unrestricted rule of universal introduction, do they still understand the universal quantifier? In the first edition, I argued at length that they do, on grounds connected with the nature of understanding and the social determination of meaning. Smokrović’s paper provides no criticism of that part of my argument, which I will therefore not repeat.
One further consideration deserves notice. In a very suggestive paper, the late Paolo Casalegno pointed out that inferential dispositions do not exhaust the dispositions relevant to understanding logical constants. We also use such expressions to construct complex descriptions of what we perceive: 'Some of the things in front of me are red, and none of them are green.' He gives the example of someone who lacks inferential dispositions as a result of some cognitive disability, but still manifests understanding of the logical constants by using them to describe visually presented scenes (Casalegno 2004: 407).
Although Boghossian has doubted the possibility of such a case, his criticisms can be met (Boghossian 2012, Williamson 2012). If inferential dispositions are highly modular, as Smokrović conjectures, the inferential disability could be much more localized, and the case correspondingly even easier to envisage. Since specific inferential dispositions ground just one aspect of our use of logical constants, they are all the less essential to our understanding.
In the light of these considerations, I maintain my rejection of dispositional as well as canonical inferentialism.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in the Croatian Journal of Philosophy
(Williamson 2013g). See also the acknowledgment to Section 12.6. 12.6 Reply to Trobok
One theme of the first edition is that philosophical questions are normally to be taken at face value. For example, when metaphysicians ask 'What is causality?,' they are primarily asking about the nature of causality itself, a worldly relation between events, not about the word 'cause' or a concept it expresses. Even if a sentence used in philosophical discourse is analytic in some sense, it is still to be given its literal meaning, not reinterpreted as being about words or concepts. For example, 'Bachelors are unmarried' is just as much a generalization about bachelors as 'Bachelors are untidy is.' Like mathematics, philosophy makes generalizations from the armchair about a world of which the armchair is one tiny part. On this theme,
I find myself in agreement with Nenad Miščević but in disagreement with Majda Trobok.
In 'Defending Analyticity' (Trobok 2013), she starts by arguing that the precedent of mathematics does not help me, because mathematics itself is about concepts. She gives two separable considerations in favor of that claim, with which I will deal in turn.
Trobok’s first point is that, on a Fregean analysis, numbers are
ascribed to concepts rather than objects. For instance, the purely mathematical statement 'There are four prime numbers between 10 and
20' ascribes the number four to the concept prime number between
10 and 20. More generally, Frege interprets second-order quantifiers, binding variables in predicate position, as quantifiers over concepts.
I accept standard arguments for axiomatizing arithmetic and set theory in a second-order language, in order properly to capture the intended strength of the axioms. Thus, on the Fregean analysis, both arithmetic and set theory routinely involve quantification over concepts. However, none of this poses any threat to what I say about mathematics. For the reading of 'concept' ('Begriff') relevant to Frege’s texts is quite different from those used in the first edition and by most contemporary philosophers. In current philosophical discourse, 'concept'
means something like 'mode of presentation' or 'mental representation.' Thus, when I deny that metaphysicians are primarily interested in concepts of causation, rather than in the worldly relation itself,
I am denying that they are primarily interested in modes of presentation or mental representations of that relation. But 'concepts' on the Fregean reading are not modes of presentation, or mental representations, or anything like them. In Frege’s terms, modes of presentation are senses, whereas concepts belong to the realm of reference, not of sense, and have still less to do with mental representations. For example, although the two predicative expressions '_ is part of Hesperus'
and '_ is part of Phosphorus' have different senses, and correspond to different mental representations, they refer to the same concept, the function mapping every part of Hesperus (= Phosphorus) to truth and every other object to falsity. More generally, Frege treats functions, and in particular concepts, extensionally: the analogue of identity for functions is returning the same values for the same arguments, so in particular the analogue of identity for concepts is coextensiveness.
By contrast, distinct modes of presentation or mental representations may be coextensive. The Fregean interpretation of mathematics is incompatible with a metaconceptual interpretation in the modern sense of 'concept,' the only one I will use henceforth.
Trobok’s second point is that it is often natural to speak of mathematical axioms as introducing a concept. That holds even on a non-Fregean reading of 'concept.' But it is not specific to mathematics. For instance, we might describe a physicist as introducing a technical concept of force by laying down some principles about it. Clearly, that does not commit us to the implausible claim that the physicist is primarily interested in the concept of force rather than in the nature of force itself. After all, we might equally well describe her as introducing a technical term 'force' by laying down some principles about it, but that does not commit us to the claim that she is primarily interested in the term 'force' rather than in the nature of force itself. The point is simply that the best way to get people to understand a new scientific term is often by setting forth some axioms involving it. Once they understand the new term, they will be able to take those axioms at face value, as literally about that to which the term refers, which is the reading that fits the role those principles play in ordinary scientific practice. That provides no evidence for the idea that the subject matter of the science itself is metalinguistic or metaconceptual.
Consequently, I am unconvinced by Trobok’s case that mathematics is about concepts. I continue to regard mathematics as an impressive paradigm of a non-metaconceptual, non-metalinguistic, armchair discipline. The rest of her paper concentrates mainly on arguing by various means for a metaconceptual reading of analytic sentences, as a precedent for such a reading of philosophical discourse.
Consider these three sentences:
(1) Every vixen is a female fox.
(2) Every female fox is a female fox.
(3) Every vixen is a terrestrial renate.
Here 'vixen' is synonymous with 'female fox' (and 'renate' with
'creature with a kidney'). For present purposes we may assume that
(1) and (2) are analytic, at least in the sense of being synonymous with the logical truth (2), and that (3) is not analytic in any relevant sense.
By the standard compositional semantics for English, (3) has a literal reading as an ordinary first-order universal generalization. In exactly the same way, (1) and (2) have literal readings as first-order universal generalizations with the same overall syntactic and semantic structure as (3). That much is hardly in doubt. Of course, Trobok could still argue that for special reasons in some contexts (1) must be interpreted non-literally, or perhaps that all strings like (1)-(3) are ambiguous in English and have a second literal reading as something other than first-order universal generalizations. However, such an argument would require quite specific semantic or pragmatic considerations of a sort that I do not find in the paper.
In the first edition, I remark as an objection to a metalinguistic reading of (1) that vixens would have been female foxes no matter how words had been used. At the end of section 1 of her paper,
Trobok responds to that objection. She correctly points out that the syntactically individuated sentence (1) expresses a falsehood in an alien language in which 'vixen' means female cat but all other words mean the same as in English. However, she suggests that we disagree with the aliens as to whether vixens are female foxes. We do not. The scenario as she sets it up involves no disagreement between us and the aliens. To be clear, let (1)E be the English sentence (1) and (1)A be the Alien sentence (1). The aliens correctly dissent from (1)A. If we interpret them as thereby dissenting from (1)E, we misinterpret them, precisely because the Alien word 'vixen' differs in meaning and extension from the English word 'vixen.' They are not denying that every vixen is a female fox, for every vixen is a female fox, so if they were denying it they would be in error while speaking their native language, which they are not in this situation any more than we are.
Of course, if at first we and the aliens do not realize that we mean different things by 'vixen,' we may get into a silly argument with them in which each side makes false statements, literally interpreted, when speaking the language of the other. However, the possibility of such trivial misunderstandings does not help Trobok, because it fails to provide any possibility of not every vixen being a female fox. Although we could have spoken a language like Alien, in those circumstances every vixen would still have been a female fox, although (1)A
would have expressed the false proposition that every female cat is a female fox rather than the true propositions that every female fox is a female fox. Provided that one takes care with the distinction between using an expression and mentioning it, the possibility of alternative stipulations poses no threat to my argument.
In section 2 of her paper, Trobok sketches an epistemic objection to the first-order reading of (1), along the lines that it would make
(1) unknowable, or at least not knowable a priori. However, it is hard to see how any such objection could succeed. Just focus on the literal reading of (1) as a first-order universal generalization. If you are worried about some hidden complexity of English grammar, focus instead on a standard formalization of (1) in first-order logic. Now ask yourself whether it is true on that reading. Most of us recognize at once that it is, in a way that would be classified as a priori by those happy to apply that term. We have no epistemological difficulty with (1) on its first-order reading.
Section 3 of Trobok’s paper culminates in the challenge to me to explain how we know (1) if, as I claim in the first edition, (1)
is not epistemologically analytic: someone can understand (1) without being disposed to assent to it, because they espouse non-classical principles of logic. Of course, what one regards as an adequate answer to Trobok’s challenge will depend on the general shape of one’s epistemology, and so on issues beyond the scope of these remarks. I
have argued elsewhere for a strongly externalist view of knowledge, with an emphasis on safety from error as a mark of knowledge (Williamson 2000a). Someone who employs standard natural deduction rules for classical logic can easily use them to derive (2), and thence derive (1) by treating 'vixen' as interchangeable with 'female fox,'
at least in non-quotational contexts. There is no reason why such a person should not count as safe from error and as satisfying any other r easonable externalist requirement on knowing. No metalinguistic or metaconceptual reflection is needed on their part. In particular, the knower need not wonder why the expressions 'vixen' and 'female fox' are interchangeable, or even entertain the thought that they are interchangeable; she need only be disposed to interchange them. Most ordinary knowledge involves no such logical or semantic reflection.
Contrary to Trobok’s claim, the knower does not 'have to know at least a segment of the metasemantic story.' Rather, the role of the metasemantic story is in making the knower safe from error, and so on, whether she appreciates that role or not. All of that is perfectly consistent with the literal reading of (1) as a first-order universal generalization. We can take logical truths and their synonyms at face value, just as we can normal stretches of philosophical discourse.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in the Croatian Journal of Philosophy (Williamson 2013g). My exchanges with Majda Trobok, Nenad
Smokrović, and Nenad Miščević on themes from the first edition, at the University of Rijeka, the Inter-University Centre in Dubrovnik, and elsewhere, before and after its publication, have been a source of both intellectual pleasure and intellectual profit, at least for me and
I hope for them too. In replying here to their thoughtful and sophisticated comments, I follow the usual and fruitful practice of focusing on points of disagreement. Nevertheless, the possibility of such focus on sharp points rather than blurred regions of disagreement indicates how much background agreement there is between us, on matters both philosophical and metaphilosophical.

c12.indd 537 13
Wittgensteinian Approaches

13.1 Reply to Moore
In his characteristically nuanced 'Not to be Taken at Face Value'
(Moore 2009), Adrian Moore expresses concern at 'Williamson’s lack of serious engagement with the history of philosophy.' Although that is not the focus of his discussion, I will start with a comment on it. I noted that the book 'touches on historical matters only glancingly' (10, this volume). For example, in my critique of the linguistic turn I abjured the attempt to trace all the forms it took in twentiethcentury philosophy (13, this volume). Nevertheless, a looming background presence in the book is after all the history of philosophy: most notably, its recent history. For the history of philosophy did not stop forty years ago. A central motivation for writing the book was my sense that over the past forty years philosophy has developed in ways to which its inherited twentieth-century self-images cannot do justice (xxx, this volume). They are anachronisms; reliance on them betrays a lack of historical sensitivity, however much one discusses
Kant or Wittgenstein. I stressed the need for a new narrative of the history of recent analytic philosophy, uncommitted to obsolescent assumptions about its direction, in order to make sense of its development over our own lifetimes (21, 24, this volume). Much of the evidence for the intellectual bankruptcy of the linguistic turn consists not in one-off arguments against it but in its historical record. That includes both the recent proliferation and flourishing of forms of philosophy that can only be forced into the linguistic turn by crassly
Procrustean means and the repeated failure of its ablest proponents to respond fruitfully to objections: for instance, of Wittgenstein’s followers to make good on the invocation of grammar in passages such as the one that Moore displays as his epigraph. Similarly, the basis for my characterization of anti-realist semantics as a degenerating research program was largely historical, as befits Lakatos’s concept
(286, this volume).
Moore’s sympathies are anti-realist. As an example of an antirealist account of truth, he gives what he calls 'the Wittgensteinian
View' of truth for mathematical discourse (unhistorically, without attributing it to Wittgenstein). As he presents it, the view is too rudimentary to constitute a serious alternative. It claims that 'In asserting a mathematical truth one is stating a rule, not saying how things are independently of any such assertion,' but it does not specify what the rule is, or whether in making the assertion one is saying how things are not independently of any such assertion, or what it is to make assertive use of a sentence in which a mathematical component is embedded within the scope of other operators (the standard Frege–
Geach problem), or what it is to ask a mathematical question, … The
Wittgensteinian View also constrains the epistemology of mathematics: 'nothing but a mathematical proof can establish a mathematical truth.' In defending this constraint, Moore claims that 'empirical evidence is only ever evidence for an empirical conclusion.' Faced with apparent counterexamples, Moore says 'In mathematical terms, the empirical evidence establishes nothing.' But there is a gap between not establishing a mathematical proposition and not being evidence for it. One can accept that in mathematics the agreed standard for assertion (and knowledge) is proof, while not trying to explain away all the numerous cases in which most mathematicians would agree that empirical evidence gives some nonconclusive support to mathematical propositions.1
In attempting to show how to 'sidestep certainly apparently decisive objections' to the Wittgensteinian View, Moore acquiesces in the charge that it makes the consistency of a mathematical theory a matter of stipulation: we adopt a rule 'that guarantees the consistency of Peano Arithmetic.' Here as elsewhere, he leaves the content of the rules he invokes unspecified. We could indeed add to a given proof system for the language of Peano Arithmetic the rule that if one of A
and B is the negation of the other then nothing as long as a proof of A
If all mathematical truths have probability 1, then the support will need to be understood non-probabilistically.

1 counts as a proof of B, which guarantees that A and B are never both provable in the new proof system. But that does nothing to guarantee that they were not both provable in the old proof system, without the extra rule, which was the question at issue. We can no more make the old system consistent by fiat than we can the system of the Grundgesetze. No doubt anti-realists can always 'sidestep' objections in the sense in which defenders of astrology always can (243, this volume), but more than that is needed to maintain a view as a worthwhile protagonist in philosophical discussion.
Moore’s main concern is the defensibility of an anti-realist view of philosophical discourse. He discusses my example, the original question 'Was Mars always either dry or not dry?' Moore says that he
'cannot hear that interrogative sentence, as used in that context [in which TW asks it], except as a question about the workings of the word ‘dry’ or the concept of dryness.' Perhaps he cannot imagine why someone would ask it if they had no interest in words or concepts
(I can), but the motivation for asking it should not be confused with the question’s content. Moore does not dispute the argument in the book that a strict and literal reading of the original question according to its compositional semantics does not make the answer trivially obvious. So if we believe his profession of inability to hear the question in a non-metalinguistic, non-metaconceptual way, perhaps we should take it as just in his words 'an autobiographical observation.' However, he does have a more theoretical motivation for denying that the original question has the strict and literal content it appears to have. His theory runs roughly along these lines: when borderline cases come into play, no proposition is expressed. Given that Mars is a borderline case for the vague term 'dry' with respect to some past time, the sentence
'Mars was always either dry or not dry' fails to express a proposition on its strict and literal reading, and the original question correspondingly lacks strict and literal content (in the relevant context). By contrast, given that Mars clearly falls in the extension of 'dry' with respect to the present, the sentence 'Mars is dry' expresses a proposition on its strict and literal reading, and the question 'Is Mars dry?'
correspondingly has strict and literal content (in that context). Needless to say, such a view plays havoc with compositional semantics. Of the property of being dry, we can contentfully ask whether Mars has it but not whether Mars has always either had it or not had it. Standard semantic operations on the proposition strictly and literally expressed by 'Mars is dry' in a given context somehow fail to yield a proposition to be strictly and literally expressed by 'Mars was always either dry or not dry'; relevant forms of Evans’s Generality Constraint will fail.
Presumably this does not worry Moore: 'I think language is messy.'
To some extent it is. But that does not justify giving up the attempt to achieve what systematic understanding we can of it at the first sign of difficulty. Moore would probably regard it as scientistic to point out that physicists do not proceed in that way ('I think the world is messy'). Linguists too are reluctant to shrug off systematic constraints as easily as Moore does.
Moore’s final comments address my critique of epistemological conceptions of analyticity, in which I argue that even extreme logical unorthodoxy is compatible with using the relevant words with their usual meanings. According to him:
Strictly speaking, when Graham Priest says, 'There are true contradictions,' he is violating rules that govern the workings of those words in the English language and is not using them with the meanings that these rules help to determine[.]

Moore does not specify exactly which words Priest is using with
deviant meanings ('true?' 'contradictions?' both? the sentence as a whole?) or what those deviant meanings are. Nor does he specify which rules of English Priest is violating. Is there a rule that simply forbids one to say 'There are true contradictions,' or is that prohibition derivable from more general rules of English, and if so what is their content? How does he handle the evidence in the book about normal speakers from the psychology of reasoning that looks unfavorable to his rule-based conception of logical understanding (105–9, this volume)? If one had no idea who Graham Priest was and overheard him in a pub saying 'There are true contradictions,' one might think at first that he was only saying that because he misunderstood the long word 'contradiction.' Once one starts talking to him, that hypothesis feels rather less attractive. Unconsidered initial judgments are not decisive in determining linguistic rules. Moore allows that
Priest may count as using the words with their standard meanings
'on a looser way of speaking,' but the case is utterly unlike that of a language-learner whom it would be genuinely natural to describe as having only a partial understanding of the words. It is philosophical dogma, not respect for English, that prevents one from seeing that
Priest is as linguistically competent with the words as any other normal speaker of the language.
Moore presents himself as representing an alternative way of doing philosophy to the one urged in this book: more humanistic, concerned to preserve unsystematic insights, respectful of the complexities of actual life and language, sensitive to deep differences in conversational and historical context and so responsive to areas of discourse whose underlying purposes need anti-realist treatment, in short warmer, by contrast with the cold scientism, the ahistorical, harshly systematic, uniformly realist theory-building that I represent.
When one examines his text more closely, however, one finds that its unsystematic, unscientific air depends not on avoiding theoretical commitments but on avoiding making good on them. This is particularly clear in his repeated invocation of unspecified rules. If he were to state the content of the supposed rules, and provide some evidence that they are really in force, his claims would then be open to testing and challenge of kinds that only the evasiveness of his presentation now protects them from. He would become embroiled in just the kind of 'scientific' discourse he shuns. The problem is not some individual failing on Moore’s part. On the contrary, he is unusually conscientious and fair-minded to his opponents. The problem is with the subtradition he represents, from which he has inherited a style of discourse that effectively discourages the sort of systematic, painfully explicit and articulated questioning (not completely unfamiliar to the victims of Socrates) without which it is just too easy to get away with falsehoods.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in Analysis Reviews (Williamson
2009a). I thank Adrian Moore for his interesting comments, which help bring into relief some main themes of the book. 13.2 Reply to Horwich
In 'Williamson’s Philosophy of Philosophy' (Horwich 2011), Paul
Horwich defends the idea that the proper business of philosophy is clarification rather than systematic theory-building. His target is my methodological sermon 'Must Do Better,' the afterword to the first edition, which he treats as based on a misconceived assimilation of philosophy to science.
On one point Horwich and I are agreed. Philosophy suffers from a shortage of established constraints of the sort required for a discipline to make scientific progress. For Horwich, this means that scientific progress is an inappropriate model for philosophy. To the contrary,
I suggest that the shortage is not a total absence, that skill in science often consists in finding ingenious and surprising ways to extract answers to questions from constraints that seemed too elementary for the task, and that philosophy is no different in that respect.
As an example of philosophy, Horwich contrasts 'traditional moral theory' with 'the empirical sciences': 'It isn’t founded on perception; its central facts are not contingent; causal explanation seems to be out of place; and so does the very idea of theoretical depth' (italics in the original). The oddest claim in that passage is that the very idea of theoretical depth seems to be out of place in traditional moral theory. There is nothing strange in the idea that Kant’s moral philosophy has more theoretical depth than Bentham’s. Of course, some utilitarians will dissent, but probably by arguing that Bentham’s moral philosophy has more theoretical depth than Kant’s. Thus Horwich’s final contrast between traditional moral theory and the empirical sciences seems to be a figment of his philosophical preconceptions, rather than something independently plausible. At first sight, his other three contrasts seem much less contentious. On further scrutiny, however, they turn out to be less clear-cut.
Horwich presupposes that the 'central facts' of the empirical sciences, by contrast with those of traditional moral theory, are contingent.
He does not mention Kripke’s examples of the necessary a posteriori, such as the fact that gold is the element with atomic number 79. Recent philosophy of science has developed Kripke’s suggestion that many scientific laws usually classified as physically but not metaphysically  ecessary may in fact be metaphysically necessary.1 Even if they are n
merely physically necessary, Horwich does not say what the methodological significance of the contrast between physical and metaphysical necessity is supposed to be.
Perhaps Horwich has in mind that empirical science starts from observations of contingent facts. In that respect, however, it is not obviously different from moral theory. Perception is arguably a source of moral knowledge. In suitable circumstances one can literally see that someone is being cruel to a child, just as one can literally see that they are acting in anger and causing pain.2 Such moral knowledge may be the starting point for moral theorizing, and a continuing constraint. Contingent facts about the Nazis are used as a touchstone in moral philosophy: a theory that cannot acknowledge that Hitler acted wrongly must be inadequate. Thus Horwich’s claim that traditional moral theory is not founded on perception – in the broad sense in which his empirical sciences are founded on perception – is also dubious. Of course, specific claims to moral knowledge by perception are not beyond question; even if they are granted, they do not take us all the way by themselves to systematic moral theory. But the same goes for Horwich’s empirical sciences. Specific claims to physical knowledge by perception are not beyond question; even if they are granted, they do not take us all the way by themselves to systematic physical theory.
Horwich’s own description of the starting point of traditional moral theory is 'intuitions.' Presumably, he has in mind the results of thought experiments, which obviously play a larger role in contemporary moral philosophy than in the empirical sciences he lists (physics, biology, and psychology). He does not address the extended critique of talk of intuitions in the book, nor its positive analysis of thought experiments and their epistemology. On the latter, they typically involve offline
applications of the very same skills in applying moral concepts that

Kripke 1980: 164, Bird 2007.
See McGrath 2004. It is not epistemologically plausible that one merely sees that they acted in non-moral way W and combines that knowledge with the necessary moral principle, known a priori, that whoever acts in way W acts cruelly to reach inferential moral knowledge that they acted cruelly. One may know the conclusion of the supposed inference without knowing the premises. Note also that no faculty dedicated to moral perception is being postulated.

1
2 are applied online in judging empirically encountered moral situations.
The gulf between 'perceptions' and 'intuitions' is not as deep as Horwich assumes. After all, the epistemological position of moral philosophy would not be radically transformed if we set up trolley problems and other moral thought experiments in real life rather than the imagination, so that our judgments of them would constitute perceptions rather than intuitions. Of course, supposed moral perceptions are often more controversial than supposed physical perceptions, but Horwich has not begun to show that in this respect they differ in kind rather than in degree.
Thus Horwich’s attempts to use perception and contingency to distinguish his empirical sciences from traditional moral theory misfire.
His remaining criterion, causal explanation, may look more hopeful for distinguishing traditional moral theory in kind from empirical sciences. Causal explanation is surely not the goal of traditional moral theory. However, it is not obvious that causal explanation is the goal even of all empirical sciences. In fundamental physics, the primary aim may be to discover underlying physical laws. Although hypotheses about those laws figure in causal explanations, from the perspective of fundamental physics the point of those explanations may be to test the hypotheses rather than to explain the phenomena. Indeed, it is doubtful that the notion of cause figures in fundamental physics.3 Although causal explanation surely plays some role in empirical sciences, it plays some role in traditional moral theory too. In a recent book on ethics,
David Wiggins asks: 'are we really to believe that the courage of a soldier or the charity (benevolence, kindness, considerateness …) of a
Samaritan will not figure in any explanation of anything that exists or comes to pass?'4 In political philosophy, it would be hard to mount a credible defense of some system of government without considering what effects it causally explains.5 That an arrangement is unjust may help to explain causally why few of those who live under it thrive. In short, none of Horwich’s four criteria establishes a difference in kind between traditional moral theory and the empirical sciences.
Horwich goes further by questioning both whether there are truths in the domain of philosophical theory and, even if there are, whether
3
4
5 Russell 1913, Field 2003.
Wiggins 2008: 380.
A random example: Mill’s On Liberty is full of causal-explanatory arguments. 546   Wittgensteinian Approaches

we benefit from believing them. The first doubt seems to be correctly answered by Horwich’s own minimalist theory of truth. Consider, for instance, a question in the domain of traditional moral theory: is torture always wrong? By the law of excluded middle, either torture is always wrong or torture is not always wrong. By his minimalist condition for propositional truth, if torture is always wrong then the proposition that torture is always wrong is true. Equally, if torture is not always wrong then the proposition that torture is not always wrong is true. Thus, either way, there is a truth of the matter: either the proposition that torture is always wrong is true or the proposition that torture is not always wrong is true. Parallel arguments apply to other questions of philosophical theory.6
In the example, Horwich’s second question amounts to this: do we benefit from having a true belief as to whether torture is always wrong? Given his minimalism about truth, that is equivalent to asking two conditional questions. If torture is always wrong, do we benefit from believing that torture is always wrong? If torture is not always wrong, do we benefit from believing that torture is not always wrong? The answers seem obvious: the relevant belief will help us act well concerning torture. It would be irresponsible not to care about that.
Most philosophical questions lack direct practical applications.
Consider a metaphysician wondering whether people are events. For
Horwich’s second question, we grant that it is either true or false that people are events. What is wrong with simply wanting to know whether people are events? Horwich speaks of benefits in terms of satisfying one’s desires. Presumably, one can desire cognitive goods.
One can derive the benefit of satisfying one’s desire to know whether people are events. If Horwich has no such desire, he need not pursue the question. But the fact that a philosophical question bores Horwich does not mean that it is not worth asking.
In any discipline, some theoretical questions are not worth asking.
However, we have no general method for telling in advance which are worth asking, which are not. We may simply have to trust the instincts of leading practitioners in the field, because we have no basis on which to second-guess them. If the leading practitioners are c13.indd 546 charlatans, the 'discipline' is in trouble. Evidence that philosophers are asking worthwhile questions comes from numerous constructive interactions between theoretical philosophy and empirical or partly empirical disciplines such as biology, economics, linguistics, physics, politics, and psychology. That is hardly what one would expect if the philosophers asked bad questions while the others asked good ones.
Horwich has a further line of argument. He suggests that simplicity is a far less appropriate criterion for theory choice in philosophy than in the empirical sciences because our basic conceptual practices, concerning most concepts of philosophical interest, are not simple, being complicated by the variety of ordinary practical purposes for which we deploy those concepts.
One worry here is that Horwich writes as though the main concern of philosophy were with concepts rather than the properties and relations they are concepts of. He does not address the extensive arguments to the contrary in the book. However, he seems to mean that because our conceptual practices are ramshackle, our concepts refer to ramshackle properties and relations – properties and relations with complex boundaries, of which no simple theory is true. He is making the questionable assumption that complexity in the conceptual practice will induce complexity in its referent. If naturalness carries weight in determining the comparative eligibility of candidates for reference, some complexity in the conceptual practice may instead count as error.7
As an example of a philosophically interesting ordinary concept whose referent has complex boundaries, Horwich gives the concept of knowledge: 'the conditions for mathematical knowledge diverge somewhat from the conditions for empirical knowledge (in not
requiring there to be any causal or counterfactual connection between the knowing and what is known).' He describes these conditions for the application of 'know' as 'disjunctive' (his emphasis). The example is misdescribed. Presumably, Horwich’s reason for denying that mathematical knowledge requires a causal or counterfactual connection is that the necessity of mathematical truths is incompatible with one. If so, however, the necessity of the truth that gold is the element with atomic number 79 should also rule out a causal or counterfactual connection for knowledge that gold is the element with atomic num7

c13.indd 547 ber 79. But the latter is empirical knowledge, contrary to Horwich’s assumption that empirical knowledge does require such a causal or counterfactual connection. In any case, a unitary epistemological
condition may have to be realized in different ways for different subject matters. Thus Horwich has not shown that the conditions for knowledge are disjunctive. Of course, nobody expects them to match those of some fundamental physical relation; such matching is unnecessary for systematic epistemological theorizing. I developed a systematic non-reductive theory of knowledge in Williamson 2000a, partly guided by considerations of theoretical simplicity. Horwich does not attempt a critique of that theory. His use of the example of knowledge fails to help his case.
Horwich mentions the ordinary concept of truth as another example.
On his own minimalist conception, the main constraint on it is the simple schema 'The proposition that P is true if and only if P.' Here too, our conceptual practice does not prevent our concept from referring to something of which a simple theory is true. I applaud the work of Horwich and others in showing how much a minimal characterization of propositional truth can explain, without invoking more elaborate, dubious conceptions of correspondence and the like. Contrary to his impression, I do not regard the semantic paradoxes as the only area in which progress has been made in understanding truth.
Horwich doubts that formal work on the semantic paradoxes has constituted philosophical progress at all. He is right that there has been no convergence on a single solution. However, it is not a zerosum game between the alternative approaches. They all contribute to our knowledge of how closely a consistent theory can approximate to the original unrestricted and therefore inconsistent disquotational principle for sentential (rather than propositional) truth. They are gradually helping us map out in meticulous detail what truthlike properties there are. It would be philistine to dismiss such new knowledge as 'unphilosophical.'
As another candidate for philosophical progress, Horwich discusses the development of truth-conditional semantics. He presents the astonishingly insouciant view that if truth-conditional semantics were empirically significant, it would not be philosophy, but that
deflationism shows it to be an empirically insignificant response to a non-problem about compositionality, whose development has been largely a philosophically insignificant formal exercise. Horwich does not explain what he means by 'empirical significance.' A truth-conditional semantic theory for Serbian will tell you, for example, that the word 'krava' applies to all and only cows. In what sense does that information lack empirical significance? For a different sort of example, consider the rich tradition of work on generalized quantifiers in natural languages. From it have emerged inductively supported hypotheses about universals in natural language, specifically, constraints on quantifiers in all human natural languages that are violated by formally possible languages.8 If a human natural language is discovered to violate such a constraint, the hypothesis will have been refuted. If Horwich’s deflationism entails that the hypothesis is nevertheless devoid of empirical significance, so much the worse for his deflationism.
The case of generalized quantifiers also brings out the hollowness of Horwich’s references to 'use-theoretic approaches' as though they constituted a serious alternative to truth-conditional semantics. Standard works on generalized quantifiers in natural languages, such as the book by Peters and Westerståhl, proceed entirely within the truth-theoretic approach. What works of comparable detail and scope do 'use-theoretic approaches' have to offer?
As for Horwich’s insinuation that truth-conditional semantics has produced little of philosophical interest, it suggests an extraordinarily narrow conception of philosophy. For example, Russell’s theory of definite descriptions is an early piece of truth-conditional semantics.
Does Horwich find it of little philosophical interest?
An intriguing issue nevertheless remains as to how we should conceive the relation between philosophy and linguistics in this area.
How can a claim about the meaning of some specific sentences in a specific natural language be of distinctively philosophical interest? To fix ideas, consider Davidson’s treatment of action sentences.
For example, he proposes something like this for the sentence 'Shem kicked Shaun':9

(1) 'Shem kicked Shaun' is true if and only if there is an event x such that x is a kicking of Shaun by Shem.
8
9 Peters and Westerståhl 2006: 138–41.
Davidson 1980: 118. 550   Wittgensteinian Approaches

That is a metalinguistic hypothesis about a particular sentence of
English. We may be tempted to regard it as of no distinctively philosophical interest. We may be even more strongly tempted to regard the corresponding homophonic disquotational equivalence as of no distinctively philosophical interest:

(2) 'Shem kicked Shaun' is true if and only if Shem kicked Shaun.
We can treat (2), unlike (1), as uncontroversial. But from (1) and
(2) we can deduce a consequence that is not metalinguistic:

(3) Shem kicked Shaun if and only if there is an event x such that x is a kicking of Shaun by Shem.
But (3) is obviously of distinctively philosophical interest, since it permits one to move from a premise ('Shem kicked Shaun') that may be common ground between proponents and opponents of an ontology of events to a conclusion ('There is an event x such that x is a kicking of Shaun by Shem') that is explicitly committed to an ontology of events. Those who regard claims of truth-conditional semantics as of merely linguistic and not philosophical interest typically forget how easily disquotational platitudes allow one to move between metalinguistic and non-metalinguistic claims. Since (1) and (2) jointly entail something of philosophical interest, it is unwise to regard them as of no philosophical interest.
Is (3) 'empirically significant?' Without clarification of 'empirically significant,' the question is hardly worth discussing. The critique of the distinction between a priori and a posteriori knowledge in the book might have warned Horwich that the label 'empirically significant' is too vague to do the work he expects of it. Informed assessment of claims such as (3) requires a complicated mix of linguistic, logical and metaphysical considerations, even though (3) is not itself a claim about language. Horwich’s dichotomy between empirically significant, philosophically insignificant scientific linguistics and empirically insignificant, philosophically significant reflection on language is hopelessly inadequate to the methodological need for interaction between linguistic and non-linguistic considerations, as con- tinually exemplified by good recent work in many areas of linguistics and philosophy. As so often, Wittgensteinian preconceptions stand in the way of following Wittgenstein’s injunction to 'look and see.'
In Horwich’s view, the proper aim of philosophy is to dispel confusions and irrational presuppositions, an activity to be pursued in an unsystematic, untheoretical manner. A familiar feature of Wittgensteinians’ attempts at philosophizing in that spirit is that the informality of the presentation conceals rather than avoids theoretical presuppositions of their own. For the presuppositions they expose in others are not blatantly 'confused' or 'irrational'; they are true or false propositions that cannot be argued against in a theoretically neutral way.
Just about all human discourse involves presuppositions; we must take some things for granted in order to focus on what is relevant. Anyway, the attempt to produce a presupposition-free discourse would lead philosophy in a direction that Horwich could hardly approve, towards the construction of something like Frege’s Begriffsschrift.
Once a presupposition has been identified, the question is whether it is legitimate. That will often be a matter of controversy. Dissatisfaction with dogmatic attempts to end the controversy at a stroke, confused attempts to dispel confusion, is one motive that drives us to systematic theorizing.
For Horwich, the proper task of the philosopher is also to 'quell over hasty generalization.' But, on his view, can there be generalization in philosophy that is not over hasty? He says nothing about how philosophers are to arrive at generalizations without haste, given that they are supposed to avoid systematic theorizing. Are we not supposed to generalize at all? If there are true generalizations in philosophy, it seems a pity that we should not be allowed to look for them.
Surely Horwich does not think that there are no true generalizations in philosophy, for that would be an over hasty generalization. If there are no true generalizations in philosophy, then it is a true generalization in philosophy that there are no true generalizations in philosophy, so by reductio ad absurdum there are after all true generalizations in philosophy.
We can state the argument in a less paradoxical-sounding way.
Either there are true informative first-order generalizations about philosophy or there are not. If there are not, then a true informative second-order generalization about philosophy is that there are no true informative first-order generalizations about it. Therefore, there are true informative first- or second-order generalizations about philosophy. Although they may be difficult to find, we can at least try. In that enterprise, Horwich’s lazy philosophy of philosophy is of no help whatsoever. We must do better.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of the book in Philosophy and Phenomenological
Research (Williamson 2011e). 13.3 Reply to Frascolla
As a case study of philosophical inquiry and its relation to the linguistic and conceptual turns, I used the original question 'Was Mars always either dry or not dry?' I argued that, taken at face value, without reinterpretation as 'really' a metalinguistic or metaconceptual question, it already constitutes a challenging starting-point for philosophical inquiry. In 'On the face value of the ‘original question’ and its weight in philosophy,' Pasquale Frascolla (2011) disputes my account by distinguishing between philosophical and non-philosophical ways of taking the question. He argues that taking the question philosophically involves not taking it at face value.
The first difficulty with Frascolla’s arguments is that he persistently misstates the face value of the original question. Sometimes he does so by gratuitously introducing talk of the truth or falsity of statements.
In particular, he characterizes the classical proof of a positive answer to the question as proceeding via the Principle of Bivalence and considerations about truth-tables, rather than simply as a regular proof in the first-order object-language of a universally quantified instance of the law of excluded middle. Adding that extraneous metalinguistic layer misses the point of my insistence in the book on extreme care with the distinction between the logical and the metalogical. Elsewhere, Frascolla misstates the face value of the original question in a quite different way, by treating it as equivalent to the question 'Was
Mars never a borderline case of dryness?' The difference between the two questions is crucial for both supervaluationists and epistemicists.
On such views, the answer to the original question is positive, whether or not Mars was ever a borderline case of dryness. Thus Frascolla never engages with the actual face value of the question.
Nevertheless, Frascolla has an argument that, if sound, would bypass the first difficulty. He correctly notes that the classical proof of the positive answer to the face value original question immediately generalizes to objects other than Mars and to properties other than dryness. He concludes without further ado that in giving the proof we are not really taking the question at face value. He thereby commits a fallacy against which I explicitly warned the reader (28, this volume). It is like claiming that when I ask 'Am I mortal?' I am not really asking about myself, because the reason for a positive answer can be generalized to anyone else. Having convinced himself that the question must really be about a generalization, Frascolla compounds the error by assuming that the generalization must be a metalinguistic one – as opposed, for example, to a non-metalinguistic generalization in second-order logic.
Next, Frascolla objects to my discussion of an intuitionist’s response to the disputed law of classical logic. He distinguishes between mathematical and philosophical ways of taking the question, confining the intuitionist’s distinctively proof-theoretical considerations to the latter. This is a serious misunderstanding of intuitionism. Brouwer and his followers were revisionists about mathematical practice.
Their proof-theoretical account was intended to apply to mathematical questions, not just to philosophical ones. Frascolla’s account of the intuitionist approach is also distorted by a technical error. He discusses what the intuitionist will say on the supposition that a certain formula is neither provable nor refutable. But for intuitionists that supposition is inconsistent: according to them, A is unprovable only if it is provably unprovable, in which case ¬A is provable on their account of negation, so A is refutable.1
In summing up, Frascolla diagnoses in me 'a meta-philosophical prejudice in favor of the idea that, just like every other discipline that makes truth-claims about how things stand, so too philosophy is concerned with the world (thought and language included).' It is not entirely clear what the content of this prejudice is supposed to be. Is the intended alternative that philosophy makes truth-claims about how things stand, but is not concerned with the world, or simply that it does not make truth-claims about how things stand? I have no restrictive conception of 'how things stand' or 'the world.' If a truth-claim is a claim with a propositional content intended to be true, then it is 18-08-2021 21:07:24 more or less trivial that such a claim is about how things stand and is concerned with the world. So I take the charge to be that I have a metaphilosophical prejudice in favor of the idea that philosophy makes truth-claims. Certainly I endorse the idea, but is it a prejudice?
Is it not rather a piece of commonplace knowledge shared by almost everyone who has read some philosophy, past or present, even if it is denied by some philosophers in the grip of a wildly implausible metaphilosophical theory? Although a few philosophers deny that there are sticks and stones, it is not a prejudice that there are such things.
Many philosophical texts – Locke’s Essay Concerning Human Understanding, or Frege’s Die Grundlagen der Arithmetik – are obviously full of intelligible truth-claims, true or false. What is striking is the ability of some people to persuade themselves of the opposite.
Frascolla goes to a further extreme when he suggests that my claim that 'thinking just as much as perceiving is a way of learning how things are' (49, this volume) 'stands in urgent need of defense.' If I
know that the rabbit went this way or that way or the other way, and
I check that it did not go this way or that way, by thinking I can learn that it went the other way. By thinking, Andrew Wiles and others learned how things are concerning the truth-value of Fermat’s Last
Theorem. Those claims stand in far less urgent need of defense than any philosophical view incompatible with them.

Acknowledgment
This section first appeared as part of my contribution to a symposium on the first edition of this book in Richard Davies (ed.), Analisi: Annuario e Bollettino della Società Italiana di Filosofia Analytica (SIFA)
2011 (Williamson 2011f). I thank Pasquale Frascolla for the care and attention he spent on the book. Like him, I focus on points of divergence. All page references are to the first edition. 13.4 Reply to Marconi
In 'Wittgenstein and Williamson on Conceptual Analysis,' Diego
Marconi (2011) argues that the first edition leaves unscathed a preeminent alternative to its account of philosophy: 'Wittgenstein’s view that philosophical investigations are conceptual investigations.' He is right that although the book contains occasional more or less dismissive remarks about Wittgenstein, it has no sustained discussion of his views. He does better than Heidegger, who is passed over in silence.
The omissions were, of course, deliberate. I wanted to address the situation of philosophy now, not fifty years ago. To discuss Wittgenstein’s conception of philosophy, one must first go through a complex hermeneutic process, not least in order to understand the notorious tensions between his less than transparent philosophical practice and his fragmentary comments on the nature of philosophy – that philosophy makes or should make no controversial theoretical claims is itself a controversial theoretical claim, and so on. One can be quite sure in advance that any account of Wittgenstein’s views that forms the basis for a critique of them will be accused of misinterpretation by
Wittgenstein scholars. The worse the tensions in his corpus, the easier the charge is to make. That was exactly the sort of stale discussion with which I wanted not to take up my readers’ time. For most philosophers today, including me, seeing philosophy Wittgenstein’s way is not a live option.
In terms of Marconi’s clear version of Wittgenstein’s account, it is straightforward to explain why it is no longer a live option for so many philosophers. According to Marconi, 'Wittgenstein’s view that philosophical investigations are conceptual investigations derives from his conception of necessity'; I will not dispute that interpretative claim. The intended connection is this: If there were philosophical propositions, they would be non-contingent. 'However, there are no necessary propositions: if a proposition were necessary, its negation would describe an impossibility. But impossibilities cannot be meaningfully described, hence necessities cannot be meaningfully described either.' The false step here is 'impossibilities cannot be meaningfully described.' For it to serve its function in the argument, the claim must be something like this: whenever a meaningful sentence s expresses the proposition that P, it could be that P. But the claim falls to obvious counter-examples. The sentence '√2 is rational' is meaningful; it expresses the proposition that √2 is rational, the hypothesis for reductio ad absurdum at the start of the standard proof that √2 is irrational.
But √2 could not be rational, for it is irrational and mathematics is not contingent. I have often seen Wittgensteinians confronted with such counter-examples. Their response has always been an appeal to other bits of equally implausible Wittgensteinian dogma. The effect is merely to discredit their own view.
The meaningfulness of the sentence '√2 is rational' derives from the meaningfulness of its parts ('√,' '2,' 'is,' and 'rational') and the way in which they are put together to form a well-formed sentence according to the rules of mathematical English. Correspondingly, the compositional structure determines what proposition has been expressed. I briefly went through such an argument in the book, vainly hoping that its application to Wittgenstein’s ill-considered claims about modality would be obvious (58–60, this volume). Amusingly, another compositional objection starts from a point that Marconi himself makes in expounding the Wittgensteinian argument: 'if p, a proposition that describes a necessity, were meaningful then ~p, the description of an impossibility, would be meaningful as well.'1 By far the best ground for this conditional is the compositional thesis that meaningfulness is preserved under negation: whenever q is meaningful, so is ~q. By the same compositional principle, meaningfulness should also be preserved under conjunction, another truth-function: whenever q and r are meaningful, so is q & r. But together these two principles entail that whenever q is meaningful, so is the contradiction q & ~q, contrary to the Wittgensteinian dogma. One can give a parallel compositional argument at the level of the proposition expressed.
Contemporary theories of propositions have no difficulty with impossible propositions, that is, with propositions that are false

with respect to all possible circumstances. I am well aware that such
objections provoke no end of special pleading on the part of Wittgensteinians. To the unbiased observer, such independently implausible
reactions confirm the bankruptcy of their view. 18-08-2021 21:07:24 Although I am highly sympathetic to Kripke’s overall picture of necessity, Marconi overestimates how much of it the book assumes.
In particular, my skepticism about the usefulness of the distinction between a priori and a posteriori knowledge might have indicated that I take Kripke’s category of the necessary a posteriori with a pinch of salt, while still regarding it as important progress. But no distinctively Kripkean assumptions are needed to reject Wittgenstein’s wild claims about necessity. As just seen, far more elementary considerations suffice.
Compositional considerations also tell against Wittgenstein’s idea that sentences such as 'Knowledge entails truth' express rules for the use of words rather than true propositions about a non-linguistic subject matter. According to Marconi, 'Discovering that knowledge entails truth is discovering that within the practices where words such as ‘know’ and ‘true’ are used, the concepts of knowledge and truth are so applied that we do not call a propositional content ‘knowledge’ if we do not take it to be true.' The passage seems to involve a use–mention confusion. Ancient philosophers who knew that knowledge entails truth knew nothing about the English words 'know' and
'true.' Even if we restrict attention to competent speakers of English, the two discoveries are entirely distinct. Someone could realize that knowledge entails truth but regard the entailment as a logical subtlety to which few native speakers have access. Conversely, someone could realize that the concepts of knowledge and truth are so applied that we do not call a propositional content 'knowledge' if we do not take it to be true, but deny that knowledge entails truth on the grounds that our conceptual practices are incoherent (as witnessed by the Liar paradox) and have no automatic connection to the objective logical relations. Even if such combinations of views are mistaken, they still highlight the cognitive gap between the two discoveries. Even if we were to stipulate the linguistic rule that 'knowledge' applies only if 'true' applies, for compositional reasons the declarative sentence
'Knowledge entails truth' would still express a true or false proposition. The first edition explains the same point in terms of a less philosophical example (73–4, this volume).
One reason for Marconi’s failure to notice the anti-Wittgensteinian arguments implicit in the book is its equation of conceptual truth with analyticity and its use of very standard examples of the latter.
That may have given the impression that I was relying on a narrow traditional account of analyticity, on which many truths that count as conceptual for Wittgenstein are synthetic. I was not. On the contrary,
I was following current usage outside the Wittgensteinian camp, in which there is no clear distinction between 'conceptual truth' and
'analytic truth' but both terms are regarded as up for grabs, given the manifest inadequacy of the usual explanations as they stand. I
used traditional paradigms of analyticity out of charity to my opponents, because their claims were likely to work for those cases if for any. I canvassed a wide variety of alternative explications of 'analytic' or 'conceptual truth' (50–135, this volume). The reason why I
did not directly confront Wittgensteinian formulations about grammatical rules and the like was not definitional sleight of hand, but simply that I find them too unclear and poorly developed to be useful poles of discussion.

Acknowledgments
This section first appeared as part of my contribution to a symposium on the first edition of this book in Richard Davies (ed.), Analisi: Annuario e Bollettino della Società Italiana di Filosofia Analytica (SIFA) 2011
(Williamson 2011f). I thank Diego Marconi for the care and attention he spent on the book. Like him, I focus on points of divergence. All page references are to the first edition. 13.5 Reply to Tripodi
In the book I give counterexamples to epistemological conceptions of analyticity. They illustrate the point that even a basic disagreement in logic is compatible with shared meanings. In 'Peter, Stephen …
and Ludwig,' Paolo Tripodi (2011) maintains that my argument begs the question. He reasonably takes as one of my primary targets the claim that philosophy is connective analysis, which he defines as 'the a priori description of the conceptual connections (and exclusions) in the web of one or more words' and takes to cover the philosophical practice of the later Wittgenstein, Peter Strawson, and other analytic philosophers of that epoch and general style. He then reasons that if philosophy is indeed connective analysis, two philosophers who give different connective analyses of the same word associate different concepts with it and therefore understand it differently, in which case my counterexamples fail.
One problem for Tripodi is how high he has set the bar for himself. If it is even possible for a few philosophers not to engage in connective analysis but, however mistakenly, to try doing philosophy in a more theoretical or critical spirit, then my counterexamples can involve philosophers of that sort. Thus his argument depends on something more like the premise that necessarily all meaningful philosophical activity is connective analysis. The immense variety in the world history of philosophy suggests that no such flatteningly reductive formula is even approximately correct.
But even if two philosophers do engage in connective analysis, and give different analyses of the same word, why should it follow that they associate different concepts with it or understand it differently in the sense relevant to my counterexamples: that is, why should it follow that they use the word with different meanings? Of course, if their 'analyses' were mere proposals to use the word with the stipulated meaning in future, they might bring about a divergence in meaning. But such revisionary meaning stipulations are more in the spirit of Carnap than of Wittgenstein and Strawson. Moreover, the idea that philosophy consists entirely or even mainly of meaning stipulations is hopelessly implausible. In any case, it is not what
Tripodi has in mind, since he defines connective analysis as a description of conceptual connections. On this picture, the philosopher’s task to describe (a priori) semantic networks of conceptual connections between words of a public language with which they are competent. That makes the question even more pressing: if two philosophers give inequivalent descriptions of such connections, why should it follow that they are describing different concepts or meanings? Why exclude the possibility that they are describing exactly the same thing, although one or both of them is describing it incorrectly or incompletely?
Tripodi comes closest to facing the objection in this passage: 'Of course, the connective analyst intends to describe the conceptual behavior of a shared concept. Nonetheless, she ultimately describes the conceptual behavior of what she takes to be the standard concept. Her key access to that concept is her own individual semantic competence.' But such fudging can be used in an attempt to wriggle out of any charge of misdescription of anything whatsoever. Suppose that I describe the wallpaper as having a pattern of pentagons, and you point out that in fact it is a pattern of hexagons. I reply:
'Of course, I intended to describe the pattern of the wallpaper itself.
Nonetheless, I ultimately described what I took to be the pattern of the wallpaper. My key access to that pattern is my own individual perception.' The analogue of Tripodi’s claim is that your description of the pattern on the wallpaper did not conflict with mine, because each of us was correctly describing the pattern of the wallpaper as we perceived it. But that is mere sophistry. In the envisaged case, your description was right and mine was wrong. Each of us intended to describe the pattern on the wallpaper itself, not our perception of it; those intentions set the standard of correctness for our descriptions.
Exactly the same applies to the description of a semantic network in a public language.
Tripodi’s argument does not even fit the practice or theory of the later Wittgenstein, Strawson, and the other practitioners of connective analysis he lists. Surely they thought that sloppy or prejudiced philosophers can misdescribe conceptual connections: the result is an incorrect description of public concepts, not a correct description of private ones.
Thus, contrary to Tripodi’s charge, my counterexamples do not beg the question against the view that philosophy is connective analysis, since they work even on that view. Of course, I deny that philosophy is connective analysis, and part of my reason for doing so is that the critique of epistemological analyticity helps undermine the very idea of a conceptual connection. But that does not make the critique question-begging.1, 2

Acknowledgments
This section first appeared as part of my contribution to a symposium on the first edition of this book in Richard Davies (ed.), Analisi: Annuario e Bollettino della Società Italiana di Filosofia Analytica (SIFA)
2011 (Williamson 2011f). I thank Paolo Tripodi for the care and attention he spent on the book. Like him, I focus on points of divergence. All page references are to the first edition.

Another tendentious aspect of Tripodi’s comments is that he describes my counterexamples to epistemological analyticity as borderline cases of understanding. As I
emphasize in the book, they are in fact clear cases of understanding, controversial only for those in the grip of a philosophical theory. 2
Contrary to a speculation that Tripodi reports, my imaginary philosopher Stephen was named after Stephen Cole Kleene (for his three-valued tables), not after Stephen Schiffer. 13.6 On Paul Horwich’s Wittgenstein’s
Metaphilosophy
'Arguably,' says Paul Horwich, 'Wittgenstein’s singular achievement was to have appreciated the true nature of philosophy' (vii).
The book’s primary aim is to expound and support a certain conception of philosophy. Arguing that it was Wittgenstein’s conception is a secondary aim, although one that Horwich takes to be rather easily achieved on the basis of Part I of Philosophical Investigations.
The reader is exposed to just two sorts of philosophy. One of them is traditional theoretical philosophy, which Horwich calls 'T-philosophy.' The other is Wittgenstein’s therapeutic critique of T-philosophy.
The latter does not rest on any particular view of meaning, according to Horwich. Rather, it engages in detailed case studies of T-philosophy, showing up its ill-founded scientistic pretensions, its cavalier way with recalcitrant data, its blindness to simple resolutions of supposedly deep problems, and the irrational dogmatism of its practitioners.
On the picture that emerges, 90% of philosophy is a waste of space, while the remaining 10% consists of praiseworthy demolitions of the
90%. Horwich does not explain why taxpayers should be expected to fund a branch of the academy with that structure. Would it not be cheaper and more effective simply to abolish philosophy altogether?
Proponents of a therapeutic conception of philosophy often argue that it can perform valuable purgative services for the wider culture, so we should not be better off without it. But Horwich does not make that argument. Doing so might generalize the imputation of intellectual bankruptcy to many other domains.
Naturally, Horwich and Wittgenstein’s conclusion is not that we should do T-philosophy better, but that we should not do it at all. The upshot of the critique is supposed to be that T-philosophy is a hopeless enterprise, the construction of elaborate theories to solve what are in fact mere pseudo-problems. Of course, that is just the sort of surprising, very general conclusion characteristic of T-philosophy, and so raises the notorious difficulty that Wittgenstein’s metaphilosophy seems to be self-refuting. To his credit, Horwich confronts the difficulty head-on. His response is that the critique involves no theory about some hidden reality: it merely draws attention to straightforward matters open to view on the surface, after which the conclusion that T-philosophy is irrational is a statement of the obvious (65–6).
Although many philosophers deny that T-philosophy is irrational,
Horwich correctly insists that something may be potentially obvious yet highly controversial.
However, some T-philosophers claim that their conclusions are potentially obvious, once one has attended to the relevant straightforward matters. The question is whether Horwich’s considerations are really clearer and more decisive than the T-philosophers’, whether they really render their conclusions more obvious. They do not. Horwich offers arguments of a recognizably philosophical kind; as he says, he writes in the style of contemporary analytic philosophy (xiii).
His arguments are better than many in T-philosophy, and worse than many others. Indeed, his arguments tend to suffer from the very faults of which they accuse T-philosophy.
One example is Horwich’s discussion of the use of the word 'pain,'
a major part of his attempted dissolution of the 'mystery' of consciousness. Following Wittgenstein, he claims that '‘He thinks he is in pain but perhaps he is mistaken’ and ‘I am not sure if I am in pain’
are considered deviant, anomalous – a sort of violation of linguistic rules' (184). But when my son pinches me, I am sometimes unsure whether the irritating sensation is bad enough to be pain, and people prone to self-pity sometimes mistakenly think that they are in pain when they get a slight bump. In neglecting such common sense cases,
Horwich is just as cavalier with the data as he claims T-philosophers to be. On minimal and misdescribed evidence, he postulates an unspecified rule of English unknown to linguists outlawing such ordinary utterances: just the sort of reckless theorizing he treats as typical of T-philosophy. Horwich also claims that his account of 'pain' talk removes 'the worry that other peoples’ pain might be different from our own' (194). In dismissing such individual variation, he ignores the everyday differentiations amongst pains in natural language. For instance, a doctor may ask her patient 'Is it a throbbing pain?' The phrase 'throbbing pain' is not familiarly correlated with specific nonlinguistic throbbing-pain behavior in anything like the way in which
Horwich, following Wittgenstein, describes 'pain' as familiarly correlated with specific non-linguistic pain behavior. Since Horwich is reaching a general conclusion about different types of pain on the basis of considerations about ordinary talk, while neglecting ordinary talk about different types of pain, he is again doing just what he criticizes T-philosophers for doing. Of course, the ordinary possibility that I have a throbbing pain while you have a pain of some other type does not justify regarding consciousness as a mystery. The point is just that Horwich’s arguments, far from making his conclusions obvious, clearly belong to T-philosophy as he describes and condemns it.
Similar illustrations can be given from other parts of the book.
We are told that 'if everything is normal, red things look red, and they look that way to everybody' (204): does 'everybody' include the color-blind? On almost no evidence, Horwich proposes a highly speculative use theory of meaning, on which the use of a word is explained by a basic regularity for its use. Although a few examples are given, they are not developed. In each case, the alleged basic regularity for a word w involves using other words too, even though one can understand w perfectly well without having encountered those other words (122–3, 154–5). Nevertheless, we are told, 'it is potentially obvious' that meaning is use (115). A supposedly non-intentional characterization of use is given in terms of premises and assertions
(113). And so on.
If one could argue by the highest standards of T-philosophy that Tphilosophy is irrational (a word Horwich frequently applies to it), that might be taken to show by reductio ad absurdum that T-philosophy is indeed irrational, even without making that conclusion obvious.
But Horwich’s arguments fall well short of the highest standards of contemporary T-philosophy. Many past and present T-philosophers do better. Rather, the book resembles a flawed statistical argument for the irrationality of statistical argument. That might constitute a useful warning of the need for high standards in statistical argument; it would not show that statistical argument itself is irrational. Similarly, although Horwich’s book may constitute a useful warning of the need for high standards in T-philosophy, it does not show that
T-philosophy itself is irrational.
A further reason for skepticism about Horwich’s arguments comes from their tendency to generalize from T-philosophy to other branches of inquiry. He considers the objection that arithmetic qualifies as Tphilosophy because it too 'purports to arrive a priori at non-obvious results.' But arithmetic is different, says Horwich, 'since it arrives at its number-theoretic conclusions by demonstrative proof rather than by the forms of conjectural inference relied upon in T-philosophy'
(22). The trouble with that reply is that it does not address the status of the axioms or other first principles of demonstrative proof. If one treats arithmetic as basic, an example is the principle of mathematical induction. If one derives the arithmetical principles from definitions, that merely shifts the problem to the status of the first principles of second-order logic or set theory on which the derivations rely. When one looks at how mathematicians actually justify their first principles of proof, one finds speculative abductive reasoning and stretched appeals to the imagination, both of a kind quite reminiscent of T-philosophy. Considerations of simplicity play a significant role, despite
Horwich’s talk of 'an irrational distortion that tends to occur when the demand for simplicity is carried over from empirical science to a priori philosophy' (34). He also asserts that 'in the a priori domain we cannot reasonably deploy the picture of increasingly profound layers of reality' (39). But mathematicians and logicians often do deploy just that picture, taking new results to give a deeper understanding of old ones. To a much greater extent than Horwich realizes, his critique of T-philosophy relies on features that T-philosophy shares with logic and mathematics.
Horwich’s arguments also have an uneasy relationship with the special sciences. He criticizes systematization in philosophy on the grounds that 'in all but a few cases the complexity of our data makes it unreasonable to expect interesting results' (49) and that 'If a complex systematization is all that can be achieved then there are bound to be equally good alternatives; in which case we won’t have legitimate epistemic norms that will enable us [to] decide between them' (50).
The reader is left wondering why such points, if good, would not also tell against systematization at the level of linguistics, psychology, or biology. In a different connection, Horwich describes the use of ideal laws as 'a common and legitimate feature of scientific theorizing,'
and correctly notes that 'the standardly desired blend of empirical adequacy, simplicity, and explanatory power is sometimes best achieved by means of a theory whose two-pronged form is to postulate certain ideal laws (or ceteris paribus laws) and certain distorting factors'
(156–7). The natural question is not raised: why shouldn’t philosophers achieve systematicity in complex domains by constructing theories with ideal laws? Indeed, in formal epistemology they have already done so, quite successfully. The sense of a double standard at work is confirmed by Horwich’s complaint that T-philosophers do not respect their data in the way scientists do, because T-philosophers sometimes reject observations made by normal subjects in normal conditions
(37–8, 46). But natural scientists are just as liable as T-philosophers to reject the judgment of a normal observer in normal conditions that the sun is rising or that a fish is breaching. The possible explanations for observational and experimental error are not circumscribed in advance. When done well, both natural science and T-philosophy second-guess their data in flexible but intellectually responsible ways.
A more nuanced and accurate description of natural scientific practice in this respect would not support the stark contrast with T-philosophy that Horwich claims.
The book depicts T-philosophy as starting from an unwarranted scientistic presumption that the given abstract domain satisfies simple yet deeply hidden laws. But no such presumption is needed. For example, one can ask what principles of quantified modal logic hold when the modal operators are read as expressing metaphysical modalities and the quantifiers are read as unrestricted. The question is philosophical, not merely technical. It does not presuppose that some principles of quantified modal logic do hold on those readings. If none hold, that is itself a simple and deeply hidden answer to the question.
As it happens, much progress has already been made towards answering the question. We know many principles to hold universally on the specified readings: for example, all those of the propositional modal logic KT. Other principles remain highly controversial, such as the Barcan formula, and the principle that everything is necessarily something. If some of us are curious whether those further principles hold, why is it irrational for us to try to find out? The book provides no serious evidence that the inquiry must fail.
Of course, a standard Wittgensteinian objection to such an inquiry is that the alleged T-philosophical questions are meaningless, because they confuse grammatical matters with factual ones, or spin in the void, or whatever. A refreshing feature of Horwich’s book is that he does not rely on that implausible charge, since – whatever its advocates may say – supporting it requires large and distinctively T-philosophical assumptions about the nature of meaning. For Horwich,
Wittgenstein’s views about meaning and other philosophical topics derive from his metaphilosophy, not the other way round. Whether
Horwich is right about that is a question for Wittgenstein scholars to decide. This review has not addressed the faithfulness of Horwich’s interpretation of Wittgenstein to the original, since that is only a secondary aim of the book, albeit one Horwich takes himself to have achieved. However, if his interpretation is even roughly faithful, then
Wittgenstein is not a philosopher of much depth or consistency. The point emerges the more clearly thanks to Horwich’s commendably straightforward and accessible style and his refusal to take refuge in mysticism or dark sayings (but no thanks to the awful proof-reading).
One may therefore predict that most Wittgenstein scholars will find
Horwich’s interpretation unfaithful.

Acknowledgment
This section first appeared as a review of Horwich 2012 in the European Journal of Philosophy (Williamson 2013h).

c13.indd 568 14
Miscellany

14.1 Reply to Ichikawa
The first edition analyses the Gettier thought experiment as an
argument whose major premise is a counterfactual conditional. In
'Knowing the Intuition and Knowing the Counterfactual' (Ichikawa 2009), Jonathan Ichikawa objects that this misrepresents the thought experiment as more accident-prone than it really is. If the world does not cooperate, the counterfactual will fail: it will be false that if the Gettier text had been realized, there would have been justified true belief without knowledge. Even if the world cooperates enough to make the counterfactual true, it may still not cooperate enough to enable us to know it, if it could too easily have been false.
Ichikawa denies that the thought experiment is such a hostage to empirical fortune. The first edition considers such objections, arguing that although the thought experiment is indeed not immune to misfortune, that should not drive us to skepticism. If we identify an unwanted way in which the Gettier text might well have been realized, we can easily fix it by extending the text to rule out that way (202–6, this volume). There is no need to pretend that we had already fixed the problem before we had even thought of it. Rather than repeating those arguments, I will inquire whether Ichikawa’s proposed alternative does any better.1
The main idea behind his proposal is to replace the Gettier text by the Gettier story. The latter strictly implies far more than the former does, because many things are true in a story without having been explicitly stated in the text of that story. Thus, unlike the Gettier text, the Gettier story is supposed to strictly imply that there is justi1

c14.indd 569 fied true belief without knowledge, so that the problem of unwanted
realizations no longer arises. However, we are not to conceive thinkers performing the thought experiment as conceptualizing the Gettier story to themselves as what is true in the fiction presented by the
Gettier text. Rather, given their familiarity with the practice of fiction, reading the text puts them in a position to entertain a more specific proposition, which they might articulate to themselves as 'Things are like that.'2 They can then argue: it is possible for things to be like that; necessarily, if things are like that then there is justified true belief without knowledge; therefore, it is possible for there to be justified true belief without knowledge.
The significance of the proposal does not lie in the use of strict implication rather than the counterfactual conditional to formulate the major premise. For a strict implication entails the corresponding counterfactual, and the latter suffices to validate the passage from the possibility of its antecedent to the possibility of its consequent, while making an epistemically less risky claim. In fact, Ichikawa could take over exactly the formalization of the Gettier argument that the book recommends, counterfactual and all. The only difference would lie in the interpretation of the predicate GC. Whereas I explain it in terms of realizing the Gettier text, Ichikawa would explain it in terms of realizing the Gettier story, or verifying the proposition that things are like that. What matters for his proposal is that the strict implication be true, not that it be used as the major premise. Its truth is what is supposed to remove the element of epistemic luck.
An obvious danger for Ichikawa’s account is that truth in fiction may itself depend on counterfactuals that one can be wrong about if the world does not cooperate, as in David Lewis’s classic account
(1978). In a world in which it is highly abnormal not to have many alternative sources of knowledge for a given belief, Gettier’s text may present a fiction in which it is not true that the protagonist has justified true belief without knowledge. If we are in an abnormal pocket of ignorance within such a world, then the Gettier story does not strictly imply that there is justified true belief without knowledge; perhaps it even strictly implies that there is no justified true belief without knowledge. Thus it is not obvious that Ichikawa’s account c14.indd 570 avoids the epistemic risks to which he objects in mine. That we articulate the proposition as 'Things are like that' rather than 'Whatever is true in the Gettier fiction is true' does not help us avoid the risk of error when we believe that proposition to strictly imply a case of justified true belief without knowledge.
Ichikawa does not address the challenge in exactly that form. He does tell us that when one considers the Gettier text, one 'enriches it, considering a more-determinate scenario.' He allows that 'divergent private fillings-out of the scenario' are possible, but suggests that we normally avoid them because 'we have particular conventions, grounded in our practices with fictions, that govern how to move from a weaker description to a stronger scenario in the intended way.' This suggests a psychological process, inspired by the Gettier text, of constructing our own fiction, whose additional content can be generated in part by our false beliefs. Thus, even if it is not really true in the Gettier fiction that there is justified true belief without knowledge, the proposition that we express by 'Things are like that'
may nevertheless still imply that there is justified true belief without knowledge.
Is such an account psychologically plausible? Often, when we perform a thought experiment, we simply read the text and make a verdict, or hesitate to do so. We need not sit there, daydreaming, adding detail after detail to the story. Visual imagery is absent or, if present, usually irrelevant (one may imagine the protagonist of Gettier’s story with black hair). Entertaining the proposition that things are like that is not just a matter of demonstrating a possible world that one can already see in one’s mind’s eye.
In Ichikawa’s example, the original Gettier-like text is this:
T1 At 8:28, somebody looked at a clock to see what time it was. The clock was broken; it had stopped exactly twenty-four hours previously. The subject believed, on the basis of the clock’s reading, that it was 8:28.

Ichikawa points out that T1 conjoined with the originally unintended T2 no longer works as a Gettier case:
T2 The subject knew in advance that the clock had stopped exactly twenty-four hours previously. On Ichikawa’s view, the normal reader of T1 constructs a more specific proposition than T1 expresses that is incompatible with the proposition that T2 expresses. But how, exactly? Normal readers of
T1 are taken by surprise when the possibility of elaborating T1 with
T2 is pointed out to them. They have not already gone through a psychological process of formulating T2 and elaborating T1 with its negation, still less with the negation of T3 or of T4:3
T3 The subject knew in advance that the clock had stopped an exact multiple of twenty-four hours previously.
T4
The subject knew in advance that she suffered from a rare psychological condition that rendered her incapable of reading a clock as saying 8:28 at any time other than 8:28.

If the normal reader of T1 has excluded T2, T3, and T4 before even having formulated them, it is not through a psychological process of explicitly formulating something that, combined with T1, logically implies their negations. The original exclusion, if psychological at all, is dispositional rather than occurrent. The relevant disposition might be to add the negations of T2, T3, and T4 to T1 if the question arises.
On this view, what proposition the reader expresses by 'Things are like that' is determined by the set of sentences she is disposed to add to T1 if the question arises.
Such a view faces many problems.
First, the sentences a given reader is disposed to add to T1 if the question arises are quite likely to form an inconsistent set. This need not mean that she is disposed to continue T1 in an inconsistent way.
She may rather be disposed to continue T1 in different individually consistent but jointly inconsistent ways, depending on which question arises first. For example, a mildly suggestible reader may be disposed to add either T5 or T6 to T1, depending on which question arises first:
T5 The subject was not wearing a wristwatch.
T6 The subject was wearing a wristwatch, but it had stopped. 18-08-2021 21:34:04 After all, each of T5 and T6 seems to be a reasonably adequate and natural way of filling out the text of T1. But once such a reader has added T5 to T1, she may lose the disposition to add T6, and vice versa. Even the dispositions to add T2, T3, and T4 may be sensitive to what else has already been added. It is by no means obvious how to construct a metaphysically possible proposition out of such a complex web of interrelated dispositions. Yet Ichikawa’s rendering of the
Gettier argument requires such a proposition, to verify the premise that it is possible for things to be like that. Indeed, he requires us to know that it is possible, if the argument is to give us knowledge of its conclusion, that it is possible for there to be justified true belief without knowledge. Thus Ichikawa’s account makes the epistemology of the first premise of the Gettier argument problematic in ways that mine does not.
Second, an account of the content of 'Things are like that' in terms of the reader’s psychological dispositions to fill out the original text almost guarantees that different readers will express different contents by the sentence. Ichikawa’s appeal to our familiarity with the conventions of fiction merely suggests that those contents will tend not to differ too greatly from reader to reader. By hypothesis, the contents do not in general coincide with the shared story itself, on pain of undermining his implied account of the epistemology of the major premise. When two readers apparently disagree in their verdicts on a thought experiment, that already constitutes a difference in their psychological dispositions to fill out the original text, and so provides prima facie reason to believe that they associate different contents with 'Things are like that.' If so, they are not really disagreeing on
Ichikawa’s account. But that is not how philosophical discussion of thought experiments works. We allow the text of the thought experiment to fix a shared content, and then discuss that scenario.
Third, even if one is performing a thought experiment in isolation from other people, one’s verdict on it is still in general a judgment that can be true or false independently of one’s disposition to make it. Only a very foolish philosopher, on coming to a verdict on a tricky example in ethics, would think 'I can’t be wrong about this; it’s just how I’m envisaging the case.' Ichikawa’s account has not yet shown enough distance between the specification of the scenario in a thought experiment and our dispositions to make further judgments as to what would be the case in that scenario. Providing that  istance will tend to reintroduce the epistemic risks with respect to d
the major premise of the Gettier argument that he complains about in my account.
Whatever the details of Ichikawa’s account, it exemplifies a strategy against which I argued in the first edition: the attempt to combat skepticism about our evidence in philosophy by psychologization. His application of the strategy is quite subtle, since what he psychologizes is not the content of the premises of the Gettier argument but our relation to that content. Rather than grasping it by understanding the public verbal description of the scenario, our filling out of the description is supposed to acquaint us psychologically with the content in a way that not only allows us to articulate it as 'Things are like that'
but somehow enables us to avoid the normal risks of error in judging what would be the case in a scenario. The strategy is no more successful here than elsewhere.
We cannot realistically expect that the method of thought experiments in philosophy will turn out to be much more reliable than the methods of the natural sciences. What, then, is so bad about accepting that the former is not immune from a mass of easily corrected small errors like those to which the latter are quite obviously subject?

Acknowledgments
This section originally appeared in Philosophical Studies as part of my half of a symposium on the first edition (Williamson 2009b).
Thanks to Jonathan Jenkins Ichikawa for his interesting questions and to participants at the Arché workshop in St. Andrews which led to this exchange for discussion. 14.2 Reply to Martin
In 'Reupholstering a Discipline' (Martin 2009), Michael Martin contests two themes of the first edition: the idea that philosophy makes progress and knowledge maximization as a principle of charity in interpretation. I will discuss his comments on each theme in turn.

1
Martin suggests that the idea of progress in a discipline, although applicable to mathematics and the natural sciences, fails to fit some of the humanities, such as history, so that we should not be too surprised if it also fails to fit philosophy. In making that suggestion, he does not intend to align himself with post-modern conceptions of inquiry as merely continuing or subverting a conversation.
Does the comparison with history help Martin’s case? Of course, historians tend to distance themselves from the idea of progress in history as the succession of human doings and sufferings. But that is not what Martin means. He is questioning whether history as a discipline makes progress. He says very little to support a negative answer. Yet significantly more is known about a vast range of historical matters than was known fifty years ago. That is not just factgrubbing. Significantly more is understood about those matters too.
For instance, the role of religious belief in the English Civil War is better understood than it was. Again, history has vastly extended the range of its inquiries, for instance into the lives of members of marginalized groups. Its methods have developed, not only through the application of advances in science, such as statistics and DNA
analysis. More critical and more imaginative ways of learning from documents are available. It seems merely quixotic to deny that if such changes really have taken place, they constitute progress in history as a discipline. Of course, someone may deny that the role of religious belief in the English Civil War is really any better understood now than it was fifty years ago. But, if so, that neither would nor should be a matter of indifference to the historians concerned. It would be a failure on their own terms. Martin does not seem ready to endorse such skepticism about history as a discipline. Although the progress it makes is piecemeal, the sort of progress I suggested philosophy makes is piecemeal too. Thus the comparison with history, to the extent to which it is relevant, undermines Martin’s case against progress in philosophy.
Martin is more willing to countenance progress for individual philosophers than for the discipline as a whole. But this individualistic preference is hard to reconcile with the social nature of philosophy.
Many of us see ourselves as participating in a collective enterprise, one that goes back to the ancient Greeks if not further and, we hope, will continue for millennia to come. The point of publishing is not only to advance one’s career or benefit from feedback. It is to contribute, if only in a very small way, to an inquiry that will continue after one’s death. For example, one tries to bring to others’ attention a possibility they have missed, so that in the long run philosophers may determine whether it actually obtains. One defines one’s individual goals in relation to progress in the discipline.
Even at the level of the individual, Martin is cautious about the idea of philosophical knowledge, and seems happier speaking of understanding. The thought that, individually or collectively, we might progress in understanding without progressing in knowledge is a familiar cop-out in defense of the humanities. Does it withstand scrutiny? If you don’t know why Rome fell, you don’t understand why
Rome fell. If you do know why Rome fell, you have at least made considerable progress towards understanding why it fell. You might know that such-and-such caused Rome to fall without knowing why such-and-such caused Rome to fall, but what you lack there is more knowledge. Nor is knowing why some mysterious sort of nonpropositional knowledge. What constitutes knowing why the barn caught fire is, for instance, knowing that the burning match Innocent dropped in the straw caused the fire. It is not radically different in philosophy. If you don’t know why zombies are impossible, you don’t understand why zombies are impossible. In such cases, the idea that understanding transcends knowledge depends on too narrow a conception of the facts to be known.1 In any discipline, practitioners may be reluctant to summarize progress in a one-liner. 18-08-2021 21:34:04 2
In the latter part of his comments, Martin develops a putative counterexample to knowledge maximization as a principle for determining reference. He assumes that one can simultaneously attend visually to each of two objects in different parts of one’s visual field; I am quite happy to grant that assumption for the sake of argument. In the imagined case, one is simultaneously attending visually to each of two qualitatively identical pink Dolly Mixtures, righty and lefty, while attending in thought only to lefty. One thinks 'That’s pink,'
referring only to lefty. Martin suggests that knowledge maximization cannot determine whether the reference is to righty or to lefty, because the sentence would express knowledge either way. He stipulates that the 'salient non-intentional facts' are symmetrical between righty and lefty.
Presumably, Martin is not suggesting that the symmetry between righty and lefty at the non-intentional level is perfect. If asked 'Which one?,' one will answer 'The one on the left,' not 'The one on the right.' That difference corresponds to some causal asymmetry at the non-intentional level. The question is whether my account can engage with that asymmetry. It can if the question is asked; as Martin notes, only the correct assignment of reference makes the thought 'That’s furthest to the left' knowledgeable. But he stipulates, legitimately, that one has no such actual thought in the given case. The book does not formulate knowledge maximization in counterfactual terms.
The account of reference determination in the book appeals to naturalness at more than one point. Martin designs the case to pre-empt a straightforward appeal, but neglects a subtler possibility. Knowledge itself should be a somewhat natural relation (268, this volume).
If one refers to lefty in the counterfactual case in which the question
'Which one?' subsequently occurs, then it is more natural for the reference to be to lefty in the actual case in which the question does not occur, for the two cases begin the same. A difference in reference between them would make knowledge less natural.
Perhaps we can go deeper. For although one is visually attending to both lefty and righty equally, it does not follow that one’s thought
'That’s pink' has symmetrical causal relations to righty and lefty.
The simplest suggestion would be that it is causally explained by the fact that lefty is pink and not by the fact that righty is pink. That is insufficiently general, for in one version of the example I first think
'They are both pink,' an event which does have symmetrical causal relations to righty and lefty, and then infer 'That’s pink' of lefty, with no further causally relevant input from the color of lefty. In such a case, what – if anything – do we imagine the reference of 'that' to lefty rather than righty as consisting in?
An appealing picture is that when one starts using 'that' with reference to lefty, one opens some sort of mental file, if only a very temporary one, with a predominant causal connection to lefty that enables it to act as a channel for perceptual information about lefty more directly than it can act as a channel for perceptual information about righty: potentially, a channel for knowledge of lefty rather than righty. It does not matter whether that knowledge includes the particular item that it is pink, for the thought 'That is pink' still has a compositional semantics. Even if no knowledge actually happens to be gained through that channel, the naturalness of the reference relation may still keep the reference constant between the actual case and counterfactual cases in which knowledge of lefty is gained through the channel.
That picture is not the only one consistent with the knowledge maximization principle. However unappealing on other grounds, a descriptivist account on which 'that' somehow abbreviates a description such as 'The one on the left' or 'The one actually on the left' is also consistent with the principle. Other, more complex possibilities are consistent too. But if we suppose that no such story is to be told in the example, it ceases to be a clear case of reference to lefty; a verdict of reference failure becomes much more plausible. The case was not intended to be one in which the reference to lefty was puzzling to everyone; it was intended to discredit the knowledge maximization principle by providing a puzzle distinctive to it. But, as just seen, it can be accommodated within the book’s framework of knowledge maximization and naturalness.

Acknowledgments
This section originally appeared in Philosophical Studies as part of my half of a symposium on the first edition (Williamson 2009b). Thanks to Michael Martin for his interesting questions, and to participants in the Arché workshop in St. Andrews that led to this exchange for discussion. 14.3	 On Robert Brandom’s Reason in Philosophy:
Animating Ideas
Humans have a predictable liking for theories of what makes humans special, far above mere beasts and machines. Robert Brandom backs one of the most popular candidates, reason, in a specific form indicated by the word 'reasoning': making inferences, reaching conclusions from premises. Are we really the only reasoners? A dog traces its quarry to a place where it could have gone any of three ways, sniffs at two of them and rushes off along the third without sniffing. The Stoic
Chrysippus interpreted the dog as reasoning 'It went this way, that way or the other way; it did not go this way or that way; therefore it went the other way.' Far more complex logic is routine for computers. Such examples would not convince Brandom. For him, they lack a normative dimension essential to genuine engagement with reasons.
When humans make a judgment, we incur both a responsibility to provide our reasons if challenged and a commitment to endorse consequences of what we claimed or else withdraw the claim. Dogs and computers incur no such responsibilities or commitments. Brandom labels his view 'normative rationalism.'
Distinguishing humans from others is just one of many achievements attributed to normative rationalism. Brandom is going for broke. In the first half of this short book, 'A Semantic Sonata in Kant and Hegel,' he depicts normative rationalism as the rightful inheritor of the best and deepest in the German idealist tradition. His argument ranges boldly over norms, selves, concepts, autonomy, community, freedom, history, reason, reality. Selves come in because they incur the responsibilities and commitments. Since contradicting oneself is bad, unlike contradicting someone else, rational norms demarcate the boundaries between selves. Concepts are rules for applying words; they give specific shape to the norms. Those concepts are ours because we make the rules. Our autonomy is that power to bind ourselves with self-given norms. Since it would amount to little if one always acted as judge and jury in one’s own case, we must make and maintain the rules as a community, rather than each of us drawing up our own personal rulebook. In particular, concepts are expressed by words in a public language. It is in such a language that we request and supply reasons. The rules develop as a system of case law, not statutory law, for words have meanings in virtue of how we use them, not by a once-for-all act of stipulation. Thus normativity and reason have an essential historical dimension, because applications of rules must be judged by the standard of past applications and in turn modify the standard for judging future applications. Since retrospective criticism is possible too, the process works backwards as well as forwards. We grasp the concept of objective reality by reflecting on that history of self-correction. This does not make reality itself as mind-dependent as the process of self-correction; Brandom’s idealism is more semantic than metaphysical. He makes no pretense at detailed exegesis of Kant and Hegel’s crucial texts. Rather, he self-consciously engages in a selective rewriting of the history of philosophy as a triumphant progress up to his own views, including the view that so presenting one’s views is a central philosophical task.
The second half of the book, less dense with abstractions than the first, is intended to be accessible to non-philosophers, although one wonders how they will get there. It contains five independent essays, two of them previously published, in which Brandom applies his normative rationalism to the nature of philosophy, the value of the philosophical life, the role of truth, problems for an empiricist conception of concepts, and philosophy’s lessons for cognitive science.
The volume feels slightly miscellaneous and repetitive. There are no big surprises, given his previous four books. However, it offers useful material for assessing his grand program.
Brandom repeatedly argues that reasoning is what matters by contrasts like this: a human assertion 'That’s red' with a similarsounding noise made by a parrot or a tape recorder attached to a photocell. Even if the latter two have no concept of red, they may be just as reliable as the human at producing the noise in the presence of red objects. The crucial difference, Brandom argues, is that only the human can do things like reasoning from 'That’s red' to 'That’s colored.' Although a dog or computer can do things which look like reasoning, he denies them the normative status of reasoning. But if one is going to play the normative card, one could just as easily have played it straight off, contrasting the human judgment 'That’s red' in normative status with the noise made by the parrot or tape recorder.
If it isn’t red, the human is getting it wrong, unlike the parrot or tape recorder. Although Brandom insists that the normative role of the judgment depends on its inferential connections, his evidence does not support that conclusion. At the critical point, he is using a normative difference between humans and non-humans to justify restricting genuine reasoning to humans, but since the normative difference is no worse a justification for restricting genuine judgment to humans, it provides no non-circular basis for privileging reasoning over judgment, as his normative rationalism demands.
The norms of judgment are not those of reasoning. To reason is to move from premises to a conclusion. A central norm of reasoning is validity: the conclusion should follow from the premises. Thus 'Shergar was a racehorse, so he was kidnapped' is invalid, even though
Shergar was both, for most racehorses are not kidnapped. The corresponding norm for judgment is truth. If you simply judge 'Shergar was kidnapped,' the question is whether Shergar was kidnapped.
Since we can use valid reasoning to expand our stock of true beliefs, for instance by applying mathematics in science, it is natural to explain validity in terms of truth: if the premises in valid reasoning are true, the conclusion must be true too.
That is not how Brandom sees it. He acknowledges a fundamental norm of validity for reasoning, but no fundamental norm of truth for judgment. He allows truth no important explanatory role in philosophy; in particular, he does not explain validity in terms of truth.
On the theory he endorses, 'true' is merely a linguistic device similar in function to a pronoun. Just as I sometimes use 'he' instead of 'Brandom,' one can sometimes use 'That’s true' instead of 'Yes,
Shergar was kidnapped.' Truth is no 'metaphysically weighty property' (whatever that means). For Brandom, any norm of judgment derives from norms of reasoning.
Brandom’s downplaying of truth shapes his theory of meaning. On current orthodoxy, the meaning of 'Shergar was kidnapped' demarcates circumstances in which Shergar was kidnapped from all others; the judgment is true if made in the former circumstances, false otherwise. This simple idea has been basic to the massive development of mainstream formal semantics over recent decades, in both linguistics and philosophy of language, for natural and artificial languages. If
Brandom is right about truth, that development is profoundly wrongheaded. Semantics will have to be done again from scratch. To illustrate the difficulties: when Brandom applies his approach to the semantics of 'if,' 'necessary,' and 'possible,' all three of his proposals are vitiated by logical errors (46). Although his previous book Between Saying and Doing (2008) contains a better developed attempt, it remains an isolated fragment by contrast with mainstream semantic theories.
Is Brandom right about truth? He makes little attempt to construct criticisms of orthodoxy sharp enough to worry its defenders. That would not be decisive if his positive account had significant advantages. Its economy is attractive, but cuts can go too far. For example, Brandom’s account implies that the probability that the sentence 'Snow is white' is true simply equals the probability that snow is white (see
164). That sounds good, until we remember that we can talk about how probable something is for someone else. The probability for us
English speakers that 'Snow is white' is true equals the probability for us that snow is white, if we are certain that 'Snow is white' means that snow is white. But consider a monolingual Inuit who sees the sentence 'Snow is white' on a fragment of philosophical text blown by the wind, without knowing what it means. On Brandom’s account, the probability for her that the sentence 'Snow is white' is true equals the probability for her that snow is white. Since she knows better than we do that snow is white, the probability for her that snow is white is high. But the probability for her that the sentence 'Snow is white'
is true is not high, since she has no evidence that the sentence means that snow is white rather than that blood is green. Thus Brandom’s account is incorrect, and no improvement on orthodoxy.
Even if Brandom is wrong about truth, how much explanatory work can his norms of reasoning do? He does not intend a purely formal or a priori standard. Perhaps for that reason, he avoids the word
'validity,' preferring 'good material inference.' 'Material' signals that the norm can be satisfied by an informal, a posteriori connection between premises and conclusion. He emphasizes that 'what is really a reason for what depends on how things actually are.' That pushes his norms of reasoning closer to an orthodox norm of truth (what is really true depends on how things actually are).
Brandom often prefers to work with a relation of material incompatibility in terms of which he can define good material inference. The corresponding norm is to avoid incompatible commitments. As an example of material incompatibility, he gives the triad 'A is a blackberry,'
'A is red,' and 'A is ripe.' The incompatibility depends on the actual nature of blackberries. Avoiding such incompatible commitments is not unlike avoiding false commitments. Presumably the norms are not quite equivalent, since one can avoid incompatible commitments without avoiding false commitments, for example by committing oneself only to 'A is a blackberry' and 'A is ripe' when A is actually an unripe blackberry. Brandom does not make the standard for material incompatibility explicit, but seems to intend some kind of natural impossibility: it is a natural impossibility for A to be a ripe red blackberry (freak cases apart?). This suggests that one has materially incompatible commitments whenever one misidentifies fruit, for if A is a raspberry then it is a natural impossibility for A to be a blackberry. The reader is left guessing how far 'material incompatibility' is supposed to extend.
Some passages give the impression of sneaking a norm of truth back in by using the word 'correct' in place of 'true.' For example,
Brandom writes: what is represented must provide a standard for normative assessment of [representings’] correctness, as representings and
In [engaging in discursive practices], we bind ourselves by norms articulated by the contents of the concepts we apply. If I claim that the coin is copper, I have said something that, whether I know it or not, is correct only if the coin would melt at 1084oC and would not melt at 1083oC.

He does not say how he reconciles such passages with truth’s explanatory unimportance.
Brandom contrasts 'horizontal' relations between different 'representings' with 'vertical' relations between those representings and what is represented. Inferential relations are horizontal. Truth, as normally conceived, depends on vertical relations such as that of the word 'copper' to the metal copper. Sometimes he seems to hint at explaining the vertical relations in terms of horizontal ones, a highly ambitious form of inferentialism. But then he admits that he is explaining only the horizontal relation of purporting to refer to the same thing, which different utterances of 'copper' have to each other.
However far you extend a horizontal, it will not turn vertical. Brandom’s demotion of reference elsewhere is analogous to his demotion of truth and faces analogous problems. These tensions come from the attempt to have semantic idealism without metaphysical idealism. To put it schematically, Brandom’s semantic idealism characterizes meaning in terms of moves in a language game; which is attractive because it ties meaning to speakers’
practical abilities. By contrast, metaphysical idealism wildly asserts that there is no world independent of the game. Earlier forms of semantic idealism involved some form of metaphysical idealism too.
The most logically sophisticated was the intuitionist school of Brouwer, Heyting, Prawitz, Dummett, and others, which characterized the meaning of mathematical sentences in terms of the structure of their proofs, but in doing so assumed, implausibly, that every mathematical truth is provable by a finite mind. While ignoring such precedents,
Brandom tries to avoid their defects. He accepts that a move in the language game can be a true or false statement about something independent of the game. He attempts to explain how the rules provide for such moves by making their legitimacy depend on the independent world. If he goes all the way, however, material incompatibility collapses into falsity, the norms of reasoning collapse into those of judgment, and everything distinctive of inferentialism is lost. The danger is that Brandom has gone far enough to disappoint the original motivation for semantic idealism, but not far enough for a satisfying rejection of metaphysical idealism. Since inferential relations can depend on facts about nature inaccessible to speakers, meaning has not been adequately tied to speakers’ practical abilities. Since inferential relations do not fix truth and reference, meaning has not been adequately tied to the language-independent world.
All the erudite sophistication and laborious ingenuity with which
Brandom tries explaining meaning in terms of inferential relations may ultimately help convince the reader that it cannot be done. Fifteen years after the publication of his magnum opus, Making it Explicit,
Brandom’s semantic inferentialism remains largely programmatic, unlike more orthodox semantic theories based on truth and reference.
If you want an explicit theory of how some particular linguistic construction contributes to the meanings of sentences in which it occurs, the inferentialist is unlikely to have one. Better try the referentialist.
Although Brandom can show awareness that the devil is in the detail, in philosophy as elsewhere, his more grandiose paragraphs discourage any attempt to put his theory into practice by working out and critically testing the details. For philosophical prose style, Kant and Hegel are not the best influences:

c14.indd 584 Miscellany  585
It is by placing both within a larger historical developmental structure that Hegel fits the model of the synthesis of an original unity of apperception by rational integration together with the model of the synthesis of normative-status-bearing apperceiving selves and their communities by reciprocal recognition so as to make the discursive commitments instituted thereby intelligible as determinately contentful.

(Bold type and italics Brandom’s.) Although his writing isn’t all as bad as that, its paucity of clear detail has increasingly concentrated his readership amongst those – not few in number – who prefer philosophy to come in vast, vague programs, like the election manifestos of parties that know they will never have to govern. Brandom cannot want such marginalization. This volume will not reverse the trend.

Acknowledgment
This section originally appeared as a review of Brandom 2009a in the
Times Literary Supplement (Williamson 2010). 14.4	 On Peter Unger’s Empty Ideas: A Critique of
Analytic Philosophy
Metaphysics is back in fashion, at least in the analytic tradition that dominates English-speaking philosophy and is growing rapidly across the rest of the world too. It’s quite a turnaround. In the mid-twentieth century, the analytic tradition had two main strands: logical positivism and ordinary language philosophy. The logical positivists dismissed metaphysics as cognitively meaningless, unverifiable by observation and logic. Ordinary language philosophers tended to be equally suspicious, diagnosing metaphysical speculation as the pathological result of using words outside the down-to-earth contexts that gave them meaning. But things have changed. These anti-metaphysical arguments rested on assumptions about meaning that have not withstood the test of time. Moreover, the resurgence of metaphysics was led by philosophers such as Saul Kripke and David Lewis, who wrote so clearly and intelligibly about essential properties (think Aristotle), possible worlds (think Leibniz), and the like that the charge of meaninglessness just would not stick.
Contemporary analytic metaphysicians see themselves as theorizing boldly and systematically about the deepest and most general nature of reality. In Peter Unger’s view, they are deluded: far from resuming pre-Kantian metaphysics in the grand old style, they do little more than play with words. Their ideas are mostly empty. Indeed, he widens the charge to analytic philosophy more generally. Nor does he think better of non-analytic philosophy; he just has no time for it.
One might expect that by 'empty' Unger means something like
'meaningless.' He does not. He allows that some empty ideas are true. For instance, the idea that all red things are colored is true, not meaningless, but is still empty by Unger’s standard. What he objects to in empty ideas is their lack of interest, rather than of meaning or truth. Thus it’s not self-defeating for him to admit, as he does, that some of his own ideas in the book are empty, for analytic philosophers – of whom Unger is one – might have done badly enough to deserve a boring sermon. But Unger does not use 'empty' as a synonym for 'boring,' otherwise the book would be one long yawn. Instead, emptiness is supposed to be a more objective property of some ideas that explains why they should not excite our interest. To assess Unger’s critique, one must get clear what he does mean by 'empty.' He contrasts empty ideas with 'substantial' ones. As far as the reader can tell, for an idea to be 'substantial' is just for it to be contingent, to concern what could have been otherwise. It’s contingent that Napoleon died on Saint Helena, since he could have died elsewhere, but it’s not contingent whether all red things are colored.
Thus for an idea to be 'empty' is just for it to be non-contingent: either necessary or impossible. But, Unger notices, that doesn’t give him what he needs, for all purely mathematical truths are necessary too: 5 + 7 could not have been 13. If mathematics yields only empty ideas, to say that analytic philosophy yields only empty ideas is at worst to say that it’s as bad as mathematics, which isn’t bad at all.
To differentiate philosophy from mathematics, Unger distinguishes between concrete reality (including things in space and time) and abstract reality (including numbers). Supposedly, mathematics succeeds by informing us about abstract reality, whereas analytic philosophy tries but fails to inform us about concrete reality. According to Unger, analytic philosophy yields almost no 'concretely substantial ideas': that is, contingent information about concrete reality.
Unger’s focus on concrete reality doesn’t solve the problem. One reason is that logic and mathematics don’t only inform us about some realm of abstract objects. They are also useful because they can be applied to concrete reality itself, as in natural science. They give us necessary but far from obvious truths of the form 'If concrete reality satisfies these conditions, then it satisfies this other condition.' Why assume that analytic philosophy isn’t doing the same? Yet such truths are 'concretely empty' by Unger’s standard. Indeed, many ideas of blatant philosophical interest will be 'concretely empty.' Abbreviate
'being that has, of necessity, all these attributes: omniscience, omnipotence, omnibenevolence, concreteness, and so existence' as 'god.'
Then the idea that there is a god is non-contingent and so concretely empty, because it’s not contingent whether something is necessary.
But a philosopher who tells us whether there is a god is doing metaphysics in the grand old style. Indeed, a characteristic ambition of such metaphysics past and present is to understand the deepest, most general, and necessary nature of reality. Thus Unger’s complaint that analytic metaphysicians give us only concretely empty ideas will not threaten them, since it’s in line with their hopes. Unger’s use of the term 'empty' is just an advertising trick. It’s like a competitor who defines 'empty' as 'containing nothing but brand X fruit juice' and then puts up posters warning that cartons of brand X fruit juice are empty. To read Empty Ideas, one must get through the equivalent of numerous elaborate descriptions of cartons of brand X fruit juice of various types, each concluding that the carton was empty, and for contrast some elaborate descriptions of cartons of brand Y fruit juice of various other types, each concluding that the carton was full. The reader’s task is made no easier by Unger’s loquacious, attention-seeking prose.
The book does have a way of turning up the heat, by adding a second charge against analytic philosophy: its ideas are not just concretely empty, they are 'analytically empty.' Unger is more evasive about what he means by 'analytically empty' than with 'concretely empty.'
His picture seems to be that the truth or falsity of analytically empty ideas depends on semantic interrelations amongst our words or concepts rather than on features of the reality to which those words or concepts refer. For example, the truth of 'All red things are colored'
is supposed to depend on a semantic relation between the word 'red'
and the word 'colored,' or a relation between our concept of red and our concept of color, rather than on a relation between the red things and the colored things. By contrast, the truth of 'Napoleon died on
St. Helena' is supposed to depend on a relation between the man
Napoleon and the island of St. Helena, rather than between the name
'Napoleon' and the name 'St. Helena,' or between our concept of
Napoleon and our concept of St. Helena. So if analytic philosophers’
ideas are analytically empty, they are asking verbal questions, not engaging with the concrete reality whose deepest and most general nature they were hoping to understand.
Unfortunately for Unger, the picture on which his second charge relies has turned out to be much less useful than it may look at first sight. For a start, whether one speaks truly or falsely in uttering any sentence whatsoever depends on the meanings of the words one utters, or on the concepts one uses them to express. Thus 'Napoleon died on St. Helena' expresses a falsehood when uttered by someone who uses 'St. Helena' to refer to the town of St. Helens in Lancashire, but the other words normally. Moreover, the truth of 'All red things are colored' does turn on a relation between the red things and the colored things: that the latter include the former. Of course, the meaning of 'All red things are colored' is such that it expresses a necessary truth, while the meaning of 'Napoleon died on St. Helena' is such that it expresses a contingent one, but that just returns to the original contrast between concretely empty and concretely substantial ideas, and so adds nothing to the first charge. Unger shows no awareness of the difficulty, and says nothing that might help to resolve it.
Some philosophers restrict the term 'analytic' to cases where the semantic or conceptual relation at issue should be obvious to a competent user of the language or someone who grasps the relevant concepts. On that reading, the second charge would simply be that analytic philosophers deserve no prizes because what they tell us was obvious anyway, like 'All red things are colored.' But that cannot be what Unger means, for many of the ideas he classifies as analytically empty concern matters that are utterly unobvious even on reflection, hard or even impossible to decide, and he does not pretend otherwise.
Unger’s usual procedure is just to report an analytic philosopher’s view and then confidently assert without argument that it is concretely empty, often adding with slightly less confidence and still no argument that it is analytically empty. If he had really uncovered some dark secret about what analytic philosophers are up to, one might have expected the case for the prosecution to take a somewhat more elaborate form.
Occasionally, Unger shares with the reader some of his wild fantasies about mind and matter, as a hint of where the sort of concretely substantial philosophy he favors might go. However, he mostly refrains from claiming that those fantasies are true. According to him, serious progress on that front will require a combination of talent and knowledge in both philosophy and physics to a level that only a handful of favored individuals currently attain, not including him.
The book ends with the injunction that 'we philosophers should assume, or maintain, a deeply held attitude of intellectual modesty.'
The modesty he has in mind seems to be collective, with respect to practitioners of other disciplines, rather than individual, with respect to other philosophers. For he also tells us: what’s already presented in this book, much of it first proposed in my earlier All the Power in the World, probably comprises more in the way of novel substantial philosophical ideas than everything published by prominent mainstreamers, all taken together, during the last 70
years or so. To maintain his modesty with respect to non-philosophers, he adds a disclaimer, perhaps in view of the lack of scientific support for his speculations: 'precious little of it – maybe none at all – is worth significant or sustained consideration.' If one wanted to refute Unger’s claim to (probably) outdo the mainstream in novel substantial philosophical ideas, one could start with a mass of recent work in the philosophy of mind about the contingent workings of the human mind, closely engaged with experimental psychology.
Empty Ideas has several virtues, all characteristic of good analytic philosophy. It is often bold, clear, intelligent, ingenious, and independent-minded. In passing, it makes some useful contributions to debates in analytic metaphysics, offering examples that repay further reflection, for instance on the topic of essentialism. But it is vitiated by an overall framework that has not been properly constructed and cannot bear the weight of the argument.
There is a genuine question about how learning necessary truths can bring new knowledge, since they exclude no possibilities. But the first step towards answering it is to realize that it is a special case of a more general question: how can learning necessarily equivalent truths bring different knowledge? For instance, knowing the contingent truth 'There are 172 tiles on the floor' is somehow different from knowing the necessarily equivalent contingent truth 'There are 289 tiles on the floor,' just as knowing the trivial necessary truth '172 = 172' is somehow different from knowing the necessarily equivalent but less trivial necessary truth
'172 = 289.' It is still unclear what the best framework is for understanding such matters, but it will surely articulate the way in which our thinking about the same state of affairs can be mediated by different sentences. Whatever the details, there is no good reason to expect the explanation to make a big deal of the difference between disciplines that mainly investigate non-contingent matters, such as mathematics, logic, and philosophy, and most other disciplines, which investigate contingent matters. The large differences in methodology between disciplines have more specific sources. A critique based on confusion about such fundamental issues should not move analytic philosophers.

Acknowledgment
This section originally appeared as a review of Unger 2014 in the
Times Literary Supplement (Williamson 2015b). 14.5 Plato Goes Pop
It was only a matter of time, after the success of Stephen Hawking and the subsequent wave of popular science books, before someone noticed the gap in the market for books of popular philosophy. The gap is now rapidly being filled. A pile of them sits on my desk as I
write. But they don’t emulate the stereotype of popular science. The authors are not trying to communicate mind-twisting recent developments in philosophy beyond the readership of technical journals. Indeed, several of them seem rather embarrassed about the association with academic philosophy, anxiously emphasizing their credentials as streetsmart, clued-in drinking companions (Beer and Philosophy,
Wine and Philosophy): despite being philosophers, they are sexy and never in any way in the least boring. The blurb for the Blackwell
Philosophy and PopCulture series (South Park and Philosophy, The
Office and Philosophy) says 'Philosophy has had a public relations problem for a few centuries now. This series aims to change that, showing that philosophy is relevant to your life.' The titles, not only in that series, tell a slightly different story: 'philosophy,' 'philosopher' (The Undercover Philosopher), 'philosophical' (Philosophical
Provocations) are treated as words that sell books, not as put-offs to be concealed until the reader is already hooked. An old-fashioned image is not always bad for business.
Recent changes in philosophy’s self-image facilitate popularization.
'The linguistic turn' belongs in the last century. Increasingly, philosophers have returned to seeing their subject matter as the world, rather than only our talk or thought about it: not just the word 'beer' or the concept of beer, but the stuff you can drink. Philosophers of time study time itself, alert to the possibility that Special Relativity undermines the ordinary language of time. Contemporary moral philosophers do not restrict themselves to describing the rules of moral discourse; they can argue directly about whether torture is absolutely always wrong. In these ways, philosophy no longer defines its questions in ways radically alien to a more innocent understanding.
At the same time, the growing specialization and technicality of academic philosophy has made it ever less accessible to non-specialists, thus ever more in need of popularization. Much work in moral and political philosophy bears on urgent practical issues, public or private, but often in a qualified, indirect way; it may become tractable for decision-makers only after going through several stages of mediation, in what the original author may regard as a process of crass over-simplification. Similarly, philosophers of language are currently debating relativism in terms of subtle issues about the exact structure of a formal theory of meaning. The debate really does implicate popular versions of relativism often invoked when disagreement looks irresolvable ('That’s true for us even if it’s false for you'). For non-specialists, some mediating process is needed to elucidate what is at stake.
Not much popular philosophy attempts to mediate recent developments in technical or academic philosophy to a wider audience. When philosophers are cited, they tend to be the mighty dead. Philosophy, unlike physics, is apparently best consumed when well pickled. Many of the authors seem too little acquainted with recent developments to be in a position to mediate them. Some seem actively hostile. Academic philosophy is presented as trivial logic-chopping that has lost touch with the deep, simple questions at the heart of real philosophy.
Thus popular philosophy steps in to undertake the proper task of philosophy, which the professionals disdain.
The bluff amateur style of philosophy is not without presuppositions. It takes for granted that simple questions ('Why be good?,'
'What is truth?') have simple answers, and that to find those answers it is unnecessary to take much notice of what other people working on the same questions have recently come up with – popular philosophers tend to ignore each other as well as the professionals.
This optimistic procedure is taken to be the way to make philosophy serious again. Naturally, the actual results are riddled with boring old fallacies and confusions, rarely even amusing new ones. For instance,
I read 'when Jane says she loves Dick, she is actually saying that she is in love with her ideas of Dick,' which embodies at least two mistakes as old as the undergraduate essay. Too often, the genre of popular philosophy is abused as an opportunity to pass off one’s pet theories dogmatically on a readership unacquainted with the standard objections and alternatives to them, unhampered by the tiresome business of being reviewed by one’s peers.
Few professional philosophers that I know have forgotten the fundamental questions from which their inquiry originated, not least because they have to explain the connections every year when teaching undergraduates. The elaborate apparatus of academic writing in philosophy results not from self-indulgent pedantry but from the need to distinguish different interpretations of the question, which may have different answers, to provide non-question-begging evidence in support of one’s answers, to assess whether one’s answer is any better supported than those carefully developed by others, and so on.
Although rigor is sometimes portrayed as the resort of those who lack the courage to speak from the gut, the real risk-taking is in precise statements and explicitly articulated arguments, since the point of such formality is to make errors maximally easy to spot. If you are afraid of being caught out, take refuge behind a smokescreen of vagueness and obscurity.
Of course, similar remarks apply to specialization in any academic discipline. But philosophy seems peculiarly vulnerable to the charge that its nature requires accessibility. It would be more blatantly dumb to tell physicists to drop their equations and start doing real physics, or historians to get out of their archives and start doing real history.
According to a venerable tradition, philosophy is an essentially practical activity, whose aim is to improve our lives. If so, it should be accessible, for there is little point in giving people advice they can’t understand. This conception is not limited to ethics, the branch of philosophy most obviously relevant to how to live. Descartes, typecast as the founding father of modern epistemology, tried to develop a method of inquiry that would enable one to avoid error and gain genuine knowledge. By contrast, most contemporary epistemologists have lowered their sights. They may tell you what knowledge is, but they won’t tell you how to get it. Wouldn’t it be nice, though, to have a sort of epistemology that did tell you how to get knowledge? Some popular philosophers seem to be moved by the practical calling. For those in a hurry for practical advice, academic philosophy is not the best place to go. That is nothing new. The founder of the Academy gave a lecture On the Good. Most of Plato’s audience came expecting to be told how to get rich, or stay healthy, or be happy, and were disappointed to hear a lecture full of mathematics, culminating in the statement that the Good is One. Its practical implications were not immediate. As a research instrument, Descartes’ method fell short of his advertising.
Not all contemporary academic epistemologists are determined to be practically useless. The Bayesian school applies probability theory in ways that really do help one handle uncertainty better in predicaments that lend themselves to a probabilistic representation. A mass of psychological evidence indicates that, without such training, humans are scarily bad at thinking with probabilities. But Bayesian epistemology is not popular philosophy: it is highly mathematical. There are also theoretical reasons for doubting that any rule of action can be fully practical, although some are less impractical than others. If the rule says 'In such-and-such circumstances, do so-and-so,' cases can always arise in which it is unclear whether the circumstances are so-and-so, and therefore unclear what you must do to comply with the rule.
Although practical and academic medicine have different and sometimes conflicting imperatives, we don’t want practical medicine to ignore academic medicine (as alternative medicine does). It is not wholly different in philosophy. Although there is even more uncertainty in academic philosophy than in academic medicine, in both cases practice should take account of that uncertainty, not hide it from the patients. Philosophical questions are too interesting and important to be left to the professionals. The more people who ask them, the better.
It is good that accessible books exist to feed such curiosity. A few do it well. But it is a pity that so much of the genre shows such incuriosity about what is really happening in philosophy now.

Acknowledgment
This section originally appeared in the Times Literary Supplement as
Williamson 2009c.
Miscellany  595

14.6 Popular Philosophy and Populist Philosophy
Every intellectual discipline needs to speak to others as well as to itself, both to learn and to teach. If it is getting anywhere, it has something new to say to neighboring disciplines, but also to the general public.
If a discipline has practical applications, it should communicate them where they can help. It should also provide points of entry to the curious. Its survival depends on that: if it can’t explain to the uninitiated what it is up to, how will it recruit new members? Politically, it is unwise to tell the taxpayers who fund it 'Shut up and give us the money; never you mind how we spend it.'
All that applies to philosophy in particular. A civilized society has popular philosophy just as it has popular physics, popular psychology, popular history, … So one might expect the relation between popular and academic philosophy to resemble the corresponding relations for other disciplines. Thus popular philosophy would communicate recent research in academic philosophy to a wider audience.
In my experience, a surprisingly high proportion of popular philosophy is not like that. Instead, it sets itself up as a rival to academic philosophy, which it portrays as trivial, sterile, pedantic, irrelevant logic-chopping.
This popular philosophy claims to be the real philosophy, the true heir to what was done in ancient times. It asks and answers the questions that really matter, going straight to the point by arguments that can be understood with no previous training. It speaks over the heads of the scholastics to laypeople who approach philosophy fresh and unprejudiced.
The message that with little effort one can do better than the professionals is naturally gratifying to non-professionals; it finds a ready audience. One might call that populist message the Michael Gove view of philosophy, in honor of the British politician who, when asked during the 2016 referendum campaign which economists favored leaving the European Union, replied 'people in this country have had enough of experts' – though Covid-19 has changed his public attitude to experts.
Like Gove with economic expertise, populist philosophers are uncomfortable with the idea of genuine expertise in philosophy. They may admit that there are experts on the history of philosophy, who understand numerous difficult texts hardly anyone else has even read.
They may also accept that there are experts on formal logic, and expert teachers of philosophy. But such concessions are consistent with the populist idea that the apparatus of academic philosophy – all the to-and-fro of point-by-point discussion in conferences and refereed journals – contributes nothing of significance to answering central questions of philosophy, and should be bypassed.
Sometimes I encounter people who take a similar attitude to modern natural science. They say that science went wrong after Aristotle, or send me their theory of 'qualitative physics,' which bypasses all that boring mathematics to go straight to the secret of the universe.
But such ideas are not the stuff of most popular science, which has better things to do.
Philosophy is more vulnerable than natural science to the populist belief that laypeople are just as qualified as professionals. This belief derives from the ideal of the radically autonomous inquirer, who takes nothing for granted and uses nothing second-hand. In other words, such a thinker refuses to learn anything from other people.
That’s a recipe for the endless repetition of the same elementary mistakes, generation after generation. Anyway, the instructions cannot be carried out; all thinking takes much for granted. The ideal of the radically autonomous inquirer is itself stale and nth-hand.
A less arrogant attitude is that we all have much to learn from other people, in philosophy as everywhere else. Philosophy is even harder than it seems; the right response to its difficulty is not to trash all the work already done by thousands of highly gifted and knowledgeable men and women. Compared to the size of the task, their contributions may have been small, and often mistaken, but that does not mean you can do better by ignoring them.
Philosophy is a collective enterprise, which has developed slowly through various traditions over many centuries in many parts of the world. It has never been just the work of a few isolated geniuses. Joining one of those traditions has always involved acquiring the relevant forms of philosophical expertise. We shouldn’t be coy about it. We need to explain honestly and openly how philosophy works.
Recent philosophical research has produced lots of fascinating new ideas, which deserve to be better known. Now there’s a task for popular philosophy. Acknowledgment
This section first appeared as a post on the blog Daily Nous as part of the series 'The Philosophy of Popular Philosophy,' edited by Aaron James Wendland.