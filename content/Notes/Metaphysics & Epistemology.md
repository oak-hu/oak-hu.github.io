---
draft: true
---

### Week 1

Generality: be responsive to cases
Flexibility: Don't entail location

Delegation theory of presence

> A delegation structure <P, D+, D-, @?, D> where
> P: set of positions
> D+ set of delegators
> D- set of delegates
> @ set of two-place locative relations : @i $\subseteq$ D- x Pi
> D: three-place relation : D $\subseteq$ D+ x D- x P

Intuitively: delegators delegate their presence in P to another thing , their delegate in D-, that is somehow located in @

x weakly located at y iff x is to be found in y
x pervasively located at y iff x completely fills y
x entirely located at y iff x lies within y
x exactly located at y iff x perfectly fits in y without any gaps

exact => entire
exact => pervasive
entire => weak
pervasive => weak

delegates are at least weakly located at the relevant place of delegation, cannot perform duties in absentia; but delegators can. (But what if I hire a lawyer, who hires a lawyer, who...?)

Some more principles, e.g., of transitivity, auto-delegation, etc.

Presence: for x to be present at y is for x to have a delegate at y

Occupant: for x to be an occupant of a system P is for it to be weakly located at a position in P

Proper Delegate: what it sounds like (distinct from delegator)

Claim: location entails presence. This follows from auto-delegation!

Weak location theory of presence: fails flexibility requirement

Delegate location theory of presence: for x to be present at place y is for it to be weakly located at one of its delegates at y. Fails generality requirement.

Stronger than delegation theory, in the presence of principle p3

primitive theory: presence is irreducible to notions such as location and delegation, even if it might display some substantive connections to them, and should not be defined in their terms.

a perdurant delegates its proper temporal parts at a time, an endurant delegates itself, a social entity delegates its members, a universal delegates of of the things that exemplify it, a contingent object delegates its counterparts (induced relations)

might allow higher-order identities between presence and these induced relations. 

an induced relation is location conducive iff it entails that the delegator is weakly located at the place of delegation; exlusive, indifferent clear generalizations

Loc Con requires delegator to be there; occupany only requires it to be somewhere in the system.

### Week 2
**Belief Change as Evidence - Elise Woodard (KCL)**

Motivating Case: I'm against some position; I learn that you used to be against it, for the same reasons, but then changed your mind.

The View:

This can provide
1. zetetic ('inquiric') reasons to investigate further
2. second-order evidence (a) that there is more evidence out there, and (b) about the quality of your reasoning

But not when
1. It's not a genuine change of mind
2. There's overwhelming counterevidence against the adopted view

Minimal pairs (over, say, the relative importance of family, or philosophical pragmatism)
1. A and B disagree, and always have.
2. A and B disagree, but B used to agree with A.

Being A in version 2 seems much more worrying!

Changes of mind:
- Not just any belief-revision (just as forgetting is not just any loss of knowledge)
- Indicator of epistemic improvement
- Epistemic virtue and avoiding certain biases
- Evidence of epistemic superiority & empathy

(So, like, this is why we give the advice to be able to argue for your opponents' positions at least as well as they can themselves. Also, this is why people parade around, say, religious converts.)

### Week 3
**Iterated Knowledge isn't Better Knowledge - Bernhard Salow (Oxford)**

1. Set Up

> **Iterated Knowledge**
>
> - You 1-know something just if you know it.
> - You $n+1$-know something just if you know that you $n$-know it.
> - You $\omega$-know it just if you $n$-know it for every $n$.

We assume (according to Bernhard, per impossible) that $KK$ is false; that is, you can know something without 2-knowing it. But if $KK$ is true, then the claim is just immediate (as all knowledge is $\omega$-knowledge).

> **Better Knowledge**
>
> - Knowledge you can act on even when more is at stake
> - Knowledge that might motivate further inquiry
> - Knowledge that licenses assertion in a wider range of situations

Example: Bernhard knows much better that WWII ended in 1945, than that Queen Elizabeth I died in 1603 - the latter is so trivial, that the British citizenship test didn't even ask about it. 'Actually, they didn't ask me about WWII either, maybe out of sensitivity.' (Bernhard is German).

There are cases where you shouldn't bet on something, even if you know it; or don't assert something, even if you know it; or keep investigating something, even if you know it. A notion of better knowledge is helpful here, to make sense of (say) knowledge norms. Some people appeal to iterated knowledge to play this role.

We'll describe a case where you go from 1-knowledge to $\omega$-knowledge, but you don't get any better knowledge. There might be a strong correlation, but iteration isn't the reason for better knowledge.

2. The Old Case

> **Headcount**
>
> You count lecture attendees, getting the answer 350. You know that you often miscount slightly with numbers this big.

Standard model: You believe that you miscounted by at most $M$ (say, 5); if you miscounted by $x$, you know that you miscounted by at most $x+5$. And you $m$-know these two facts for some large $m$.

With a simple modal model: (350) $\to$ (354) $\to$ (358)

For all you know in (350), you could be in (354); so, for all you 2-know in (350), you could be in (358). You $n$-know (but don't $n+1$-know) that it's within $5n$ of 350. Predicts (plausibly, surprisingly) that, say, 'it's within 5 of 350, or at least 400' isn't better knowledge.

4. The New Case

> **Headcount, with Oracle**
>
> [...] But then, on a whim (so this doesn't give extra information), you ask an oracle whether you miscounted by 1 to 5, and the oracle says that you didn't.

We assume that after the oracle's announcement, you $m$-know that you did not miscount by 1 to 5 for some large $m$; we also assume (iffier) that the anncouncement doesn't defeat any previous knowledge. (Note that this $m$, and the one about, could be $\omega$.)

Now, if there are 350 people, you $m$-know it. You also go from merely 1-knowing to $m$-knowing that it's less than 356. But you don't know this any better now. It's not more likely on your evidence; your belief isn't safer; we have no effects on action, inquiry, assertion, ... (imagine being the fire safety officer).

Wait, why is it that you $m$-know that there are 350 people? You combined $m$-knowledge that error isn't between 1 and 5, with 1-knowledge that it's no more than 5. You do $m$-know that [if you miscounted by 0, you know that you miscounted by at most 5].

(Oh, you remove all the intermediaries; you can't get to 358 in two steps.): (350) ... (358).

6. Iterated Safety

Iterated physical safety. You can be safe from getting hit (outside the danger zone), but not safely safe (not safely outside the danger zone).

But now add bulletproof glass which just covers the danger zone. Now every position is safe; your position is now $\omega$-safe. Are you safer? (Actually, maybe!)

8. Defeat

The no-defeat assumption is wrong. Before the oracle, you knew that you miscounted by up to five; now, you only know that you miscounted by either 0, or 6 to (say) 10. But:

- You ask whether you were off by 1 to (say) 7. Eventually we can choose a number big enough that eliminating 1 to that number raises the probability that you were right! So there's no defeat here, but your knowledge that it's no more than 358 doesn't seem better.
- 

- You ask the oracle (i) whether you overcounted, and (ii) whether you undercounted by 1 to x; the oracle says you did neither, thus raising the probability that you miscounted by at most 5.

10. Generalizing

Can generalize to any case where one knows, but doesn't 2-know something; just have an oracle tell them that either they do know it, or that it's false. Susan on a quiz show (Radford). Telling Susan that she's either wrong or remembering won't give her better knowledge (?); in fact, she arguably knows this already. In general, this gives you cheap iterated knowledge, but no better knowledge.


K(345-355)
+ K (not 345-349, or 351-355)
=> K(350)
+ K(if 350, K 350)
+ KK(350)
+ KK(if 350, K 350)
+ KKK(350)
