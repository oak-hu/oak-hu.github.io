---
date: January 2024
---

This is the class that I think I've put the most work into. Here's the feedback I got from my tutor:

> Oak's work on Mill has been stellar. She writes extremely sophisticated philosophical prose at the level of a good graduate student. The only issue is that occasionally she tries to pack in too much in too short a space, leading to unclarity. By the end of our four sessions, after I had warned her of this, it looked like she had overcome this tendency; but she would still be well advised to bear this issue in mind.

Funny story: it only looked like I overcame that tendency because, after I finished my last essay, I decided to go through and rewrite the entire thing to make it move as slowly as possible. You can see both versions below.

I got an 80 on my collections essay for moral philosophy, which I'm quite proud of; it was largely on material from the Week 3 essay, with some more discussion of moral motivation (drawing from Kagan's *Limits of Morality*).

## Week 1: [[/Week-1|Mill's Principle]]
**Was Mill an advocate of act utilitarianism or rule utilitarianism? Which one is better?**

I take it that this question was intended, at least in part, to emphasize the distinction between multi-level act utilitarianism and genuine rule utilitarianism (as these are popularly conflated). But, surprisingly, Mill does seem to be a rule-utilitarian after all! Today, I would at the very least reword some of the discussion of act versus rule utilitarianism, which I think is slightly misguided. For instance, the best argument for expected-value consequentialism isn't that it avoids uncertainty (it doesn't), but just by extensional adequacy (see [[/Notes/2024-2025/Non-Consequentialism#week-1-introduction|here]] for some discussion).

## Week 3: [[/Week-3|Higher Pleasures]]
**Does Mill’s distinction between higher and lower pleasures achieve what he wants it to achieve?**

I think some of the symmetry discussion, like a lot of discussion of skepticism in general, is too dialectically-minded. People can know what the higher pleasures are, even if they can't convince their opponents. However, there might still be a problem of making the higher pleasures depend on peoples' judgments ('what makes one pleasure more valuable than another'), rather than taking these judgments as merely indicating what the objectively higher pleasures are. Also, note that the transfinite ordinal scale isn't really needed (as with slightly less naive utility functions we can represent welfare levels with just the reals).

## Week 5: [[/Week-5|Justice & Rights]]
**Is Mill’s utilitarianism capable of satisfying our intuitions about justice and rights? If not, does it matter?**

Since writing, I've become much more sympathetic to a sort of objective-list theory, and slightly less sympathetic to sophisticated subjectivism (think Railton); so, I'd probably change some of the wording / framing. But I do think that consequentialism more broadly isn't as counterintuitive as you'd initially think! Obviously, there's the worry that consequentialists may pursue a degenerating research program of adding epicycles to accommodate unfriendly intuitions (something like this, I think, is a problem with sophisticated subjectivisms). But I don't think this holds.

## Week 7: [[/Week-7|Moral Intuitions]]
**Is it a problem for a normative ethical theory if it is in conflict with widely felt moral intuitions?**

This essay was rewritten from scratch before submitting, to make it move much more slowly. I might put up the original version, too, so you can see the contrast. I'm not sure how large a distinction there is between the natural and the normative: for instance, I don't think there's any deep distinction between natural and normative facts: we may understand both as just sets of possible worlds that include the actual world (see Williamson). There's also a bit more to say about moral dilemmas. For instance, if we accept (a) that ought(X) implies can(X), and (b) that ought(X) and ought(Y) imply ought(X and Y), then there are no moral dilemmas (Amos Wollen mentioned this to me). (Assume for sake of contradiction that there's some X such that ought(X) and ought(not X). Then by (b) we have ought(X and not X), and so by (a) we have can(X and not X), which is a contradiction.) Also, we might understand individual inconsistency on the model of collective disagreement, such that inconsistency is just self-disagreement; this lets us treat things like inconsistent intuitions a bit more nicely (see Kodsi).

Here's the [[/Week-7-(Original)|original draft]].
