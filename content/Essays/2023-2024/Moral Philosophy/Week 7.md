## It is a problem for a normative ethical theory if it is in conflict with widely felt moral intuitions.

*(January 2025): This essay was rewritten from scratch before submitting, to make it move much more slowly. I might put up the original version, too, so you can see the contrast. I'm not sure how large a distinction there is between the natural and the normative: for instance, I don't think there's any deep distinction between natural and normative facts: we may understand both as just sets of possible worlds that include the actual world (see Williamson). There's also a bit more to say about moral dilemmas. For instance, if we accept (a) that ought(X) implies can(X), and (b) that ought(X) and ought(Y) imply ought(X and Y), then there are no moral dilemmas (Amos Wollen mentioned this to me). (Assume for sake of contradiction that there's some X such that ought(X) and ought(not X). Then by (b) we have ought(X and not X), and so by (a) we have can(X and not X), which is a contradiction.) Also, we might understand individual inconsistency on the model of collective disagreement, such that inconsistency is just self-disagreement; this lets us treat things like inconsistent intuitions a bit more nicely (see Kodsi).*

### Normative ethical theories

For this essay, I stipulate[^1] a distinction between natural and normative theories. A natural theory gives descriptions how things are, or how things could be. For instance, Newtonian mechanics is a natural theory about how physical objects behave. For the descriptions of a natural theory to be successful, they must be accurate and simple. So, it is a problem for a natural theory if it is not accurate, or if it is not simple. Newtonian mechanics is a little bit inaccurate. Accuracy is a relatively small problem for it; it is still very successful. Aristotelian mechanics is very inaccurate. Accuracy is a relatively big problem for it; it is not very successful. So, problems for theories come in degrees.

Meanwhile, a normative theory gives prescriptions about how things should be. It says what things are good or bad, wrong or right, etc. This is its extension. It also says why these things are so. (This is its intension.) For instance, Savage’s decision theory is a normative theory about how you should decide among choices with uncertain outcomes. For the prescriptions of a normative theory to be successful, they must be accepted and complied with. So, it is a problem for a normative theory if it is not accepted, or if it is not complied with. It seems right to say: ‘The problem with Savage’s decision theory is that nobody accepts it!’ (and similarly for ‘complies with’). Like accuracy, the problems of acceptance and compliance can come in degrees.

Some theories about ethics are natural theories, while others are normative. A natural ethical theory might ‘describe our moral sense’.[^2] A simple one might describe our actual judgements about what is good or bad, wrong or right, etc. A more sophisticated one might describe ‘what we would be motivated to do if we were vividly aware of the relevant facts.’[^3] Meanwhile, a normative ethical theory might give us external reasons to act in certain ways. It does this by saying what consequences are good or bad, what actions are wrong or right, etc., and by telling us why they are so. Here is an illustration of the difference. A natural ethical theory might say:

> ‘If you knew the facts, you would want to do X.’

The normative version of that ethical theory would say:

> ‘If you knew the facts, you would want to do X, so do it!’4

Notice that both of these theories might have problems with accuracy; for instance, perhaps if you knew all the facts, you would want to do Y, not X! The same thing goes for simplicity. But the normative ethical theory alone faces the problems of acceptance and compliance. This is because the success of a description does not depend on whether it guides action, but the success of a prescription does depend on whether it does so. So, acceptance and compliance give us no good reason to reject a natural theory. They also might give us no good reason to reject a normative theory. However, they would still be problems for a normative theory. If these are big problems for a normative ethical theory, its advocates might need to spend quite a bit of effort promoting acceptance or compliance. This effort might include ingraining new patterns of thought, or establishing social and political institutions.[^5] So these problems can be overcome, even if they are big.

We’ve defined normative ethical theories as things which might give us external reasons to act in certain ways, and we’ve contrasted these with natural ethical theories. We’ve discussed potential problems for normative ethical theories, such as acceptance, compliance, accuracy, and simplicity. And we’ve noted that these problems come in degrees. For the rest of this essay, I will write 'T' to stand for a generic normative ethical theory.

### Moral intuitions
A moral intuition is the way something seems; in particular, whether that thing is good or bad, wrong or right, etc, and perhaps why it is so. For instance, I have the moral intuition that it would be seriously wrong not to donate my kidney to save someone’s life, even if they are a stranger. I also have the moral intuition that it would be good if people were more satisfied with their lives. Unfortunately, not many people share the moral intuition. It is not very widely felt. Fortunately, though, many people share the second moral intuition. It is very widely felt. For the rest of this essay, I will abbreviate 'the class of widely felt moral intuitions' as 'WFMI'.

I feel some of my moral intuitions more intensely, and I feel others more mildly. For instance, I feel very intensely that we should go to great lengths to avoid killing humans, but more mildly that we should do the same for insects.

One important type of moral intuition is about whether something is impermissible, strictly permissible, or obligatory. The first means that it would be very wrong to do it; we must not do it. The last means that it would be very wrong not to do it; we must do it. The middle one means that it is neither very wrong to do it, nor very wrong not to do it; we may do it or not. I have the moral intuition that there are moral dilemmas; that is, some things are impermissible when described one way, but obligatory when described another. For instance, Sartre’s pupil faced the moral dilemma over whether to defend his country or to stay home for his mother. It seems impermissible for him to leave his mother, but it seems obligatory for him to defend his country.

In the case of a moral dilemma, there is a strong conflict between two of my moral intuitions. One of my moral intuitions says that an action is obligatory, while another says that it is impermissible. It’s impossible to satisfy both of these moral intuitions. So, there is a strong conflict between them.

Strong conflicts might also arise between some normative ethical theory T and WFMI: for instance, T might say that it’s obligatory to kick every baby that you see, or that it’s impermissible to help your mother if she collapses.

Next, there are asymmetric conflicts. T conflicts asymmetrically with WFMI when WFMI says that something is strictly permissible, but T either says that it’s obligatory or says that it’s impermissible. For instance, T might say that it’s obligatory to donate your spare kidney, or that it’s impermissible to eat meat. (Notice that WFMI does not conflict asymmetrically with T about these cases; that is why this type of conflict is asymmetric.)

When WFMI does conflict asymmetrically with T, I say that T conflicts weakly with WFMI. Here, T says that something is strictly permissible, but WFMI either says that it’s obligatory or says that it’s impermissible. For instance, T might say that it’s strictly permissible to save your child over saving a stranger, or that it’s strictly permissible to defile a corpse. I call these weak conflicts with WFMI because T will never say that we are very wrong for acting on WFMI.

Finally, I consider minimal conflicts. These are any disagreements between T and WFMI about what things are good or bad, wrong or right, etc., or about why we should believe that they are so. There is only one type of disagreement that this excludes, called self-effacement. This is a specific disagreement about why things actually are good or bad, wrong or right, etc. Self-effacement arises when T says that you should reject T in favor of your moral intuitions. In this case, T specifically says that you should follow your moral intuitions. So, it seems like an abuse of the term ‘conflict’ to say that T conflicts with your moral intuitions. Because of this, we can’t say that T conflicts with WFMI if it T self-effaces in favor of WFMI.

I’ve defined strong, asymmetric, weak, and minimal conflicts between a normative ethical theory and WFMI. Earlier, I defined some moral intuitions as intense, and others as mild. I extend that definition to say that some conflict is more intense when it is against a more intensely felt WFMI, and more mild when it is against a more mildly felt WFMI. As I’m using the terms, the intensity and the strength of a conflict are different. For instance, T might say that it’s strictly permissible to save your child over a stranger. This was an earlier example of a weak conflict; however, it is a very intense one, since most people feel very intensely that saving your child over a stranger is not strictly permissible, but obligatory.

### Problems from conflict

Here is one version of an argument (ACCURACY) that it is a problem for a normative ethical theory if it conflicts with widely felt moral intuitions:

> (1) It is a problem for T if its extension is probably inaccurate.
> (2) T’s extension is probably inaccurate if T is in conflict with WFMI.
> (∗) So, it is a problem for T if it is in conflict with WFMI.

If I want to defend T, I could accept ACCURACY but argue that T is not in conflict with WFMI; this would mean that ACCURACY poses no problems for T in particular. I could also take a more general strategy by attacking (2): perhaps WFMI are merely results of evolutionary pressures, and thus unlikely to be a guide to the truth.[^6] If this sort of attack is successful, then ACCURACY fails to show (∗). This would mean that ACCURACY poses no problems for any normative ethical theory. However, this might not mean (∗) is false, since there might be other reasons to believe something like it. These other reasons might still pose problems for normative ethical theories. I will briefly argue for two.

One reason to believe something like (∗) is COMPLIANCE:

> (C1) It is a problem for T if we won’t comply with it.
> (C2a) We won’t comply with T if we have motivation against compliance.
> (C2b) We won’t comply with T if we lack motivation for compliance.
> (C3a) We have motivation against compliance if T conflicts strongly with WFMI.
> (C3b) We lack motivation for compliance if T conflicts asym-ly with WFMI.
> (C∗) So, it is a problem for T if it conflicts strongly or asymmetrically with WFMI.

We have (C1) from our discussion of problems for normative ethical theories, and (C2a) seems pretty clear if there are no overriding considerations. (C2b) is similar; note that here T calls something either obligatory or impermissible, and it seems difficult to always or never do something if there are no overriding considerations. By introducing such considerations, advocates of T can block these two premises and thereby defeat the COMPLIANCE problem. As I suggested in the first section, COMPLIANCE is defeasible.

For (C3a), recall that strong conflict with WFMI means that WFMI calls something impermissible or obligatory, i.e., very wrong to do or fail to do. I assume that this is motivating to the extent that we intensely share the WFMI. So, if the moral intuition is not very intense, or not very widely felt, then COMPLIANCE is less of a problem. COMPLIANCE is a problem which comes in degrees.

For (C3b), recall that asymmetric conflict with WFMI means that T calls something impermissible or obligatory, i.e., very wrong to do or fail to do. It seems unlikely that we will always do or fail to do something if we don’t have some reason for it. Since asymmetric conflict means that WFMI says this thing is strictly permissible, it doesn’t provide this reason. So, in the absence of some other consideration, this premise seems clear. Note that this means a COMPLIANCE problem arising from asymmetric conflict is much more defeasible than one arising from strong conflict. For instance, T may have a compliance problem because it is too demanding (e.g., in requiring us to donate our spare kidneys). This is easier to overcome than the compliance problem which arises if T requires us to do something we and most of society feels is very intensely immoral (e.g., killing someone for the greater good).

Another reason to believe something like (∗) is ACCEPTANCE:

> (A1) It is a problem for T if we will not accept what it says to accept.
> (A2) We won’t accept what T says to if it means rejecting our moral intuitions.
> (A3) Acceptance means rejecting our moral intuitions if T conflicts with WFMI.
> (A∗) So, it is a problem for T if it conflicts with WFMI.

Like (C1), we have (A1) from our discussion of problems for normative ethical theories. For (A2), I assume that we need some overriding consideration to reject our moral intuitions, especially if they are intensely felt. This makes ACCEPTANCE defeasible as well, since its advocates might be able to provide such considerations. For (A3), I assume that conflict means at least minimal conflict. Recall that this means that T disagrees with WFMI about, at the very least, what we should believe about why some things are good or bad, right or wrong, etc.; T and WFMI might also have other conflicts between their extensions. To accept T when it disagrees with WFMI just means to reject our moral intuitions, at least for all of those people who share them.

To wrap up, I consider a few edge cases and complications. The first occurs for COMPLIANCE if T or WFMI admit moral dilemmas. Firstly, notice that the main argument still works in this case. More interestingly, if T yields a moral dilemma, then we have an even quicker argument for COMPLIANCE it’s impossible to comply with T when it yields a moral dilemma, since we are both obligated to do something and obligated not to do it. So, no matter what, we fail to comply with T. So of course it has a compliance problem!

Another complication for COMPLIANCE is when T conflicts asymmetrically with WFMI by calling something obligatory (or impermissible) when WFMI calls it supererogatory (or suberogatory). That is, WFMI says that the act is strictly permissible, but better than an obligatory act or worse than an impermissible one. In this case, it seems like WFMI does provide some reason for doing or for avoiding the act. Firstly, an act seeming supererogatory (or suberogatory) may not be enough of a reason to always do (or always avoid doing) the act. Secondly, though, we can amend our conception of conflict to directly deal with reasons instead of the principle deontic categories. In particular, strong conflict obtains when T and WFMI give opposing reasons; asymmetric conflict obtains when T gives a reason while WFMI doesn’t; and weak conflict obtains when T gives no reason while WFMI does.

An edge case for ACCEPTANCE is self-effacing theories. Notice that the main argument works because it deals with accepting what T says to accept, rather than with accepting T itself. (Of course, for theories which aren’t self-effacing, these amount to the same thing.) Interestingly, though, this raises the idea that ACCEPTANCE is a particular type of COMPLIANCE; namely, complying with T’s prescription to accept something. This can be developed with the amended conception of conflict.

A final complication for ACCEPTANCE is the worry that it is too broad. In particular, the only theories which avoid ACCEPTANCE are those that don’t even minimally conflict with WFMI. But there’s good reason to think that WFMI are extensionally incorrect. For instance, the WFMI of the past may have included the permissibility of slavery, or the inferior moral worth of various groups of people. If the WFMI of so many eras are so flawed, it’s difficult to believe that our current WFMI are somehow flawless. But if our current WFMI are extensionally flawed, then so is any theory which self-effaces in favor of our current WFMI! Such a theory also seems incapable of revising our moral intuitions, which is something we might seek from a moral theory. These two problems seem worse than ACCEPTANCE; so, perhaps ACCEPTANCE is a good problem to have. However, recall again that ACCEPTANCE comes in degrees. While a little bit of this problem is the price for avoiding much worse problems, this problem can also become severe for moral theories that diverge very far from our current WFMI. So, ACCEPTANCE still represents a genuine problem.

References

* Parfit, Derek, and Samuel Scheffler. On What Matters. Volume Two. Oxford: Oxford University Press, 2011.
* Parfit, Derek. Reasons and Persons. Oxford: Clarendon Press, 1986.
* Rawls, John. A Theory of Justice. Revised edition. Cambridge, Massachusetts: The Belknap Press of Harvard University Press, 1999.
* Sandberg, Joakim, and Niklas Juth. “Ethics and Intuitions: A Reply to Singer.” The Journal of Ethics 15, no. 3 (2011): 209–226.
* Singer, Peter. “Ethics and Intuitions.” The Journal of Ethics 9, no. 3/4 (2005): 331–352.

[^1]: See Part Six of On What Matters for a defense of the idea that natural theories aren’t normative.
[^2]: Rawls, p. 41
[^3]: Attributed to Darwall in ‘The Unimportance of Internal Reasons’ in On What Matters.
[^4]: See ‘Normative Beliefs’ in On What Matters.
[^5]: See the last chapter of Kagan, which is dedicated to dealing with the compliance problem.
[^6]: This is a sort of evolutionary debunking argument. If an EDA isn’t selective enough to undercut only actual moral intuitions, it risks undermining morality (or even human reasoning) in general; this might mean that advocates of EDAs are companions in guilt. See Singer for an EDA which Sandberg & Juth argue isn’t selective enough.
